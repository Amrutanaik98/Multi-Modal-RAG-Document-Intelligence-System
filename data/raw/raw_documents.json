{
  "metadata": {
    "timestamp": "2025-12-16T17:27:43.830307",
    "total_documents": 33,
    "successful": 31
  },
  "documents": [
    {
      "title": "Machine learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Machine_learning",
      "content": "Machine learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\n2\nRelationships to other fields\nToggle Relationships to other fields subsection\n2.1\nArtificial intelligence\n2.2\nData compression\n2.3\nData mining\n2.4\nGeneralization\n2.5\nStatistics\n2.6\nStatistical physics\n3\nTheory\n4\nApproaches\nToggle Approaches subsection\n4.1\nSupervised learning\n4.2\nUnsupervised learning\n4.3\nSemi-supervised learning\n4.4\nReinforcement learning\n4.5\nDimensionality reduction\n4.6\nOther types\n4.6.1\nSelf-learning\n4.6.2\nFeature learning\n4.6.3\nSparse dictionary learning\n4.6.4\nAnomaly detection\n4.6.5\nRobot learning\n4.6.6\nAssociation rules\n5\nModels\nToggle Models subsection\n5.1\nArtificial neural networks\n5.2\nDecision trees\n5.3\nRandom forest regression\n5.4\nSupport-vector machines\n5.5\nRegression analysis\n5.6\nBayesian networks\n5.7\nGaussian processes\n5.8\nGenetic algorithms\n5.9\nBelief functions\n5.10\nRule-based models\n5.11\nTraining models\n5.11.1\nFederated learning\n6\nApplications\n7\nLimitations\nToggle Limitations subsection\n7.1\nExplainability\n7.2\nOverfitting\n7.3\nOther limitations and vulnerabilities\n8\nModel assessments\n9\nEthics\nToggle Ethics subsection\n9.1\nBias\n9.2\nFinancial incentives\n10\nHardware\nToggle Hardware subsection\n10.1\nTensor Processing Units (TPUs)\n10.2\nNeuromorphic computing\n10.2.1\nPhysical neural networks\n10.3\nEmbedded machine learning\n11\nSoftware\nToggle Software subsection\n11.1\nFree and open-source software\n11.2\nProprietary software with free and open-source editions\n11.3\nProprietary software\n12\nJournals\n13\nConferences\n14\nSee also\n15\nReferences\n16\nSources\n17\nFurther reading\n18\nExternal links\nToggle the table of contents\nMachine learning\n88 languages\nAfrikaans\nالعربية\nঅসমীয়া\nAzərbaycanca\nتۆرکجه\nবাংলা\n閩南語 / Bân-lâm-gí\nБашҡортса\nБеларуская\nभोजपुरी\nБългарски\nབོད་ཡིག\nBosanski\nCatalà\nČeština\nCymraeg\nDansk\nالدارجة\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaelg\nGalego\n한국어\nՀայերեն\nहिन्दी\nIdo\nBahasa Indonesia\nIsiZulu\nÍslenska\nItaliano\nעברית\nJawa\nಕನ್ನಡ\nქართული\nКыргызча\nLatviešu\nLietuvių\nLigure\nMagyar\nМакедонски\nമലയാളം\nमराठी\nBahasa Melayu\nМонгол\nNederlands\n日本語\nNorsk bokmål\nNorsk nynorsk\nOccitan\nଓଡ଼ିଆ\nOʻzbekcha / ўзбекча\nਪੰਜਾਬੀ\nپنجابی\nپښتو\nPolski\nPortuguês\nQaraqalpaqsha\nRomână\nRuna Simi\nРусский\nᱥᱟᱱᱛᱟᱲᱤ\nShqip\nSimple English\nSlovenščina\nکوردی\nСрпски / srpski\nSrpskohrvatski / српскохрватски\nSuomi\nSvenska\nTagalog\nதமிழ்\nతెలుగు\nไทย\nTürkçe\nУкраїнська\nاردو\nئۇيغۇرچە / Uyghurche\nTiếng Việt\nVõro\n吴语\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikiquote\nWikiversity\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nStudy of algorithms that improve automatically through experience\nFor the journal, see\nMachine Learning (journal)\n.\n\"Statistical learning\" redirects here. For statistical learning in linguistics, see\nStatistical learning in language acquisition\n.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nPart of\na series\non\nArtificial intelligence (AI)\nMajor goals\nArtificial general intelligence\nIntelligent agent\nRecursive self-improvement\nPlanning\nComputer vision\nGeneral game playing\nKnowledge representation\nNatural language processing\nRobotics\nAI safety\nApproaches\nMachine learning\nSymbolic\nDeep learning\nBayesian networks\nEvolutionary algorithms\nHybrid intelligent systems\nSystems integration\nOpen-source\nApplications\nBioinformatics\nDeepfake\nEarth sciences\nFinance\nGenerative AI\nArt\nAudio\nMusic\nGovernment\nHealthcare\nMental health\nIndustry\nSoftware development\nTranslation\nMilitary\nPhysics\nProjects\nPhilosophy\nAI alignment\nArtificial consciousness\nThe bitter lesson\nChinese room\nFriendly AI\nEthics\nExistential risk\nTuring test\nUncanny valley\nHuman–AI interaction\nHistory\nTimeline\nProgress\nAI winter\nAI boom\nAI bubble\nControversies\nDeepfake pornography\nTaylor Swift deepfake pornography controversy\nGoogle Gemini image generation controversy\nPause Giant AI Experiments\nRemoval of Sam Altman from OpenAI\nStatement on AI Risk\nTay (chatbot)\nThéâtre D'opéra Spatial\nVoiceverse NFT plagiarism scandal\nGlossary\nGlossary\nv\nt\ne\nMachine learning\n(\nML\n) is a\nfield of study\nin\nartificial intelligence\nconcerned with the development and study of\nstatistical algorithms\nthat can learn from\ndata\nand\ngeneralise\nto unseen data, and thus perform\ntasks\nwithout explicit\ninstructions\n.\n[\n1\n]\nWithin a subdiscipline in machine learning, advances in the field of\ndeep learning\nhave allowed\nneural networks\n, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\nML finds application in many fields, including\nnatural language processing\n,\ncomputer vision\n,\nspeech recognition\n,\nemail filtering\n,\nagriculture\n, and\nmedicine\n. The application of ML to business problems is known as\npredictive analytics\n.\nStatistics\nand\nmathematical optimisation\n(mathematical programming) methods comprise the foundations of machine learning.\nData mining\nis a related field of study, focusing on\nexploratory data analysis\n(EDA) via\nunsupervised learning\n.\n[\n3\n]\n[\n4\n]\nFrom a theoretical viewpoint,\nprobably approximately correct learning\nprovides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as\nempirical risk minimisation\nunder this framework.\nHistory\n[\nedit\n]\nSee also:\nTimeline of machine learning\nThe term\nmachine learning\nwas coined in 1959 by\nArthur Samuel\n, an\nIBM\nemployee and pioneer in the field of\ncomputer gaming\nand\nartificial intelligence\n.\n[\n5\n]\n[\n6\n]\nThe synonym\nself-teaching computers\nwas also used in this time period.\n[\n7\n]\n[\n8\n]\nThe earliest machine learning program was introduced in the 1950s when\nArthur Samuel\ninvented a\ncomputer program\nthat calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.\n[\n9\n]\nIn 1949,\nCanadian\npsychologist\nDonald Hebb\npublished the book\nThe Organization of Behavior\n, in which he introduced a\ntheoretical neural structure\nformed by certain interactions among\nnerve cells\n.\n[\n10\n]\nHebb's model\nof\nneurons\ninteracting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or\nartificial neurons\nused by computers to communicate data.\n[\n9\n]\nOther researchers who have studied human\ncognitive systems\ncontributed to the modern machine learning technologies as well, including logician\nWalter Pitts\nand\nWarren McCulloch\n, who proposed the early mathematical models of neural networks to come up with\nalgorithms\nthat mirror human thought processes.\n[\n9\n]\nBy the early 1960s, an experimental \"learning machine\" with\npunched tape\nmemory, called Cybertron, had been developed by\nRaytheon Company\nto analyse\nsonar\nsignals,\nelectrocardiograms\n, and speech patterns using rudimentary\nreinforcement learning\n. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"\ngoof\n\" button to cause it to reevaluate incorrect decisions.\n[\n11\n]\nA representative book on research into machine learning during the 1960s was\nNils Nilsson\n's book on Learning Machines, dealing mostly with machine learning for pattern classification.\n[\n12\n]\nInterest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.\n[\n13\n]\nIn 1981, a report was given on using teaching strategies so that an\nartificial neural network\nlearns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.\n[\n14\n]\nTom M. Mitchell\nprovided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience\nE\nwith respect to some class of tasks\nT\nand performance measure\nP\nif its performance at tasks in\nT\n, as measured by\nP\n,  improves with experience\nE\n.\"\n[\n15\n]\nThis definition of the tasks in which machine learning is concerned offers a fundamentally\noperational definition\nrather than defining the field in cognitive terms. This follows\nAlan Turing\n's proposal in his paper \"\nComputing Machinery and Intelligence\n\", in which the question, \"Can machines think?\", is replaced with the question, \"Can machines do what we (as thinking entities) can do?\".\n[\n16\n]\nModern-day Machine Learning algorithms are broken into 3 algorithm types: Supervised Learning Algorithms, Unsupervised Learning Algorithms, and Reinforcement Learning Algorithms.\n[\n17\n]\nCurrent Supervised Learning Algorithms have objectives of classification and regression.\nCurrent Unsupervised Learning Algorithms have objectives of clustering, dimensionality reduction, and association rule.\nCurrent Reinforcement Learning Algorithms focus on decisions that must be made with respect to some previous, unknown time and are broken down to either be studies of model-based methods or model-free methods.\nIn 2014 Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis.\n[\n18\n]\nBy 2016 AlphaGo obtained victory against top human players using reinforcement learning techniques.\n[\n19\n]\nRelationships to other fields\n[\nedit\n]\nArtificial intelligence\n[\nedit\n]\nDeep learning\nis a subset of machine learning, which is itself a subset of\nartificial intelligence\n.\n[\n20\n]\nAs a scientific endeavour, machine learning grew out of the quest for\nartificial intelligence\n(AI). In the early days of AI as an\nacademic discipline\n, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"\nneural networks\n\"; these were mostly\nperceptrons\nand\nother models\nthat were later found to be reinventions of the\ngeneralised linear models\nof statistics.\n[\n21\n]\nProbabilistic reasoning\nwas also employed, especially in\nautomated medical diagnosis\n.\n[\n22\n]\n: 488\nHowever, an increasing emphasis on the\nlogical, knowledge-based approach\ncaused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.\n[\n22\n]\n: 488\nBy 1980,\nexpert systems\nhad come to dominate AI, and statistics was out of favour.\n[\n23\n]\nWork on symbolic/knowledge-based learning did continue within AI, leading to\ninductive logic programming\n(ILP), but the more statistical line of research was now outside the field of AI proper, in\npattern recognition\nand\ninformation retrieval\n.\n[\n22\n]\n: 708–710, 755\nNeural networks research had been abandoned by AI and\ncomputer science\naround the same time. This line, too, was continued outside the AI/CS field, as \"\nconnectionism\n\", by researchers from other disciplines, including\nJohn Hopfield\n,\nDavid Rumelhart\n, and\nGeoffrey Hinton\n. Their main success came in the mid-1980s with the reinvention of\nbackpropagation\n.\n[\n22\n]\n: 25\nMachine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the\nsymbolic approaches\nit had inherited from AI, and toward methods and models borrowed from statistics,\nfuzzy logic\n, and\nprobability theory\n.\n[\n23\n]\nData compression\n[\nedit\n]\nThis section is an excerpt from\nData compression § Machine learning\n.\n[\nedit\n]\nThere is a close connection between machine learning and compression. A system that predicts the\nposterior probabilities\nof a sequence given its entire history can be used for optimal data compression (by using\narithmetic coding\non the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".\n[\n24\n]\n[\n25\n]\n[\n26\n]\nAn alternative view can show compression algorithms implicitly map strings into implicit\nfeature space vectors\n, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.\n[\n27\n]\nAccording to\nAIXI\ntheory, a connection more directly explained in\nHutter Prize\n, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.\nExamples of AI-powered audio/video compression software include\nNVIDIA Maxine\n, AIVC.\n[\n28\n]\nExamples of software that can perform AI-powered image compression include\nOpenCV\n,\nTensorFlow\n,\nMATLAB\n's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.\n[\n29\n]\nIn\nunsupervised machine learning\n,\nk-means clustering\ncan be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as\nimage compression\n.\n[\n30\n]\nData compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the\ncentroid\nof its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in\nimage\nand\nsignal processing\n, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.\n[\n31\n]\nLarge language models\n(LLMs) are also efficient lossless data compressors on some data sets, as demonstrated by\nDeepMind\n's research with the Chinchilla 70B model. Developed by DeepMind, Chinchilla 70B effectively compressed data, outperforming conventional methods such as\nPortable Network Graphics\n(PNG) for images and\nFree Lossless Audio Codec\n(FLAC) for audio. It achieved compression of image and audio data to 43.4% and 16.4% of their original sizes, respectively. There is, however, some reason to be concerned that the data set used for testing overlaps the LLM training data set, making it possible that the Chinchilla 70B model is only an efficient compression tool on data it has already been trained on.\n[\n32\n]\n[\n33\n]\nData mining\n[\nedit\n]\nMachine learning and\ndata mining\noften employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on\nknown\nproperties learned from the training data, data mining focuses on the\ndiscovery\nof (previously)\nunknown\nproperties in the data (this is the analysis step of\nknowledge discovery\nin databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"\nunsupervised learning\n\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals,\nECML PKDD\nbeing a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to\nreproduce known\nknowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously\nunknown\nknowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\n[\ncitation needed\n]\nMachine learning also has intimate ties to\noptimisation\n: Many learning problems are formulated as minimisation of some\nloss function\non a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a\nlabel\nto instances, and models are trained to correctly predict the preassigned labels of a set of examples).\n[\n34\n]\nGeneralization\n[\nedit\n]\nCharacterizing the generalisation of various learning algorithms is an active topic of current research, especially for\ndeep learning\nalgorithms.\nStatistics\n[\nedit\n]\nMachine learning and\nstatistics\nare closely related fields in terms of methods, but distinct in their principal goal: statistics draws population\ninferences\nfrom a\nsample\n, while machine learning finds generalisable predictive patterns.\n[\n35\n]\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.\n[\n36\n]\nLeo Breiman\ndistinguished two statistical modelling paradigms: data model and algorithmic model,\n[\n37\n]\nwherein \"algorithmic model\" means more or less the machine learning algorithms like\nRandom Forest\n.\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call\nstatistical learning\n.\n[\n38\n]\nStatistical physics\n[\nedit\n]\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of\ndeep neural networks\n.\n[\n39\n]\nStatistical physics is thus finding applications in the area of\nmedical diagnostics\n.\n[\n40\n]\nTheory\n[\nedit\n]\nMain articles:\nComputational learning theory\nand\nStatistical learning theory\nA core objective of a learner is to generalise from its experience.\n[\n2\n]\n[\n41\n]\nGeneralization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\nThe computational analysis of machine learning algorithms and their performance is a branch of\ntheoretical computer science\nknown as\ncomputational learning theory\nvia the\nprobably approximately correct learning\nmodel. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The\nbias–variance decomposition\nis one way to quantify generalisation\nerror\n.\nFor the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to\noverfitting\nand generalisation will be poorer.\n[\n42\n]\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in\npolynomial time\n. There are two kinds of\ntime complexity\nresults: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\nApproaches\n[\nedit\n]\nIn\nsupervised learning\n, the training data is labelled with the expected answers, while in\nunsupervised learning\n, the model identifies patterns or structures in unlabelled data.\nMachine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\nSupervised learning\n: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that\nmaps\ninputs to outputs.\nUnsupervised learning\n: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (\nfeature learning\n).\nReinforcement learning\n: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as\ndriving a vehicle\nor playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximise.\n[\n2\n]\nAlthough each algorithm has advantages and limitations, no single algorithm works for all problems.\n[\n43\n]\n[\n44\n]\n[\n45\n]\nSupervised learning\n[\nedit\n]\nMain article:\nSupervised learning\nA\nsupport-vector machine\nis a supervised learning model that divides the data into regions separated by a\nlinear boundary\n. Here, the linear boundary divides the black circles from the white.\nSupervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.\n[\n46\n]\nThe data, known as\ntraining data\n, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an\narray\nor vector, sometimes called a\nfeature vector\n, and the training data is represented by a\nmatrix\n. Through\niterative optimisation\nof an\nobjective function\n, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.\n[\n47\n]\nAn optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.\n[\n15\n]\nTypes of supervised-learning algorithms include\nactive learning\n,\nclassification\nand\nregression\n.\n[\n48\n]\nClassification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email. In contrast, regression is used for tasks such as predicting a person's height based on factors like age and genetics or forecasting future temperatures based on historical data.\n[\n49\n]\nSimilarity learning\nis an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in\nranking\n,\nrecommendation systems\n, visual identity tracking, face verification, and speaker verification.\nUnsupervised learning\n[\nedit\n]\nMain article:\nUnsupervised learning\nSee also:\nCluster analysis\nUnsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering,\ndimensionality reduction\n,\n[\n4\n]\nand\ndensity estimation\n.\n[\n50\n]\nCluster analysis is the assignment of a set of observations into subsets (called\nclusters\n) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some\nsimilarity metric\nand evaluated, for example, by\ninternal compactness\n, or the similarity between members of the same cluster, and\nseparation\n, the difference between clusters. Other methods are based on\nestimated density\nand\ngraph connectivity\n.\nA special type of unsupervised learning called,\nself-supervised learning\ninvolves training a model by generating the supervisory signal from the data itself.\n[\n51\n]\n[\n52\n]\nSemi-supervised learning\n[\nedit\n]\nMain article:\nSemi-supervised learning\nSemi-supervised learning falls between\nunsupervised learning\n(without any labelled training data) and\nsupervised learning\n(with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy.\nIn\nweakly supervised learning\n, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.\n[\n53\n]\nReinforcement learning\n[\nedit\n]\nMain article:\nReinforcement learning\nIn reinforcement learning, an agent takes actions in an environment: these produce a reward and/or a representation of the state, which is fed back to the agent.\nReinforcement learning is an area of machine learning concerned with how\nsoftware agents\nought to take\nactions\nin an environment to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as\ngame theory\n,\ncontrol theory\n,\noperations research\n,\ninformation theory\n,\nsimulation-based optimisation\n,\nmulti-agent systems\n,\nswarm intelligence\n,\nstatistics\nand\ngenetic algorithms\n. In reinforcement learning, the environment is typically represented as a\nMarkov decision process\n(MDP). Many reinforcement learning algorithms use\ndynamic programming\ntechniques.\n[\n54\n]\nReinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\nDimensionality reduction\n[\nedit\n]\nDimensionality reduction\nis a process of reducing the number of random variables under consideration by obtaining a set of principal variables.\n[\n55\n]\nIn other words, it is a process of reducing the dimension of the\nfeature\nset, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or\nextraction\n. One of the popular methods of dimensionality reduction is\nprincipal component analysis\n(PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\nThe\nmanifold hypothesis\nproposes that high-dimensional data sets lie along low-dimensional\nmanifolds\n, and many dimensionality reduction techniques make this assumption, leading to the areas of\nmanifold learning\nand\nmanifold regularisation\n.\nOther types\n[\nedit\n]\nOther approaches have been developed which do not fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example,\ntopic modelling\n,\nmeta-learning\n.\n[\n56\n]\nSelf-learning\n[\nedit\n]\nSelf-learning, as a machine learning paradigm, was introduced in 1982 along with a neural network capable of self-learning, named\ncrossbar adaptive array\n(CAA).\n[\n57\n]\n[\n58\n]\nIt gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward. Emotion is used as a state evaluation of a self-learning agent. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.\n[\n59\n]\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine:\nin situation\ns\nact\na\nreceive a consequence situation\ns\n'\ncompute emotion of being in the consequence situation\nv(s')\nupdate crossbar memory\nw'(a,s) = w(a,s) + v(s')\nIt is a system with only one input, situation, and only one output, action (or behaviour) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioural environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behaviour in an environment that contains both desirable and undesirable situations.\n[\n60\n]\nFeature learning\n[\nedit\n]\nMain article:\nFeature learning\nSeveral learning algorithms aim at discovering better representations of the inputs provided during training.\n[\n61\n]\nClassic examples include\nprincipal component analysis\nand cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual\nfeature engineering\n, and allows a machine to both learn the features and use them to perform a specific task.\nFeature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labelled input data. Examples include\nartificial neural networks\n,\nmultilayer perceptrons\n, and supervised\ndictionary learning\n. In unsupervised feature learning, features are learned with unlabelled input data.  Examples include dictionary learning,\nindependent component analysis\n,\nautoencoders\n,\nmatrix factorisation\n[\n62\n]\nand various forms of\nclustering\n.\n[\n63\n]\n[\n64\n]\n[\n65\n]\nManifold learning\nalgorithms attempt to do so under the constraint that the learned representation is low-dimensional.\nSparse coding\nalgorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros.\nMultilinear subspace learning\nalgorithms aim to learn low-dimensional representations directly from\ntensor\nrepresentations for multidimensional data, without reshaping them into higher-dimensional vectors.\n[\n66\n]\nDeep learning\nalgorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine learns a representation that disentangles the underlying factors of variation that explain the observed data.\n[\n67\n]\nFeature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data have not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\nSparse dictionary learning\n[\nedit\n]\nMain article:\nSparse dictionary learning\nSparse dictionary learning is a feature learning method where a training example is represented as a linear combination of\nbasis functions\nand assumed to be a\nsparse matrix\n. The method is\nstrongly NP-hard\nand difficult to solve approximately.\n[\n68\n]\nA popular\nheuristic\nmethod for sparse dictionary learning is the\nk\n-SVD\nalgorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in\nimage denoising\n. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.\n[\n69\n]\nAnomaly detection\n[\nedit\n]\nMain article:\nAnomaly detection\nIn\ndata mining\n, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations that raise suspicions by differing significantly from the majority of the data.\n[\n70\n]\nTypically, the anomalous items represent an issue such as\nbank fraud\n, a structural defect, medical problems or errors in a text. Anomalies are referred to as\noutliers\n, novelties, noise, deviations and exceptions.\n[\n71\n]\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.\n[\n72\n]\nThree broad categories of anomaly detection techniques exist.\n[\n73\n]\nUnsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance being generated by the model.\nRobot learning\n[\nedit\n]\nRobot learning\nis inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,\n[\n74\n]\n[\n75\n]\nand finally\nmeta-learning\n(e.g. MAML).\nAssociation rules\n[\nedit\n]\nMain article:\nAssociation rule learning\nSee also:\nInductive logic programming\nAssociation rule learning is a\nrule-based machine learning\nmethod for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".\n[\n76\n]\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.\n[\n77\n]\nRule-based machine learning approaches include\nlearning classifier systems\n, association rule learning, and\nartificial immune systems\n.\nBased on the concept of strong rules,\nRakesh Agrawal\n,\nTomasz Imieliński\nand Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by\npoint-of-sale\n(POS) systems in supermarkets.\n[\n78\n]\nFor example, the rule\n{\no\nn\ni\no\nn\ns\n,\np\no\nt\na\nt\no\ne\ns\n}\n⇒\n{\nb\nu\nr\ng\ne\nr\n}\n{\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\nfound in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional\npricing\nor\nproduct placements\n. In addition to\nmarket basket analysis\n, association rules are employed today in application areas including\nWeb usage mining\n,\nintrusion detection\n,\ncontinuous production\n, and\nbioinformatics\n. In contrast with\nsequence mining\n, association rule learning typically does not consider the order of items either within a transaction or across transactions.\nLearning classifier systems\n(LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a\ngenetic algorithm\n, with a learning component, performing either\nsupervised learning\n,\nreinforcement learning\n, or\nunsupervised learning\n. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a\npiecewise\nmanner to make predictions.\n[\n79\n]\nInductive logic programming\n(ILP) is an approach to rule learning using\nlogic programming\nas a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that\nentails\nall positive and no negative examples.\nInductive programming\nis a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as\nfunctional programs\n.\nInductive logic programming is particularly useful in\nbioinformatics\nand\nnatural language processing\n.\nGordon Plotkin\nand\nEhud Shapiro\nlaid the initial theoretical foundation for inductive machine learning in a logical setting.\n[\n80\n]\n[\n81\n]\n[\n82\n]\nShapiro built their first implementation (Model Inference System) in 1981: a\nProlog\nprogram that inductively inferred logic programs from positive and negative examples.\n[\n83\n]\nThe term\ninductive\nhere refers to\nphilosophical\ninduction, suggesting a theory to explain observed facts, rather than\nmathematical induction\n, proving a property for all members of a well-ordered set.\nModels\n[\nedit\n]\nA\nmachine learning model\nis a type of\nmathematical model\nthat, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions.\n[\n84\n]\nBy extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.\n[\n85\n]\nVarious types of models have been used and researched for machine learning systems, picking the best model for a task is called\nmodel selection\n.\nArtificial neural networks\n[\nedit\n]\nMain article:\nArtificial neural network\nSee also:\nDeep learning\nAn artificial neural network is an interconnected group of nodes, akin to the vast network of\nneurons\nin a\nbrain\n. Here, each circular node represents an\nartificial neuron\nand an arrow represents a connection from the output of one artificial neuron to the input of another.\nArtificial neural networks (ANNs), or\nconnectionist\nsystems, are computing systems vaguely inspired by the\nbiological neural networks\nthat constitute animal\nbrains\n. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"\nartificial neurons\n\", which loosely model the\nneurons\nin a biological brain. Each connection, like the\nsynapses\nin a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a\nreal number\n, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a\nweight\nthat adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a\nhuman brain\nwould. However, over time, attention moved to performing specific tasks, leading to deviations from\nbiology\n. Artificial neural networks have been used on a variety of tasks, including\ncomputer vision\n,\nspeech recognition\n,\nmachine translation\n,\nsocial network\nfiltering,\nplaying board and video games\nand\nmedical diagnosis\n.\nDeep learning\nconsists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.\n[\n86\n]\nDecision trees\n[\nedit\n]\nMain article:\nDecision tree learning\nA decision tree showing survival probability of passengers on the\nTitanic\nDecision tree learning uses a\ndecision tree\nas a\npredictive model\nto go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures,\nleaves\nrepresent class labels, and branches represent\nconjunctions\nof features that lead to those class labels. Decision trees where the target variable can take continuous values (typically\nreal numbers\n) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and\ndecision making\n. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\nRandom forest regression\n[\nedit\n]\nRandom forest regression\n(RFR) falls under the umbrella of decision\ntree-based models\n. RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting. To build decision trees, RFR uses bootstrapped sampling; for instance, each decision tree is trained on random data from the training set. This random selection of RFR for training enables the model to reduce biased predictions and achieve a higher degree of accuracy. RFR generates independent decision trees, and it can work on single-output data as well as multiple regressor tasks. This makes RFR compatible to be use in various applications.\n[\n87\n]\n[\n88\n]\nSupport-vector machines\n[\nedit\n]\nMain article:\nSupport-vector machine\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related\nsupervised learning\nmethods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.\n[\n89\n]\nAn SVM training algorithm is a non-\nprobabilistic\n,\nbinary\n,\nlinear classifier\n, although methods such as\nPlatt scaling\nexist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the\nkernel trick\n, implicitly mapping their inputs into high-dimensional feature spaces.\nRegression analysis\n[\nedit\n]\nMain article:\nRegression analysis\nIllustration of linear regression on a data set\nRegression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is\nlinear regression\n, where a single line is drawn to best fit the given data according to a mathematical criterion such as\nordinary least squares\n. The latter is often extended by\nregularisation\nmethods to mitigate overfitting and bias, as in\nridge regression\n. When dealing with non-linear problems, go-to models include\npolynomial regression\n(for example, used for trendline fitting in Microsoft Excel\n[\n90\n]\n),\nlogistic regression\n(often used in\nstatistical classification\n) or even\nkernel regression\n, which introduces non-linearity by taking advantage of the\nkernel trick\nto implicitly map input variables to higher-dimensional space.\nMultivariate linear regression\nextends the concept of linear regression to handle multiple dependent variables simultaneously. This approach estimates the relationships between a set of input variables and several output variables by fitting a\nmultidimensional\nlinear model. It is particularly useful in scenarios where outputs are interdependent or share underlying patterns, such as predicting multiple economic indicators or reconstructing images,\n[\n91\n]\nwhich are inherently multi-dimensional.\nBayesian networks\n[\nedit\n]\nMain article:\nBayesian network\nA simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet.\nA Bayesian network, belief network, or directed acyclic graphical model is a probabilistic\ngraphical model\nthat represents a set of\nrandom variables\nand their\nconditional independence\nwith a\ndirected acyclic graph\n(DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform\ninference\nand learning. Bayesian networks that model sequences of variables, like\nspeech signals\nor\nprotein sequences\n, are called\ndynamic Bayesian networks\n. Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called\ninfluence diagrams\n.\nGaussian processes\n[\nedit\n]\nMain article:\nGaussian processes\nAn example of Gaussian Process Regression (prediction) compared with other regression models\n[\n92\n]\nA Gaussian process is a\nstochastic process\nin which every finite collection of the random variables in the process has a\nmultivariate normal distribution\n, and it relies on a pre-defined\ncovariance function\n, or kernel, that models how pairs of points relate to each other depending on their locations.\nGiven a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as a function of its input data can be directly computed by looking at the observed points and the covariances between those points and the new, unobserved point.\nGaussian processes are popular surrogate models in\nBayesian optimisation\nused to do\nhyperparameter optimisation\n.\nGenetic algorithms\n[\nedit\n]\nMain article:\nGenetic algorithm\nA genetic algorithm (GA) is a\nsearch algorithm\nand\nheuristic\ntechnique that mimics the process of\nnatural selection\n, using methods such as\nmutation\nand\ncrossover\nto generate new\ngenotypes\nin the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.\n[\n93\n]\n[\n94\n]\nConversely, machine learning techniques have been used to improve the performance of genetic and\nevolutionary algorithms\n.\n[\n95\n]\nBelief functions\n[\nedit\n]\nMain article:\nDempster–Shafer theory\nThe theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as\nprobability\n,\npossibility\nand\nimprecise probability theories\n. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster's rule of combination), just like how in a\npmf\n-based Bayesian approach would combine probabilities.\n[\n96\n]\nHowever, there are many caveats to these beliefs functions when compared to Bayesian approaches to incorporate ignorance and\nuncertainty quantification\n. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various\nensemble methods\nto better handle the learner's\ndecision boundary\n, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.\n[\n97\n]\n[\n6\n]\nHowever, the computational complexity of these algorithms is dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.\nRule-based models\n[\nedit\n]\nMain article:\nRule-based machine learning\nRule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns 'rules' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes\nlearning classifier systems\n,\n[\n98\n]\nassociation rule learning\n,\n[\n99\n]\nartificial immune systems\n,\n[\n100\n]\nand other similar models. These methods extract patterns from data and evolve rules over time.\nTraining models\n[\nedit\n]\nTypically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative\nsample\nof data. Data from the training set can be as varied as a\ncorpus of text\n, a collection of images,\nsensor\ndata, and data collected from individual users of a service.\nOverfitting\nis something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives.\nAlgorithmic bias\nis a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and, notably, becoming integrated within machine learning engineering teams.\nFederated learning\n[\nedit\n]\nMain article:\nFederated learning\nFederated learning is an adapted form of\ndistributed artificial intelligence\nto train machine learning models that decentralises the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example,\nGboard\nuses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to\nGoogle\n.\n[\n101\n]\nApplications\n[\nedit\n]\nThere are many applications for machine learning, including:\nAgriculture\nAnatomy\nAdaptive website\nAffective computing\nAstronomy\nAutomated decision-making\nBanking\nBehaviorism\nBioinformatics\nBrain–machine interfaces\nCheminformatics\nCitizen Science\nClimate Science\nComputer networks\nComputer vision\nCredit-card fraud\ndetection\nData quality\nDNA sequence\nclassification\nEconomics\nFinancial data analysis\n[\n102\n]\nGeneral game playing\nHandwriting recognition\nHealthcare\nInformation retrieval\nInsurance\nInternet fraud\ndetection\nInvestment management\n[\n103\n]\nKnowledge graph embedding\nLinguistics\nMachine learning control\nMachine perception\nMachine translation\nMaterial Engineering\nMarketing\nMedical diagnosis\nNatural language processing\nNatural language understanding\nOnline advertising\nOptimisation\nRecommender systems\nRobot locomotion\nSearch engines\nSentiment analysis\nSequence mining\nSoftware engineering\nSpeech recognition\nStructural health monitoring\nSyntactic pattern recognition\nTelecommunications\nTheorem proving\nTime-series forecasting\nTomographic reconstruction\n[\n104\n]\nUser behaviour analytics\nIn 2006, the media-services provider\nNetflix\nheld the first \"\nNetflix Prize\n\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from\nAT&T Labs\n-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an\nensemble model\nto win the Grand Prize in 2009 for $1 million.\n[\n105\n]\nShortly after the prize was awarded, Netflix realised that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.\n[\n106\n]\nIn 2010, an article in\nThe Wall Street Journal\nnoted the use of machine learning by Rebellion Research to predict the\n2008 financial crisis\n.\n[\n107\n]\nIn 2012, co-founder of\nSun Microsystems\n,\nVinod Khosla\n, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.\n[\n108\n]\nIn 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists.\n[\n109\n]\nIn 2019\nSpringer Nature\npublished the first research book created using machine learning.\n[\n110\n]\nIn 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.\n[\n111\n]\nMachine learning was recently applied to predict the pro-environmental behaviour of travellers.\n[\n112\n]\nRecently, machine learning technology was also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.\n[\n113\n]\n[\n114\n]\n[\n115\n]\nWhen applied correctly, machine learning algorithms (MLAs) can utilise a wide range of company characteristics to predict stock returns without\noverfitting\n. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like\nOLS\n.\n[\n116\n]\nRecent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.\n[\n117\n]\nMachine Learning is becoming a useful tool to investigate and predict evacuation decision-making in large-scale and small-scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.\n[\n118\n]\n[\n119\n]\n[\n120\n]\nOther applications have been focusing on pre evacuation decisions in building fires.\n[\n121\n]\n[\n122\n]\nLimitations\n[\nedit\n]\nAlthough machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.\n[\n123\n]\n[\n124\n]\n[\n125\n]\nReasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.\n[\n126\n]\nThe \"\nblack box theory\n\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted from the data.\n[\n127\n]\nThe House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual's life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.\n[\n127\n]\nIn 2018, a self-driving car from\nUber\nfailed to detect a pedestrian, who was killed after a collision.\n[\n128\n]\nAttempts to use machine learning in healthcare with the\nIBM Watson\nsystem failed to deliver even after years of time and billions of dollars invested.\n[\n129\n]\n[\n130\n]\nMicrosoft's\nBing Chat\nchatbot has been reported to produce hostile and offensive response against its users.\n[\n131\n]\nMachine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research itself.\n[\n132\n]\nExplainability\n[\nedit\n]\nMain article:\nExplainable artificial intelligence\nExplainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.\n[\n133\n]\nIt contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.\n[\n134\n]\nBy refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\nOverfitting\n[\nedit\n]\nMain article:\nOverfitting\nThe blue line could be an example of overfitting a linear function due to random noise.\nSettling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is.\n[\n135\n]\nOther limitations and vulnerabilities\n[\nedit\n]\nLearners can also be disappointed by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.\n[\n136\n]\nA real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.\n[\n137\n]\n[\n138\n]\nAdversarial vulnerabilities can also result in nonlinear systems or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.\n[\n139\n]\nMachine learning models are often vulnerable to manipulation or evasion via\nadversarial machine learning\n.\n[\n140\n]\nResearchers have demonstrated how\nbackdoors\ncan be placed undetectably into classifying (e.g., for categories \"spam\" and \"not spam\" of posts) machine learning models that are often developed or trained by third parties. Parties can change the classification of any input, including in cases for which a type of\ndata/software transparency\nis provided, possibly including\nwhite-box access\n.\n[\n141\n]\n[\n142\n]\n[\n143\n]\nModel assessments\n[\nedit\n]\nClassification of machine learning models can be validated by accuracy estimation techniques like the\nholdout\nmethod, which splits the data into a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-\ncross-validation\nmethod randomly partitions the data into K subsets and then K experiments are performed each considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods,\nbootstrap\n, which samples n instances with replacement from the dataset, can be used to assess model accuracy.\n[\n144\n]\nIn addition to overall accuracy, investigators frequently report\nsensitivity and specificity\n, meaning true positive rate (TPR) and true negative rate (TNR), respectively. Similarly, investigators sometimes report the\nfalse positive rate\n(FPR) as well as the\nfalse negative rate\n(FNR). However, these rates are ratios that fail to reveal their numerators and denominators.\nReceiver operating characteristic\n(ROC), along with the accompanying Area Under the ROC Curve (AUC), offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.\n[\n145\n]\nEthics\n[\nedit\n]\nThis section is an excerpt from\nEthics of artificial intelligence\n.\n[\nedit\n]\nThe\nethics\nof\nartificial intelligence\ncovers a broad range of topics within AI that are considered to have particular ethical stakes.\n[\n146\n]\nThis includes\nalgorithmic biases\n,\nfairness\n,\naccountability\n, transparency, privacy, and\nregulation\n, particularly where systems influence or automate human decision-making.\n[\n147\n]\nIt also covers various emerging or potential future challenges such as\nmachine ethics\n(how to make machines that behave ethically),\nlethal autonomous weapon systems\n,\narms race\ndynamics,\nAI safety\nand\nalignment\n,\ntechnological unemployment\n, AI-enabled\nmisinformation\n,\n[\n148\n]\nhow to treat certain AI systems if they have a\nmoral status\n(AI welfare and rights),\nartificial superintelligence\nand\nexistential risks\n.\n[\n146\n]\nSome application areas may also have particularly important ethical implications, like\nhealthcare\n, education, criminal justice, or the military.\nBias\n[\nedit\n]\nMain article:\nAlgorithmic bias\nDifferent machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.\n[\n149\n]\nSystems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.\n[\n150\n]\nFor example, in 1988, the UK's\nCommission for Racial Equality\nfound that\nSt. George's Medical School\nhad been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to either be women or have non-European-sounding names.\n[\n149\n]\nUsing job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.\n[\n151\n]\n[\n152\n]\nAnother example includes predictive policing company\nGeolitica\n's predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.\n[\n153\n]\nWhile responsible\ncollection of data\nand documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame the lack of participation and representation of minority populations in the field of AI for machine learning's vulnerability to biases.\n[\n154\n]\nIn fact, according to research carried out by the Computing Research Association in 2021, \"female faculty make up just 16.1%\" of all faculty members who focus on AI among several universities around the world.\n[\n155\n]\nFurthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.\n[\n155\n]\nLanguage models learned from data have been shown to contain human-like biases.\n[\n156\n]\n[\n157\n]\nBecause human languages contain biases, machines trained on language\ncorpora\nwill necessarily also learn these biases.\n[\n158\n]\n[\n159\n]\nIn 2016, Microsoft tested\nTay\n, a\nchatbot\nthat learned from Twitter, and it quickly picked up racist and sexist language.\n[\n160\n]\nIn an experiment carried out by\nProPublica\n, an\ninvestigative journalism\norganisation, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants\".\n[\n153\n]\nIn 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognise gorillas.\n[\n161\n]\nSimilar issues with recognising non-white people have been found in many other systems.\n[\n162\n]\nBecause of such challenges, the effective use of machine learning may take longer to be adopted in other domains.\n[\n163\n]\nConcern for\nfairness\nin machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including\nFei-Fei Li\n, who said that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"\n[\n164\n]\nFinancial incentives\n[\nedit\n]\nThere are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States, where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals with an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.\n[\n165\n]\nHardware\n[\nedit\n]\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training\ndeep neural networks\n(a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.\n[\n166\n]\nBy 2019, graphics processing units (\nGPUs\n), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.\n[\n167\n]\nOpenAI\nestimated the hardware compute used in the largest deep learning projects from\nAlexNet\n(2012) to\nAlphaZero\n(2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.\n[\n168\n]\n[\n169\n]\nTensor Processing Units (TPUs)\n[\nedit\n]\nTensor Processing Units (TPUs)\nare specialised hardware accelerators developed by\nGoogle\nspecifically for machine learning workloads. Unlike general-purpose\nGPUs\nand\nFPGAs\n, TPUs are optimised for tensor computations, making them particularly efficient for deep learning tasks such as training and inference. They are widely used in Google Cloud AI services and large-scale machine learning models like Google's DeepMind AlphaFold and large language models. TPUs leverage matrix multiplication units and high-bandwidth memory to accelerate computations while maintaining energy efficiency.\n[\n170\n]\nSince their introduction in 2016, TPUs have become a key component of AI infrastructure, especially in cloud-based environments.\nNeuromorphic computing\n[\nedit\n]\nNeuromorphic computing\nrefers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialised hardware architectures.\n[\n171\n]\nPhysical neural networks\n[\nedit\n]\nA\nphysical neural network\nis a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of\nneural synapses\n. The term \"physical neural network\" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.\n[\n172\n]\n[\n173\n]\nEmbedded machine learning\n[\nedit\n]\nEmbedded machine learning is a sub-field of machine learning where models are deployed on\nembedded systems\nwith limited computing resources, such as\nwearable computers\n,\nedge devices\nand\nmicrocontrollers\n.\n[\n174\n]\n[\n175\n]\n[\n176\n]\n[\n177\n]\nRunning models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as\nhardware acceleration\n,\n[\n178\n]\n[\n179\n]\napproximate computing\n,\n[\n180\n]\nand model optimisation.\n[\n181\n]\n[\n182\n]\nCommon optimisation techniques include\npruning\n,\nquantisation\n,\nknowledge distillation\n, low-rank factorisation, network architecture search, and parameter sharing.\nSoftware\n[\nedit\n]\nSoftware suites\ncontaining a variety of machine learning algorithms include the following:\nFree and open-source software\n[\nedit\n]\nSee also:\nLists of open-source artificial intelligence software\nCaffe\nDeeplearning4j\nDeepSpeed\nELKI\nGoogle JAX\nInfer.NET\nJASP\nJubatus\nKeras\nKubeflow\nLightGBM\nMahout\nMallet\nMicrosoft Cognitive Toolkit\nML.NET\nmlpack\nMXNet\nOpenNN\nOrange\npandas (software)\nROOT\n(TMVA with ROOT)\nscikit-learn\nShogun\nSpark MLlib\nSystemML\nTheano\nTensorFlow\nTorch\n/\nPyTorch\nWeka\n/\nMOA\nXGBoost\nYooreeka\nProprietary software with free and open-source editions\n[\nedit\n]\nKNIME\nRapidMiner\nProprietary software\n[\nedit\n]\nAmazon Machine Learning\nAngoss\nKnowledgeSTUDIO\nAzure Machine Learning\nIBM Watson Studio\nGoogle Cloud Vertex AI\nGoogle Prediction API\nIBM SPSS Modeller\nKXEN Modeller\nLIONsolver\nMathematica\nMATLAB\nNeural Designer\nNeuroSolutions\nOracle Data Mining\nOracle AI Platform Cloud Service\nPolyAnalyst\nRCASE\nSAS Enterprise Miner\nSequenceL\nSplunk\nSTATISTICA\nData Miner\nJournals\n[\nedit\n]\nJournal of Machine Learning Research\nMachine Learning\nNature Machine Intelligence\nNeural Computation\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nConferences\n[\nedit\n]\nAAAI Conference on Artificial Intelligence\nAssociation for Computational Linguistics (\nACL\n)\nEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (\nECML PKDD\n)\nInternational Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (\nCIBB\n)\nInternational Conference on Machine Learning (\nICML\n)\nInternational Conference on Learning Representations (\nICLR\n)\nInternational Conference on Intelligent Robots and Systems (\nIROS\n)\nConference on Knowledge Discovery and Data Mining (\nKDD\n)\nConference on Neural Information Processing Systems (\nNeurIPS\n)\nSee also\n[\nedit\n]\nAutomated machine learning\n– Process of automating the application of machine learning\nBig data\n– Extremely large or complex datasets\nDeep learning\n— branch of ML concerned with\nartificial neural networks\nDifferentiable programming\n– Programming paradigm\nList of datasets for machine-learning research\nList of machine learning algorithms\nand\nList of algorithms for machine learning and statistical classification\nM-theory (learning framework)\n– Framework in machine learning\nMachine unlearning\n– Field of study in artificial intelligence\nOutline of machine learning\nSolomonoff's theory of inductive inference\n– Mathematical theory\nReferences\n[\nedit\n]\n^\nThe definition \"without being explicitly programmed\" is often attributed to\nArthur Samuel\n, who coined the term \"machine learning\" in 1959, but the phrase is not found verbatim in this publication, and may be a\nparaphrase\nthat appeared later. Confer \"Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?\" in\nKoza, John R.; Bennett, Forrest H.; Andre, David; Keane, Martin A. (1996). \"Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming\".\nArtificial Intelligence in Design '96\n. Artificial Intelligence in Design '96. Dordrecht, Netherlands: Springer Netherlands. pp.\n151–\n170.\ndoi\n:\n10.1007/978-94-009-0279-4_9\n.\nISBN\n978-94-010-6610-5\n.\n^\na\nb\nc\nBishop, C. M.\n(2006),\nPattern Recognition and Machine Learning\n, Springer,\nISBN\n978-0-387-31073-2\n^\nMachine learning and pattern recognition \"can be viewed as two facets of the same field\".\n[\n2\n]\n: vii\n^\na\nb\nFriedman, Jerome H.\n(1998). \"Data Mining and Statistics: What's the connection?\".\nComputing Science and Statistics\n.\n29\n(1):\n3–\n9.\n^\nSamuel, Arthur (1959). \"Some Studies in Machine Learning Using the Game of Checkers\".\nIBM Journal of Research and Development\n.\n3\n(3):\n210–\n229.\nCiteSeerX\n10.1.1.368.2254\n.\ndoi\n:\n10.1147/rd.33.0210\n.\nS2CID\n2126705\n.\n^\na\nb\nR. Kohavi and F. Provost, \"Glossary of terms\", Machine Learning, vol. 30, no. 2–3, pp. 271–274, 1998.\n^\nGerovitch, Slava (9 April 2015).\n\"How the Computer Got Its Revenge on the Soviet Union\"\n.\nNautilus\n. Archived from\nthe original\non 22 September 2021\n. Retrieved\n19 September\n2021\n.\n^\nLindsay, Richard P. (1 September 1964).\n\"The Impact of Automation On Public Administration\"\n.\nWestern Political Quarterly\n.\n17\n(3):\n78–\n81.\ndoi\n:\n10.1177/106591296401700364\n.\nISSN\n0043-4078\n.\nS2CID\n154021253\n.\nArchived\nfrom the original on 6 October 2021\n. Retrieved\n6 October\n2021\n.\n^\na\nb\nc\n\"History and Evolution of Machine Learning: A Timeline\"\n.\nWhatIs\n.\nArchived\nfrom the original on 8 December 2023\n. Retrieved\n8 December\n2023\n.\n^\nMilner, Peter M. (1993). \"The Mind and Donald O. Hebb\".\nScientific American\n.\n268\n(1):\n124–\n129.\nBibcode\n:\n1993SciAm.268a.124M\n.\ndoi\n:\n10.1038/scientificamerican0193-124\n.\nISSN\n0036-8733\n.\nJSTOR\n24941344\n.\nPMID\n8418480\n.\n^\n\"Science: The Goof Button\",\nTime\n, 18 August 1961.\n^\nNilsson, Nils J. (1965).\nLearning Machines\n. McGraw-Hill.\n^\nDuda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973\n^\nS. Bozinovski, \"Teaching space: A representation concept for adaptive pattern classification\" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981.\nhttps://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf\nArchived\n25 February 2021 at the\nWayback Machine\n^\na\nb\nMitchell, T. (1997).\nMachine Learning\n. McGraw Hill. p. 2.\nISBN\n978-0-07-042807-2\n.\n^\nHarnad, Stevan\n(2008),\n\"The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence\"\n, in Epstein, Robert; Peters, Grace (eds.),\nThe Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer\n, Kluwer, pp.\n23–\n66,\nISBN\n978-1-4020-6708-2\n, archived from\nthe original\non 9 March 2012\n, retrieved\n11 December\n2012\n^\n\"Machine Learning Algorithms\"\n.\nGeeksforGeeks\n. 17 August 2023\n. Retrieved\n3 September\n2025\n.\n^\nGoodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi (2014).\nGenerative adversarial nets\n(PDF)\n. Advances in Neural Information Processing Systems 27 (2014).\n^\nSilver, David; Huang, Aja; Maddison, Christopher J. (2016).\n\"Mastering the game of Go with deep neural networks and tree search\"\n.\nNature\n.\n529\n:\n484–\n489.\ndoi\n:\n10.1038/nature16961\n.\n^\nSindhu V, Nivedha S, Prakash M (February 2020).\n\"An Empirical Science Research on Bioinformatics in Machine Learning\"\n.\nJournal of Mechanics of Continua and Mathematical Sciences\n(7).\ndoi\n:\n10.26782/jmcms.spl.7/2020.02.00006\n.\n^\nSarle, Warren S. (1994). \"Neural Networks and statistical models\".\nSUGI 19: proceedings of the Nineteenth Annual SAS Users Group International Conference\n. SAS Institute. pp.\n1538–\n50.\nISBN\n978-1-55544-611-6\n.\nOCLC\n35546178\n.\n^\na\nb\nc\nd\nRussell, Stuart\n;\nNorvig, Peter\n(2003) [1995].\nArtificial Intelligence: A Modern Approach\n(2nd ed.). Prentice Hall.\nISBN\n978-0137903955\n.\n^\na\nb\nLangley, Pat (2011).\n\"The changing science of machine learning\"\n.\nMachine Learning\n.\n82\n(3):\n275–\n9.\ndoi\n:\n10.1007/s10994-011-5242-y\n.\n^\nMahoney, Matt.\n\"Rationale for a Large Text Compression Benchmark\"\n. Florida Institute of Technology. Archived from\nthe original\non 18 August 2006\n. Retrieved\n5 March\n2013\n.\n^\nShmilovici A.; Kahiri Y.; Ben-Gal I.; Hauser S. (2009).\n\"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\"\n(PDF)\n.\nComputational Economics\n.\n33\n(2):\n131–\n154.\nCiteSeerX\n10.1.1.627.3751\n.\ndoi\n:\n10.1007/s10614-008-9153-3\n.\nS2CID\n17234503\n.\nArchived\n(PDF)\nfrom the original on 9 July 2009.\n^\nBen-Gal, I. (2008).\n\"On the Use of Data Compression Measures to Analyze Robust Designs\"\n(PDF)\n.\nIEEE Transactions on Reliability\n.\n54\n(3):\n381–\n388.\ndoi\n:\n10.1109/TR.2005.853280\n.\nS2CID\n9376086\n. Archived from\nthe original\n(PDF)\non 26 September 2020\n. Retrieved\n6 April\n2016\n.\n^\nD. Scully;\nCarla E. Brodley\n(2006). \"Compression and Machine Learning: A New Perspective on Feature Space Vectors\".\nData Compression Conference (DCC'06)\n. p. 332.\ndoi\n:\n10.1109/DCC.2006.13\n.\nISBN\n0-7695-2545-8\n.\nS2CID\n12311412\n.\n^\nGary Adcock (5 January 2023).\n\"What Is AI Video Compression?\"\n.\nmassive.io\n. Retrieved\n6 April\n2023\n.\n^\nMentzer, Fabian; Toderici, George; Tschannen, Michael; Agustsson, Eirikur (2020). \"High-Fidelity Generative Image Compression\".\narXiv\n:\n2006.09965\n[\neess.IV\n].\n^\n\"What is Unsupervised Learning? | IBM\"\n.\nwww.ibm.com\n. 23 September 2021\n. Retrieved\n5 February\n2024\n.\n^\n\"Differentially private clustering for large-scale datasets\"\n.\nblog.research.google\n. 25 May 2023\n. Retrieved\n16 March\n2024\n.\n^\nEdwards, Benj (28 September 2023).\n\"AI language models can exceed PNG and FLAC in lossless compression, says study\"\n.\nArs Technica\n. Retrieved\n7 March\n2024\n.\n^\nDelétang, Grégoire; Ruoss, Anian; Duquenne, Paul-Ambroise; Catt, Elliot; Genewein, Tim; Mattern, Christopher; Grau-Moya, Jordi; Li Kevin Wenliang; Aitchison, Matthew; Orseau, Laurent; Hutter, Marcus; Veness, Joel (2023). \"Language Modeling is Compression\".\narXiv\n:\n2309.10668\n[\ncs.LG\n].\n^\nLe Roux, Nicolas; Bengio, Yoshua; Fitzgibbon, Andrew (2012).\n\"Improving First and Second-Order Methods by Modeling Uncertainty\"\n. In Sra, Suvrit; Nowozin, Sebastian; Wright, Stephen J. (eds.).\nOptimization for Machine Learning\n. MIT Press. p. 404.\nISBN\n978-0-262-01646-9\n.\nArchived\nfrom the original on 17 January 2023\n. Retrieved\n12 November\n2020\n.\n^\nBzdok, Danilo;\nAltman, Naomi\n; Krzywinski, Martin (2018).\n\"Statistics versus Machine Learning\"\n.\nNature Methods\n.\n15\n(4):\n233–\n234.\ndoi\n:\n10.1038/nmeth.4642\n.\nPMC\n6082636\n.\nPMID\n30100822\n.\n^\nHung et al. Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery. JAMA Surg. 2018\n^\nCornell University Library (August 2001).\n\"Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\"\n.\nStatistical Science\n.\n16\n(3).\ndoi\n:\n10.1214/ss/1009213726\n.\nS2CID\n62729017\n.\nArchived\nfrom the original on 26 June 2017\n. Retrieved\n8 August\n2015\n.\n^\nGareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013).\nAn Introduction to Statistical Learning\n. Springer. p. vii.\nArchived\nfrom the original on 23 June 2019\n. Retrieved\n25 October\n2014\n.\n^\nRamezanpour, A.; Beam, A.L.; Chen, J.H.; Mashaghi, A. (17 November 2020).\n\"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\"\n.\nDiagnostics\n.\n10\n(11): 972.\ndoi\n:\n10.3390/diagnostics10110972\n.\nPMC\n7699346\n.\nPMID\n33228143\n.\n^\nMashaghi, A.; Ramezanpour, A. (16 March 2018). \"Statistical physics of medical diagnostics: Study of a probabilistic model\".\nPhysical Review E\n.\n97\n(\n3–\n1) 032118.\narXiv\n:\n1803.10019\n.\nBibcode\n:\n2018PhRvE..97c2118M\n.\ndoi\n:\n10.1103/PhysRevE.97.032118\n.\nPMID\n29776109\n.\nS2CID\n4955393\n.\n^\nMohri, Mehryar\n; Rostamizadeh, Afshin; Talwalkar, Ameet (2012).\nFoundations of Machine Learning\n. US, Massachusetts: MIT Press.\nISBN\n9780262018258\n.\n^\nAlpaydin, Ethem (2010).\nIntroduction to Machine Learning\n. London: The MIT Press.\nISBN\n978-0-262-01243-0\n. Retrieved\n4 February\n2017\n.\n^\nJordan, M. I.; Mitchell, T. M. (17 July 2015). \"Machine learning: Trends, perspectives, and prospects\".\nScience\n.\n349\n(6245):\n255–\n260.\nBibcode\n:\n2015Sci...349..255J\n.\ndoi\n:\n10.1126/science.aaa8415\n.\nPMID\n26185243\n.\nS2CID\n677218\n.\n^\nEl Naqa, Issam; Murphy, Martin J. (2015). \"What is Machine Learning?\".\nMachine Learning in Radiation Oncology\n. pp.\n3–\n11.\ndoi\n:\n10.1007/978-3-319-18305-3_1\n.\nISBN\n978-3-319-18304-6\n.\nS2CID\n178586107\n.\n^\nOkolie, Jude A.; Savage, Shauna; Ogbaga, Chukwuma C.; Gunes, Burcu (June 2022).\n\"Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon\"\n.\nTotal Environment Research Themes\n.\n1–\n2\n100001.\nBibcode\n:\n2022TERT....100001O\n.\ndoi\n:\n10.1016/j.totert.2022.100001\n.\nS2CID\n249022386\n.\n^\nRussell, Stuart J.; Norvig, Peter (2010).\nArtificial Intelligence: A Modern Approach\n(Third ed.). Prentice Hall.\nISBN\n978-0-13-604259-4\n.\n^\nMohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012).\nFoundations of Machine Learning\n. The MIT Press.\nISBN\n978-0-262-01825-8\n.\n^\nAlpaydin, Ethem (2010).\nIntroduction to Machine Learning\n. MIT Press. p. 9.\nISBN\n978-0-262-01243-0\n.\nArchived\nfrom the original on 17 January 2023\n. Retrieved\n25 November\n2018\n.\n^\nDe Sa, Christopher (Spring 2022).\n\"Lecture 2 Notes: Supervised Learning\"\n.\nCornell: Computer Science\n. Retrieved\n1 July\n2024\n.\n^\nJordan, Michael I.; Bishop, Christopher M. (2004). \"Neural Networks\". In Allen B. Tucker (ed.).\nComputer Science Handbook, Second Edition (Section VII: Intelligent Systems)\n. Boca Raton, Florida: Chapman & Hall/CRC Press LLC.\nISBN\n978-1-58488-360-9\n.\n^\nMisra, Ishan; Maaten, Laurens van der (2020).\nSelf-Supervised Learning of Pretext-Invariant Representations\n. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Seattle, WA, US:\nIEEE\n. pp.\n6707–\n6717.\narXiv\n:\n1912.01991\n.\ndoi\n:\n10.1109/CVPR42600.2020.00674\n.\n^\nJaiswal, Ashish; Babu, Ashwin Ramesh; Zadeh, Mohammad Zaki; Banerjee, Debapriya; Makedon, Fillia (March 2021).\n\"A Survey on Contrastive Self-Supervised Learning\"\n.\nTechnologies\n.\n9\n(1): 2.\narXiv\n:\n2011.00362\n.\ndoi\n:\n10.3390/technologies9010002\n.\nISSN\n2227-7080\n.\n^\nAlex Ratner; Stephen Bach; Paroma Varma; Chris.\n\"Weak Supervision: The New Programming Paradigm for Machine Learning\"\n.\nhazyresearch.github.io\n. referencing work by many other members of Hazy Research. Archived from\nthe original\non 6 June 2019\n. Retrieved\n6 June\n2019\n.\n^\nvan Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\".\nReinforcement Learning\n. Adaptation, Learning, and Optimization. Vol. 12. pp.\n3–\n42.\ndoi\n:\n10.1007/978-3-642-27645-3_1\n.\nISBN\n978-3-642-27644-6\n.\n^\nRoweis, Sam T.; Saul, Lawrence K. (22 December 2000).\n\"Nonlinear Dimensionality Reduction by Locally Linear Embedding\"\n.\nScience\n.\n290\n(5500):\n2323–\n2326.\nBibcode\n:\n2000Sci...290.2323R\n.\ndoi\n:\n10.1126/science.290.5500.2323\n.\nPMID\n11125150\n.\nS2CID\n5987139\n.\nArchived\nfrom the original on 15 August 2021\n. Retrieved\n17 July\n2023\n.\n^\nPavel Brazdil; Christophe Giraud Carrier; Carlos Soares; Ricardo Vilalta (2009).\nMetalearning: Applications to Data Mining\n(Fourth ed.).\nSpringer Science+Business Media\n. pp.\n10–\n14,\npassim\n.\nISBN\n978-3-540-73262-4\n.\n^\nBozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402.\nISBN\n978-0-444-86488-8\n.\n^\nBozinovski, S. (1999) \"Crossbar Adaptive Array: The first connectionist network that solved the delayed reinforcement learning problem\" In A. Dobnikar, N. Steele, D. Pearson, R. Albert (eds.) Artificial Neural Networks and Genetic Algorithms, Springer Verlag, p. 320–325, ISBN 3-211-83364-1\n^\nBozinovski, Stevo (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255–263\n^\nBozinovski, S. (2001) \"Self-learning agents: A connectionist theory of emotion based on crossbar value judgment.\" Cybernetics and Systems 32(6) 637–667.\n^\nY. Bengio; A. Courville; P. Vincent (2013). \"Representation Learning: A Review and New Perspectives\".\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n.\n35\n(8):\n1798–\n1828.\narXiv\n:\n1206.5538\n.\nBibcode\n:\n2013ITPAM..35.1798B\n.\ndoi\n:\n10.1109/tpami.2013.50\n.\nPMID\n23787338\n.\nS2CID\n393948\n.\n^\nNathan Srebro; Jason D. M. Rennie; Tommi S. Jaakkola (2004).\nMaximum-Margin Matrix Factorization\n.\nNIPS\n.\n^\nCoates, Adam; Lee, Honglak; Ng, Andrew Y. (2011).\nAn analysis of single-layer networks in unsupervised feature learning\n(PDF)\n. Int'l Conf. on AI and Statistics (AISTATS). Archived from\nthe original\n(PDF)\non 13 August 2017\n. Retrieved\n25 November\n2018\n.\n^\nCsurka, Gabriella; Dance, Christopher C.; Fan, Lixin; Willamowski, Jutta; Bray, Cédric (2004).\nVisual categorization with bags of keypoints\n(PDF)\n. ECCV Workshop on Statistical Learning in Computer Vision.\nArchived\n(PDF)\nfrom the original on 13 July 2019\n. Retrieved\n29 August\n2019\n.\n^\nDaniel Jurafsky; James H. Martin (2009).\nSpeech and Language Processing\n. Pearson Education International. pp.\n145–\n146.\n^\nLu, Haiping; Plataniotis, K.N.; Venetsanopoulos, A.N. (2011).\n\"A Survey of Multilinear Subspace Learning for Tensor Data\"\n(PDF)\n.\nPattern Recognition\n.\n44\n(7):\n1540–\n1551.\nBibcode\n:\n2011PatRe..44.1540L\n.\ndoi\n:\n10.1016/j.patcog.2011.01.004\n.\nArchived\n(PDF)\nfrom the original on 10 July 2019\n. Retrieved\n4 September\n2015\n.\n^\nYoshua Bengio\n(2009).\nLearning Deep Architectures for AI\n. Now Publishers Inc. pp.\n1–\n3.\nISBN\n978-1-60198-294-0\n.\nArchived\nfrom the original on 17 January 2023\n. Retrieved\n15 February\n2016\n.\n^\nTillmann, A. M. (2015). \"On the Computational Intractability of Exact and Approximate Dictionary Learning\".\nIEEE Signal Processing Letters\n.\n22\n(1):\n45–\n49.\narXiv\n:\n1405.6664\n.\nBibcode\n:\n2015ISPL...22...45T\n.\ndoi\n:\n10.1109/LSP.2014.2345761\n.\nS2CID\n13342762\n.\n^\nAharon, M\n, M Elad, and A Bruckstein. 2006. \"\nK-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation\nArchived\n2018-11-23 at the\nWayback Machine\n.\" Signal Processing, IEEE Transactions on 54 (11): 4311–4322\n^\nZimek, Arthur; Schubert, Erich (2017), \"Outlier Detection\",\nEncyclopedia of Database Systems\n, Springer New York, pp.\n1–\n5,\ndoi\n:\n10.1007/978-1-4899-7993-3_80719-1\n,\nISBN\n978-1-4899-7993-3\n^\nHodge, V. J.; Austin, J. (2004).\n\"A Survey of Outlier Detection Methodologies\"\n(PDF)\n.\nArtificial Intelligence Review\n.\n22\n(2):\n85–\n126.\nCiteSeerX\n10.1.1.318.4023\n.\ndoi\n:\n10.1007/s10462-004-4304-y\n.\nS2CID\n59941878\n.\nArchived\n(PDF)\nfrom the original on 22 June 2015\n. Retrieved\n25 November\n2018\n.\n^\nDokas, Paul; Ertoz, Levent; Kumar, Vipin; Lazarevic, Aleksandar; Srivastava, Jaideep; Tan, Pang-Ning (2002).\n\"Data mining for network intrusion detection\"\n(PDF)\n.\nProceedings NSF Workshop on Next Generation Data Mining\n.\nArchived\n(PDF)\nfrom the original on 23 September 2015\n. Retrieved\n26 March\n2023\n.\n^\nChandola, V.; Banerjee, A.; Kumar, V. (2009). \"Anomaly detection: A survey\".\nACM Computing Surveys\n.\n41\n(3):\n1–\n58.\ndoi\n:\n10.1145/1541880.1541882\n.\nS2CID\n207172599\n.\n^\nFleer, S.; Moringen, A.; Klatzky, R. L.; Ritter, H. (2020).\n\"Learning efficient haptic shape exploration with a rigid tactile sensor array, S. Fleer, A. Moringen, R. Klatzky, H. Ritter\"\n.\nPLOS ONE\n.\n15\n(1) e0226880.\narXiv\n:\n1902.07501\n.\ndoi\n:\n10.1371/journal.pone.0226880\n.\nPMC\n6940144\n.\nPMID\n31896135\n.\n^\nMoringen, Alexandra; Fleer, Sascha; Walck, Guillaume; Ritter, Helge (2020), Nisky, Ilana; Hartcher-O'Brien, Jess; Wiertlewski, Michaël; Smeets, Jeroen (eds.), \"Attention-Based Robot Learning of Haptic Interaction\",\nHaptics: Science, Technology, Applications\n, Lecture Notes in Computer Science, vol. 12272, Cham: Springer International Publishing, pp.\n462–\n470,\ndoi\n:\n10.1007/978-3-030-58147-3_51\n,\nISBN\n978-3-030-58146-6\n,\nS2CID\n220069113\n^\nPiatetsky-Shapiro, Gregory (1991),\nDiscovery, analysis, and presentation of strong rules\n, in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds.,\nKnowledge Discovery in Databases\n, AAAI/MIT Press, Cambridge, MA.\n^\nBassel, George W.; Glaab, Enrico; Marquez, Julietta; Holdsworth, Michael J.; Bacardit, Jaume (1 September 2011).\n\"Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets\"\n.\nThe Plant Cell\n.\n23\n(9):\n3101–\n3116.\nBibcode\n:\n2011PlanC..23.3101B\n.\ndoi\n:\n10.1105/tpc.111.088153\n.\nISSN\n1532-298X\n.\nPMC\n3203449\n.\nPMID\n21896882\n.\n^\nAgrawal, R.; Imieliński, T.; Swami, A. (1993). \"Mining association rules between sets of items in large databases\".\nProceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD '93\n. p. 207.\nCiteSeerX\n10.1.1.40.6984\n.\ndoi\n:\n10.1145/170035.170072\n.\nISBN\n978-0-89791-592-2\n.\nS2CID\n490415\n.\n^\nUrbanowicz, Ryan J.; Moore, Jason H. (22 September 2009).\n\"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\"\n.\nJournal of Artificial Evolution and Applications\n.\n2009\n:\n1–\n25.\ndoi\n:\n10.1155/2009/736398\n.\nISSN\n1687-6229\n.\n^\nPlotkin G.D.\nAutomatic Methods of Inductive Inference\nArchived\n22 December 2017 at the\nWayback Machine\n, PhD thesis, University of Edinburgh, 1970.\n^\nShapiro, Ehud Y.\nInductive inference of theories from facts\nArchived\n21 August 2021 at the\nWayback Machine\n, Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199–254.\n^\nShapiro, Ehud Y. (1983).\nAlgorithmic program debugging\n. Cambridge, Mass: MIT Press.\nISBN\n0-262-19218-7\n^\nShapiro, Ehud Y. \"\nThe model inference system\nArchived\n2023-04-06 at the\nWayback Machine\n.\" Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981.\n^\nBurkov, Andriy (2019).\nThe hundred-page machine learning book\n. Polen: Andriy Burkov.\nISBN\n978-1-9995795-0-0\n.\n^\nRussell, Stuart J.; Norvig, Peter (2021).\nArtificial intelligence: a modern approach\n. Pearson series in artificial intelligence (Fourth ed.). Hoboken: Pearson.\nISBN\n978-0-13-461099-3\n.\n^\nHonglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. \"\nConvolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations\nArchived\n2017-10-18 at the\nWayback Machine\n\" Proceedings of the 26th Annual International Conference on Machine Learning, 2009.\n^\n\"RandomForestRegressor\"\n.\nscikit-learn\n. Retrieved\n12 February\n2025\n.\n^\n\"What Is Random Forest? | IBM\"\n.\nwww.ibm.com\n. 20 October 2021\n. Retrieved\n12 February\n2025\n.\n^\nCortes, Corinna\n; Vapnik, Vladimir N. (1995).\n\"Support-vector networks\"\n.\nMachine Learning\n.\n20\n(3):\n273–\n297.\ndoi\n:\n10.1007/BF00994018\n.\n^\nStevenson, Christopher.\n\"Tutorial: Polynomial Regression in Excel\"\n.\nfacultystaff.richmond.edu\n.\nArchived\nfrom the original on 2 June 2013\n. Retrieved\n22 January\n2017\n.\n^\nWanta, Damian; Smolik, Aleksander; Smolik, Waldemar T.; Midura, Mateusz; Wróblewski, Przemysław (2025).\n\"Image reconstruction using machine-learned pseudoinverse in electrical capacitance tomography\"\n.\nEngineering Applications of Artificial Intelligence\n.\n142\n109888.\ndoi\n:\n10.1016/j.engappai.2024.109888\n.\n^\nThe documentation for\nscikit-learn\nalso has similar\nexamples\nArchived\n2 November 2022 at the\nWayback Machine\n.\n^\nGoldberg, David E.; Holland, John H. (1988).\n\"Genetic algorithms and machine learning\"\n(PDF)\n.\nMachine Learning\n.\n3\n(2):\n95–\n99.\ndoi\n:\n10.1007/bf00113892\n.\nS2CID\n35506513\n.\nArchived\n(PDF)\nfrom the original on 16 May 2011\n. Retrieved\n3 September\n2019\n.\n^\nMichie, D.; Spiegelhalter, D. J.; Taylor, C. C. (1994). \"Machine Learning, Neural and Statistical Classification\".\nEllis Horwood Series in Artificial Intelligence\n.\nBibcode\n:\n1994mlns.book.....M\n.\n^\nZhang, Jun; Zhan, Zhi-hui; Lin, Ying; Chen, Ni; Gong, Yue-jiao; Zhong, Jing-hui; Chung, Henry S.H.; Li, Yun; Shi, Yu-hui (2011). \"Evolutionary Computation Meets Machine Learning: A Survey\".\nIEEE Computational Intelligence Magazine\n.\n6\n(4):\n68–\n75.\nBibcode\n:\n2011ICIM....6d..68Z\n.\ndoi\n:\n10.1109/mci.2011.942584\n.\nS2CID\n6760276\n.\n^\nVerbert, K.; Babuška, R.; De Schutter, B. (1 April 2017).\n\"Bayesian and Dempster–Shafer reasoning for knowledge-based fault diagnosis–A comparative study\"\n.\nEngineering Applications of Artificial Intelligence\n.\n60\n:\n136–\n150.\ndoi\n:\n10.1016/j.engappai.2017.01.011\n.\nISSN\n0952-1976\n.\n^\nYoosefzadeh-Najafabadi, Mohsen; Hugh, Earl; Tulpan, Dan; Sulik, John; Eskandari, Milad (2021).\n\"Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean?\"\n.\nFront. Plant Sci\n.\n11\n624273.\nBibcode\n:\n2021FrPS...1124273Y\n.\ndoi\n:\n10.3389/fpls.2020.624273\n.\nPMC\n7835636\n.\nPMID\n33510761\n.\n^\nUrbanowicz, Ryan J.; Moore, Jason H. (22 September 2009).\n\"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\"\n.\nJournal of Artificial Evolution and Applications\n.\n2009\n:\n1–\n25.\ndoi\n:\n10.1155/2009/736398\n.\nISSN\n1687-6229\n.\n^\nZhang, C. and Zhang, S., 2002.\nAssociation rule mining: models and algorithms\n. Springer-Verlag.\n^\nDe Castro, Leandro Nunes, and Jonathan Timmis.\nArtificial immune systems: a new computational intelligence approach\n. Springer Science & Business Media, 2002.\n^\n\"Federated Learning: Collaborative Machine Learning without Centralized Training Data\"\n.\nGoogle AI Blog\n. 6 April 2017.\nArchived\nfrom the original on 7 June 2019\n. Retrieved\n8 June\n2019\n.\n^\nMachine learning is included in the\nCFA Curriculum\n; see:\n[1]\n{{Webarchive|url=\nhttps://www.cfainstitute.org/\n^\nMarcos M. López de Prado (2010).\nMachine Learning for Asset Managers\n.\nCambridge University Press\n.\nISBN\n9781108883658\n^\nIvanenko, Mikhail; Smolik, Waldemar T.; Wanta, Damian; Midura, Mateusz; Wróblewski, Przemysław; Hou, Xiaohan; Yan, Xiaoheng (2023).\n\"Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax\"\n.\nSensors\n.\n23\n(18): 7774.\nBibcode\n:\n2023Senso..23.7774I\n.\ndoi\n:\n10.3390/s23187774\n.\nPMC\n10538128\n.\nPMID\n37765831\n.\n^\n\"BelKor Home Page\"\nresearch.att.com\n^\n\"The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)\"\n. 6 April 2012. Archived from\nthe original\non 31 May 2016\n. Retrieved\n8 August\n2015\n.\n^\nScott Patterson (13 July 2010).\n\"Letting the Machines Decide\"\n.\nThe Wall Street Journal\n.\nArchived\nfrom the original on 24 June 2018\n. Retrieved\n24 June\n2018\n.\n^\nVinod Khosla (10 January 2012).\n\"Do We Need Doctors or Algorithms?\"\n. Tech Crunch.\nArchived\nfrom the original on 18 June 2018\n. Retrieved\n20 October\n2016\n.\n^\nWhen A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed\nArchived\n4 June 2016 at the\nWayback Machine\n,\nThe Physics at\nArXiv\nblog\n^\nVincent, James (10 April 2019).\n\"The first AI-generated textbook shows what robot writers are actually good at\"\n.\nThe Verge\n.\nArchived\nfrom the original on 5 May 2019\n. Retrieved\n5 May\n2019\n.\n^\nVaishya, Raju; Javaid, Mohd; Khan, Ibrahim Haleem; Haleem, Abid (1 July 2020).\n\"Artificial Intelligence (AI) applications for COVID-19 pandemic\"\n.\nDiabetes & Metabolic Syndrome: Clinical Research & Reviews\n.\n14\n(4):\n337–\n339.\ndoi\n:\n10.1016/j.dsx.2020.04.012\n.\nPMC\n7195043\n.\nPMID\n32305024\n.\n^\nRezapouraghdam, Hamed; Akhshik, Arash; Ramkissoon, Haywantee (10 March 2021).\n\"Application of machine learning to predict visitors' green behavior in marine protected areas: evidence from Cyprus\"\n.\nJournal of Sustainable Tourism\n.\n31\n(11):\n2479–\n2505.\ndoi\n:\n10.1080/09669582.2021.1887878\n.\nhdl\n:\n10037/24073\n.\n^\nDey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (15 June 2020).\n\"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\"\n.\n2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)\n(PDF)\n. pp.\n1728–\n1733.\ndoi\n:\n10.23919/DATE48585.2020.9116294\n.\nISBN\n978-3-9819263-4-7\n.\nS2CID\n219858480\n.\nArchived\nfrom the original on 13 December 2021\n. Retrieved\n20 January\n2022\n.\n^\nQuested, Tony.\n\"Smartphone",
      "scraped_at": "2025-12-16T17:25:37.460292",
      "status": "success",
      "content_length": 125995,
      "topic": "machine_learning"
    },
    {
      "title": "Supervised learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Supervised_learning",
      "content": "Supervised learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nSteps to follow\n2\nAlgorithm choice\nToggle Algorithm choice subsection\n2.1\nBias–variance tradeoff\n2.2\nFunction complexity and amount of training data\n2.3\nDimensionality of the input space\n2.4\nNoise in the output values\n2.5\nOther factors to consider\n2.6\nAlgorithms\n3\nHow supervised learning algorithms work\nToggle How supervised learning algorithms work subsection\n3.1\nEmpirical risk minimization\n3.2\nStructural risk minimization\n4\nGenerative training\n5\nGeneralizations\n6\nApproaches and algorithms\n7\nApplications\n8\nGeneral issues\n9\nSee also\n10\nReferences\n11\nExternal links\nToggle the table of contents\nSupervised learning\n40 languages\nالعربية\nتۆرکجه\nবাংলা\n閩南語 / Bân-lâm-gí\nBosanski\nCatalà\nČeština\nDansk\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEuskara\nفارسی\nFrançais\n한국어\nՀայերեն\nBahasa Indonesia\nItaliano\nעברית\nಕನ್ನಡ\nमराठी\nNederlands\n日本語\nଓଡ଼ିଆ\nPolski\nPortuguês\nRuna Simi\nРусский\nShqip\nSimple English\nکوردی\nСрпски / srpski\nSuomi\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nMachine learning paradigm\nIn supervised learning, the training data is labeled with the expected answers, while in\nunsupervised learning\n, the model identifies patterns or structures in unlabeled data.\nIn\nmachine learning\n,\nsupervised learning\n(\nSL\n) is a type of\nmachine learning paradigm\nwhere an algorithm learns to map input data to a specific output based on example input-output pairs. This process involves training a statistical model using labeled data, meaning each piece of input data is provided with the correct output. For instance, if you want a model to identify cats in images, supervised learning would involve feeding it many images of cats (inputs) that are explicitly labeled \"cat\" (outputs).\nThe goal of supervised learning is for the trained model to accurately predict the output for new, unseen data.\n[\n1\n]\nThis requires the algorithm to effectively\ngeneralize\nfrom the training examples, a quality measured by its\ngeneralization error\n. Supervised learning is commonly used for tasks like\nclassification\n(predicting a category, e.g., spam or not spam) and\nregression\n(predicting a continuous value, e.g., house prices).\nSteps to follow\n[\nedit\n]\nTo solve a given problem of supervised learning, the following steps must be performed:\nAlgorithm choice\n[\nedit\n]\nA wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the\nNo free lunch theorem\n).\nThere are four major issues to consider in supervised learning:\nBias–variance tradeoff\n[\nedit\n]\nMain article:\nBias–variance tradeoff\nA first issue is the tradeoff between\nbias\nand\nvariance\n.\n[\n2\n]\nImagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input\nx\n{\\displaystyle x}\nif, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for\nx\n{\\displaystyle x}\n. A learning algorithm has high variance for a particular input\nx\n{\\displaystyle x}\nif it predicts different output values when trained on different training sets. The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm.\n[\n3\n]\nGenerally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be \"flexible\" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).\nFunction complexity and amount of training data\n[\nedit\n]\nThe second issue is of the amount of training data available relative to the complexity of the \"true\" function (classifier or regression function). If the true function is simple, then an \"inflexible\" learning algorithm with high bias and low variance will be able to learn it from a small amount of data. But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be able to learn with a large amount of training data paired with a \"flexible\" learning algorithm with low bias and high variance.\nDimensionality of the input space\n[\nedit\n]\nA third issue is the dimensionality of the input space. If the input feature vectors have large dimensions, learning the function can be difficult even if the true function only depends on a small number of those features. This is because the many \"extra\" dimensions can confuse the learning algorithm and cause it to have high variance. Hence, input data of large dimensions typically requires tuning the classifier to have low variance and high bias. In practice, if the engineer can manually remove irrelevant features from the input data, it will likely improve the accuracy of the learned function. In addition, there are many algorithms for\nfeature selection\nthat seek to identify the relevant features and discard the irrelevant ones. This is an instance of the more general strategy of\ndimensionality reduction\n, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.\nNoise in the output values\n[\nedit\n]\nA fourth issue is the degree of noise in the desired output values (the supervisory\ntarget variables\n). If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to\noverfitting\n. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation, the part of the target function that cannot be modeled \"corrupts\" your training data – this phenomenon has been called\ndeterministic noise\n. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.\nIn practice, there are several approaches to alleviate noise in the output values such as\nearly stopping\nto prevent overfitting as well as\ndetecting\nand removing the noisy training examples prior to training the supervised learning algorithm. There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased\ngeneralization error\nwith\nstatistical significance\n.\n[\n4\n]\n[\n5\n]\nOther factors to consider\n[\nedit\n]\nOther factors to consider when choosing and applying a learning algorithm include the following:\nHeterogeneity of the data. If the feature vectors include features of many different kinds (discrete, discrete ordered, counts, continuous values), some algorithms are easier to apply than others. Many algorithms, including\nsupport-vector machines\n,\nlinear regression\n,\nlogistic regression\n,\nneural networks\n, and\nnearest neighbor methods\n, require that the input features be numerical and scaled to similar ranges (e.g., to the [-1,1] interval). Methods that employ a distance function, such as nearest neighbor methods and\nsupport-vector machines with Gaussian kernels\n, are particularly sensitive to this. An advantage of\ndecision trees\nis that they easily handle heterogeneous data.\nRedundancy in the data. If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g.,\nlinear regression\n,\nlogistic regression\n, and\ndistance-based methods\n) will perform poorly because of numerical instabilities. These problems can often be solved by imposing some form of\nregularization\n.\nPresence of interactions and non-linearities. If each of the features makes an independent contribution to the output, then algorithms based on linear functions (e.g.,\nlinear regression\n,\nlogistic regression\n,\nsupport-vector machines\n,\nnaive Bayes\n) and distance functions (e.g., nearest neighbor methods,\nsupport-vector machines with Gaussian kernels\n) generally perform well. However, if there are complex interactions among features, then algorithms such as\ndecision trees\nand neural networks work better, because they are specifically designed to discover these interactions. Linear methods can also be applied, but the engineer must manually specify the interactions when using them.\nWhen considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see\ncross-validation\n). Tuning the performance of a learning algorithm can be very time-consuming. Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.\nAlgorithms\n[\nedit\n]\nThe most widely used learning algorithms are:\nSupport-vector machines\nLinear regression\nLogistic regression\nNaive Bayes\nLinear discriminant analysis\nDecision trees\nk\n-nearest neighbors algorithm\nNeural networks\n(e.g.,\nMultilayer perceptron\n)\nSimilarity learning\nHow supervised learning algorithms work\n[\nedit\n]\nGiven a set of\nN\n{\\displaystyle N}\ntraining examples of the form\n{\n(\nx\n1\n,\ny\n1\n)\n,\n.\n.\n.\n,\n(\nx\nN\n,\ny\nN\n)\n}\n{\\displaystyle \\{(x_{1},y_{1}),...,(x_{N},\\;y_{N})\\}}\nsuch that\nx\ni\n{\\displaystyle x_{i}}\nis the\nfeature vector\nof the\ni\n{\\displaystyle i}\n-th example and\ny\ni\n{\\displaystyle y_{i}}\nis its label (i.e., class), a learning algorithm seeks a function\ng\n:\nX\n→\nY\n{\\displaystyle g:X\\to Y}\n, where\nX\n{\\displaystyle X}\nis the input space and\nY\n{\\displaystyle Y}\nis the output space. The function\ng\n{\\displaystyle g}\nis an element of some space of possible functions\nG\n{\\displaystyle G}\n, usually called the\nhypothesis space\n. It is sometimes convenient to represent\ng\n{\\displaystyle g}\nusing a\nscoring function\nf\n:\nX\n×\nY\n→\nR\n{\\displaystyle f:X\\times Y\\to \\mathbb {R} }\nsuch that\ng\n{\\displaystyle g}\nis defined as returning the\ny\n{\\displaystyle y}\nvalue that gives the highest score:\ng\n(\nx\n)\n=\narg\n⁡\nmax\ny\nf\n(\nx\n,\ny\n)\n{\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;f(x,y)}\n. Let\nF\n{\\displaystyle F}\ndenote the space of scoring functions.\nAlthough\nG\n{\\displaystyle G}\nand\nF\n{\\displaystyle F}\ncan be any space of functions, many learning algorithms are probabilistic models where\ng\n{\\displaystyle g}\ntakes the form of a\nconditional probability\nmodel\ng\n(\nx\n)\n=\narg\n⁡\nmax\ny\nP\n(\ny\n|\nx\n)\n{\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;P(y|x)}\n, or\nf\n{\\displaystyle f}\ntakes the form of a\njoint probability\nmodel\nf\n(\nx\n,\ny\n)\n=\nP\n(\nx\n,\ny\n)\n{\\displaystyle f(x,y)=P(x,y)}\n. For example,\nnaive Bayes\nand\nlinear discriminant analysis\nare joint probability models, whereas\nlogistic regression\nis a conditional probability model.\nThere are two basic approaches to choosing\nf\n{\\displaystyle f}\nor\ng\n{\\displaystyle g}\n:\nempirical risk minimization\nand\nstructural risk minimization\n.\n[\n6\n]\nEmpirical risk minimization seeks the function that best fits the training data. Structural risk minimization includes a\npenalty function\nthat controls the bias/variance tradeoff.\nIn both cases, it is assumed that the training set consists of a sample of\nindependent and identically distributed pairs\n,\n(\nx\ni\n,\ny\ni\n)\n{\\displaystyle (x_{i},\\;y_{i})}\n. In order to measure how well a function fits the training data, a\nloss function\nL\n:\nY\n×\nY\n→\nR\n≥\n0\n{\\displaystyle L:Y\\times Y\\to \\mathbb {R} ^{\\geq 0}}\nis defined. For training example\n(\nx\ni\n,\ny\ni\n)\n{\\displaystyle (x_{i},\\;y_{i})}\n, the loss of predicting the value\ny\n^\n{\\displaystyle {\\hat {y}}}\nis\nL\n(\ny\ni\n,\ny\n^\n)\n{\\displaystyle L(y_{i},{\\hat {y}})}\n.\nThe\nrisk\nR\n(\ng\n)\n{\\displaystyle R(g)}\nof function\ng\n{\\displaystyle g}\nis defined as the expected loss of\ng\n{\\displaystyle g}\n. This can be estimated from the training data as\nR\ne\nm\np\n(\ng\n)\n=\n1\nN\n∑\ni\nL\n(\ny\ni\n,\ng\n(\nx\ni\n)\n)\n{\\displaystyle R_{emp}(g)={\\frac {1}{N}}\\sum _{i}L(y_{i},g(x_{i}))}\n.\nEmpirical risk minimization\n[\nedit\n]\nMain article:\nEmpirical risk minimization\nIn empirical risk minimization, the supervised learning algorithm seeks the function\ng\n{\\displaystyle g}\nthat minimizes\nR\n(\ng\n)\n{\\displaystyle R(g)}\n. Hence, a supervised learning algorithm can be constructed by applying an\noptimization algorithm\nto find\ng\n{\\displaystyle g}\n.\nWhen\ng\n{\\displaystyle g}\nis a conditional probability distribution\nP\n(\ny\n|\nx\n)\n{\\displaystyle P(y|x)}\nand the loss function is the negative log likelihood:\nL\n(\ny\n,\ny\n^\n)\n=\n−\nlog\n⁡\nP\n(\ny\n|\nx\n)\n{\\displaystyle L(y,{\\hat {y}})=-\\log P(y|x)}\n, then empirical risk minimization is equivalent to\nmaximum likelihood estimation\n.\nWhen\nG\n{\\displaystyle G}\ncontains many candidate functions or the training set is not sufficiently large, empirical risk minimization leads to high variance and poor generalization. The learning algorithm is able to memorize the training examples without generalizing well (overfitting).\nStructural risk minimization\n[\nedit\n]\nStructural risk minimization\nseeks to prevent overfitting by incorporating a\nregularization penalty\ninto the optimization. The regularization penalty can be viewed as implementing a form of\nOccam's razor\nthat prefers simpler functions over more complex ones.\nA wide variety of penalties have been employed that correspond to different definitions of complexity. For example, consider the case where the function\ng\n{\\displaystyle g}\nis a linear function of the form\ng\n(\nx\n)\n=\n∑\nj\n=\n1\nd\nβ\nj\nx\nj\n{\\displaystyle g(x)=\\sum _{j=1}^{d}\\beta _{j}x_{j}}\n.\nA popular regularization penalty is\n∑\nj\nβ\nj\n2\n{\\displaystyle \\sum _{j}\\beta _{j}^{2}}\n, which is the squared\nEuclidean norm\nof the weights, also known as the\nL\n2\n{\\displaystyle L_{2}}\nnorm. Other norms include the\nL\n1\n{\\displaystyle L_{1}}\nnorm,\n∑\nj\n|\nβ\nj\n|\n{\\displaystyle \\sum _{j}|\\beta _{j}|}\n, and the\nL\n0\n{\\displaystyle L_{0}}\n\"norm\"\n, which is the number of non-zero\nβ\nj\n{\\displaystyle \\beta _{j}}\ns. The penalty will be denoted by\nC\n(\ng\n)\n{\\displaystyle C(g)}\n.\nThe supervised learning optimization problem is to find the function\ng\n{\\displaystyle g}\nthat minimizes\nJ\n(\ng\n)\n=\nR\ne\nm\np\n(\ng\n)\n+\nλ\nC\n(\ng\n)\n.\n{\\displaystyle J(g)=R_{emp}(g)+\\lambda C(g).}\nThe parameter\nλ\n{\\displaystyle \\lambda }\ncontrols the bias-variance tradeoff. When\nλ\n=\n0\n{\\displaystyle \\lambda =0}\n, this gives empirical risk minimization with low bias and high variance. When\nλ\n{\\displaystyle \\lambda }\nis large, the learning algorithm will have high bias and low variance. The value of\nλ\n{\\displaystyle \\lambda }\ncan be chosen empirically via\ncross-validation\n.\nThe complexity penalty has a Bayesian interpretation as the negative log prior probability of\ng\n{\\displaystyle g}\n,\n−\nlog\n⁡\nP\n(\ng\n)\n{\\displaystyle -\\log P(g)}\n, in which case\nJ\n(\ng\n)\n{\\displaystyle J(g)}\nis the\nposterior probability\nof\ng\n{\\displaystyle g}\n.\nGenerative training\n[\nedit\n]\nThe training methods described above are\ndiscriminative training\nmethods, because they seek to find a function\ng\n{\\displaystyle g}\nthat discriminates well between the different output values (see\ndiscriminative model\n). For the special case where\nf\n(\nx\n,\ny\n)\n=\nP\n(\nx\n,\ny\n)\n{\\displaystyle f(x,y)=P(x,y)}\nis a\njoint probability distribution\nand the loss function is the negative log likelihood\n−\n∑\ni\nlog\n⁡\nP\n(\nx\ni\n,\ny\ni\n)\n,\n{\\displaystyle -\\sum _{i}\\log P(x_{i},y_{i}),}\na risk minimization algorithm is said to perform\ngenerative training\n, because\nf\n{\\displaystyle f}\ncan be regarded as a\ngenerative model\nthat explains how the data were generated. Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms. In some cases, the solution can be computed in closed form as in\nnaive Bayes\nand\nlinear discriminant analysis\n.\nGeneralizations\n[\nedit\n]\nTendency for a task to employ supervised vs. unsupervised methods. Task names straddling circle boundaries is intentional. It shows that the classical division of imaginative tasks (left) employing unsupervised methods is blurred in today's learning schemes.\nThere are several ways in which the standard supervised learning problem can be generalized:\nSemi-supervised learning\nor\nweak supervision\n: the desired output values are provided only for a subset of the training data. The remaining data is unlabeled or imprecisely labeled.\nActive learning\n: Instead of assuming that all of the training examples are given at the start, active learning algorithms interactively collect new examples, typically by making queries to a human user. Often, the queries are based on unlabeled data, which is a scenario that combines semi-supervised learning with active learning.\nStructured prediction\n: When the desired output value is a complex object, such as a\nparse tree\nor a labeled graph, then standard methods must be extended.\nLearning to rank\n: When the input is a set of objects and the desired output is a ranking of those objects, then again the standard methods must be extended.\nApproaches and algorithms\n[\nedit\n]\nAnalytical learning\nArtificial neural network\nBackpropagation\nBoosting (meta-algorithm)\nBayesian statistics\nCase-based reasoning\nDecision tree learning\nInductive logic programming\nGaussian process regression\nGenetic programming\nGroup method of data handling\nKernel estimators\nLearning automata\nLearning classifier systems\nLearning vector quantization\nMinimum message length\n(\ndecision trees\n, decision graphs, etc.)\nMultilinear subspace learning\nNaive Bayes classifier\nMaximum entropy classifier\nConditional random field\nNearest neighbor algorithm\nProbably approximately correct learning\n(PAC) learning\nRipple down rules\n, a knowledge acquisition methodology\nSymbolic machine learning algorithms\nSubsymbolic machine learning algorithms\nSupport vector machines\nMinimum complexity machines (MCM)\nRandom forests\nEnsembles of classifiers\nOrdinal classification\nData pre-processing\nHandling imbalanced datasets\nStatistical relational learning\nProaftn\n, a multicriteria classification algorithm\nApplications\n[\nedit\n]\nBioinformatics\nCheminformatics\nQuantitative structure–activity relationship\nDatabase marketing\nHandwriting recognition\nInformation retrieval\nLearning to rank\nInformation extraction\nObject recognition in\ncomputer vision\nOptical character recognition\nSpam detection\nPattern recognition\nSpeech recognition\nSupervised learning is a special case of\ndownward causation\nin biological systems\nLandform classification using\nsatellite imagery\n[\n7\n]\nSpend classification in\nprocurement\nprocesses\n[\n8\n]\nGeneral issues\n[\nedit\n]\nComputational learning theory\nInductive bias\nOverfitting\n(Uncalibrated)\nclass membership probabilities\nVersion spaces\nSee also\n[\nedit\n]\nList of datasets for machine-learning research\nUnsupervised learning\nReferences\n[\nedit\n]\n^\nMehryar Mohri\n, Afshin Rostamizadeh, Ameet Talwalkar (2012)\nFoundations of Machine Learning\n, The MIT Press\nISBN\n9780262018258\n.\n^\nS. Geman, E. Bienenstock, and R. Doursat (1992).\nNeural networks and the bias/variance dilemma\n. Neural Computation 4, 1–58.\n^\nG. James (2003) Variance and Bias for General Loss Functions, Machine Learning 51, 115–135. (\nhttp://www-bcf.usc.edu/~gareth/research/bv.pdf\n)\n^\nC.E. Brodely and M.A. Friedl (1999). Identifying and Eliminating Mislabeled Training Instances, Journal of Artificial Intelligence Research 11, 131–167. (\nhttp://jair.org/media/606/live-606-1803-jair.pdf\n)\n^\nM.R. Smith and T. Martinez (2011). \"Improving Classification Accuracy by Identifying and Removing Instances that Should Be Misclassified\".\nProceedings of International Joint Conference on Neural Networks (IJCNN 2011)\n. pp.\n2690–\n2697.\nCiteSeerX\n10.1.1.221.1371\n.\ndoi\n:\n10.1109/IJCNN.2011.6033571\n.\n^\nVapnik, V. N.\nThe Nature of Statistical Learning Theory\n(2nd Ed.), Springer Verlag, 2000.\n^\nA. Maity (2016). \"Supervised Classification of RADARSAT-2 Polarimetric Data for Different Land Features\".\narXiv\n:\n1608.00501\n[\ncs.CV\n].\n^\n\"Key Technologies for Agile Procurement | SIPMM Publications\"\n.\npublication.sipmm.edu.sg\n. 2020-10-09\n. Retrieved\n2022-06-16\n.\nExternal links\n[\nedit\n]\nMachine Learning Open Source Software (MLOSS)\nv\nt\ne\nDifferentiable computing\nGeneral\nDifferentiable programming\nInformation geometry\nStatistical manifold\nAutomatic differentiation\nNeuromorphic computing\nPattern recognition\nRicci calculus\nComputational learning theory\nInductive bias\nHardware\nIPU\nTPU\nVPU\nMemristor\nSpiNNaker\nSoftware libraries\nTensorFlow\nPyTorch\nKeras\nscikit-learn\nTheano\nJAX\nFlux.jl\nMindSpore\nPortals\nComputer programming\nTechnology\nAuthority control databases\nNational\nUnited States\nIsrael\nOther\nYale LUX\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Supervised_learning&oldid=1327148921\n\"\nCategory\n:\nSupervised learning\nHidden categories:\nArticles with short description\nShort description is different from Wikidata\nThis page was last edited on 12 December 2025, at 22:11\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nSupervised learning\n40 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:25:39.519688",
      "status": "success",
      "content_length": 22282,
      "topic": "machine_learning"
    },
    {
      "title": "Unsupervised learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Unsupervised_learning",
      "content": "Unsupervised learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nTasks\n2\nNeural network architectures\nToggle Neural network architectures subsection\n2.1\nTraining\n2.2\nEnergy\n2.3\nNetworks\n2.4\nHistory\n2.5\nSpecific Networks\n2.6\nComparison of networks\n2.7\nHebbian Learning, ART, SOM\n3\nProbabilistic methods\nToggle Probabilistic methods subsection\n3.1\nApproaches\n3.2\nMethod of moments\n4\nSee also\n5\nReferences\n6\nFurther reading\nToggle the table of contents\nUnsupervised learning\n33 languages\nالعربية\n閩南語 / Bân-lâm-gí\nCatalà\nČeština\nDeutsch\nEesti\nΕλληνικά\nEspañol\nفارسی\nFrançais\n한국어\nՀայերեն\nBahasa Indonesia\nIsiZulu\nItaliano\nעברית\n日本語\nPolski\nPortuguês\nRuna Simi\nРусский\nShqip\nSimple English\nکوردی\nСрпски / srpski\nSuomi\nTagalog\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nParadigm in machine learning that uses no classification labels\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nUnsupervised learning\nis a framework in\nmachine learning\nwhere, in contrast to\nsupervised learning\n, algorithms learn patterns exclusively from unlabeled data.\n[\n1\n]\nOther frameworks in the spectrum of supervisions include\nweak- or semi-supervision\n, where a small portion of the data is tagged, and\nself-supervision\n. Some researchers consider self-supervised learning a form of unsupervised learning.\n[\n2\n]\nConceptually, unsupervised learning divides into the aspects of data, training, algorithm, and downstream applications. Typically, the dataset is harvested cheaply \"in the wild\", such as massive\ntext corpus\nobtained by\nweb crawling\n, with only minor filtering (such as\nCommon Crawl\n). This compares favorably to supervised learning, where the dataset (such as the\nImageNet1000\n) is typically constructed manually, which is much more expensive.\nThere are algorithms designed specifically for unsupervised learning, such as\nclustering algorithms\nlike\nk-means\n,\ndimensionality reduction\ntechniques like\nprincipal component analysis (PCA)\n,\nBoltzmann machine learning\n, and\nautoencoders\n. After the rise of deep learning, most large-scale unsupervised learning has been done by training general-purpose neural network architectures by\ngradient descent\n, adapted to performing unsupervised learning by designing an appropriate training procedure.\nSometimes a trained model can be used as-is, but more often they are modified for downstream applications. For example, the generative pretraining method trains a model to generate a textual dataset, before finetuning it for other applications, such as text classification.\n[\n3\n]\n[\n4\n]\nAs another example, autoencoders are trained to produce\ngood features\n, which can then be used as a module for other models, such as in a\nlatent diffusion model\n.\nTasks\n[\nedit\n]\nTendency for a task to employ supervised vs. unsupervised methods. Task names straddling circle boundaries is intentional. It shows that the classical division of imaginative tasks (left) employing unsupervised methods is blurred in today's learning schemes.\nTasks are often categorized as\ndiscriminative\n(recognition) or\ngenerative\n(imagination).  Often but not always, discriminative tasks use supervised methods and generative tasks use unsupervised (see\nVenn diagram\n); however, the separation is very hazy.  For example, object recognition favors supervised learning but unsupervised learning can also cluster objects into groups.  Furthermore, as progress marches onward, some tasks employ both methods, and some tasks swing from one to another.  For example, image recognition started off as heavily supervised, but became hybrid by employing unsupervised pre-training, and then moved towards supervision again with the advent of\ndropout\n,\nReLU\n, and\nadaptive learning rates\n.\nA typical generative task is as follows. At each step, a datapoint is sampled from the dataset, and part of the data is removed, and the model must infer the removed part. This is particularly clear for the\ndenoising autoencoders\nand\nBERT\n.\nNeural network architectures\n[\nedit\n]\nTraining\n[\nedit\n]\nDuring the learning phase, an unsupervised network tries to mimic the data it is given and uses the error in its mimicked output to correct itself (i.e. correct its weights and biases). Sometimes the error is expressed as a low probability that the erroneous output occurs, or it might be expressed as an unstable high energy state in the network.\nIn contrast to supervised methods' dominant use of\nbackpropagation\n, unsupervised learning also employs other methods  including: Hopfield learning rule, Boltzmann learning rule,\nContrastive Divergence\n,\nWake Sleep\n,\nVariational Inference\n,\nMaximum Likelihood\n,\nMaximum A Posteriori\n,\nGibbs Sampling\n, and backpropagating reconstruction errors or hidden state reparameterizations. See the table below for more details.\nEnergy\n[\nedit\n]\nAn energy function is a macroscopic measure of a network's activation state.  In Boltzmann machines, it plays the role of the Cost function.  This analogy with physics is inspired by Ludwig Boltzmann's analysis of a gas' macroscopic energy from the microscopic probabilities of particle motion\np\n∝\ne\n−\nE\n/\nk\nT\n{\\displaystyle p\\propto e^{-E/kT}}\n, where k is the Boltzmann constant and T is temperature. In the\nRBM\nnetwork the relation is\np\n=\ne\n−\nE\n/\nZ\n{\\displaystyle p=e^{-E}/Z}\n,\n[\n5\n]\nwhere\np\n{\\displaystyle p}\nand\nE\n{\\displaystyle E}\nvary over every possible activation pattern and\nZ\n=\n∑\nAll Patterns\ne\n−\nE\n(\npattern\n)\n{\\displaystyle \\textstyle {Z=\\sum _{\\scriptscriptstyle {\\text{All Patterns}}}e^{-E({\\text{pattern}})}}}\n. To be more precise,\np\n(\na\n)\n=\ne\n−\nE\n(\na\n)\n/\nZ\n{\\displaystyle p(a)=e^{-E(a)}/Z}\n, where\na\n{\\displaystyle a}\nis an activation pattern of all neurons (visible and hidden). Hence, some early neural networks bear the name Boltzmann Machine.  Paul Smolensky calls\n−\nE\n{\\displaystyle -E\\,}\nthe\nHarmony\n. A network seeks low energy which is high Harmony.\nNetworks\n[\nedit\n]\nThis table shows connection diagrams of various unsupervised networks, the details of which will be given in the section Comparison of Networks.  Circles are neurons and edges between them are connection weights.  As network design changes, features are added on to enable new capabilities or removed to make learning faster.  For instance, neurons change between deterministic (Hopfield) and stochastic (Boltzmann) to allow robust output, weights are removed within a layer (RBM) to hasten learning, or connections are allowed to become asymmetric (Helmholtz).\nHopfield\nBoltzmann\nRBM\nStacked Boltzmann\nA network based on magnetic domains in iron with a single self-connected layer.  It can be used as a content addressable memory.\nNetwork is separated into 2 layers (hidden vs. visible), but still using symmetric 2-way weights.  Following Boltzmann's thermodynamics, individual  probabilities give rise to macroscopic energies.\nRestricted Boltzmann Machine.  This is a Boltzmann machine where lateral connections within a layer are prohibited to make analysis tractable.\nThis network has multiple RBM's to encode a hierarchy of hidden features.  After a single RBM is trained, another blue hidden layer (see left RBM) is added, and the top 2 layers are trained as a red & blue RBM.  Thus the middle layers of an RBM acts as hidden or visible, depending on the training phase it is in.\nHelmholtz\nAutoencoder\nVAE\nInstead of the bidirectional symmetric connection of the stacked Boltzmann machines, we have separate one-way connections to form a loop.  It does both generation and discrimination.\nA feed forward network that aims to find a good middle layer representation of its input world.  This network is deterministic, so it is not as robust as its successor the VAE.\nApplies Variational Inference to the Autoencoder.  The middle layer is a set of means & variances for Gaussian distributions.  The stochastic nature allows for more robust imagination than the deterministic autoencoder.\nOf the networks bearing people's names, only Hopfield worked directly with neural networks. Boltzmann and Helmholtz came before artificial neural networks, but their work in physics and physiology inspired the analytical methods that were used.\nHistory\n[\nedit\n]\n1974\nIsing magnetic model proposed by\nWA Little\n(\nde\n)\nfor cognition\n1980\nKunihiko Fukushima\nintroduces the\nneocognitron\n, which is later called a\nconvolutional neural network\n. It is mostly used in SL, but deserves a mention here.\n1982\nIsing variant Hopfield net described as\nCAMs\nand classifiers by John Hopfield.\n1983\nIsing variant Boltzmann machine with probabilistic neurons described by\nHinton\n&\nSejnowski\nfollowing Sherington & Kirkpatrick's 1975 work.\n1986\nPaul Smolensky\npublishes Harmony Theory, which is an RBM with practically the same Boltzmann energy function. Smolensky did not give a practical training scheme. Hinton did in mid-2000s.\n1995\nHochreiter\nand\nSchmidhuber\nintroduce the\nLSTM\nneuron for languages.\n1995\nDayan & Hinton introduces Helmholtz machine\n2013\nKingma, Rezende, & co. introduced Variational Autoencoders as Bayesian graphical probability network, with neural nets as components.\nSpecific Networks\n[\nedit\n]\nHere, we highlight some characteristics of select networks.  The details of each are given in the comparison table below.\nHopfield Network\nFerromagnetism inspired Hopfield networks.  A neuron correspond to an iron domain with binary magnetic moments Up and Down, and neural connections correspond to the domain's influence on each other.  Symmetric connections enable a global energy formulation. During inference the network updates each state using the standard activation step function. Symmetric weights and the right energy functions guarantees convergence to a stable activation pattern.  Asymmetric weights are difficult to analyze.  Hopfield nets are used as Content Addressable Memories (CAM).\nBoltzmann Machine\nThese are stochastic Hopfield nets. Their state value is sampled from this\npdf\nas follows: suppose a binary neuron fires with the Bernoulli probability p(1) = 1/3 and rests with p(0) = 2/3. One samples from it by taking a\nuniformly\ndistributed random number y, and plugging it into the inverted\ncumulative distribution function\n, which in this case is the step function thresholded at 2/3. The inverse function = { 0 if x <= 2/3, 1 if x > 2/3 }.\nSigmoid Belief Net\nIntroduced by Radford Neal in 1992, this network applies ideas from probabilistic graphical models to neural networks.  A key difference is that nodes in graphical models have pre-assigned meanings, whereas Belief Net neurons' features are determined after training. The network is a sparsely connected directed acyclic graph composed of binary stochastic neurons.  The learning rule comes from Maximum Likelihood on p(X):  Δw\nij\n∝\n{\\displaystyle \\propto }\ns\nj\n* (s\ni\n- p\ni\n), where p\ni\n= 1 / ( 1 + e\nweighted inputs into neuron i\n).  s\nj\n's are activations from an unbiased sample of the posterior distribution and this is problematic due to the Explaining Away problem raised by Judea Perl.\nVariational Bayesian methods\nuses a surrogate posterior and blatantly disregard this complexity.\nDeep Belief Network\nIntroduced by Hinton, this network is a hybrid of RBM and Sigmoid Belief Network.  The top 2 layers is an RBM and the second layer downwards form a sigmoid belief network.  One trains it by the\nstacked RBM\nmethod and then throw away the recognition weights below the top RBM.  As of 2009, 3-4 layers seems to be the optimal depth.\n[\n6\n]\nHelmholtz machine\nThese are early inspirations for the Variational Auto Encoders. Its 2 networks combined into one—forward weights operates recognition and backward weights implements imagination. It is perhaps the first network to do both. Helmholtz did not work in machine learning but he inspired the view of \"statistical inference engine whose function is to infer probable causes of sensory input\".\n[\n7\n]\nthe stochastic binary neuron outputs a probability that its state is 0 or 1. The data input is normally not considered a layer, but in the Helmholtz machine generation mode, the data layer receives input from the middle layer and has separate weights for this purpose, so it is considered a layer. Hence this network has 3 layers.\nVariational autoencoder\nThese are inspired by Helmholtz machines and combines probability network with neural networks. An Autoencoder is a 3-layer CAM network, where the middle layer is supposed to be some internal representation of input patterns. The encoder neural network is a probability distribution q\nφ\n(z given x) and the decoder network is p\nθ\n(x given z). The weights are named phi & theta rather than W and V as in Helmholtz—a cosmetic difference. These 2 networks here can be fully connected, or use another NN scheme.\nComparison of networks\n[\nedit\n]\nHopfield\nBoltzmann\nRBM\nStacked RBM\nHelmholtz\nAutoencoder\nVAE\nUsage & notables\nCAM, traveling salesman problem\nCAM. The freedom of connections makes this network difficult to analyze.\npattern recognition. used in MNIST digits and speech.\nrecognition & imagination.   trained with unsupervised pre-training and/or supervised fine tuning.\nimagination, mimicry\nlanguage: creative writing, translation.  vision: enhancing blurry images\ngenerate realistic data\nNeuron\ndeterministic binary state. Activation = { 0 (or -1) if x is negative, 1 otherwise }\nstochastic binary Hopfield neuron\n← same. (extended to real-valued in mid 2000s)\n← same\n← same\nlanguage: LSTM. vision: local receptive fields. usually real valued relu activation.\nmiddle layer neurons encode means & variances for Gaussians.  In run mode (inference), the output of the middle layer are sampled values from the Gaussians.\nConnections\n1-layer with symmetric weights. No self-connections.\n2-layers. 1-hidden & 1-visible. symmetric weights.\n← same.\nno lateral connections within a layer.\ntop layer is undirected, symmetric.  other layers are 2-way, asymmetric.\n3-layers: asymmetric weights. 2 networks combined into 1.\n3-layers. The input is considered a layer even though it has no inbound weights. recurrent layers for NLP. feedforward convolutions for vision. input & output have the same neuron counts.\n3-layers: input, encoder, distribution sampler decoder. the sampler is not considered a layer\nInference & energy\nEnergy is given by Gibbs probability measure :\nE\n=\n−\n1\n2\n∑\ni\n,\nj\nw\ni\nj\ns\ni\ns\nj\n+\n∑\ni\nθ\ni\ns\ni\n{\\displaystyle E=-{\\frac {1}{2}}\\sum _{i,j}{w_{ij}{s_{i}}{s_{j}}}+\\sum _{i}{\\theta _{i}}{s_{i}}}\n← same\n← same\nminimize KL divergence\ninference is only feed-forward. previous UL networks ran forwards AND backwards\nminimize error = reconstruction error - KLD\nTraining\nΔw\nij\n= s\ni\n*s\nj\n, for +1/-1 neuron\nΔw\nij\n= e*(p\nij\n- p'\nij\n). This is derived from minimizing KLD. e = learning rate, p' = predicted and p = actual distribution.\nΔw\nij\n= e*( < v\ni\nh\nj\n>\ndata\n- < v\ni\nh\nj\n>\nequilibrium\n).  This is a form of contrastive divergence w/ Gibbs Sampling.  \"<>\" are expectations.\n← similar. train 1-layer at a time.  approximate equilibrium state with a 3-segment pass.  no back propagation.\nwake-sleep 2 phase training\nback propagate the reconstruction error\nreparameterize hidden state for backprop\nStrength\nresembles physical systems so it inherits their equations\n← same. hidden neurons act as internal representatation of the external world\nfaster more practical training scheme than Boltzmann machines\ntrains quickly.  gives hierarchical layer of features\nmildly anatomical. analyzable w/ information theory & statistical mechanics\nWeakness\nhard to train due to lateral connections\nequilibrium requires too many iterations\ninteger & real-valued neurons are more complicated.\nHebbian Learning, ART, SOM\n[\nedit\n]\nThe classical example of unsupervised learning in the study of neural networks is\nDonald Hebb\n's principle, that is, neurons that fire together wire together.\n[\n8\n]\nIn\nHebbian learning\n, the connection is reinforced irrespective of an error, but is exclusively a function of the coincidence between action potentials between the two neurons.\n[\n9\n]\nA similar version that modifies synaptic weights takes into account the time between the action potentials (\nspike-timing-dependent plasticity\nor STDP). Hebbian Learning has been hypothesized to underlie a range of cognitive functions, such as\npattern recognition\nand experiential learning.\nAmong\nneural network\nmodels, the\nself-organizing map\n(SOM) and\nadaptive resonance theory\n(ART) are commonly used in unsupervised learning algorithms. The SOM is a topographic organization in which nearby locations in the map represent inputs with similar properties. The ART model allows the number of clusters to vary with problem size and lets the user control the degree of similarity between members of the same clusters by means of a user-defined constant called the vigilance parameter. ART networks are used for many pattern recognition tasks, such as\nautomatic target recognition\nand seismic signal processing.\n[\n10\n]\nProbabilistic methods\n[\nedit\n]\nTwo of the main methods used in unsupervised learning are\nprincipal component\nand\ncluster analysis\n. Cluster analysis is used in unsupervised learning to group, or segment, datasets with shared attributes in order to extrapolate algorithmic relationships.\n[\n11\n]\nCluster analysis is a branch of\nmachine learning\nthat groups the data that has not been\nlabelled\n, classified or categorized. Instead of responding to feedback, cluster analysis identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data. This approach helps detect anomalous data points that do not fit into either group.\nA central application of unsupervised learning is in the field of\ndensity estimation\nin\nstatistics\n,\n[\n12\n]\nthough unsupervised learning encompasses many other domains involving summarizing and explaining data features. It can be contrasted with supervised learning by saying that whereas supervised learning intends to infer a\nconditional probability distribution\nconditioned on the label  of input data; unsupervised learning intends to infer an\na priori probability\ndistribution .\nApproaches\n[\nedit\n]\nSome of the most common algorithms used in unsupervised learning include: (1) Clustering, (2) Anomaly detection, (3) Approaches for learning latent variable models. Each approach uses several methods as follows:\nClustering\nmethods include:\nhierarchical clustering\n,\n[\n13\n]\nk-means\n,\n[\n14\n]\nmixture models\n,\nmodel-based clustering\n,\nDBSCAN\n, and\nOPTICS algorithm\nAnomaly detection\nmethods include:\nLocal Outlier Factor\n, and\nIsolation Forest\nApproaches for learning\nlatent variable models\nsuch as\nExpectation–maximization algorithm\n(EM),\nMethod of moments\n, and\nBlind signal separation\ntechniques (Principal component analysis,\nIndependent component analysis\n,\nNon-negative matrix factorization\n,\nSingular value decomposition\n)\nMethod of moments\n[\nedit\n]\nOne of the statistical approaches for unsupervised learning is the\nmethod of moments\n. In the method of moments, the unknown parameters (of interest) in the model are related to the moments of one or more random variables, and thus, these unknown parameters can be estimated given the moments. The moments are usually estimated from samples empirically. The basic moments are first and second order moments. For a random vector, the first order moment is the\nmean\nvector, and the second order moment is the\ncovariance matrix\n(when the mean is zero). Higher order moments are usually represented using\ntensors\nwhich are the generalization of matrices to higher orders as multi-dimensional arrays.\nIn particular, the method of moments is shown to be effective in learning the parameters of\nlatent variable models\n. Latent variable models are statistical models where in addition to the observed variables, a set of latent variables also exists which is not observed. A highly practical example of latent variable models in machine learning is the\ntopic modeling\nwhich is a statistical model for generating the words (observed variables) in the document based on the topic (latent variable) of the document. In the topic modeling, the words in the document are generated according to different statistical parameters when the topic of the document is changed. It is shown that method of moments (tensor decomposition techniques) consistently recover the parameters of a large class of latent variable models under some assumptions.\n[\n15\n]\nThe\nExpectation–maximization algorithm\n(EM) is also one of the most practical methods for learning latent variable models. However, it can get stuck in local optima, and it is not guaranteed that the algorithm will converge to the true unknown parameters of the model. In contrast, for the method of moments, the global convergence is guaranteed under some conditions.\nSee also\n[\nedit\n]\nAutomated machine learning\nCluster analysis\nModel-based clustering\nAnomaly detection\nExpectation–maximization algorithm\nGenerative topographic map\nMeta-learning (computer science)\nMultivariate analysis\nRadial basis function network\nWeak supervision\nReferences\n[\nedit\n]\n^\nWu, Wei.\n\"Unsupervised Learning\"\n(PDF)\n.\nArchived\n(PDF)\nfrom the original on 14 April 2024\n. Retrieved\n26 April\n2024\n.\n^\nLiu, Xiao; Zhang, Fanjin; Hou, Zhenyu; Mian, Li; Wang, Zhaoyu; Zhang, Jing; Tang, Jie (2021). \"Self-supervised Learning: Generative or Contrastive\".\nIEEE Transactions on Knowledge and Data Engineering\n: 1.\narXiv\n:\n2006.08218\n.\ndoi\n:\n10.1109/TKDE.2021.3090866\n.\nISSN\n1041-4347\n.\n^\nRadford, Alec; Narasimhan, Karthik; Salimans, Tim; Sutskever, Ilya (11 June 2018).\n\"Improving Language Understanding by Generative Pre-Training\"\n(PDF)\n.\nOpenAI\n. p. 12.\nArchived\n(PDF)\nfrom the original on 26 January 2021\n. Retrieved\n23 January\n2021\n.\n^\nLi, Zhuohan; Wallace, Eric; Shen, Sheng; Lin, Kevin; Keutzer, Kurt; Klein, Dan; Gonzalez, Joey (2020-11-21).\n\"Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers\"\n.\nProceedings of the 37th International Conference on Machine Learning\n. PMLR:\n5958–\n5968.\n^\nHinton, G. (2012).\n\"A Practical Guide to Training Restricted Boltzmann Machines\"\n(PDF)\n.\nNeural Networks: Tricks of the Trade\n. Lecture Notes in Computer Science. Vol. 7700. Springer. pp.\n599–\n619.\ndoi\n:\n10.1007/978-3-642-35289-8_32\n.\nISBN\n978-3-642-35289-8\n.\nArchived\n(PDF)\nfrom the original on 2022-09-03\n. Retrieved\n2022-11-03\n.\n^\n\"Deep Belief Nets\"\n(video). September 2009.\nArchived\nfrom the original on 2022-03-08\n. Retrieved\n2022-03-27\n.\n^\nPeter, Dayan\n;\nHinton, Geoffrey E.\n;\nNeal, Radford M.\n;\nZemel, Richard S.\n(1995). \"The Helmholtz machine\".\nNeural Computation\n.\n7\n(5):\n889–\n904.\ndoi\n:\n10.1162/neco.1995.7.5.889\n.\nhdl\n:\n21.11116/0000-0002-D6D3-E\n.\nPMID\n7584891\n.\nS2CID\n1890561\n.\n^\nBuhmann, J.; Kuhnel, H. (1992). \"Unsupervised and supervised data clustering with competitive neural networks\".\n[Proceedings 1992] IJCNN International Joint Conference on Neural Networks\n. Vol. 4. IEEE. pp.\n796–\n801.\ndoi\n:\n10.1109/ijcnn.1992.227220\n.\nISBN\n0780305590\n.\nS2CID\n62651220\n.\n^\nComesaña-Campos, Alberto; Bouza-Rodríguez, José Benito (June 2016). \"An application of Hebbian learning in the design process decision-making\".\nJournal of Intelligent Manufacturing\n.\n27\n(3):\n487–\n506.\ndoi\n:\n10.1007/s10845-014-0881-z\n.\nISSN\n0956-5515\n.\nS2CID\n207171436\n.\n^\nCarpenter, G.A. & Grossberg, S. (1988).\n\"The ART of adaptive pattern recognition by a self-organizing neural network\"\n(PDF)\n.\nComputer\n.\n21\n(3):\n77–\n88.\ndoi\n:\n10.1109/2.33\n.\nS2CID\n14625094\n. Archived from\nthe original\n(PDF)\non 2018-05-16\n. Retrieved\n2013-09-16\n.\n^\nRoman, Victor (2019-04-21).\n\"Unsupervised Machine Learning: Clustering Analysis\"\n.\nMedium\n.\nArchived\nfrom the original on 2020-08-21\n. Retrieved\n2019-10-01\n.\n^\nJordan, Michael I.; Bishop, Christopher M. (2004). \"7. Intelligent Systems §Neural Networks\". In Tucker, Allen B. (ed.).\nComputer Science Handbook\n(2nd ed.). Chapman & Hall/CRC Press.\ndoi\n:\n10.1201/9780203494455\n.\nISBN\n1-58488-360-X\n.\nArchived\nfrom the original on 2022-11-03\n. Retrieved\n2022-11-03\n.\n^\nHastie, Tibshirani & Friedman 2009\n, pp. 485–586\n^\nGarbade, Dr Michael J. (2018-09-12).\n\"Understanding K-means Clustering in Machine Learning\"\n.\nMedium\n.\nArchived\nfrom the original on 2019-05-28\n. Retrieved\n2019-10-31\n.\n^\nAnandkumar, Animashree; Ge, Rong; Hsu, Daniel; Kakade, Sham; Telgarsky, Matus (2014).\n\"Tensor Decompositions for Learning Latent Variable Models\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n15\n:\n2773–\n2832.\narXiv\n:\n1210.7559\n.\nBibcode\n:\n2012arXiv1210.7559A\n.\nArchived\n(PDF)\nfrom the original on 2015-03-20\n. Retrieved\n2015-04-10\n.\nFurther reading\n[\nedit\n]\nBousquet, O.;\nvon Luxburg, U.\n; Raetsch, G., eds. (2004).\nAdvanced Lectures on Machine Learning\n. Springer.\nISBN\n978-3540231226\n.\nDuda, Richard O.\n;\nHart, Peter E.\n; Stork, David G. (2001). \"Unsupervised Learning and Clustering\".\nPattern classification\n(2nd ed.). Wiley.\nISBN\n0-471-05669-3\n.\nHastie, Trevor\n;\nTibshirani, Robert\n; Friedman, Jerome (2009).\n\"Unsupervised Learning\"\n.\nThe Elements of Statistical Learning: Data mining, Inference, and Prediction\n. Springer. pp.\n485–\n586.\ndoi\n:\n10.1007/978-0-387-84858-7_14\n.\nISBN\n978-0-387-84857-0\n.\nArchived\nfrom the original on 2022-11-03\n. Retrieved\n2022-11-03\n.\nHinton, Geoffrey\n;\nSejnowski, Terrence J.\n, eds. (1999).\nUnsupervised Learning: Foundations of Neural Computation\n.\nMIT Press\n.\nISBN\n0-262-58168-X\n.\nv\nt\ne\nDifferentiable computing\nGeneral\nDifferentiable programming\nInformation geometry\nStatistical manifold\nAutomatic differentiation\nNeuromorphic computing\nPattern recognition\nRicci calculus\nComputational learning theory\nInductive bias\nHardware\nIPU\nTPU\nVPU\nMemristor\nSpiNNaker\nSoftware libraries\nTensorFlow\nPyTorch\nKeras\nscikit-learn\nTheano\nJAX\nFlux.jl\nMindSpore\nPortals\nComputer programming\nTechnology\nAuthority control databases\nGND\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Unsupervised_learning&oldid=1326538062\n\"\nCategory\n:\nUnsupervised learning\nHidden categories:\nArticles with short description\nShort description is different from Wikidata\nThis page was last edited on 9 December 2025, at 14:00\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nUnsupervised learning\n33 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:25:41.593514",
      "status": "success",
      "content_length": 29608,
      "topic": "machine_learning"
    },
    {
      "title": "Reinforcement learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
      "content": "Reinforcement learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nPrinciples\n2\nExploration\n3\nAlgorithms for control learning\nToggle Algorithms for control learning subsection\n3.1\nCriterion of optimality\n3.1.1\nPolicy\n3.1.2\nState-value function\n3.2\nBrute force\n3.3\nValue function\n3.3.1\nMonte Carlo methods\n3.3.2\nTemporal difference methods\n3.3.3\nFunction approximation methods\n3.4\nDirect policy search\n3.5\nModel-based algorithms\n4\nTheory\n5\nResearch\n6\nComparison of key algorithms\nToggle Comparison of key algorithms subsection\n6.1\nAssociative reinforcement learning\n6.2\nDeep reinforcement learning\n6.3\nAdversarial deep reinforcement learning\n6.4\nFuzzy reinforcement learning\n6.5\nInverse reinforcement learning\n6.6\nMulti-objective reinforcement learning\n6.7\nSafe reinforcement learning\n6.8\nSelf-reinforcement learning\n6.9\nReinforcement Learning in Natural Language Processing\n7\nStatistical comparison of reinforcement learning algorithms\n8\nChallenges and Limitations\nToggle Challenges and Limitations subsection\n8.1\nSample Inefficiency\n8.2\nStability and Convergence Issues\n8.3\nGeneralization and Transferability\n8.4\nBias and Reward Function Issues\n9\nSee also\n10\nReferences\n11\nFurther reading\n12\nExternal links\nToggle the table of contents\nReinforcement learning\n39 languages\nالعربية\nবাংলা\nБългарски\nBosanski\nCatalà\nČeština\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEuskara\nفارسی\nFrançais\n한국어\nՀայերեն\nBahasa Indonesia\nItaliano\nעברית\nBahasa Melayu\nNederlands\n日本語\nNorsk bokmål\nଓଡ଼ିଆ\nPolski\nPortuguês\nRuna Simi\nРусский\nSimple English\nSlovenščina\nکوردی\nСрпски / srpski\nSuomi\nSvenska\nTürkçe\nУкраїнська\nTiếng Việt\n吴语\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nField of machine learning\nFor reinforcement learning in psychology, see\nReinforcement\nand\nOperant conditioning\n.\nThe typical framing of a reinforcement learning (RL) scenario: an agent takes actions in an environment, which is interpreted into a reward and a state representation, which are fed back to the agent.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nIn\nmachine learning\nand\noptimal control\n,\nreinforcement learning\n(\nRL\n) is concerned with how an\nintelligent agent\nshould\ntake actions\nin a dynamic environment in order to\nmaximize a reward\nsignal. Reinforcement learning is one of the\nthree basic machine learning paradigms\n, alongside\nsupervised learning\nand\nunsupervised learning\n.\nWhile supervised learning and unsupervised learning algorithms respectively attempt to discover patterns in labeled and unlabeled data, reinforcement learning involves training an agent through interactions with its environment. To learn to maximize rewards from these interactions, the agent makes decisions between trying new actions to learn more about the environment (exploration), or using current knowledge of the environment to take the best action (exploitation).\n[\n1\n]\nThe search for the optimal balance between these two strategies is known as the\nexploration–exploitation dilemma\n.\nThe environment is typically stated in the form of a\nMarkov decision process\n, as many reinforcement learning algorithms use\ndynamic programming\ntechniques.\n[\n2\n]\nThe main difference between classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process, and they target large Markov decision processes where exact methods become infeasible.\n[\n3\n]\nPrinciples\n[\nedit\n]\nDue to its generality, reinforcement learning is studied in many disciplines, such as\ngame theory\n,\ncontrol theory\n,\noperations research\n,\ninformation theory\n,\nsimulation-based optimization\n,\nmulti-agent systems\n,\nswarm intelligence\n, and\nstatistics\n. In the operations research and control literature, RL is called\napproximate dynamic programming\n, or\nneuro-dynamic programming.\nThe problems of interest in RL have also been studied in the\ntheory of optimal control\n, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation (particularly in the absence of a mathematical model of the environment).\nBasic reinforcement learning is modeled as a\nMarkov decision process\n:\nA set of environment and agent states (the state space),\nS\n{\\displaystyle {\\mathcal {S}}}\n;\nA set of actions (the action space),\nA\n{\\displaystyle {\\mathcal {A}}}\n, of the agent;\nP\na\n(\ns\n,\ns\n′\n)\n=\nPr\n(\nS\nt\n+\n1\n=\ns\n′\n∣\nS\nt\n=\ns\n,\nA\nt\n=\na\n)\n{\\displaystyle P_{a}(s,s')=\\Pr(S_{t+1}{=}s'\\mid S_{t}{=}s,A_{t}{=}a)}\n, the transition probability (at time\nt\n{\\displaystyle t}\n) from state\ns\n{\\displaystyle s}\nto state\ns\n′\n{\\displaystyle s'}\nunder action\na\n{\\displaystyle a}\n.\nR\na\n(\ns\n,\ns\n′\n)\n{\\displaystyle R_{a}(s,s')}\n, the immediate reward after transitioning from\ns\n{\\displaystyle s}\nto\ns\n′\n{\\displaystyle s'}\nunder action\na\n{\\displaystyle a}\n.\nThe purpose of reinforcement learning is for the agent to learn an optimal (or near-optimal) policy that maximizes the reward function or other user-provided reinforcement signal that accumulates from immediate rewards. This is similar to\nprocesses\nthat appear to occur in animal psychology. For example, biological brains are hardwired to interpret signals such as pain and hunger as negative reinforcements, and interpret pleasure and food intake as positive reinforcements. In some circumstances, animals learn to adopt behaviors that optimize these rewards. This suggests that animals are capable of reinforcement learning.\n[\n4\n]\n[\n5\n]\nA basic reinforcement learning agent interacts with its environment in discrete time steps. At each time step\nt\n, the agent receives the current state\nS\nt\n{\\displaystyle S_{t}}\nand reward\nR\nt\n{\\displaystyle R_{t}}\n. It then chooses an action\nA\nt\n{\\displaystyle A_{t}}\nfrom the set of available actions, which is subsequently sent to the environment. The environment moves to a new state\nS\nt\n+\n1\n{\\displaystyle S_{t+1}}\nand the reward\nR\nt\n+\n1\n{\\displaystyle R_{t+1}}\nassociated with the\ntransition\n(\nS\nt\n,\nA\nt\n,\nS\nt\n+\n1\n)\n{\\displaystyle (S_{t},A_{t},S_{t+1})}\nis determined. The goal of a reinforcement learning agent is to learn a\npolicy\n:\nπ\n:\nS\n×\nA\n→\n[\n0\n,\n1\n]\nπ\n(\ns\n,\na\n)\n=\nPr\n(\nA\nt\n=\na\n∣\nS\nt\n=\ns\n)\n{\\displaystyle {\\begin{aligned}&\\pi :{\\mathcal {S}}\\times {\\mathcal {A}}\\to [0,1]\\\\&\\pi (s,a)=\\Pr(A_{t}{=}a\\mid S_{t}{=}s)\\end{aligned}}}\nthat maximizes the expected cumulative reward.\nFormulating the problem as a Markov decision process assumes the agent directly observes the current environmental state; in this case, the problem is said to have\nfull observability\n. If the agent only has access to a subset of states, or if the observed states are corrupted by noise, the agent is said to have\npartial observability\n, and formally the problem must be formulated as a\npartially observable Markov decision process\n. In both cases, the set of actions available to the agent can be restricted. For example, the state of an account balance could be restricted to be positive; if the current value of the state is 3 and the state transition attempts to reduce the value by 4, the transition will not be allowed.\nWhen the agent's performance is compared to that of an agent that acts optimally, the difference in performance yields the notion of\nregret\n. In order to act near optimally, the agent must reason about long-term consequences of its actions (i.e., maximize future rewards), although the immediate reward associated with this might be negative.\nThus, reinforcement learning is particularly well-suited to problems that include a long-term versus short-term reward trade-off. It has been applied successfully to various problems, including\nenergy storage\n,\n[\n6\n]\nrobot control\n,\n[\n7\n]\nphotovoltaic generators\n,\n[\n8\n]\nbackgammon\n,\ncheckers\n,\n[\n9\n]\nGo\n(\nAlphaGo\n), and\nautonomous driving systems\n.\n[\n10\n]\nTwo elements make reinforcement learning powerful: the use of samples to optimize performance, and the use of\nfunction approximation\nto deal with large environments. Thanks to these two key components, RL can be used in large environments in the following situations:\nA model of the environment is known, but an\nanalytic solution\nis not available;\nOnly a simulation model of the environment is given (the subject of\nsimulation-based optimization\n);\n[\n11\n]\nThe only way to collect information about the environment is to interact with it.\nThe first two of these problems could be considered planning problems (since some form of model is available), while the last one could be considered to be a genuine learning problem. However, reinforcement learning converts both planning problems to\nmachine learning\nproblems.\nExploration\n[\nedit\n]\nThe\ntrade-off between exploration and exploitation\nhas been most thoroughly studied through the\nmulti-armed bandit\nproblem and for finite state space Markov decision processes in Burnetas and Katehakis (1997).\n[\n12\n]\nReinforcement learning requires clever exploration mechanisms; randomly selecting actions, without reference to an estimated probability distribution, shows poor performance. The case of (small) finite Markov decision processes is relatively well understood. However, due to the lack of algorithms that scale well with the number of states (or scale to problems with infinite state spaces), simple exploration methods are the most practical.\nOne such method is\nε\n{\\displaystyle \\varepsilon }\n-greedy, where\n0\n<\nε\n<\n1\n{\\displaystyle 0<\\varepsilon <1}\nis a parameter controlling the amount of exploration vs. exploitation. With probability\n1\n−\nε\n{\\displaystyle 1-\\varepsilon }\n, exploitation is chosen, and the agent chooses the action that it believes has the best long-term effect (ties between actions are broken uniformly at random). Alternatively, with probability\nε\n{\\displaystyle \\varepsilon }\n, exploration is chosen, and the action is chosen uniformly at random.\nε\n{\\displaystyle \\varepsilon }\nis usually a fixed parameter but can be adjusted either according to a schedule (making the agent explore progressively less), or adaptively based on heuristics.\n[\n13\n]\nAlgorithms for control learning\n[\nedit\n]\nEven if the issue of exploration is disregarded and even if the state was observable (assumed hereafter), the problem remains to use past experience to find out which actions lead to higher cumulative rewards.\nCriterion of optimality\n[\nedit\n]\nPolicy\n[\nedit\n]\nThe agent's action selection is modeled as a map called\npolicy\n:\nπ\n:\nA\n×\nS\n→\n[\n0\n,\n1\n]\nπ\n(\na\n,\ns\n)\n=\nPr\n(\nA\nt\n=\na\n∣\nS\nt\n=\ns\n)\n{\\displaystyle {\\begin{aligned}&\\pi :{\\mathcal {A}}\\times {\\mathcal {S}}\\to [0,1]\\\\&\\pi (a,s)=\\Pr(A_{t}{=}a\\mid S_{t}{=}s)\\end{aligned}}}\nThe policy map gives the probability of taking action\na\n{\\displaystyle a}\nwhen in state\ns\n{\\displaystyle s}\n.\n[\n14\n]\n: 61\nThere are also deterministic policies\nπ\n{\\displaystyle \\pi }\nfor which\nπ\n(\ns\n)\n{\\displaystyle \\pi (s)}\ndenotes the action that should be played at state\ns\n{\\displaystyle s}\n.\nState-value function\n[\nedit\n]\nThe state-value function\nV\nπ\n(\ns\n)\n{\\displaystyle V_{\\pi }(s)}\nis defined as,\nexpected discounted return\nstarting with state\ns\n{\\displaystyle s}\n, i.e.\nS\n0\n=\ns\n{\\displaystyle S_{0}=s}\n, and successively following policy\nπ\n{\\displaystyle \\pi }\n. Hence, roughly speaking, the value function estimates \"how good\" it is to be in a given state.\n[\n14\n]\n: 60\nV\nπ\n(\ns\n)\n=\nE\n⁡\n[\nG\n∣\nS\n0\n=\ns\n]\n=\nE\n⁡\n[\n∑\nt\n=\n0\n∞\nγ\nt\nR\nt\n+\n1\n∣\nS\n0\n=\ns\n]\n,\n{\\displaystyle V_{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid S_{0}{=}s]=\\operatorname {\\mathbb {E} } \\left[\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}\\mid S_{0}{=}s\\right],}\nwhere the random variable\nG\n{\\displaystyle G}\ndenotes the\ndiscounted return\n, and is defined as the sum of future discounted rewards:\nG\n=\n∑\nt\n=\n0\n∞\nγ\nt\nR\nt\n+\n1\n=\nR\n1\n+\nγ\nR\n2\n+\nγ\n2\nR\n3\n+\n⋯\n,\n{\\displaystyle G=\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}=R_{1}+\\gamma R_{2}+\\gamma ^{2}R_{3}+\\cdots ,}\nwhere\nR\nt\n+\n1\n{\\displaystyle R_{t+1}}\nis the reward for transitioning from state\nS\nt\n{\\displaystyle S_{t}}\nto\nS\nt\n+\n1\n{\\displaystyle S_{t+1}}\n,\n0\n≤\nγ\n<\n1\n{\\displaystyle 0\\leq \\gamma <1}\nis the\ndiscount rate\n.\nγ\n{\\displaystyle \\gamma }\nis less than 1, so rewards in the distant future are weighted less than rewards in the immediate future.\nThe algorithm must find a policy with maximum expected discounted return. From the theory of Markov decision processes it is known that, without loss of generality, the search can be restricted to the set of so-called\nstationary\npolicies. A policy is\nstationary\nif the action-distribution returned by it depends only on the last state visited (from the observation agent's history). The search can be further restricted to\ndeterministic\nstationary policies. A\ndeterministic stationary\npolicy deterministically selects actions based on the current state. Since any such policy can be identified with a mapping from the set of states to the set of actions, these policies can be identified with such mappings with no loss of generality.\nBrute force\n[\nedit\n]\nThe\nbrute force\napproach entails two steps:\nFor each possible policy, sample returns while following it\nChoose the policy with the largest expected discounted return\nOne problem with this is that the number of policies can be large, or even infinite. Another is that the variance of the returns may be large, which requires many samples to accurately estimate the discounted return of each policy.\nThese problems can be ameliorated if we assume some structure and allow samples generated from one policy to influence the estimates made for others. The two main approaches for achieving this are\nvalue function estimation\nand\ndirect policy search\n.\nValue function\n[\nedit\n]\nSee also:\nValue function\nValue function approaches attempt to find a policy that maximizes the discounted return by maintaining a set of estimates of expected discounted returns\nE\n⁡\n[\nG\n]\n{\\displaystyle \\operatorname {\\mathbb {E} } [G]}\nfor some policy (usually either the \"current\" [on-policy] or the optimal [off-policy] one).\nThese methods rely on the theory of Markov decision processes, where optimality is defined in a sense stronger than the one above: A policy is optimal if it achieves the best-expected discounted return from\nany\ninitial state (i.e., initial distributions play no role in this definition). Again, an optimal policy can always be found among stationary policies.\nTo define optimality in a formal manner, define the state-value of a policy\nπ\n{\\displaystyle \\pi }\nby\nV\nπ\n(\ns\n)\n=\nE\n⁡\n[\nG\n∣\ns\n,\nπ\n]\n,\n{\\displaystyle V^{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid s,\\pi ],}\nwhere\nG\n{\\displaystyle G}\nstands for the discounted return associated with following\nπ\n{\\displaystyle \\pi }\nfrom the initial state\ns\n{\\displaystyle s}\n. Defining\nV\n∗\n(\ns\n)\n{\\displaystyle V^{*}(s)}\nas the maximum possible state-value of\nV\nπ\n(\ns\n)\n{\\displaystyle V^{\\pi }(s)}\n, where\nπ\n{\\displaystyle \\pi }\nis allowed to change,\nV\n∗\n(\ns\n)\n=\nmax\nπ\nV\nπ\n(\ns\n)\n.\n{\\displaystyle V^{*}(s)=\\max _{\\pi }V^{\\pi }(s).}\nA policy that achieves these optimal state-values in each state is called\noptimal\n. Clearly, a policy that is optimal in this sense is also optimal in the sense that it maximizes the expected discounted return, since\nV\n∗\n(\ns\n)\n=\nmax\nπ\nE\n[\nG\n∣\ns\n,\nπ\n]\n{\\displaystyle V^{*}(s)=\\max _{\\pi }\\mathbb {E} [G\\mid s,\\pi ]}\n, where\ns\n{\\displaystyle s}\nis a state randomly sampled from the distribution\nμ\n{\\displaystyle \\mu }\nof initial states (so\nμ\n(\ns\n)\n=\nPr\n(\nS\n0\n=\ns\n)\n{\\displaystyle \\mu (s)=\\Pr(S_{0}=s)}\n).\nAlthough state-values suffice to define optimality, it is useful to define action-values. Given a state\ns\n{\\displaystyle s}\n, an action\na\n{\\displaystyle a}\nand a policy\nπ\n{\\displaystyle \\pi }\n, the action-value of the pair\n(\ns\n,\na\n)\n{\\displaystyle (s,a)}\nunder\nπ\n{\\displaystyle \\pi }\nis defined by\nQ\nπ\n(\ns\n,\na\n)\n=\nE\n⁡\n[\nG\n∣\ns\n,\na\n,\nπ\n]\n,\n{\\displaystyle Q^{\\pi }(s,a)=\\operatorname {\\mathbb {E} } [G\\mid s,a,\\pi ],}\nwhere\nG\n{\\displaystyle G}\nnow stands for the random discounted return associated with first taking action\na\n{\\displaystyle a}\nin state\ns\n{\\displaystyle s}\nand following\nπ\n{\\displaystyle \\pi }\n, thereafter.\nThe theory of Markov decision processes states that if\nπ\n∗\n{\\displaystyle \\pi ^{*}}\nis an optimal policy, we act optimally (take the optimal action) by choosing the action from\nQ\nπ\n∗\n(\ns\n,\n⋅\n)\n{\\displaystyle Q^{\\pi ^{*}}(s,\\cdot )}\nwith the highest action-value at each state,\ns\n{\\displaystyle s}\n. The\naction-value function\nof such an optimal policy (\nQ\nπ\n∗\n{\\displaystyle Q^{\\pi ^{*}}}\n) is called the\noptimal action-value function\nand is commonly denoted by\nQ\n∗\n{\\displaystyle Q^{*}}\n. In summary, the knowledge of the optimal action-value function alone suffices to know how to act optimally.\nAssuming full knowledge of the Markov decision process, the two basic approaches to compute the optimal action-value function are\nvalue iteration\nand\npolicy iteration\n. Both algorithms compute a sequence of functions\nQ\nk\n{\\displaystyle Q_{k}}\n(\nk\n=\n0\n,\n1\n,\n2\n,\n…\n{\\displaystyle k=0,1,2,\\ldots }\n) that converge to\nQ\n∗\n{\\displaystyle Q^{*}}\n. Computing these functions involves computing expectations over the whole state-space, which is impractical for all but the smallest (finite) Markov decision processes. In reinforcement learning methods, expectations are approximated by averaging over samples and using function approximation techniques to cope with the need to represent value functions over large state-action spaces.\nMonte Carlo methods\n[\nedit\n]\nMonte Carlo methods\n[\n15\n]\nare used to solve reinforcement learning problems by averaging sample returns. Unlike methods that require full knowledge of the environment's dynamics, Monte Carlo methods rely solely on actual or\nsimulated\nexperience—sequences of states, actions, and rewards obtained from interaction with an environment. This makes them applicable in situations where the complete dynamics are unknown. Learning from actual experience does not require prior knowledge of the environment and can still lead to optimal behavior. When using simulated experience, only a model capable of generating sample transitions is required, rather than a full specification of\ntransition probabilities\n, which is necessary for\ndynamic programming\nmethods.\nMonte Carlo methods apply to episodic tasks, where experience is divided into episodes that eventually terminate. Policy and value function updates occur only after the completion of an episode, making these methods incremental on an episode-by-episode basis, though not on a step-by-step (online) basis. The term \"Monte Carlo\" generally refers to any method involving\nrandom sampling\n; however, in this context, it specifically refers to methods that compute averages from\ncomplete\nreturns, rather than\npartial\nreturns.\nThese methods function similarly to the\nbandit algorithms\n, in which returns are averaged for each state-action pair. The key difference is that actions taken in one state affect the returns of subsequent states within the same episode, making the problem\nnon-stationary\n. To address this non-stationarity, Monte Carlo methods use the framework of general policy iteration (GPI). While dynamic programming computes\nvalue functions\nusing full knowledge of the Markov decision process, Monte Carlo methods learn these functions through sample returns. The value functions and policies interact similarly to dynamic programming to achieve\noptimality\n, first addressing the prediction problem and then extending to policy improvement and control, all based on sampled experience.\n[\n14\n]\nTemporal difference methods\n[\nedit\n]\nMain article:\nTemporal difference learning\nThe first problem is corrected by allowing the procedure to change the policy (at some or all states) before the values settle. This too may be problematic as it might prevent convergence. Most current algorithms do this, giving rise to the class of\ngeneralized policy iteration\nalgorithms. Many\nactor-critic\nmethods\nbelong to this category.\nThe second issue can be corrected by allowing trajectories to contribute to any state-action pair in them. This may also help to some extent with the third problem, although a better solution when returns have high variance is Sutton's\ntemporal difference\n(TD) methods that are based on the recursive\nBellman equation\n.\n[\n16\n]\n[\n17\n]\nThe computation in TD methods can be incremental (when after each transition the memory is changed and the transition is thrown away), or batch (when the transitions are batched and the estimates are computed once based on the batch). Batch methods, such as the least-squares temporal difference method,\n[\n18\n]\nmay use the information in the samples better, while incremental methods are the only choice when batch methods are infeasible due to their high computational or memory complexity. Some methods try to combine the two approaches. Methods based on temporal differences also overcome the fourth issue.\nAnother problem specific to TD comes from their reliance on the recursive Bellman equation. Most TD methods have a so-called\nλ\n{\\displaystyle \\lambda }\nparameter\n(\n0\n≤\nλ\n≤\n1\n)\n{\\displaystyle (0\\leq \\lambda \\leq 1)}\nthat can continuously interpolate between Monte Carlo methods that do not rely on the Bellman equations and the basic TD methods that rely entirely on the Bellman equations. This can be effective in palliating this issue.\nFunction approximation methods\n[\nedit\n]\nIn order to address the fifth issue,\nfunction approximation methods\nare used.\nLinear function approximation\nstarts with a mapping\nϕ\n{\\displaystyle \\phi }\nthat assigns a finite-dimensional vector to each state-action pair. Then, the action values of a state-action pair\n(\ns\n,\na\n)\n{\\displaystyle (s,a)}\nare obtained by linearly combining the components of\nϕ\n(\ns\n,\na\n)\n{\\displaystyle \\phi (s,a)}\nwith some\nweights\nθ\n{\\displaystyle \\theta }\n:\nQ\n(\ns\n,\na\n)\n=\n∑\ni\n=\n1\nd\nθ\ni\nϕ\ni\n(\ns\n,\na\n)\n.\n{\\displaystyle Q(s,a)=\\sum _{i=1}^{d}\\theta _{i}\\phi _{i}(s,a).}\nThe algorithms then adjust the weights, instead of adjusting the values associated with the individual state-action pairs. Methods based on ideas from\nnonparametric statistics\n(which can be seen to construct their own features) have been explored.\nValue iteration can also be used as a starting point, giving rise to the\nQ-learning\nalgorithm and its many variants.\n[\n19\n]\nIncluding Deep Q-learning methods when a neural network is used to represent Q, with various applications in stochastic search problems.\n[\n20\n]\nThe problem with using action-values is that they may need highly precise estimates of the competing action values that can be hard to obtain when the returns are noisy, though this problem is mitigated to some extent by temporal difference methods. Using the so-called compatible function approximation method compromises generality and efficiency.\nDirect policy search\n[\nedit\n]\nAn alternative method is to search directly in (some subset of) the policy space, in which case the problem becomes a case of\nstochastic optimization\n. The two approaches available are gradient-based and gradient-free methods.\nGradient\n-based methods (\npolicy gradient methods\n) start with a mapping from a finite-dimensional (parameter) space to the space of policies: given the parameter vector\nθ\n{\\displaystyle \\theta }\n, let\nπ\nθ\n{\\displaystyle \\pi _{\\theta }}\ndenote the policy associated to\nθ\n{\\displaystyle \\theta }\n. Defining the performance function by\nρ\n(\nθ\n)\n=\nρ\nπ\nθ\n{\\displaystyle \\rho (\\theta )=\\rho ^{\\pi _{\\theta }}}\nunder mild conditions this function will be differentiable as a function of the parameter vector\nθ\n{\\displaystyle \\theta }\n. If the gradient of\nρ\n{\\displaystyle \\rho }\nwas known, one could use\ngradient ascent\n. Since an analytic expression for the gradient is not available, only a noisy estimate is available. Such an estimate can be constructed in many ways, giving rise to algorithms such as Williams's REINFORCE method\n[\n21\n]\n(which is known as the likelihood ratio method in the\nsimulation-based optimization\nliterature).\n[\n22\n]\nA large class of methods avoids relying on gradient information. These include\nsimulated annealing\n,\ncross-entropy search\nor methods of\nevolutionary computation\n. Many gradient-free methods can achieve (in theory and in the limit) a global optimum.\nPolicy search methods may converge slowly given noisy data. For example, this happens in episodic problems when the trajectories are long and the variance of the returns is large. Value-function based methods that rely on temporal differences might help in this case. In recent years,\nactor–critic methods\nhave been proposed and performed well on various problems.\n[\n23\n]\nPolicy search methods have been used in the\nrobotics\ncontext.\n[\n24\n]\nMany policy search methods may get stuck in local optima (as they are based on\nlocal search\n).\nModel-based algorithms\n[\nedit\n]\nFinally, all of the above methods can be combined with algorithms that first learn a model of the\nMarkov decision process\n, the probability of each next state given an action taken from an existing state. For instance, the Dyna algorithm learns a model from experience, and uses that to provide more modelled transitions for a value function, in addition to the real transitions.\n[\n25\n]\nSuch methods can sometimes be extended to use of non-parametric models, such as when the transitions are simply stored and \"replayed\" to the learning algorithm.\n[\n26\n]\nModel-based methods can be more computationally intensive than model-free approaches, and their utility can be limited by the extent to which the Markov decision process can be learnt.\n[\n27\n]\nThere are other ways to use models than to update a value function.\n[\n28\n]\nFor instance, in\nmodel predictive control\nthe model is used to update the behavior directly.\nTheory\n[\nedit\n]\nBoth the asymptotic and finite-sample behaviors of most algorithms are well understood. Algorithms with provably good online performance (addressing the exploration issue) are known.\nEfficient exploration of Markov decision processes is given in Burnetas and Katehakis (1997).\n[\n12\n]\nFinite-time performance bounds have also appeared for many algorithms, but these bounds are expected to be rather loose and thus more work is needed to better understand the relative advantages and limitations.\nFor incremental algorithms, asymptotic convergence issues have been settled.\n[\nclarification needed\n]\nTemporal-difference-based algorithms converge under a wider set of conditions than was previously possible (for example, when used with arbitrary, smooth function approximation).\nResearch\n[\nedit\n]\nThis section\nneeds additional citations for\nverification\n.\nPlease help\nimprove this article\nby\nadding citations to reliable sources\nin this section. Unsourced material may be challenged and removed.\n(\nOctober 2022\n)\n(\nLearn how and when to remove this message\n)\nResearch topics include:\nactor-critic architecture\n[\n29\n]\nactor-critic-scenery architecture\n[\n3\n]\nadaptive methods that work with fewer (or no) parameters under a large number of conditions\nbug detection in software projects\n[\n30\n]\ncontinuous learning\ncombinations with logic-based frameworks (e.g., temporal-logic specifications,\n[\n31\n]\nreward machines,\n[\n32\n]\nand probabilistic argumentation).\n[\n33\n]\nexploration in large Markov decision processes\nentity-based reinforcement learning\n[\n34\n]\n[\n35\n]\n[\n36\n]\nhuman feedback\n[\n37\n]\ninteraction between implicit and explicit learning in skill acquisition\nintrinsic motivation\nwhich differentiates information-seeking, curiosity-type behaviours from task-dependent goal-directed behaviours large-scale empirical evaluations\nlarge (or continuous) action spaces\nmodular and hierarchical reinforcement learning\n[\n38\n]\nmultiagent/distributed reinforcement learning is a topic of interest. Applications are expanding.\n[\n39\n]\noccupant-centric control\noptimization of computing resources\n[\n40\n]\n[\n41\n]\n[\n42\n]\npartial information\n(e.g., using\npredictive state representation\n)\nreward function based on maximising novel information\n[\n43\n]\n[\n44\n]\n[\n45\n]\nsample-based planning (e.g., based on\nMonte Carlo tree search\n).\nsecurities trading\n[\n46\n]\ntransfer learning\n[\n47\n]\nTD learning modeling\ndopamine\n-based learning in the brain.\nDopaminergic\nprojections from the\nsubstantia nigra\nto the\nbasal ganglia\nfunction are the prediction error.\nvalue-function and policy search methods\nComparison of key algorithms\n[\nedit\n]\nThe following table lists the key algorithms for learning a policy depending on several criteria:\nThe algorithm can be on-policy (it performs policy updates using trajectories sampled via the current policy)\n[\n48\n]\nor off-policy.\nThe action space may be discrete (e.g. the action space could be \"going up\", \"going left\", \"going right\", \"going down\", \"stay\") or continuous (e.g. moving the arm with a given angle).\nThe state space may be discrete (e.g. the agent could be in a cell in a grid) or continuous (e.g. the agent could be located at a given position in the plane).\nAlgorithm\nDescription\nPolicy\nAction space\nState space\nOperator\nMonte Carlo\nEvery visit to Monte Carlo\nEither\nDiscrete\nDiscrete\nSample-means of state-values or action-values\nTD learning\nState–action–reward–state\nOff-policy\nDiscrete\nDiscrete\nState-value\nQ-learning\nState–action–reward–state\nOff-policy\nDiscrete\nDiscrete\nAction-value\nSARSA\nState–action–reward–state–action\nOn-policy\nDiscrete\nDiscrete\nAction-value\nDQN\nDeep Q Network\nOff-policy\nDiscrete\nContinuous\nAction-value\nDDPG\nDeep Deterministic Policy Gradient\nOff-policy\nContinuous\nContinuous\nAction-value\nA3C\nAsynchronous Advantage Actor-Critic Algorithm\nOn-policy\nDiscrete\nContinuous\nAdvantage (=action-value - state-value)\nTRPO\nTrust Region Policy Optimization\nOn-policy\nContinuous or Discrete\nContinuous\nAdvantage\nPPO\nProximal Policy Optimization\nOn-policy\nContinuous or Discrete\nContinuous\nAdvantage\nTD3\nTwin Delayed Deep Deterministic Policy Gradient\nOff-policy\nContinuous\nContinuous\nAction-value\nSAC\nSoft Actor-Critic\nOff-policy\nContinuous\nContinuous\nAdvantage\nDSAC\n[\n49\n]\n[\n50\n]\n[\n51\n]\nDistributional Soft Actor Critic\nOff-policy\nContinuous\nContinuous\nAction-value distribution\nAssociative reinforcement learning\n[\nedit\n]\nAssociative reinforcement learning tasks combine facets of stochastic learning automata tasks and supervised learning pattern classification tasks. In associative reinforcement learning tasks, the learning system interacts in a closed loop with its environment.\n[\n52\n]\nDeep reinforcement learning\n[\nedit\n]\nThis approach extends reinforcement learning by using a deep neural network and without explicitly designing the state space.\n[\n53\n]\nThe work on learning ATARI games by Google\nDeepMind\nincreased attention to\ndeep reinforcement learning\nor\nend-to-end reinforcement learning\n.\n[\n54\n]\nAdversarial deep reinforcement learning\n[\nedit\n]\nAdversarial deep reinforcement learning is an active area of research in reinforcement learning focusing on vulnerabilities of learned policies. In this research area some studies initially showed that reinforcement learning policies are susceptible to imperceptible adversarial manipulations.\n[\n55\n]\n[\n56\n]\n[\n57\n]\nWhile some methods have been proposed to overcome these susceptibilities, in the most recent studies it has been shown that these proposed solutions are far from providing an accurate representation of current vulnerabilities of deep reinforcement learning policies.\n[\n58\n]\nFuzzy reinforcement learning\n[\nedit\n]\nBy introducing\nfuzzy inference\nin reinforcement learning,\n[\n59\n]\napproximating the state-action value function with\nfuzzy rules\nin continuous space becomes possible. The IF - THEN form of fuzzy rules make this approach suitable for expressing the results in a form close to natural language. Extending FRL with Fuzzy Rule Interpolation\n[\n60\n]\nallows the use of reduced size sparse fuzzy rule-bases to emphasize cardinal rules (most important state-action values).\nInverse reinforcement learning\n[\nedit\n]\nIn inverse reinforcement learning (IRL), no reward function is given. Instead, the reward function is inferred given an observed behavior from an expert. The idea is to mimic observed behavior, which is often optimal or close to optimal.\n[\n61\n]\nOne popular IRL paradigm is named maximum entropy inverse reinforcement learning (MaxEnt IRL).\n[\n62\n]\nMaxEnt IRL estimates the parameters of a linear model of the reward function by maximizing the entropy of the probability distribution of observed trajectories subject to constraints related to matching expected feature counts. Recently it has been shown that MaxEnt IRL is a particular case of a more general framework named random utility inverse reinforcement learning (RU-IRL).\n[\n63\n]\nRU-IRL is based on\nrandom utility theory\nand Markov decision processes. While prior IRL approaches assume that the apparent random behavior of an observed agent is due to it following a random policy, RU-IRL assumes that the observed agent follows a deterministic policy but randomness in observed behavior is due to the fact that an observer only has partial access to the features the observed agent uses in decision making. The utility function is modeled as a random variable to account for the ignorance of the observer regarding the features the observed agent actually considers in its utility function.\nMulti-objective reinforcement learning\n[\nedit\n]\nMulti-objective reinforcement learning (MORL) is a form of reinforcement learning concerned with conflicting alternatives. It is distinct from\nmulti-objective optimization\nin that it is concerned with agents acting in environments.\n[\n64\n]\n[\n65\n]\nSafe reinforcement learning\n[\nedit\n]\nSafe reinforcement learning (SRL) can be defined as the process of learning policies that maximize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deployment processes.\n[\n66\n]\n[\n67\n]\nAn alternative approach is risk-averse reinforcement learning, where instead of the\nexpected\nreturn, a\nrisk-measure\nof the return is optimized, such as the\nconditional value at risk\n(CVaR).\n[\n68\n]\nIn addition to mitigating risk, the CVaR objective increases robustness to model uncertainties.\n[\n69\n]\n[\n70\n]\nHowever, CVaR optimization in risk-averse RL requires special care, to prevent gradient bias\n[\n71\n]\nand blindness to success.\n[\n72\n]\nSelf-reinforcement learning\n[\nedit\n]\nSelf-reinforcement learning (or self-learning), is a learning paradigm which does not use the concept of immediate reward\nR\na\n(\ns\n,\ns\n′\n)\n{\\displaystyle R_{a}(s,s')}\nafter transition from\ns\n{\\displaystyle s}\nto\ns\n′\n{\\displaystyle s'}\nwith action\na\n{\\displaystyle a}\n. It does not use an external reinforcement, it only uses the agent internal self-reinforcement. The internal self-reinforcement is provided by mechanism of feelings and emotions. In the learning process emotions are backpropagated by a mechanism of secondary reinforcement. The learning equation does not include the immediate reward, it only includes the state evaluation.\nThe self-reinforcement algorithm updates a memory matrix\nW\n=\n‖\nw\n(\na\n,\ns\n)\n‖\n{\\displaystyle W=\\|w(a,s)\\|}\nsuch that in each iteration executes the following machine learning routine:\nIn situation\ns\n{\\displaystyle s}\nperform action\na\n{\\displaystyle a}\n.\nReceive a consequence situation\ns\n′\n{\\displaystyle s'}\n.\nCompute state evaluation\nv\n(\ns\n′\n)\n{\\displaystyle v(s')}\nof how good is to be in the consequence situation\ns\n′\n{\\displaystyle s'}\n.\nUpdate crossbar memory\nw\n′\n(\na\n,\ns\n)\n=\nw\n(\na\n,\ns\n)\n+\nv\n(\ns\n′\n)\n{\\displaystyle w'(a,s)=w(a,s)+v(s')}\n.\nInitial conditions of the memory are received as input from the genetic environment. It is a system with only one input (situation), and only one output (action, or behavior).\nSelf-reinforcement (self-learning) was introduced in 1982 along with a neural network capable of self-reinforcement learning, named Crossbar Adaptive Array (CAA).\n[\n73\n]\n[\n74\n]\nThe CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence states. The system is driven by the interaction between cognition and emotion.\n[\n75\n]\nReinforcement Learning in Natural Language Processing\n[\nedit\n]\nIn recent years\n[\nwhen?\n]\n, reinforcement learning has become a significant concept in\nnatural language processing (NLP)\n, where tasks are often sequential decision-making rather than static classification. Reinforcement learning is where an agent take actions in an environment to maximize the accumulation of rewards. This framework is best fit for many NLP tasks, including dialogue generation, text summarization, and machine translation, where the quality of the output depends on optimizing long-term or human-centered goals rather than the prediction of single correct label.\nEarly application of RL in NLP emerged in dialogue systems, where conversation was determined as a series of actions optimized for fluency and coherence. These early attempts, including policy gradient and sequence-level training techniques, laid a foundation for the broader application of reinforcement learning to other areas of NLP.\nA major breakthrough happened with the introduction of\nreinforcement learning from human feedback (RLHF)\n, a method in which human feedback ratings are used to train a reward model that guides the RL agent. Unlike traditional rule-based or supervised systems, RLHF allows models to align their behavior with human judgments on complex and subjective tasks. This technique was initially used in the development of\nInstructGPT\n, an effective language model trained to follow human instructions and later in\nChatGPT\nwhich incorporates RLHF for improving output responses and ensuring safety.\nMore recently\n[\nwhen?\n]\n, researchers have explored the use of offline RL in NLP to improve dialogue systems without the need of live human interaction. These methods optimize for user engagement, coherence, and diversity based on past conversation logs and pre-trained reward models.\n[\n76\n]\nOne example is DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. This model was trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step.\n[\n77\n]\nStatistical comparison of reinforcement learning algorithms\n[\nedit\n]\nEfficient comparison of RL algorithms is essential for research, deployment and monitoring of RL systems. To compare different algorithms on a given environment, an agent can be trained for each algorithm. Since the performance is sensitive to implementation details, all algorithms should be implemented as closely as possible to each other.\n[\n78\n]\nAfter the training is finished, the agents can be run on a sample of test episodes, and their scores (returns) can be compared. Since episodes are typically assumed to be\ni.i.d\n, standard statistical tools can be used for hypothesis testing, such as\nT-test\nand\npermutation test\n.\n[\n79\n]\nThis requires to accumulate all the rewards within an episode into a single number—the episodic return. However, this causes a loss of information, as different time-steps are averaged together, possibly with different levels of noise. Whenever the noise level varies across the episode, the statistical power can be improved significantly, by weighting the rewards according to their estimated noise.\n[\n80\n]\nChallenges and Limitations\n[\nedit\n]\nDespite significant advancements, reinforcement learning (RL) continues to face several challenges and limitations that hinder its widespread application in real-world scenarios.\nSample Inefficiency\n[\nedit\n]\nRL algorithms often require a large number of interactions with the environment to learn effective policies, leading to high computational costs and time-intensive to train the agent. For instance,\nOpenAI's\nDota-playing bot utilized thousands of years of simulated gameplay to achieve human-level performance. Techniques like experience replay and\ncurriculum learning\nhave been proposed to deprive sample inefficiency, but these techniques add more complexity and are not always sufficient for real-world applications.\nStability and Convergence Issues\n[\nedit\n]\nTraining RL models, particularly for\ndeep neural network-based models\n, can be unstable and prone to divergence. A small change in the policy or environment can lead to extreme fluctuations in performance, making it difficult to achieve consistent results. This instability is further enhanced in the case of the continuous or high-dimensional action space, where the learning step becomes more complex and less predictable.\nGeneralization and Transferability\n[\nedit\n]\nThe RL agents trained in specific environments often struggle to generalize their learned policies to new, unseen scenarios. This is the major setback preventing the application of RL to dynamic real-world environments where adaptability is crucial. The challenge is to develop such algorithms that can transfer knowledge across tasks and environments without extensive retraining.\nBias and Reward Function Issues\n[\nedit\n]\nDesigning appropriate reward functions is critical in RL because poorly designed reward functions can lead to unintended behaviors. In addition, RL systems trained on biased data may perpetuate existing biases and lead to discriminatory or unfair outcomes. Both of these issues requires careful consideration of reward structures and data sources to ensure fairness and desired behaviors.\nSee also\n[\nedit\n]\nActive learning (machine learning)\nApprenticeship learning\nError-driven learning\nModel-free (reinforcement learning)\nMulti-agent reinforcement learning\nOptimal control\nQ-learning\nReinforcement learning from human feedback\nState–action–reward–state–action\n(SARSA)\nTemporal difference learning\nReferences\n[\nedit\n]\n^\nKaelbling, Leslie P.\n;\nLittman, Michael L.\n;\nMoore, Andrew W.\n(1996).\n\"Reinforcement Learning: A Survey\"\n.\nJournal of Artificial Intelligence Research\n.\n4\n:\n237–\n285.\narXiv\n:\ncs/9605103\n.\ndoi\n:\n10.1613/jair.301\n.\nS2CID\n1708582\n. Archived from\nthe original\non 2001-11-20.\n^\nvan Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\".\nReinforcement Learning\n. Adaptation, Learning, and Optimization. Vol. 12. pp.\n3–\n42.\ndoi\n:\n10.1007/978-3-642-27645-3_1\n.\nISBN\n978-3-642-27644-6\n.\n^\na\nb\nLi, Shengbo (2023).\nReinforcement Learning for Sequential Decision and Optimal Control\n(First ed.). Springer Verlag, Singapore. pp.\n1–\n460.\ndoi\n:\n10.1007/978-981-19-7784-8\n.\nISBN\n978-9-811-97783-1\n.\nS2CID\n257928563\n.\n{{\ncite book\n}}\n:  CS1 maint: location missing publisher (\nlink\n)\n^\nRussell, Stuart J.; Norvig, Peter (2010).\nArtificial intelligence: a modern approach\n(Third ed.). Upper Saddle River, New Jersey:\nPrentice Hall\n. pp. 830, 831.\nISBN\n978-0-13-604259-4\n.\n^\nLee, Daeyeol; Seo, Hyojung; Jung, Min Whan (21 July 2012).\n\"Neural Basis of Reinforcement Learning and Decision Making\"\n.\nAnnual Review of Neuroscience\n.\n35\n(1):\n287–\n308.\ndoi\n:\n10.1146/annurev-neuro-062111-150512\n.\nPMC\n3490621\n.\nPMID\n22462543\n.\n^\nSalazar Duque, Edgar Mauricio; Giraldo, Juan S.; Vergara, Pedro P.; Nguyen, Phuong; Van Der Molen, Anne; Slootweg, Han (2022).\n\"Community energy storage operation via reinforcement learning with eligibility traces\"\n.\nElectric Power Systems Research\n.\n212\n108515.\nBibcode\n:\n2022EPSR..21208515S\n.\ndoi\n:\n10.1016/j.epsr.2022.108515\n.\nS2CID\n250635151\n.\n^\nXie, Zhaoming; Hung Yu Ling; Nam Hee Kim; Michiel van de Panne (2020). \"ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills\".\narXiv\n:\n2005.04323\n[\ncs.GR\n].\n^\nVergara, Pedro P.; Salazar, Mauricio; Giraldo, Juan S.; Palensky, Peter (2022).\n\"Optimal dispatch of PV inverters in unbalanced distribution systems using Reinforcement Learning\"\n.\nInternational Journal of Electrical Power & Energy Systems\n.\n136\n107628.\nBibcode\n:\n2022IJEPE.13607628V\n.\ndoi\n:\n10.1016/j.ijepes.2021.107628\n.\nS2CID\n244099841\n.\n^\nSutton & Barto 2018\n, Chapter 11.\n^\nRen, Yangang; Jiang, Jianhua; Zhan, Guojian; Li, Shengbo Eben; Chen, Chen; Li, Keqiang; Duan, Jingliang (2022). \"Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections\".\nIEEE Transactions on Intelligent Transportation Systems\n.\n23\n(12):\n24145–\n24156.\narXiv\n:\n2110.12359\n.\nBibcode\n:\n2022ITITr..2324145R\n.\ndoi\n:\n10.1109/TITS.2022.3196167\n.\n^\nGosavi, Abhijit\n(2003).\nSimulation-based Optimization: Parametric Optimization Techniques and Reinforcement\n. Operations Research/Computer Science Interfaces Series. Springer.\nISBN\n978-1-4020-7454-7\n.\n^\na\nb\nBurnetas, Apostolos N.;\nKatehakis, Michael N.\n(1997), \"Optimal adaptive policies for Markov Decision Processes\",\nMathematics of Operations Research\n,\n22\n(1):\n222–\n255,\ndoi\n:\n10.1287/moor.22.1.222\n,\nJSTOR\n3690147\n^\nTokic, Michel; Palm, Günther (2011),\n\"Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax\"\n(PDF)\n,\nKI 2011: Advances in Artificial Intelligence\n, Lecture Notes in Computer Science, vol. 7006, Springer, pp.\n335–\n346,\nISBN\n978-3-642-24455-1\n^\na\nb\nc\n\"Reinforcement learning: An introduction\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 2017-07-12\n. Retrieved\n2017-07-23\n.\n^\nSingh, Satinder P.; Sutton, Richard S. (1996-03-01).\n\"Reinforcement learning with replacing eligibility traces\"\n.\nMachine Learning\n.\n22\n(1):\n123–\n158.\ndoi\n:\n10.1007/BF00114726\n.\nISSN\n1573-0565\n.\n^\nSutton, Richard S.\n(1984).\nTemporal Credit Assignment in Reinforcement Learning\n(PhD thesis). University of Massachusetts, Amherst, MA. Archived from\nthe original\non 2017-03-30\n. Retrieved\n2017-03-29\n.\n^\nSutton & Barto 2018\n,\n§6. Temporal-Difference Learning\n.\n^\nBradtke, Steven J.\n;\nBarto, Andrew G.\n(1996). \"Learning to predict by the method of temporal differences\".\nMachine Learning\n.\n22\n:\n33–\n57.\nCiteSeerX\n10.1.1.143.857\n.\ndoi\n:\n10.1023/A:1018056104778\n.\nS2CID\n20327856\n.\n^\nWatkins, Christopher J.C.H.\n(1989).\nLearning from Delayed Rewards\n(PDF)\n(PhD thesis). King's College, Cambridge, UK.\n^\nMatzliach, Barouch; Ben-Gal, Irad; Kagan, Evgeny (2022).\n\"Detection of Static and Mobile Targets by an Autonomous Agent with Deep Q-Learning Abilities\"\n.\nEntropy\n.\n24\n(8): 1168.\nBibcode\n:\n2022Entrp..24.1168M\n.\ndoi\n:\n10.3390/e24081168\n.\nPMC\n9407070\n.\nPMID\n36010832\n.\n^\nWilliams, Ronald J.\n(1987). \"A class of gradient-estimating algorithms for reinforcement learning in neural networks\".\nProceedings of the IEEE First International Conference on Neural Networks\n.\nCiteSeerX\n10.1.1.129.8871\n.\n^\nPeters, Jan\n;\nVijayakumar, Sethu\n;\nSchaal, Stefan\n(2003).\nReinforcement Learning for Humanoid Robotics\n(PDF)\n. IEEE-RAS International Conference on Humanoid Robots. Archived from\nthe original\n(PDF)\non 2013-05-12\n. Retrieved\n2006-05-08\n.\n^\nJuliani, Arthur (2016-12-17).\n\"Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)\"\n.\nMedium\n. Retrieved\n2018-02-22\n.\n^\nDeisenroth, Marc Peter\n; Neumann, Gerhard;\nPeters, Jan\n(2013).\nA Survey on Policy Search for Robotics\n(PDF)\n. Foundations and Trends in Robotics. Vol. 2. NOW Publishers. pp.\n1–\n142.\ndoi\n:\n10.1561/2300000021\n.\nhdl\n:\n10044/1/12051\n.\n^\nSutton, Richard (1990). \"Integrated Architectures for Learning, Planning and Reacting based on Dynamic Programming\".\nMachine Learning: Proceedings of the Seventh International Workshop\n.\n^\nLin, Long-Ji (1992).\n\"Self-improving reactive agents based on reinforcement learning, planning and teaching\"\n(PDF)\n.\nMachine Learning\n. Vol. 8.\ndoi\n:\n10.1007/BF00992699\n.\n^\nZou, Lan (2023-01-01), Zou, Lan (ed.),\n\"Chapter 7 - Meta-reinforcement learning\"\n,\nMeta-Learning\n, Academic Press, pp.\n267–\n297,\ndoi\n:\n10.1016/b978-0-323-89931-4.00011-0\n,\nISBN\n978-0-323-89931-4\n, retrieved\n2023-11-08\n^\nvan Hasselt, Hado; Hessel, Matteo; Aslanides, John (2019).\n\"When to use parametric models in reinforcement learning?\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n. Vol. 32.\n^\nGrondman, Ivo; Vaandrager, Maarten; Busoniu, Lucian; Babuska, Robert; Schuitema, Erik (2012-06-01).\n\"Efficient Model Learning Methods for Actor–Critic Control\"\n.\nIEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics\n.\n42\n(3):\n591–\n602.\nBibcode\n:\n2012ITSMC..42..591G\n.\ndoi\n:\n10.1109/TSMCB.2011.2170565\n.\nISSN\n1083-4419\n.\nPMID\n22156998\n.\n^\n\"On the Use of Reinforcement Learning for Testing Game Mechanics: ACM - Computers in Entertainment\"\n.\ncie.acm.org\n. Retrieved\n2018-11-27\n.\n^\nLi, Xiao; Vasile, Cristian-Ioan; Belta, Calin (2017).\n\"Reinforcement Learning with Temporal Logic Rewards\"\n.\n2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n. pp.\n3834–\n3839.\ndoi\n:\n10.1109/IROS.2017.8206234\n.\n^\nToro Icarte, Rodrigo; Klassen, Toryn Q.; Valenzano, Richard; McIlraith, Sheila A. (2022).\n\"Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning\"\n.\nJournal of Artificial Intelligence Research\n.\n73\n:\n173–\n208.\narXiv\n:\n2010.03950\n.\ndoi\n:\n10.1613/jair.1.12440\n.\n^\nRiveret, Régis; Gao, Yang; Governatori, Guido; Rotolo, Antonino; Pitt, Jeremy; Sartor, Giovanni (2019).\n\"A probabilistic argumentation framework for reinforcement learning agents\"\n.\nAutonomous Agents and Multi-Agent Systems\n.\n33\n(\n1–\n2):\n216–\n274.\ndoi\n:\n10.1007/s10458-019-09404-2\n.\n^\nHaramati, Dan; Daniel, Tal; Tamar, Aviv (2024). \"Entity-Centric Reinforcement Learning for Object Manipulation from Pixels\".\narXiv\n:\n2404.01220\n[\ncs.RO\n].\n^\nThompson, Isaac Symes; Caron, Alberto; Hicks, Chris; Mavroudis, Vasilios (2024-11-07). \"Entity-based Reinforcement Learning for Autonomous Cyber Defence\".\nProceedings of the Workshop on Autonomous Cybersecurity (AutonomousCyber '24)\n. ACM. pp.\n56–\n67.\narXiv\n:\n2410.17647\n.\ndoi\n:\n10.1145/3689933.3690835\n.\n^\nWinter, Clemens (2023-04-14).\n\"Entity-Based Reinforcement Learning\"\n.\nClemens Winter's Blog\n.\n^\nYamagata, Taku; McConville, Ryan; Santos-Rodriguez, Raul (2021-11-16). \"Reinforcement Learning with Feedback from Multiple Humans with Diverse Skills\".\narXiv\n:\n2111.08596\n[\ncs.LG\n].\n^\nKulkarni, Tejas D.; Narasimhan, Karthik R.; Saeedi, Ardavan; Tenenbaum, Joshua B. (2016).\n\"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\"\n.\nProceedings of the 30th International Conference on Neural Information Processing Systems\n. NIPS'16. USA: Curran Associates Inc.:\n3682–\n3690.\narXiv\n:\n1604.06057\n.\nBibcode\n:\n2016arXiv160406057K\n.\nISBN\n978-1-5108-3881-9\n.\n^\n\"Reinforcement Learning / Successes of Reinforcement Learning\"\n.\numichrl.pbworks.com\n. Retrieved\n2017-08-06\n.\n^\nDey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (March 2020).\n\"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\"\n.\n2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)\n(PDF)\n. pp.\n1728–\n1733.\ndoi\n:\n10.23919/DATE48585.2020.9116294\n.\nISBN\n978-3-9819263-4-7\n.\nS2CID\n219858480\n.\n^\nQuested, Tony.\n\"Smartphones get smarter with Essex innovation\"\n.\nBusiness Weekly\n. Retrieved\n2021-06-17\n.\n^\nWilliams, Rhiannon (2020-07-21).\n\"Future smartphones 'will prolong their own battery life by monitoring owners' behaviour'\n\"\n.\ni\n. Retrieved\n2021-06-17\n.\n^\nKaplan, F.; Oudeyer, P. (2004). \"Maximizing Learning Progress: An Internal Reward System for Development\". In Iida, F.; Pfeifer, R.; Steels, L.; Kuniyoshi, Y. (eds.).\nEmbodied Artificial Intelligence\n. Lecture Notes in Computer Science. Vol. 3139. Berlin; Heidelberg: Springer. pp.\n259–\n270.\ndoi\n:\n10.1007/978-3-540-27833-7_19\n.\nISBN\n978-3-540-22484-6\n.\nS2CID\n9781221\n.\n^\nKlyubin, A.; Polani, D.; Nehaniv, C. (2008).\n\"Keep your options open: an information-based driving principle for sensorimotor systems\"\n.\nPLOS ONE\n.\n3\n(12) e4018.\nBibcode\n:\n2008PLoSO...3.4018K\n.\ndoi\n:\n10.1371/journal.pone.0004018\n.\nPMC\n2607028\n.\nPMID\n19107219\n.\n^\nBarto, A. G. (2013). \"Intrinsic motivation and reinforcement learning\".\nIntrinsically Motivated Learning in Natural and Artificial Systems\n(PDF)\n. Berlin; Heidelberg: Springer. pp.\n17–\n47.\n^\nDabérius, Kevin; Granat, Elvin; Karlsson, Patrik (2020). \"Deep Execution - Value and Policy Based Reinforcement Learning for Trading and Beating Market Benchmarks\".\nThe Journal of Machine Learning in Finance\n.\n1\n.\nSSRN\n3374766\n.\n^\nGeorge Karimpanal, Thommen; Bouffanais, Roland (2019). \"Self-organizing maps for storage and transfer of knowledge in reinforcement learning\".\nAdaptive Behavior\n.\n27\n(2):\n111–\n126.\narXiv\n:\n1811.08318\n.\ndoi\n:\n10.1177/1059712318818568\n.\nISSN\n1059-7123\n.\nS2CID\n53774629\n.\n^\ncf.\nSutton & Barto 2018\n, Section 5.4, p. 100\n^\nJ Duan; Y Guan; S Li (2021). \"Distributional Soft Actor-Critic: Off-policy reinforcement learning for addressing value estimation errors\".\nIEEE Transactions on Neural Networks and Learning Systems\n.\n33\n(11):\n6584–\n6598.\narXiv\n:\n2001.02811\n.\ndoi\n:\n10.1109/TNNLS.2021.3082568\n.\nPMID\n34101599\n.\nS2CID\n211259373\n.\n^\nY Ren; J Duan; S Li (2020). \"Improving Generalization of Reinforcement Learning with Minimax Distributional Soft Actor-Critic\".\n2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\n. pp.\n1–\n6.\narXiv\n:\n2002.05502\n.\ndoi\n:\n10.1109/ITSC45102.2020.9294300\n.\nISBN\n978-1-7281-4149-7\n.\nS2CID\n211096594\n.\n^\nDuan, J; Wang, W; Xiao, L (2025). \"Distributional Soft Actor-Critic with Three Refinements\".\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n.\nPP\n(5):\n3935–\n3946.\narXiv\n:\n2310.05858\n.\nBibcode\n:\n2025ITPAM..47.3935D\n.\ndoi\n:\n10.1109/TPAMI.2025.3537087\n.\nPMID\n40031258\n.\n^\nSoucek, Branko (6 May 1992).\nDynamic, Genetic and Chaotic Programming: The Sixth-Generation Computer Technology Series\n. John Wiley & Sons, Inc. p. 38.\nISBN\n0-471-55717-X\n.\n^\nFrancois-Lavet, Vincent; et al. (2018). \"An Introduction to Deep Reinforcement Learning\".\nFoundations and Trends in Machine Learning\n.\n11\n(\n3–\n4):\n219–\n354.\narXiv\n:\n1811.12560\n.\nBibcode\n:\n2018arXiv181112560F\n.\ndoi\n:\n10.1561/2200000071\n.\nS2CID\n54434537\n.\n^\nMnih, Volodymyr; et al. (2015). \"Human-level control through deep reinforcement learning\".\nNature\n.\n518\n(7540):\n529–\n533.\nBibcode\n:\n2015Natur.518..529M\n.\ndoi\n:\n10.1038/nature14236\n.\nPMID\n25719670\n.\nS2CID\n205242740\n.\n^\nGoodfellow, Ian; Shlens, Jonathan; Szegedy, Christian (2015). \"Explaining and Harnessing Adversarial Examples\".\nInternational Conference on Learning Representations\n.\narXiv\n:\n1412.6572\n.\n^\nBehzadan, Vahid; Munir, Arslan (2017). \"Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks\".\nMachine Learning and Data Mining in Pattern Recognition\n. Lecture Notes in Computer Science. Vol. 10358. pp.\n262–\n275.\narXiv\n:\n1701.04143\n.\ndoi\n:\n10.1007/978-3-319-62416-7_19\n.\nISBN\n978-3-319-62415-0\n.\nS2CID\n1562290\n.\n^\nHuang, Sandy; Papernot, Nicolas; Goodfellow, Ian; Duan, Yan; Abbeel, Pieter (2017-02-07).\nAdversarial Attacks on Neural Network Policies\n.\nOCLC\n1106256905\n.\n^\nKorkmaz, Ezgi (2022).\n\"Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs\"\n.\nThirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\n.\n36\n(7):\n7229–\n7238.\narXiv\n:\n2112.09025\n.\ndoi\n:\n10.1609/aaai.v36i7.20684\n.\nS2CID\n245219157\n.\n^\nBerenji, H.R. (1994). \"Fuzzy Q-learning: A new approach for fuzzy dynamic programming\".\nProceedings of 1994 IEEE 3rd International Fuzzy Systems Conference\n. Orlando, FL, USA: IEEE. pp.\n486–\n491.\ndoi\n:\n10.1109/FUZZY.1994.343737\n.\nISBN\n0-7803-1896-X\n.\nS2CID\n56694947\n.\n^\nVincze, David (2017).\n\"Fuzzy rule interpolation and reinforcement learning\"\n(PDF)\n.\n2017 IEEE 15th International Symposium on Applied Machine Intelligence and Informatics (SAMI)\n. IEEE. pp.\n173–\n178.\ndoi\n:\n10.1109/SAMI.2017.7880298\n.\nISBN\n978-1-5090-5655-2\n.\nS2CID\n17590120\n.\n^\nNg, A. Y.; Russell, S. J. (2000).\n\"Algorithms for Inverse Reinforcement Learning\"\n(PDF)\n.\nProceeding ICML '00 Proceedings of the Seventeenth International Conference on Machine Learning\n. Morgan Kaufmann Publishers. pp.\n663–\n670.\nISBN\n1-55860-707-2\n.\n^\nZiebart, Brian D.; Maas, Andrew; Bagnell, J. Andrew; Dey, Anind K. (2008-07-13).\n\"Maximum entropy inverse reinforcement learning\"\n.\nProceedings of the 23rd National Conference on Artificial Intelligence - Volume 3\n. AAAI'08. Chicago, Illinois: AAAI Press:\n1433–\n1438.\nISBN\n978-1-57735-368-3\n.\nS2CID\n336219\n.\n^\nPitombeira-Neto, Anselmo R.; Santos, Helano P.; Coelho da Silva, Ticiana L.; de Macedo, José Antonio F. (March 2024). \"Trajectory modeling via random utility inverse reinforcement learning\".\nInformation Sciences\n.\n660\n120128.\narXiv\n:\n2105.12092\n.\ndoi\n:\n10.1016/j.ins.2024.120128\n.\nISSN\n0020-0255\n.\nS2CID\n235187141\n.\n^\nHayes C, Radulescu R, Bargiacchi E, et al. (2022).\n\"A practical guide to multi-objective reinforcement learning and planning\"\n.\nAutonomous Agents and Multi-Agent Systems\n.\n36\n26.\narXiv\n:\n2103.09568\n.\ndoi\n:\n10.1007/s10458-022-09552-y\n.\nS2CID\n254235920\n.\n,\n^\nTzeng, Gwo-Hshiung; Huang, Jih-Jeng (2011).\nMultiple Attribute Decision Making: Methods and Applications\n(1st ed.). CRC Press.\nISBN\n978-1-4398-6157-8\n.\n^\nGu, Shangding; Yang, Long; Du, Yali; Chen, Guang; Walter, Florian; Wang, Jun; Knoll, Alois (10 September 2024). \"A review of safe reinforcement learning: Methods, theories and applications\".\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n.\n46\n(12):\n11216–\n11235.\nBibcode\n:\n2024ITPAM..4611216G\n.\ndoi\n:\n10.1109/TPAMI.2024.3457538\n.\nPMID\n39255180\n.\n^\nGarcía, Javier; Fernández, Fernando (1 January 2015).\n\"A comprehensive survey on safe reinforcement learning\"\n(PDF)\n.\nThe Journal of Machine Learning Research\n.\n16\n(1):\n1437–\n1480.\n^\nDabney, Will; Ostrovski, Georg; Silver, David; Munos, Remi (2018-07-03).\n\"Implicit Quantile Networks for Distributional Reinforcement Learning\"\n.\nProceedings of the 35th International Conference on Machine Learning\n. PMLR:\n1096–\n1105.\narXiv\n:\n1806.06923\n.\n^\nChow, Yinlam; Tamar, Aviv; Mannor, Shie; Pavone, Marco (2015).\n\"Risk-Sensitive and Robust Decision-Making: a CVaR Optimization Approach\"\n.\nAdvances in Neural Information Processing Systems\n.\n28\n. Curran Associates, Inc.\narXiv\n:\n1506.02188\n.\n^\n\"Train Hard, Fight Easy: Robust Meta Reinforcement Learning\"\n.\nscholar.google.com\n. Retrieved\n2024-06-21\n.\n^\nTamar, Aviv; Glassner, Yonatan; Mannor, Shie (2015-02-21).\n\"Optimizing the CVaR via Sampling\"\n.\nProceedings of the AAAI Conference on Artificial Intelligence\n.\n29\n(1).\narXiv\n:\n1404.3862\n.\ndoi\n:\n10.1609/aaai.v29i1.9561\n.\nISSN\n2374-3468\n.\n^\nGreenberg, Ido; Chow, Yinlam; Ghavamzadeh, Mohammad; Mannor, Shie (2022-12-06).\n\"Efficient Risk-Averse Reinforcement Learning\"\n.\nAdvances in Neural Information Processing Systems\n.\n35\n:\n32639–\n32652.\narXiv\n:\n2205.05138\n.\n^\nBozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402. ISBN 978-0-444-86488-8\n^\nBozinovski S. (1995) \"Neuro genetic agents and structural theory of self-reinforcement learning systems\". CMPSCI Technical Report 95-107, University of Massachusetts at Amherst\n[1]\n^\nBozinovski, S. (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255–263\n^\n\"An API for reinforcement learning\"\n. January 22, 2025\n. Retrieved\nJanuary 22,\n2025\n.\n^\nDeepSeek-AI; et al. (January 22, 2025). \"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\".\narXiv\n:\n2501.12948\n[\ncs.CL\n].\n^\nEngstrom, Logan; Ilyas, Andrew; Santurkar, Shibani; Tsipras, Dimitris; Janoos, Firdaus; Rudolph, Larry; Madry, Aleksander (2019-09-25).\n\"Implementation Matters in Deep RL: A Case Study on PPO and TRPO\"\n.\nICLR\n.\n^\nColas, Cédric (2019-03-06).\n\"A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms\"\n.\nInternational Conference on Learning Representations\n.\n47\n(5):\n3935–\n3946.\narXiv\n:\n1904.06979\n.\nBibcode\n:\n2025ITPAM..47.3935D\n.\ndoi\n:\n10.1109/TPAMI.2025.3537087\n.\nPMID\n40031258\n.\n^\nGreenberg, Ido; Mannor, Shie (2021-07-01).\n\"Detecting Rewards Deterioration in Episodic Reinforcement Learning\"\n.\nProceedings of the 38th International Conference on Machine Learning\n. PMLR:\n3842–\n3853.\narXiv\n:\n2010.11660\n.\ndoi\n:\n10.1613/jair.1.12440\n.\nFurther reading\n[\nedit\n]\nAnnaswamy, Anuradha M. (3 May 2023).\n\"Adaptive Control and Intersections with Reinforcement Learning\"\n.\nAnnual Review of Control, Robotics, and Autonomous Systems\n.\n6\n(1):\n65–\n93.\ndoi\n:\n10.1146/annurev-control-062922-090153\n.\nISSN\n2573-5144\n.\nS2CID\n255702873\n.\nAuer, Peter\n; Jaksch, Thomas; Ortner, Ronald (2010).\n\"Near-optimal regret bounds for reinforcement learning\"\n.\nJournal of Machine Learning Research\n.\n11\n:\n1563–\n1600.\nBertsekas, Dimitri P. (2023) [2019].\nReinforcement Learning and Optimal Control\n(1st ed.). Athena Scientific.\nISBN\n978-1-886-52939-7\n.\nBusoniu, Lucian; Babuska, Robert;\nDe Schutter, Bart\n; Ernst, Damien (2010).\nReinforcement Learning and Dynamic Programming using Function Approximators\n. Taylor & Francis CRC Press.\nISBN\n978-1-4398-2108-4\n.\nFrançois-Lavet, Vincent; Henderson, Peter; Islam, Riashat; Bellemare, Marc G.; Pineau, Joelle (2018). \"An Introduction to Deep Reinforcement Learning\".\nFoundations and Trends in Machine Learning\n.\n11\n(\n3–\n4):\n219–\n354.\narXiv\n:\n1811.12560\n.\nBibcode\n:\n2018arXiv181112560F\n.\ndoi\n:\n10.1561/2200000071\n.\nS2CID\n54434537\n.\nLi, Shengbo Eben (2023).\nReinforcement Learning for Sequential Decision and Optimal Control\n(1st ed.). Springer Verlag, Singapore.\ndoi\n:\n10.1007/978-981-19-7784-8\n.\nISBN\n978-9-811-97783-1\n.\nPowell, Warren (2011).\nApproximate dynamic programming: solving the curses of dimensionality\n. Wiley-Interscience. Archived from\nthe original\non 2016-07-31\n. Retrieved\n2010-09-08\n.\nSutton, Richard S.\n(1988).\n\"Learning to predict by the method of temporal differences\"\n.\nMachine Learning\n.\n3\n(1):\n9–\n44.\nBibcode\n:\n1988MLear...3....9S\n.\ndoi\n:\n10.1007/BF00115009\n.\nSutton, Richard S.\n;\nBarto, Andrew G.\n(2018) [1998].\nReinforcement Learning: An Introduction\n(2nd ed.). MIT Press.\nISBN\n978-0-262-03924-6\n.\nSzita, Istvan; Szepesvari, Csaba (2010).\n\"Model-based Reinforcement Learning with Nearly Tight Exploration Complexity Bounds\"\n(PDF)\n.\nICML 2010\n. Omnipress. pp.\n1031–\n1038. Archived from\nthe original\n(PDF)\non 2010-07-14.\nExternal links\n[\nedit\n]\nDissecting Reinforcement Learning\nSeries of blog post on reinforcement learning with Python code\nA (Long) Peek into Reinforcement Learning\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nv\nt\ne\nComputer science\nNote: This template roughly follows the 2012\nACM Computing Classification System\n.\nHardware\nPrinted circuit board\nPeripheral\nIntegrated circuit\nVery-large-scale integration\nSystem on a chip\n(SoC)\nEnergy consumption\n(green computing)\nElectronic design automation\nHardware acceleration\nProcessor\nSize\n/\nForm\nComputer systems organization\nComputer architecture\nComputational complexity\nDependability\nEmbedded system\nReal-time computing\nCyber-physical system\nFault tolerance\nWireless sensor network\nNetworks\nNetwork architecture\nNetwork protocol\nNetwork components\nNetwork scheduler\nNetwork performance evaluation\nNetwork service\nSoftware organization\nInterpreter\nMiddleware\nVirtual machine\nOperating system\nSoftware quality\nSoftware notations\nand\ntools\nProgramming paradigm\nProgramming language\nCompiler\nDomain-specific language\nModeling language\nSoftware framework\nIntegrated development environment\nSoftware configuration management\nSoftware library\nSoftware repository\nSoftware development\nControl flow\nSoftware development process\nRequirements analysis\nSoftware design\nSoftware construction\nSoftware deployment\nSoftware engineering\nSoftware maintenance\nProgramming team\nOpen-source model\nTheory of computation\nModel of computation\nStochastic\nFormal language\nAutomata theory\nComputability theory\nComputational complexity theory\nLogic\nSemantics\nAlgorithms\nAlgorithm design\nAnalysis of algorithms\nAlgorithmic efficiency\nRandomized algorithm\nComputational geometry\nMathematics of\ncomputing\nDiscrete mathematics\nProbability\nStatistics\nMathematical software\nInformation theory\nMathematical analysis\nNumerical analysis\nTheoretical computer science\nComputational problem\nInformation systems\nDatabase management system\nInformation storage systems\nEnterprise information system\nSocial information systems\nGeographic information system\nDecision support system\nProcess control system\nMultimedia information system\nData mining\nDigital library\nComputing platform\nDigital marketing\nWorld Wide Web\nInformation retrieval\nSecurity\nCryptography\nFormal methods\nSecurity hacker\nSecurity services\nIntrusion detection system\nHardware security\nNetwork security\nInformation security\nApplication security\nHuman-centered computing\nInteraction design\nAugmented reality\nVirtual reality\nSocial computing\nUbiquitous computing\nVisualization\nAccessibility\nHuman–computer interaction\nMobile computing\nConcurrency\nConcurrent computing\nParallel computing\nDistributed computing\nMultithreading\nMultiprocessing\nArtificial intelligence\nNatural language processing\nKnowledge representation and reasoning\nComputer vision\nAutomated planning and scheduling\nSearch methodology\nControl method\nPhilosophy of artificial intelligence\nDistributed artificial intelligence\nMachine learning\nSupervised learning\nUnsupervised learning\nReinforcement learning\nMulti-task learning\nCross-validation\nGraphics\nAnimation\nRendering\nPhotograph manipulation\nGraphics processing unit\nImage compression\nSolid modeling\nApplied computing\nQuantum computing\nE-commerce\nEnterprise software\nComputational mathematics\nComputational physics\nComputational chemistry\nComputational biology\nComputational social science\nComputational engineering\nDifferentiable computing\nComputational healthcare\nDigital art\nElectronic publishing\nCyberwarfare\nElectronic voting\nVideo games\nWord processing\nOperations research\nEducational technology\nDocument management\nSpecialized Platform\nDevelopment\nThermodynamic computing\nCategory\nOutline\nGlossaries\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Reinforcement_learning&oldid=1326365787\n\"\nCategories\n:\nReinforcement learning\nMarkov models\nBelief revision\nHidden categories:\nCS1 maint: location missing publisher\nArticles with short description\nShort description is different from Wikidata\nWikipedia articles needing clarification from January 2020\nArticles needing additional references from October 2022\nAll articles needing additional references\nAll articles with vague or ambiguous time\nVague or ambiguous time from November 2025\nThis page was last edited on 8 December 2025, at 16:01\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nReinforcement learning\n39 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:25:44.303900",
      "status": "success",
      "content_length": 72696,
      "topic": "machine_learning"
    },
    {
      "title": "Deep learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Deep_learning",
      "content": "Deep learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nOverview\n2\nInterpretations\n3\nHistory\nToggle History subsection\n3.1\nBefore 1980\n3.2\n1980s-2000s\n3.3\n2000s\n3.4\nDeep learning revolution\n4\nNeural networks\nToggle Neural networks subsection\n4.1\nDeep neural networks\n4.1.1\nChallenges\n5\nHardware\n6\nApplications\nToggle Applications subsection\n6.1\nAutomatic speech recognition\n6.2\nImage recognition\n6.3\nVisual art processing\n6.4\nNatural language processing\n6.5\nDrug discovery and toxicology\n6.6\nRecommendation systems\n6.7\nBioinformatics\n6.8\nDeep Neural Network Estimations\n6.9\nMedical image analysis\n6.10\nMobile advertising\n6.11\nImage restoration\n6.12\nFinancial fraud detection\n6.13\nMaterials science\n6.14\nMilitary\n6.15\nPartial differential equations\n6.16\nDeep backward stochastic differential equation method\n6.17\nImage reconstruction\n6.18\nWeather prediction\n6.19\nEpigenetic clock\n7\nRelation to human cognitive and brain development\n8\nCommercial activity\n9\nCriticism and comment\nToggle Criticism and comment subsection\n9.1\nTheory\n9.2\nErrors\n9.3\nCyber threat\n9.4\nData collection ethics\n10\nSee also\n11\nReferences\n12\nFurther reading\nToggle the table of contents\nDeep learning\n62 languages\nAfrikaans\nالعربية\nAzərbaycanca\nবাংলা\n閩南語 / Bân-lâm-gí\nБългарски\nBosanski\nCatalà\nČeština\nDansk\nالدارجة\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nՀայերեն\nहिन्दी\nIdo\nBahasa Indonesia\nItaliano\nעברית\nMagyar\nമലയാളം\nBahasa Melayu\nМонгол\nNederlands\n日本語\nNorsk bokmål\nNorsk nynorsk\nOccitan\nپښتو\nPolski\nPortuguês\nQaraqalpaqsha\nRomână\nRuna Simi\nРусский\nShqip\nසිංහල\nSimple English\nSlovenščina\nکوردی\nСрпски / srpski\nSrpskohrvatski / српскохрватски\nSuomi\nSvenska\nதமிழ்\nไทย\nTürkçe\nУкраїнська\nاردو\nTiếng Việt\n文言\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nBranch of machine learning\nFor the TV series episode, see\nDeep Learning (South Park)\n.\nRepresenting images on multiple layers of abstraction in deep learning\n[\n1\n]\nPart of\na series\non\nArtificial intelligence (AI)\nMajor goals\nArtificial general intelligence\nIntelligent agent\nRecursive self-improvement\nPlanning\nComputer vision\nGeneral game playing\nKnowledge representation\nNatural language processing\nRobotics\nAI safety\nApproaches\nMachine learning\nSymbolic\nDeep learning\nBayesian networks\nEvolutionary algorithms\nHybrid intelligent systems\nSystems integration\nOpen-source\nApplications\nBioinformatics\nDeepfake\nEarth sciences\nFinance\nGenerative AI\nArt\nAudio\nMusic\nGovernment\nHealthcare\nMental health\nIndustry\nSoftware development\nTranslation\nMilitary\nPhysics\nProjects\nPhilosophy\nAI alignment\nArtificial consciousness\nThe bitter lesson\nChinese room\nFriendly AI\nEthics\nExistential risk\nTuring test\nUncanny valley\nHuman–AI interaction\nHistory\nTimeline\nProgress\nAI winter\nAI boom\nAI bubble\nControversies\nDeepfake pornography\nTaylor Swift deepfake pornography controversy\nGoogle Gemini image generation controversy\nPause Giant AI Experiments\nRemoval of Sam Altman from OpenAI\nStatement on AI Risk\nTay (chatbot)\nThéâtre D'opéra Spatial\nVoiceverse NFT plagiarism scandal\nGlossary\nGlossary\nv\nt\ne\nIn\nmachine learning\n,\ndeep learning\nfocuses on utilizing multilayered\nneural networks\nto perform tasks such as\nclassification\n,\nregression\n, and\nrepresentation learning\n. The field takes inspiration from\nbiological neuroscience\nand revolves around stacking\nartificial neurons\ninto layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be\nsupervised\n,\nsemi-supervised\nor\nunsupervised\n.\n[\n2\n]\nSome common deep learning network architectures include\nfully connected networks\n,\ndeep belief networks\n,\nrecurrent neural networks\n,\nconvolutional neural networks\n,\ngenerative adversarial networks\n,\ntransformers\n, and\nneural radiance fields\n. These architectures have been applied to fields including\ncomputer vision\n,\nspeech recognition\n,\nnatural language processing\n,\nmachine translation\n,\nbioinformatics\n,\ndrug design\n,\nmedical image analysis\n,\nclimate science\n, material inspection and\nboard game\nprograms, where they have produced results comparable to and in some cases surpassing human expert performance.\n[\n3\n]\n[\n4\n]\n[\n5\n]\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in\nbiological systems\n, particularly the\nhuman brain\n. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n[\n6\n]\nOverview\n[\nedit\n]\nMost modern deep learning models are based on multi-layered\nneural networks\nsuch as\nconvolutional neural networks\nand\ntransformers\n, although they can also include\npropositional formulas\nor latent variables organized layer-wise in deep\ngenerative models\nsuch as the nodes in\ndeep belief networks\nand deep\nBoltzmann machines\n.\n[\n7\n]\nFundamentally, deep learning refers to a class of\nmachine learning\nalgorithms\nin which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an\nimage recognition\nmodel, the raw input may be an\nimage\n(represented as a\ntensor\nof\npixels\n). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\nImportantly, a deep learning process can learn which features to optimally place at which level\non its own\n. Prior to deep learning, machine learning techniques often involved hand-crafted\nfeature engineering\nto transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model\ndiscovers\nuseful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.\n[\n8\n]\n[\n2\n]\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial\ncredit assignment path\n(CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a\nfeedforward neural network\n, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For\nrecurrent neural networks\n, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.\n[\n9\n]\nNo universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function.\n[\n10\n]\nBeyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\nDeep learning architectures can be constructed with a\ngreedy\nlayer-by-layer method.\n[\n11\n]\nDeep learning helps to disentangle these abstractions and pick out which features improve performance.\n[\n8\n]\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are\ndeep belief networks\n.\n[\n8\n]\n[\n12\n]\nThe term\ndeep learning\nwas introduced to the machine learning community by\nRina Dechter\nin 1986,\n[\n13\n]\nand to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of\nBoolean\nthreshold neurons.\n[\n14\n]\n[\n15\n]\nAlthough the history of its appearance is apparently more complicated.\n[\n16\n]\nInterpretations\n[\nedit\n]\nDeep neural networks are generally interpreted in terms of the\nuniversal approximation theorem\n[\n17\n]\n[\n18\n]\n[\n19\n]\n[\n20\n]\n[\n21\n]\nor\nprobabilistic inference\n.\n[\n22\n]\n[\n23\n]\n[\n8\n]\n[\n9\n]\n[\n24\n]\nThe classic universal approximation theorem concerns the capacity of\nfeedforward neural networks\nwith a single hidden layer of finite size to approximate\ncontinuous functions\n.\n[\n17\n]\n[\n18\n]\n[\n19\n]\n[\n20\n]\nIn 1989, the first proof was published by\nGeorge Cybenko\nfor\nsigmoid\nactivation functions\n[\n17\n]\nand was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik.\n[\n18\n]\nRecent work also showed that universal approximation also holds for non-bounded activation functions such as\nKunihiko Fukushima\n's\nrectified linear unit\n.\n[\n25\n]\n[\n26\n]\nThe universal approximation theorem for\ndeep neural networks\nconcerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al.\n[\n21\n]\nproved that if the width of a deep neural network with\nReLU\nactivation is strictly larger than the input dimension, then the network can approximate any\nLebesgue integrable function\n; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\nThe\nprobabilistic\ninterpretation\n[\n24\n]\nderives from the field of\nmachine learning\n. It features inference,\n[\n23\n]\n[\n7\n]\n[\n8\n]\n[\n9\n]\n[\n12\n]\n[\n24\n]\nas well as the\noptimization\nconcepts of\ntraining\nand\ntesting\n, related to fitting and\ngeneralization\n, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a\ncumulative distribution function\n.\n[\n24\n]\nThe probabilistic interpretation led to the introduction of\ndropout\nas\nregularizer\nin neural networks. The probabilistic interpretation was introduced by researchers including\nHopfield\n,\nWidrow\nand\nNarendra\nand popularized in surveys such as the one by\nBishop\n.\n[\n27\n]\nHistory\n[\nedit\n]\nBefore 1980\n[\nedit\n]\nThere are two\ntypes\nof artificial neural network (ANN):\nfeedforward neural network\n(FNN) or\nmultilayer perceptron\n(MLP) and\nrecurrent neural networks\n(RNN). RNNs have cycles in their connectivity structure, FNNs don't. In the 1920s,\nWilhelm Lenz\nand\nErnst Ising\ncreated the\nIsing model\n[\n28\n]\n[\n29\n]\nwhich is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972,\nShun'ichi Amari\nmade this architecture adaptive.\n[\n30\n]\n[\n31\n]\nHis learning RNN was republished by\nJohn Hopfield\nin 1982.\n[\n32\n]\nOther early\nrecurrent neural networks\nwere published by Kaoru Nakano in 1971.\n[\n33\n]\n[\n34\n]\nAlready in 1948,\nAlan Turing\nproduced work on \"Intelligent Machinery\"  that was not published in his lifetime,\n[\n35\n]\ncontaining \"ideas related to artificial evolution and learning RNNs\".\n[\n31\n]\nFrank Rosenblatt\n(1958)\n[\n36\n]\nproposed the perceptron, an MLP with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. He later published a 1962 book that also introduced variants and computer experiments, including a version with four-layer perceptrons \"with adaptive preterminal networks\" where the last two layers have learned weights (here he credits H. D. Block and B. W. Knight).\n[\n37\n]\n: section 16\nThe book cites an earlier network by R. D. Joseph (1960)\n[\n38\n]\n\"functionally equivalent to a variation of\" this four-layer system (the book mentions Joseph over 30 times). Should Joseph therefore be considered the originator of proper adaptive\nmultilayer perceptrons\nwith learning hidden units? Unfortunately, the learning algorithm was not a functional one, and fell into oblivion.\nThe first working deep learning algorithm was the\nGroup method of data handling\n, a method to train arbitrarily deep neural networks, published by\nAlexey Ivakhnenko\nand Lapa in 1965. They regarded it as a form of polynomial regression,\n[\n39\n]\nor a generalization of Rosenblatt's perceptron to handle more complex, nonlinear, and hierarchical relationships.\n[\n40\n]\nA 1971 paper described a deep network with eight layers trained by this method,\n[\n41\n]\nwhich is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates\".\n[\n31\n]\nThe first deep learning\nmultilayer perceptron\ntrained by\nstochastic gradient descent\n[\n42\n]\nwas published in 1967 by\nShun'ichi Amari\n.\n[\n43\n]\nIn computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned\ninternal representations\nto classify non-linearily separable pattern classes.\n[\n31\n]\nSubsequent developments in hardware and hyperparameter tunings have made end-to-end\nstochastic gradient descent\nthe currently dominant training technique.\nIn 1969,\nKunihiko Fukushima\nintroduced the\nReLU\n(rectified linear unit)\nactivation function\n.\n[\n25\n]\n[\n31\n]\nThe rectifier has become the most popular activation function for deep learning.\n[\n44\n]\nDeep learning architectures for\nconvolutional neural networks\n(CNNs) with convolutional layers and downsampling layers began with the\nNeocognitron\nintroduced by\nKunihiko Fukushima\nin 1979, though not trained by backpropagation.\n[\n45\n]\n[\n46\n]\nBackpropagation\nis an efficient application of the\nchain rule\nderived by\nGottfried Wilhelm Leibniz\nin 1673\n[\n47\n]\nto networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt,\n[\n37\n]\nbut he did not know how to implement this, although\nHenry J. Kelley\nhad a continuous precursor of backpropagation in 1960 in the context of\ncontrol theory\n.\n[\n48\n]\nThe modern form of backpropagation was first published in\nSeppo Linnainmaa\n's master thesis (1970).\n[\n49\n]\n[\n50\n]\n[\n31\n]\nG.M. Ostrovski et al. republished it in 1971.\n[\n51\n]\n[\n52\n]\nPaul Werbos\napplied backpropagation to neural networks in 1982\n[\n53\n]\n(his 1974 PhD thesis, reprinted in a 1994 book,\n[\n54\n]\ndid not yet describe the algorithm\n[\n52\n]\n). In 1986,\nDavid E. Rumelhart\net al. popularised backpropagation but did not cite the original work.\n[\n55\n]\n[\n56\n]\n1980s-2000s\n[\nedit\n]\nThe\ntime delay neural network\n(TDNN) was introduced in 1987 by\nAlex Waibel\nto apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.\n[\n57\n]\n[\n58\n]\nIn 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition.\n[\n59\n]\nIn 1989,\nYann LeCun\net al. created a CNN called\nLeNet\nfor\nrecognizing handwritten ZIP codes\non mail. Training required 3 days.\n[\n60\n]\nIn 1990, Wei Zhang implemented a CNN on\noptical computing\nhardware.\n[\n61\n]\nIn 1991, a CNN was applied to medical image object segmentation\n[\n62\n]\nand breast cancer detection in mammograms.\n[\n63\n]\nLeNet\n-5 (1998), a 7-level CNN by\nYann LeCun\net al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\n[\n64\n]\nRecurrent neural networks\n(RNN)\n[\n28\n]\n[\n30\n]\nwere further developed in the 1980s. Recurrence is used for sequence processing, and when a recurrent network is unrolled, it mathematically resembles a deep feedforward layer. Consequently, they have similar properties and issues, and their developments had mutual influences. In RNN, two early influential works were the\nJordan network\n(1986)\n[\n65\n]\nand the\nElman network\n(1990),\n[\n66\n]\nwhich applied RNN to study problems in\ncognitive psychology\n.\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, in 1991,\nJürgen Schmidhuber\nproposed a hierarchy of RNNs pre-trained one level at a time by\nself-supervised learning\nwhere each RNN tries to predict its own next input, which is the next unexpected input of the RNN below.\n[\n67\n]\n[\n68\n]\nThis \"neural history compressor\" uses\npredictive coding\nto learn\ninternal representations\nat multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be\ncollapsed\ninto a single RNN, by\ndistilling\na higher level\nchunker\nnetwork into a lower level\nautomatizer\nnetwork.\n[\n67\n]\n[\n68\n]\n[\n31\n]\nIn 1993, a neural history compressor solved a \"Very Deep Learning\" task that required more than 1000 subsequent\nlayers\nin an RNN unfolded in time.\n[\n69\n]\nThe \"P\" in\nChatGPT\nrefers to such pre-training.\nSepp Hochreiter\n's diploma thesis (1991)\n[\n70\n]\nimplemented the neural history compressor,\n[\n67\n]\nand identified and analyzed the\nvanishing gradient problem\n.\n[\n70\n]\n[\n71\n]\nHochreiter proposed recurrent\nresidual\nconnections to solve the vanishing gradient problem. This led to the\nlong short-term memory\n(LSTM), published in 1995.\n[\n72\n]\nLSTM can learn \"very deep learning\" tasks\n[\n9\n]\nwith long credit assignment paths that require memories of events that happened thousands of discrete time steps before. That LSTM was not yet the modern architecture, which required a \"forget gate\", introduced in 1999,\n[\n73\n]\nwhich became the standard RNN architecture.\nIn 1991,\nJürgen Schmidhuber\nalso published adversarial neural networks that contest with each other in the form of a\nzero-sum game\n, where one network's gain is the other network's loss.\n[\n74\n]\n[\n75\n]\nThe first network is a\ngenerative model\nthat models a\nprobability distribution\nover output patterns. The second network learns by\ngradient descent\nto predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in\ngenerative adversarial networks\n(GANs).\n[\n76\n]\nDuring 1985–1995, inspired by statistical mechanics, several architectures and methods were developed by\nTerry Sejnowski\n,\nPeter Dayan\n,\nGeoffrey Hinton\n, etc., including the\nBoltzmann machine\n,\n[\n77\n]\nrestricted Boltzmann machine\n,\n[\n78\n]\nHelmholtz machine\n,\n[\n79\n]\nand the\nwake-sleep algorithm\n.\n[\n80\n]\nThese were designed for unsupervised learning of deep generative models. However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112\n[\n81\n]\n). A 1988 network became state of the art in\nprotein structure prediction\n, an early application of deep learning to bioinformatics.\n[\n82\n]\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for\nspeech recognition\nhave been explored for many years.\n[\n83\n]\n[\n84\n]\n[\n85\n]\nThese methods never outperformed non-uniform internal-handcrafting Gaussian\nmixture model\n/\nHidden Markov model\n(GMM-HMM) technology based on generative models of speech trained discriminatively.\n[\n86\n]\nKey difficulties have been analyzed, including gradient diminishing\n[\n70\n]\nand weak temporal correlation structure in neural predictive models.\n[\n87\n]\n[\n88\n]\nAdditional difficulties were the lack of training data and limited computing power.\nMost\nspeech recognition\nresearchers moved away from neural nets to pursue generative modeling. An exception was at\nSRI International\nin the late 1990s. Funded by the US government's\nNSA\nand\nDARPA\n, SRI researched in speech and\nspeaker recognition\n. The speaker recognition team led by\nLarry Heck\nreported significant success with deep neural networks in speech processing in the 1998\nNIST\nSpeaker Recognition benchmark.\n[\n89\n]\n[\n90\n]\nIt was deployed in the Nuance Verifier, representing the first major industrial application of deep learning.\n[\n91\n]\nThe principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear\nfilter-bank\nfeatures in the late 1990s,\n[\n90\n]\nshowing its superiority over the\nMel-Cepstral\nfeatures that contain stages of fixed transformation from spectrograms. The raw features of speech,\nwaveforms\n, later produced excellent larger-scale results.\n[\n92\n]\n2000s\n[\nedit\n]\nNeural networks entered a lull, and simpler models that use task-specific handcrafted features such as\nGabor filters\nand\nsupport vector machines\n(SVMs) became the preferred choices in the 1990s and 2000s, because of artificial neural networks' computational cost and a lack of understanding of how the brain wires its biological networks.\n[\ncitation needed\n]\nIn 2003, LSTM became competitive with traditional speech recognizers on certain tasks.\n[\n93\n]\nIn 2006,\nAlex Graves\n, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with\nconnectionist temporal classification\n(CTC)\n[\n94\n]\nin stacks of LSTMs.\n[\n95\n]\nIn 2009, it became the first RNN to win a\npattern recognition\ncontest, in connected\nhandwriting recognition\n.\n[\n96\n]\n[\n9\n]\nIn 2006, publications by\nGeoff Hinton\n,\nRuslan Salakhutdinov\n, Osindero and\nTeh\n[\n97\n]\n[\n98\n]\ndeep belief networks\nwere developed for generative modeling. They are trained by training one restricted Boltzmann machine, then freezing it and training another one on top of the first one, and so on, then optionally\nfine-tuned\nusing supervised backpropagation.\n[\n99\n]\nThey could model high-dimensional probability distributions, such as the distribution of\nMNIST images\n, but convergence was slow.\n[\n100\n]\n[\n101\n]\n[\n102\n]\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun.\n[\n103\n]\nIndustrial applications of deep learning to large-scale speech recognition started around 2010.\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems.\n[\n104\n]\nThe nature of the recognition errors produced by the two types of systems was characteristically different,\n[\n105\n]\noffering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems.\n[\n23\n]\n[\n106\n]\n[\n107\n]\nAnalysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.\n[\n105\n]\nThat analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\n[\n104\n]\n[\n105\n]\n[\n108\n]\nIn 2010, researchers extended deep learning from\nTIMIT\nto large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by\ndecision trees\n.\n[\n109\n]\n[\n110\n]\n[\n111\n]\n[\n106\n]\nDeep learning revolution\n[\nedit\n]\nHow deep learning is a subset of machine learning and how machine learning is a subset of artificial intelligence (AI)\nThe deep learning revolution started around CNN- and GPU-based computer vision.\nAlthough CNNs trained by backpropagation had been around for decades and GPU implementations of NNs for years,\n[\n112\n]\nincluding CNNs,\n[\n113\n]\nfaster implementations of CNNs on GPUs were needed to progress on computer vision. Later, as deep learning becomes widespread, specialized hardware and algorithm optimizations were developed specifically for deep learning.\n[\n114\n]\nA key advance for the deep learning revolution was hardware advances, especially GPU. Some early work dated back to 2004.\n[\n112\n]\n[\n113\n]\nIn 2009, Raina, Madhavan, and\nAndrew Ng\nreported a 100M deep belief network trained on 30 Nvidia\nGeForce GTX 280\nGPUs, an early demonstration of GPU-based deep learning. They reported up to 70 times faster training.\n[\n115\n]\nIn 2011, a CNN named\nDanNet\n[\n116\n]\n[\n117\n]\nby Dan Ciresan, Ueli Meier, Jonathan Masci,\nLuca Maria Gambardella\n, and\nJürgen Schmidhuber\nachieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3.\n[\n9\n]\nIt then won more contests.\n[\n118\n]\n[\n119\n]\nThey also showed how\nmax-pooling\nCNNs on GPU improved performance significantly.\n[\n3\n]\nIn 2012,\nAndrew Ng\nand\nJeff Dean\ncreated an FNN that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from\nYouTube\nvideos.\n[\n120\n]\nIn October 2012,\nAlexNet\nby\nAlex Krizhevsky\n,\nIlya Sutskever\n, and\nGeoffrey Hinton\n[\n4\n]\nwon the large-scale\nImageNet competition\nby a significant margin over shallow machine learning methods. Further incremental improvements included the\nVGG-16\nnetwork by\nKaren Simonyan\nand\nAndrew Zisserman\n[\n121\n]\nand Google's\nInceptionv3\n.\n[\n122\n]\nThe success in image classification was then extended to the more challenging task of\ngenerating descriptions\n(captions) for images, often as a combination of CNNs and LSTMs.\n[\n123\n]\n[\n124\n]\n[\n125\n]\nIn 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers.\n[\n126\n]\nStacking too many layers led to a steep reduction in\ntraining\naccuracy,\n[\n127\n]\nknown as the \"degradation\" problem.\n[\n128\n]\nIn 2015, two techniques were developed to train very deep networks: the\nhighway network\nwas published in May 2015, and the\nresidual neural network\n(ResNet)\n[\n129\n]\nin Dec 2015. ResNet behaves like an open-gated Highway Net.\nAround the same time, deep learning started impacting the field of art. Early examples included\nGoogle DeepDream\n(2015), and\nneural style transfer\n(2015),\n[\n130\n]\nboth of which were based on pretrained image classification neural networks, such as\nVGG-19\n.\nGenerative adversarial network\n(GAN) by (\nIan Goodfellow\net al., 2014)\n[\n131\n]\n(based on\nJürgen Schmidhuber\n's principle of artificial curiosity\n[\n74\n]\n[\n76\n]\n)\nbecame state of the art in generative modeling during 2014-2018 period. Excellent image quality is achieved by\nNvidia\n's\nStyleGAN\n(2018)\n[\n132\n]\nbased on the Progressive GAN by Tero Karras et al.\n[\n133\n]\nHere the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning\ndeepfakes\n.\n[\n134\n]\nDiffusion models\n(2015)\n[\n135\n]\neclipsed GANs in generative modeling since then, with systems such as\nDALL·E 2\n(2022) and\nStable Diffusion\n(2022).\nIn 2015, Google's speech recognition improved by 49% by an LSTM-based model, which they made available through\nGoogle Voice Search\non\nsmartphone\n.\n[\n136\n]\n[\n137\n]\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and\nautomatic speech recognition\n(ASR). Results on commonly used evaluation sets such as\nTIMIT\n(ASR) and\nMNIST\n(\nimage classification\n), as well as a range of large-vocabulary speech recognition tasks have steadily improved.\n[\n104\n]\n[\n138\n]\nConvolutional neural networks were superseded for ASR by\nLSTM\n.\n[\n137\n]\n[\n139\n]\n[\n140\n]\n[\n141\n]\nbut are more successful in computer vision.\nYoshua Bengio\n,\nGeoffrey Hinton\nand\nYann LeCun\nwere awarded the 2018\nTuring Award\nfor \"conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing\".\n[\n142\n]\nNeural networks\n[\nedit\n]\nMain article:\nArtificial neural network\nSimplified example of training a neural network in object detection: The network is trained by multiple images that are known to depict\nstarfish\nand\nsea urchins\n, which are correlated with \"nodes\" that represent visual\nfeatures\n. The starfish match with a ringed texture and a star outline, whereas most sea urchins match with a striped texture and oval shape. However, the instance of a ring textured sea urchin creates a weakly weighted association between them.\nSubsequent run of the network on an input image (left):\n[\n143\n]\nThe network correctly detects the starfish. However, the weakly weighted association between ringed texture and sea urchin also confers a weak signal to the latter from one of two intermediate nodes. In addition, a\nshell\nthat was not included in the training gives a weak signal for the oval shape, also resulting in a weak signal for the sea urchin output. These weak signals may result in a\nfalse positive\nresult for sea urchin.\nIn reality, textures and outlines would not be represented by single nodes, but rather by associated weight patterns of multiple nodes.\nArtificial neural networks\n(\nANNs\n) or\nconnectionist\nsystems\nare computing systems inspired by the\nbiological neural networks\nthat constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually\nlabeled\nas \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using\nrule-based programming\n.\nAn ANN is based on a collection of connected units called\nartificial neurons\n, (analogous to biological\nneurons\nin a\nbiological brain\n). Each connection (\nsynapse\n) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by\nreal numbers\n, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as\nbackpropagation\n, or passing information in the reverse direction and adjusting the network to reflect that information.\nNeural networks have been used on a variety of tasks, including computer vision,\nspeech recognition\n,\nmachine translation\n,\nsocial network\nfiltering,\nplaying board and video games\nand medical diagnosis.\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\"\n[\n144\n]\n).\nDeep neural networks\n[\nedit\n]\nA deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers.\n[\n7\n]\n[\n9\n]\nThere are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions.\n[\n145\n]\nThese components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.\n[\ncitation needed\n]\nFor example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer,\n[\n146\n]\nand complex DNN have many layers, hence the name \"deep\" networks.\nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of\nprimitives\n.\n[\n147\n]\nThe extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network.\n[\n7\n]\nFor instance, it was proved that sparse\nmultivariate polynomials\nare exponentially easier to approximate with DNNs than with shallow networks.\n[\n148\n]\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\n[\n146\n]\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights.\n[\n149\n]\nThat way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\nRecurrent neural networks\n, in which data can flow in any direction, are used for applications such as\nlanguage modeling\n.\n[\n150\n]\n[\n151\n]\n[\n152\n]\n[\n153\n]\n[\n154\n]\nLong short-term memory is particularly effective for this use.\n[\n155\n]\n[\n156\n]\nConvolutional neural networks\n(CNNs) are used in computer vision.\n[\n157\n]\nCNNs also have been applied to\nacoustic modeling\nfor automatic speech recognition (ASR).\n[\n158\n]\nChallenges\n[\nedit\n]\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are\noverfitting\nand computation time.\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data.\nRegularization\nmethods such as Ivakhnenko's unit pruning\n[\n41\n]\nor\nweight decay\n(\nℓ\n2\n{\\displaystyle \\ell _{2}}\n-regularization) or\nsparsity\n(\nℓ\n1\n{\\displaystyle \\ell _{1}}\n-regularization) can be applied during training to combat overfitting.\n[\n159\n]\nAlternatively\ndropout\nregularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies.\n[\n160\n]\nAnother interesting recent development is research into models of just enough complexity through an estimation of the intrinsic complexity of the task being modelled. This approach has been successfully applied for multivariate time series prediction tasks such as traffic prediction.\n[\n161\n]\nFinally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.\n[\n162\n]\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the\nlearning rate\n, and initial weights.\nSweeping through the parameter space\nfor optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as\nbatching\n(computing the gradient on several training examples at once rather than individual examples)\n[\n163\n]\nspeed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.\n[\n164\n]\n[\n165\n]\nAlternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (\ncerebellar model articulation controller\n) is one such kind of neural network. It doesn't require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\n[\n166\n]\n[\n167\n]\nHardware\n[\nedit\n]\nSince the 2010s, advances in both machine learning algorithms and\ncomputer hardware\nhave led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.\n[\n168\n]\nBy 2019,\ngraphics processing units\n(GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method for training large-scale commercial cloud AI .\n[\n169\n]\nOpenAI\nestimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.\n[\n170\n]\n[\n171\n]\nSpecial\nelectronic circuits\ncalled\ndeep learning processors\nwere designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in\nHuawei\ncellphones\n[\n172\n]\nand\ncloud computing\nservers such as\ntensor processing units\n(TPU) in the\nGoogle Cloud Platform\n.\n[\n173\n]\nCerebras Systems\nhas also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).\n[\n174\n]\n[\n175\n]\nAtomically thin\nsemiconductors\nare considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on\nfloating-gate\nfield-effect transistors\n(FGFETs).\n[\n176\n]\nIn 2021, J. Feldmann et al. proposed an integrated\nphotonic\nhardware accelerator\nfor parallel convolutional processing.\n[\n177\n]\nThe authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through\nwavelength\ndivision\nmultiplexing\nin conjunction with\nfrequency combs\n, and (2) extremely high data modulation speeds.\n[\n177\n]\nTheir system can execute trillions of multiply-accumulate operations per second, indicating the potential of\nintegrated\nphotonics\nin data-heavy AI applications.\n[\n177\n]\nApplications\n[\nedit\n]\nAutomatic speech recognition\n[\nedit\n]\nMain article:\nSpeech recognition\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks\n[\n9\n]\nthat involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates\n[\n156\n]\nis competitive with traditional speech recognizers on certain tasks.\n[\n93\n]\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major\ndialects\nof\nAmerican English\n, where each speaker reads 10 sentences.\n[\n178\n]\nIts small size lets many configurations be tried. More importantly, the TIMIT task concerns\nphone\n-sequence recognition, which, unlike word-sequence recognition, allows weak phone\nbigram\nlanguage models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\nMethod\nPercent phone\nerror rate (PER) (%)\nRandomly Initialized RNN\n[\n179\n]\n26.1\nBayesian Triphone GMM-HMM\n25.6\nHidden Trajectory (Generative) Model\n24.8\nMonophone Randomly Initialized DNN\n23.4\nMonophone DBN-DNN\n22.4\nTriphone GMM-HMM with BMMI Training\n21.7\nMonophone DBN-DNN on fbank\n20.7\nConvolutional DNN\n[\n180\n]\n20.0\nConvolutional DNN w. Heterogeneous Pooling\n18.7\nEnsemble DNN/CNN/RNN\n[\n181\n]\n18.3\nBidirectional LSTM\n17.8\nHierarchical Convolutional Deep Maxout Network\n[\n182\n]\n16.5\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:\n[\n23\n]\n[\n108\n]\n[\n106\n]\nScale-up/out and accelerated DNN training and decoding\nSequence discriminative training\nFeature processing by deep models with solid understanding of the underlying mechanisms\nAdaptation of DNNs and related deep models\nMulti-task\nand\ntransfer learning\nby DNNs and related deep models\nCNNs\nand how to design them to best exploit\ndomain knowledge\nof speech\nRNN\nand its rich LSTM variants\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.\nMore recent speech recognition models use\nTransformers\nor\nTemporal Convolution Networks\nwith significant success and widespread applications.\n[\n183\n]\n[\n184\n]\n[\n185\n]\nAll major commercial speech recognition systems (e.g., Microsoft\nCortana\n,\nXbox\n,\nSkype Translator\n,\nAmazon Alexa\n,\nGoogle Now\n,\nApple Siri\n,\nBaidu\nand\niFlyTek\nvoice search, and a range of\nNuance\nspeech products, etc.) are based on deep learning.\n[\n23\n]\n[\n186\n]\n[\n187\n]\nImage recognition\n[\nedit\n]\nMain article:\nComputer vision\nRichard Green explains how deep learning is used with a\nremotely operated vehicle\nin\nmussel aquaculture\n.\nA common evaluation set for image classification is the\nMNIST database\ndata set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.\n[\n188\n]\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.\n[\n189\n]\n[\n190\n]\nDeep learning-trained vehicles now interpret 360° camera views.\n[\n191\n]\nAnother example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\nVisual art processing\n[\nedit\n]\nVisual art processing of Jimmy Wales in France, with the style of Munch's \"\nThe Scream\n\" applied using neural style transfer\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\nidentifying the style period of a given painting\n[\n192\n]\n[\n193\n]\nNeural Style Transfer\n–  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\n[\n192\n]\n[\n193\n]\ngenerating striking imagery based on random visual input fields.\n[\n192\n]\n[\n193\n]\nNatural language processing\n[\nedit\n]\nMain article:\nNatural language processing\nNeural networks have been used for implementing language models since the early 2000s.\n[\n150\n]\nLSTM helped to improve machine translation and language modeling.\n[\n151\n]\n[\n152\n]\n[\n153\n]\nOther key techniques in this field are negative sampling\n[\n194\n]\nand\nword embedding\n. Word embedding, such as\nword2vec\n, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a\nvector space\n. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as\nprobabilistic context free grammar\n(PCFG) implemented by an RNN.\n[\n195\n]\nRecursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing.\n[\n195\n]\nDeep neural architectures provide the best results for constituency parsing,\n[\n196\n]\nsentiment analysis\n,\n[\n197\n]\ninformation retrieval,\n[\n198\n]\n[\n199\n]\nspoken language understanding,\n[\n200\n]\nmachine translation,\n[\n151\n]\n[\n201\n]\ncontextual entity linking,\n[\n201\n]\nwriting style recognition,\n[\n202\n]\nnamed-entity recognition\n(token classification),\n[\n203\n]\ntext classification, and others.\n[\n204\n]\nRecent developments generalize\nword embedding\nto\nsentence embedding\n.\nGoogle Translate\n(GT) uses a large end-to-end\nlong short-term memory\n(LSTM) network.\n[\n205\n]\n[\n206\n]\n[\n207\n]\n[\n208\n]\nGoogle Neural Machine Translation (GNMT)\nuses an\nexample-based machine translation\nmethod in which the system \"learns from millions of examples\".\n[\n206\n]\nIt translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages.\n[\n206\n]\nThe network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\".\n[\n206\n]\n[\n209\n]\nGT uses English as an intermediate between most language pairs.\n[\n209\n]\nDrug discovery and toxicology\n[\nedit\n]\nFor more information, see\nDrug discovery\nand\nToxicology\n.\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated\ntoxic effects\n.\n[\n210\n]\n[\n211\n]\nResearch has explored use of deep learning to predict the\nbiomolecular targets\n,\n[\n212\n]\n[\n213\n]\noff-targets\n, and\ntoxic effects\nof environmental chemicals in nutrients, household products and drugs.\n[\n214\n]\n[\n215\n]\n[\n216\n]\nAtomNet is a deep learning system for structure-based\nrational drug design\n.\n[\n217\n]\nAtomNet was used to predict novel candidate biomolecules for disease targets such as the\nEbola virus\n[\n218\n]\nand\nmultiple sclerosis\n.\n[\n219\n]\n[\n218\n]\nIn 2017\ngraph neural networks\nwere used for the first time to predict various properties of molecules in a large toxicology data set.\n[\n220\n]\nIn 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\n[\n221\n]\n[\n222\n]\nRecommendation systems\n[\nedit\n]\nMain article:\nRecommender system\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations.\n[\n223\n]\n[\n224\n]\nMulti-view deep learning has been applied for learning user preferences from multiple domains.\n[\n225\n]\nThe model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\nBioinformatics\n[\nedit\n]\nMain article:\nBioinformatics\nAn\nautoencoder\nANN was used in\nbioinformatics\n, to predict\ngene ontology\nannotations and gene-function relationships.\n[\n226\n]\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables\n[\n227\n]\nand predictions of health complications from\nelectronic health record\ndata.\n[\n228\n]\nDeep neural networks have shown unparalleled performance in\npredicting protein structure\n, according to the sequence of the amino acids that make it up. In 2020,\nAlphaFold\n, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.\n[\n229\n]\n[\n230\n]\nDeep Neural Network Estimations\n[\nedit\n]\nDeep neural networks can be used to estimate the entropy of a\nstochastic process\nthrough an arrangement called a Neural Joint Entropy Estimator (NJEE).\n[\n231\n]\nSuch an estimation provides insights on the effects of input\nrandom variables\non an independent\nrandom variable\n. Practically, the DNN is trained as a\nclassifier\nthat maps an input\nvector\nor\nmatrix\nX to an output\nprobability distribution\nover the possible classes of random variable Y, given input X. For example, in\nimage classification\ntasks, the NJEE maps a vector of\npixels\n' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a\nSoftmax\nlayer with number of nodes that is equal to the\nalphabet\nsize of Y. NJEE uses continuously differentiable\nactivation functions\n, such that the conditions for the\nuniversal approximation theorem\nholds. It is shown that this method provides a strongly\nconsistent estimator\nand outperforms other methods in cases of large alphabet sizes.\n[\n231\n]\nMedical image analysis\n[\nedit\n]\nDeep learning has been shown to produce competitive results in medical applications such as cancer cell classification, lesion detection, organ segmentation and image enhancement.\n[\n232\n]\n[\n233\n]\nModern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\n[\n234\n]\n[\n235\n]\nMobile advertising\n[\nedit\n]\nFinding the appropriate mobile audience for\nmobile advertising\nis always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server.\n[\n236\n]\nDeep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\nImage restoration\n[\nedit\n]\nDeep learning has been successfully applied to\ninverse problems\nsuch as\ndenoising\n,\nsuper-resolution\n,\ninpainting\n, and\nfilm colorization\n.\n[\n237\n]\nThese applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\"\n[\n238\n]\nwhich trains on an image dataset, and\nDeep Image Prior\n, which trains on the image that needs restoration.\nFinancial fraud detection\n[\nedit\n]\nDeep learning is being successfully applied to financial\nfraud detection\n, tax evasion detection,\n[\n239\n]\nand anti-money laundering.\n[\n240\n]\nMaterials science\n[\nedit\n]\nIn November 2023, researchers at\nGoogle DeepMind\nand\nLawrence Berkeley National Laboratory\nannounced that they had developed an AI system known as GNoME. This system has contributed to\nmaterials science\nby discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic\ncrystal structures\n. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the\nMaterials Project\ndatabase, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\n[\n241\n]\n[\n242\n]\n[\n243\n]\nMilitary\n[\nedit\n]\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.\n[\n244\n]\nPartial differential equations\n[\nedit\n]\nPhysics informed neural networks have been used to solve\npartial differential equations\nin both forward and inverse problems in a data driven manner.\n[\n245\n]\nOne example is the reconstructing fluid flow governed by the\nNavier-Stokes equations\n. Using physics informed neural networks does not require the often expensive mesh generation that conventional\nCFD\nmethods rely on.\n[\n246\n]\n[\n247\n]\nIt is evident that geometric and physical constraints have a synergistic effect on neural PDE surrogates, thereby enhancing their efficacy in predicting stable and super long rollouts.\n[\n248\n]\nDeep backward stochastic differential equation method\n[\nedit\n]\nDeep backward stochastic differential equation method\nis a numerical method that combines deep learning with\nBackward stochastic differential equation\n(BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of\ndeep neural networks\n, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.\n[\n249\n]\nIn addition, the integration of\nPhysics-informed neural networks\n(PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws directly into the neural network architecture. This ensures that the solutions not only fit the data but also adhere to the governing stochastic differential equations. PINNs leverage the power of deep learning while respecting the constraints imposed by the physical models, resulting in more accurate and reliable solutions for financial mathematics problems.\nImage reconstruction\n[\nedit\n]\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging\n[\n250\n]\nand ultrasound imaging.\n[\n251\n]\nWeather prediction\n[\nedit\n]\nTraditional weather prediction systems solve a very complex system of partial differential equations. GraphCast is a deep learning based model, trained on a long history of weather data to predict how weather patterns change over time. It is able to  predict weather conditions for up to 10 days globally, at a very detailed level, and in under a minute, with precision similar to state of the art systems.\n[\n252\n]\n[\n253\n]\nEpigenetic clock\n[\nedit\n]\nMain article:\nEpigenetic clock\nAn epigenetic clock is a\nbiochemical test\nthat can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples.\n[\n254\n]\nThe clock uses information from 1000\nCpG sites\nand predicts people with certain conditions older than healthy controls:\nIBD\n,\nfrontotemporal dementia\n,\novarian cancer\n,\nobesity\n. The aging clock was planned to be released for public use in 2021 by an\nInsilico Medicine\nspinoff company Deep Longevity.\nRelation to human cognitive and brain development\n[\nedit\n]\nDeep learning is closely related to a class of theories of\nbrain development\n(specifically, neocortical development) proposed by\ncognitive neuroscientists\nin the early 1990s.\n[\n255\n]\n[\n256\n]\n[\n257\n]\n[\n258\n]\nThese developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of\nnerve growth factor\n) support the\nself-organization\nsomewhat analogous to the neural networks utilized in deep learning models. Like the\nneocortex\n, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of\ntransducers\n, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".\n[\n259\n]\nA variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the\nbackpropagation\nalgorithm have been proposed in order to increase its processing realism.\n[\n260\n]\n[\n261\n]\nOther researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical\ngenerative models\nand\ndeep belief networks\n, may be closer to biological reality.\n[\n262\n]\n[\n263\n]\nIn this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.\n[\n264\n]\nAlthough a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons\n[\n265\n]\nand neural populations.\n[\n266\n]\nSimilarly, the representations developed by deep learning models are similar to those measured in the primate visual system\n[\n267\n]\nboth at the single-unit\n[\n268\n]\nand at the population\n[\n269\n]\nlevels.\nCommercial activity\n[\nedit\n]\nFacebook\n's AI lab performs tasks such as\nautomatically tagging uploaded pictures\nwith the names of the people in them.\n[\n270\n]\nGoogle's\nDeepMind Technologies\ndeveloped a system capable of learning how to play\nAtari\nvideo games using only pixels as data input. In 2015 they demonstrated their\nAlphaGo\nsystem, which learned the game of\nGo\nwell enough to beat a professional Go player.\n[\n271\n]\n[\n272\n]\n[\n273\n]\nGoogle Translate\nuses a neural network to translate between more than 100 languages.\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.\n[\n274\n]\nAs of 2008,\n[\n275\n]\nresearchers at\nThe University of Texas at Austin\n(UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor.\n[\n244\n]\nFirst developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between\nU.S. Army Research Laboratory\n(ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation.\n[\n244\n]\nUsing Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\n[\n276\n]\nCriticism and comment\n[\nedit\n]\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\nTheory\n[\nedit\n]\nSee also:\nExplainable artificial intelligence\nA main criticism concerns the lack of theory surrounding some methods.\n[\n277\n]\nLearning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear.\n[\ncitation needed\n]\n(e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a\nblack box\n, with most confirmations done empirically, rather than theoretically.\n[\n278\n]\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained\n[\n279\n]\ndemonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on\nThe Guardian\n's\n[\n280\n]\nwebsite.\nWith the support of\nInnovation Diffusion Theory\n(IDT), a study analyzed the diffusion of Deep Learning\n[\n281\n]\nin BRICS and OECD countries using data from\nGoogle Trends\n.\nErrors\n[\nedit\n]\nSome deep learning architectures display problematic behaviors,\n[\n282\n]\nsuch as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014)\n[\n283\n]\nand misclassifying minuscule perturbations of correctly classified images (2013).\n[\n284\n]\nGoertzel\nhypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component\nartificial general intelligence\n(AGI) architectures.\n[\n282\n]\nThese issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar\n[\n285\n]\ndecompositions of observed entities and events.\n[\n282\n]\nLearning a grammar\n(visual or linguistic) from training data would be equivalent to restricting the system to\ncommonsense reasoning\nthat operates on concepts in terms of grammatical\nproduction rules\nand is a basic goal of both human language acquisition\n[\n286\n]\nand\nartificial intelligence\n(AI).\n[\n287\n]\nCyber threat\n[\nedit\n]\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception.\n[\n288\n]\nBy identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"\nadversarial attack\n\".\n[\n289\n]\nIn 2016 researchers used one ANN to doctor images in trial and error fashion, identify another's focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system.\n[\n290\n]\nOne defense is reverse image search, in which a possible fake image is submitted to a site such as\nTinEye\nthat can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken\n.\n[\n291\n]\nAnother group showed that certain\npsychedelic\nspectacles could fool a\nfacial recognition system\ninto thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to\nstop signs\nand caused an ANN to misclassify them.\n[\n290\n]\nANNs can however be further trained to detect attempts at\ndeception\n, potentially leading attackers and defenders into an arms race similar to the kind that already defines the\nmalware\ndefense industry. ANNs have been trained to defeat ANN-based anti-\nmalware\nsoftware by repeatedly attacking a defense with malware that was continually altered by a\ngenetic algorithm\nuntil it tricked the anti-malware while retaining its ability to damage the target.\n[\n290\n]\nIn 2016, another group demonstrated that certain sounds could make the\nGoogle Now\nvoice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".\n[\n290\n]\nIn \"\ndata poisoning\n\", false data is continually smuggled into a machine learning system's training set to prevent it from achieving mastery.\n[\n290\n]\nData collection ethics\n[\nedit\n]\nThe deep learning systems that are trained using supervised learning often rely on data that is created or annotated by humans, or both.\n[\n292\n]\nIt has been argued that not only low-paid\nclickwork\n(such as on\nAmazon Mechanical Turk\n) is regularly deployed for this purpose, but also implicit forms of human\nmicrowork\nthat are often not recognized as such.\n[\n293\n]\nThe philosopher\nRainer Mühlhoff\ndistinguishes five types of \"machinic capture\" of human microwork to generate training data: (1)\ngamification\n(the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g.\nCAPTCHAs\nfor image recognition or click-tracking on Google\nsearch results pages\n), (3) exploitation of social motivations (e.g.\ntagging faces\non\nFacebook\nto obtain labeled facial images), (4)\ninformation mining\n(e.g. by leveraging\nquantified-self\ndevices such as\nactivity trackers\n) and (5)\nclickwork\n.\n[\n293\n]\nSee also\n[\nedit\n]\nApplications of artificial intelligence\nComparison of deep learning software\nCompressed sensing\nDifferentiable programming\nEcho state network\nList of artificial intelligence projects\nLiquid state machine\nList of datasets for machine-learning research\nReservoir computing\nScale space and deep learning\nSparse coding\nStochastic parrot\nTopological deep learning\nReferences\n[\nedit\n]\n^\nSchulz, Hannes; Behnke, Sven (1 November 2012).\n\"Deep Learning\"\n.\nKI - Künstliche Intelligenz\n.\n26\n(4):\n357–\n363.\ndoi\n:\n10.1007/s13218-012-0198-z\n.\nISSN\n1610-1987\n.\nS2CID\n220523562\n.\n^\na\nb\nLeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (2015).\n\"Deep Learning\"\n(PDF)\n.\nNature\n.\n521\n(7553):\n436–\n444.\nBibcode\n:\n2015Natur.521..436L\n.\ndoi\n:\n10.1038/nature14539\n.\nPMID\n26017442\n.\nS2CID\n3074096\n.\n^\na\nb\nCiresan, D.; Meier, U.; Schmidhuber, J. (2012). \"Multi-column deep neural networks for image classification\".\n2012 IEEE Conference on Computer Vision and Pattern Recognition\n. pp.\n3642–\n3649.\narXiv\n:\n1202.2745\n.\ndoi\n:\n10.1109/cvpr.2012.6248110\n.\nISBN\n978-1-4673-1228-8\n.\nS2CID\n2161592\n.\n^\na\nb\nKrizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey (2012).\n\"ImageNet Classification with Deep Convolutional Neural Networks\"\n(PDF)\n.\nNIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada\n.\nArchived\n(PDF)\nfrom the original on 2017-01-10\n. Retrieved\n2017-05-24\n.\n^\n\"Google's AlphaGo AI wins three-match series against the world's best Go player\"\n.\nTechCrunch\n. 25 May 2017.\nArchived\nfrom the original on 17 June 2018\n. Retrieved\n17 June\n2018\n.\n^\n\"Study urges caution when comparing neural networks to the brain\"\n.\nMIT News | Massachusetts Institute of Technology\n. 2022-11-02\n. Retrieved\n2023-12-06\n.\n^\na\nb\nc\nd\nBengio, Yoshua (2009).\n\"Learning Deep Architectures for AI\"\n(PDF)\n.\nFoundations and Trends in Machine Learning\n.\n2\n(1):\n1–\n127.\nCiteSeerX\n10.1.1.701.9550\n.\ndoi\n:\n10.1561/2200000006\n.\nS2CID\n207178999\n. Archived from\nthe original\n(PDF)\non 4 March 2016\n. Retrieved\n3 September\n2015\n.\n^\na\nb\nc\nd\ne\nBengio, Y.; Courville, A.; Vincent, P. (2013). \"Representation Learning: A Review and New Perspectives\".\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n.\n35\n(8):\n1798–\n1828.\narXiv\n:\n1206.5538\n.\nBibcode\n:\n2013ITPAM..35.1798B\n.\ndoi\n:\n10.1109/tpami.2013.50\n.\nPMID\n23787338\n.\nS2CID\n393948\n.\n^\na\nb\nc\nd\ne\nf\ng\nh\nSchmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\".\nNeural Networks\n.\n61\n:\n85–\n117.\narXiv\n:\n1404.7828\n.\ndoi\n:\n10.1016/j.neunet.2014.09.003\n.\nPMID\n25462637\n.\nS2CID\n11715509\n.\n^\nShigeki, Sugiyama (12 April 2019).\nHuman Behavior and Another Kind in Consciousness: Emerging Research and Opportunities: Emerging Research and Opportunities\n. IGI Global.\nISBN\n978-1-5225-8218-2\n.\n^\nBengio, Yoshua; Lamblin, Pascal; Popovici, Dan; Larochelle, Hugo (2007).\nGreedy layer-wise training of deep networks\n(PDF)\n. Advances in neural information processing systems. pp.\n153–\n160.\nArchived\n(PDF)\nfrom the original on 2019-10-20\n. Retrieved\n2019-10-06\n.\n^\na\nb\nHinton, G.E. (2009).\n\"Deep belief networks\"\n.\nScholarpedia\n.\n4\n(5): 5947.\nBibcode\n:\n2009SchpJ...4.5947H\n.\ndoi\n:\n10.4249/scholarpedia.5947\n.\n^\nRina Dechter\n(1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.\nOnline\nArchived\n2016-04-19 at the\nWayback Machine\n^\nAizenberg, I.N.; Aizenberg, N.N.; Vandewalle, J. (2000).\nMulti-Valued and Universal Binary Neurons\n. Science & Business Media.\ndoi\n:\n10.1007/978-1-4757-3115-6\n.\nISBN\n978-0-7923-7824-2\n. Retrieved\n27 December\n2023\n.\n^\nCo-evolving recurrent neurons learn deep memory POMDPs. Proc. GECCO, Washington, D. C., pp. 1795–1802, ACM Press, New York, NY, USA, 2005.\n^\nFradkov, Alexander L. (2020-01-01).\n\"Early History of Machine Learning\"\n.\nIFAC-PapersOnLine\n. 21st IFAC World Congress.\n53\n(2):\n1385–\n1390.\ndoi\n:\n10.1016/j.ifacol.2020.12.1888\n.\nISSN\n2405-8963\n.\nS2CID\n235081987\n.\n^\na\nb\nc\nCybenko (1989).\n\"Approximations by superpositions of sigmoidal functions\"\n(PDF)\n.\nMathematics of Control, Signals, and Systems\n.\n2\n(4):\n303–\n314.\nBibcode\n:\n1989MCSS....2..303C\n.\ndoi\n:\n10.1007/bf02551274\n.\nS2CID\n3958369\n. Archived from\nthe original\n(PDF)\non 10 October 2015.\n^\na\nb\nc\nHornik, Kurt (1991). \"Approximation Capabilities of Multilayer Feedforward Networks\".\nNeural Networks\n.\n4\n(2):\n251–\n257.\ndoi\n:\n10.1016/0893-6080(91)90009-t\n.\nS2CID\n7343126\n.\n^\na\nb\nHaykin, Simon S. (1999).\nNeural Networks: A Comprehensive Foundation\n. Prentice Hall.\nISBN\n978-0-13-273350-2\n.\n^\na\nb\nHassoun, Mohamad H. (1995).\nFundamentals of Artificial Neural Networks\n. MIT Press. p. 48.\nISBN\n978-0-262-08239-6\n.\n^\na\nb\nLu, Z., Pu, H., Wang, F., Hu, Z., & Wang, L. (2017).\nThe Expressive Power of Neural Networks: A View from the Width\nArchived\n2019-02-13 at the\nWayback Machine\n. Neural Information Processing Systems, 6231-6239.\n^\nOrhan, A. E.; Ma, W. J. (2017).\n\"Efficient probabilistic inference in generic neural networks trained with non-probabilistic feedback\"\n.\nNature Communications\n.\n8\n(1): 138.\nBibcode\n:\n2017NatCo...8..138O\n.\ndoi\n:\n10.1038/s41467-017-00181-8\n.\nPMC\n5527101\n.\nPMID\n28743932\n.\n^\na\nb\nc\nd\ne\nDeng, L.; Yu, D. (2014).\n\"Deep Learning: Methods and Applications\"\n(PDF)\n.\nFoundations and Trends in Signal Processing\n.\n7\n(\n3–\n4):\n1–\n199.\ndoi\n:\n10.1561/2000000039\n.\nArchived\n(PDF)\nfrom the original on 2016-03-14\n. Retrieved\n2014-10-18\n.\n^\na\nb\nc\nd\nMurphy, Kevin P. (24 August 2012).\nMachine Learning: A Probabilistic Perspective\n. MIT Press.\nISBN\n978-0-262-01802-9\n.\n^\na\nb\nFukushima, K. (1969). \"Visual feature extraction by a multilayered network of analog threshold elements\".\nIEEE Transactions on Systems Science and Cybernetics\n.\n5\n(4):\n322–\n333.\ndoi\n:\n10.1109/TSSC.1969.300225\n.\n^\nSonoda, Sho; Murata, Noboru (2017). \"Neural network with unbounded activation functions is universal approximator\".\nApplied and Computational Harmonic Analysis\n.\n43\n(2):\n233–\n268.\narXiv\n:\n1505.03654\n.\ndoi\n:\n10.1016/j.acha.2015.12.005\n.\nS2CID\n12149203\n.\n^\nBishop, Christopher M. (2006).\nPattern Recognition and Machine Learning\n(PDF)\n. Springer.\nISBN\n978-0-387-31073-2\n.\nArchived\n(PDF)\nfrom the original on 2017-01-11\n. Retrieved\n2017-08-06\n.\n^\na\nb\n\"bibliotheca Augustana\"\n.\nwww.hs-augsburg.de\n.\n^\nBrush, Stephen G. (1967). \"History of the Lenz-Ising Model\".\nReviews of Modern Physics\n.\n39\n(4):\n883–\n893.\nBibcode\n:\n1967RvMP...39..883B\n.\ndoi\n:\n10.1103/RevModPhys.39.883\n.\n^\na\nb\nAmari, Shun-Ichi (1972). \"Learning patterns and pattern sequences by self-organizing nets of threshold elements\".\nIEEE Transactions\n.\nC\n(21):\n1197–\n1206.\n^\na\nb\nc\nd\ne\nf\ng\nSchmidhuber, Jürgen\n(2022). \"Annotated History of Modern AI and Deep Learning\".\narXiv\n:\n2212.11279\n[\ncs.NE\n].\n^\nHopfield, J. J. (1982).\n\"Neural networks and physical systems with emergent collective computational abilities\"\n.\nProceedings of the National Academy of Sciences\n.\n79\n(8):\n2554–\n2558.\nBibcode\n:\n1982PNAS...79.2554H\n.\ndoi\n:\n10.1073/pnas.79.8.2554\n.\nPMC\n346238\n.\nPMID\n6953413\n.\n^\nNakano, Kaoru (1971). \"Learning Process in a Model of Associative Memory\".\nPattern Recognition and Machine Learning\n. pp.\n172–\n186.\ndoi\n:\n10.1007/978-1-4615-7566-5_15\n.\nISBN\n978-1-4615-7568-9\n.\n^\nNakano, Kaoru (1972). \"Associatron-A Model of Associative Memory\".\nIEEE Transactions on Systems, Man, and Cybernetics\n. SMC-2 (3):\n380–\n388.\ndoi\n:\n10.1109/TSMC.1972.4309133\n.\n^\nTuring, Alan (1992) [1948]. \"Intelligent Machinery\". In Ince, D.C. (ed.).\nCollected Works of AM Turing: Mechanical Intelligence\n. Vol. 1. Elsevier Science Publishers. p. 107.\nISBN\n0-444-88058-5\n.\n^\nRosenblatt, F. (1958).\n\"The perceptron: A probabilistic model for information storage and organization in the brain\"\n.\nPsychological Review\n.\n65\n(6):\n386–\n408.\ndoi\n:\n10.1037/h0042519\n.\nISSN\n1939-1471\n.\nPMID\n13602029\n.\n^\na\nb\nRosenblatt, Frank\n(1962).\nPrinciples of Neurodynamics\n. Spartan, New York.\n^\nJoseph, R. D. (1960).\nContributions to Perceptron Theory, Cornell Aeronautical Laboratory Report No. VG-11 96--G-7, Buffalo\n.\n^\nIvakhnenko, A. G.; Lapa, V. G. (1967).\nCybernetics and Forecasting Techniques\n. American Elsevier Publishing Co.\nISBN\n978-0-444-00020-0\n.\n^\nIvakhnenko, A.G. (March 1970).\n\"Heuristic self-organization in problems of engineering cybernetics\"\n.\nAutomatica\n.\n6\n(2):\n207–\n219.\ndoi\n:\n10.1016/0005-1098(70)90092-0\n.\n^\na\nb\nIvakhnenko, Alexey (1971).\n\"Polynomial theory of complex systems\"\n(PDF)\n.\nIEEE Transactions on Systems, Man, and Cybernetics\n. SMC-1 (4):\n364–\n378.\ndoi\n:\n10.1109/TSMC.1971.4308320\n.\nArchived\n(PDF)\nfrom the original on 2017-08-29\n. Retrieved\n2019-11-05\n.\n^\nRobbins, H.\n; Monro, S. (1951).\n\"A Stochastic Approximation Method\"\n.\nThe Annals of Mathematical Statistics\n.\n22\n(3): 400.\ndoi\n:\n10.1214/aoms/1177729586\n.\n^\nAmari, Shun'ichi\n(1967). \"A theory of adaptive pattern classifier\".\nIEEE Transactions\n.\nEC\n(16):\n279–\n307.\n^\nRamachandran, Prajit; Barret, Zoph; Quoc, V. Le (October 16, 2017). \"Searching for Activation Functions\".\narXiv\n:\n1710.05941\n[\ncs.NE\n].\n^\nFukushima, K. (1979). \"Neural network model for a mechanism of pattern recognition unaffected by shift in position—Neocognitron\".\nTrans. IECE (In Japanese)\n. J62-A (10):\n658–\n665.\ndoi\n:\n10.1007/bf00344251\n.\nPMID\n7370364\n.\nS2CID\n206775608\n.\n^\nFukushima, K. (1980). \"Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\".\nBiol. Cybern\n.\n36\n(4):\n193–\n202.\ndoi\n:\n10.1007/bf00344251\n.\nPMID\n7370364\n.\nS2CID\n206775608\n.\n^\nLeibniz, Gottfried Wilhelm Freiherr von (1920).\nThe Early Mathematical Manuscripts of Leibniz: Translated from the Latin Texts Published by Carl Immanuel Gerhardt with Critical and Historical Notes (Leibniz published the chain rule in a 1676 memoir)\n. Open court publishing Company.\nISBN\n978-0-598-81846-1\n.\n{{\ncite book\n}}\n:\nISBN / Date incompatibility (\nhelp\n)\n^\nKelley, Henry J.\n(1960). \"Gradient theory of optimal flight paths\".\nARS Journal\n.\n30\n(10):\n947–\n954.\ndoi\n:\n10.2514/8.5282\n.\n^\nLinnainmaa, Seppo\n(1970).\nThe representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors\n(Masters) (in Finnish). University of Helsinki. p. 6–7.\n^\nLinnainmaa, Seppo\n(1976). \"Taylor expansion of the accumulated rounding error\".\nBIT Numerical Mathematics\n.\n16\n(2):\n146–\n160.\ndoi\n:\n10.1007/bf01931367\n.\nS2CID\n122357351\n.\n^\nOstrovski, G.M., Volin,Y.M., and Boris, W.W. (1971). On the computation of derivatives. Wiss. Z. Tech. Hochschule for Chemistry, 13:382–384.\n^\na\nb\nSchmidhuber, Juergen\n(25 Oct 2014).\n\"Who Invented Backpropagation?\"\n. IDSIA, Switzerland. Archived from\nthe original\non 30 July 2024\n. Retrieved\n14 Sep\n2024\n.\n^\nWerbos, Paul\n(1982).\n\"Applications of advances in nonlinear sensitivity analysis\"\n(PDF)\n.\nSystem modeling and optimization\n. Springer. pp.\n762–\n770.\nArchived\n(PDF)\nfrom the original on 14 April 2016\n. Retrieved\n2 July\n2017\n.\n^\nWerbos, Paul J. (1994).\nThe Roots of Backpropagation: From Ordered Derivatives to Neural Networks and Political Forecasting\n. New York: John Wiley & Sons.\nISBN\n0-471-59897-6\n.\n^\nRumelhart, David E.; Hinton, Geoffrey E.; Williams, Ronald J. (October 1986).\n\"Learning representations by back-propagating errors\"\n.\nNature\n.\n323\n(6088):\n533–\n536.\nBibcode\n:\n1986Natur.323..533R\n.\ndoi\n:\n10.1038/323533a0\n.\nISSN\n1476-4687\n.\n^\nRumelhart, David E., Geoffrey E. Hinton, and R. J. Williams. \"\nLearning Internal Representations by Error Propagation\nArchived\n2022-10-13 at the\nWayback Machine\n\". David E. Rumelhart, James L. McClelland, and the PDP research group. (editors), Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundation. MIT Press, 1986.\n^\nWaibel, Alex (December 1987).\nPhoneme Recognition Using Time-Delay Neural Networks\n(PDF)\n. Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE). Tokyo, Japan.\n^\nAlexander Waibel\net al.,\nPhoneme Recognition Using Time-Delay Neural Networks\nIEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. – 339 March 1989.\n^\nZhang, Wei (1988).\n\"Shift-invariant pattern recognition neural network and its optical architecture\"\n.\nProceedings of Annual Conference of the Japan Society of Applied Physics\n.\n^\nLeCun\net al.\n, \"Backpropagation Applied to Handwritten Zip Code Recognition\",\nNeural Computation\n, 1, pp. 541–551, 1989.\n^\nZhang, Wei (1990).\n\"Parallel distributed processing model with local space-invariant interconnections and its optical architecture\"\n.\nApplied Optics\n.\n29\n(32):\n4790–\n7.\nBibcode\n:\n1990ApOpt..29.4790Z\n.\ndoi\n:\n10.1364/AO.29.004790\n.\nPMID\n20577468\n.\n^\nZhang, Wei (1991).\n\"Image processing of human corneal endothelium based on a learning network\"\n.\nApplied Optics\n.\n30\n(29):\n4211–\n7.\nBibcode\n:\n1991ApOpt..30.4211Z\n.\ndoi\n:\n10.1364/AO.30.004211\n.\nPMID\n20706526\n.\n^\nZhang, Wei (1994).\n\"Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network\"\n.\nMedical Physics\n.\n21\n(4):\n517–\n24.\nBibcode\n:\n1994MedPh..21..517Z\n.\ndoi\n:\n10.1118/1.597177\n.\nPMID\n8058017\n.\n^\nLeCun, Yann; Léon Bottou; Yoshua Bengio; Patrick Haffner (1998).\n\"Gradient-based learning applied to document recognition\"\n(PDF)\n.\nProceedings of the IEEE\n.\n86\n(11):\n2278–\n2324.\nCiteSeerX\n10.1.1.32.9552\n.\ndoi\n:\n10.1109/5.726791\n.\nS2CID\n14542261\n. Retrieved\nOctober 7,\n2016\n.\n^\nJordan, Michael I. (1986).\n\"Attractor dynamics and parallelism in a connectionist sequential machine\"\n.\nProceedings of the Annual Meeting of the Cognitive Science Society\n.\n8\n.\n^\nElman, Jeffrey L. (March 1990).\n\"Finding Structure in Time\"\n.\nCognitive Science\n.\n14\n(2):\n179–\n211.\ndoi\n:\n10.1207/s15516709cog1402_1\n.\nISSN\n0364-0213\n.\n^\na\nb\nc\nSchmidhuber, Jürgen\n(April 1991).\n\"Neural Sequence Chunkers\"\n(PDF)\n.\nTR FKI-148, TU Munich\n.\n^\na\nb\nSchmidhuber, Jürgen (1992).\n\"Learning complex, extended sequences using the principle of history compression (based on TR FKI-148, 1991)\"\n(PDF)\n.\nNeural Computation\n.\n4\n(2):\n234–\n242.\ndoi\n:\n10.1162/neco.1992.4.2.234\n.\nS2CID\n18271205\n.\n^\nSchmidhuber, Jürgen (1993).\nHabilitation thesis: System modeling and optimization\n(PDF)\n. Archived from\nthe original\n(PDF)\non May 16, 2022.\nPage 150 ff demonstrates credit assignment across the equivalent of 1,200 layers in an unfolded RNN.\n^\na\nb\nc\nS. Hochreiter., \"\nUntersuchungen zu dynamischen neuronalen Netzen\n\".\nArchived\n2015-03-06 at the\nWayback Machine\n.\nDiploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber\n, 1991.\n^\nHochreiter, S.; et al. (15 January 2001).\n\"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies\"\n. In Kolen, John F.; Kremer, Stefan C. (eds.).\nA Field Guide to Dynamical Recurrent Networks\n. John Wiley & Sons.\nISBN\n978-0-7803-5369-5\n.\n^\nSepp Hochreiter\n;\nJürgen Schmidhuber\n(21 August 1995),\nLong Short Term Memory\n,\nWikidata\nQ98967430\n^\nGers, Felix; Schmidhuber, Jürgen; Cummins, Fred (1999). \"Learning to forget: Continual prediction with LSTM\".\n9th International Conference on Artificial Neural Networks: ICANN '99\n. Vol. 1999. pp.\n850–\n855.\ndoi\n:\n10.1049/cp:19991218\n.\nISBN\n0-85296-721-7\n.\n^\na\nb\nSchmidhuber, Jürgen\n(1991). \"A possibility for implementing curiosity and boredom in model-building neural controllers\".\nProc. SAB'1991\n. MIT Press/Bradford Books. pp.\n222–\n227.\n^\nSchmidhuber, Jürgen\n(2010). \"Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010)\".\nIEEE Transactions on Autonomous Mental Development\n.\n2\n(3):\n230–\n247.\nBibcode\n:\n2010ITAMD...2..230S\n.\ndoi\n:\n10.1109/TAMD.2010.2056368\n.\nS2CID\n234198\n.\n^\na\nb\nSchmidhuber, Jürgen\n(2020). \"Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)\".\nNeural Networks\n.\n127\n:\n58–\n66.\narXiv\n:\n1906.04493\n.\ndoi\n:\n10.1016/j.neunet.2020.04.008\n.\nPMID\n32334341\n.\nS2CID\n216056336\n.\n^\nAckley, David H.; Hinton, Geoffrey E.; Sejnowski, Terrence J. (1985-01-01).\n\"A learning algorithm for boltzmann machines\"\n.\nCognitive Science\n.\n9\n(1):\n147–\n169.\ndoi\n:\n10.1016/S0364-0213(85)80012-4\n.\nISSN\n0364-0213\n.\n^\nSmolensky, Paul (1986).\n\"Chapter 6: Information Processing in Dynamical Systems: Foundations of Harmony Theory\"\n(PDF)\n. In Rumelhart, David E.; McLelland, James L. (eds.).\nParallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations\n. MIT Press. pp.\n194–281\n.\nISBN\n0-262-68053-X\n.\n^\nPeter, Dayan\n;\nHinton, Geoffrey E.\n;\nNeal, Radford M.\n;\nZemel, Richard S.\n(1995). \"The Helmholtz machine\".\nNeural Computation\n.\n7\n(5):\n889–\n904.\ndoi\n:\n10.1162/neco.1995.7.5.889\n.\nhdl\n:\n21.11116/0000-0002-D6D3-E\n.\nPMID\n7584891\n.\nS2CID\n1890561\n.\n^\nHinton, Geoffrey E.\n;\nDayan, Peter\n;\nFrey, Brendan J.\n; Neal, Radford (1995-05-26). \"The wake-sleep algorithm for unsupervised neural networks\".\nScience\n.\n268\n(5214):\n1158–\n1161.\nBibcode\n:\n1995Sci...268.1158H\n.\ndoi\n:\n10.1126/science.7761831\n.\nPMID\n7761831\n.\nS2CID\n871473\n.\n^\nSejnowski, Terrence J. (2018).\nThe Deep Learning Revolution\n. Cambridge, Massachusetts:\nThe MIT Press\n.\nISBN\n978-0-262-03803-4\n.\n^\nQian, Ning; Sejnowski, Terrence J. (1988-08-20). \"Predicting the secondary structure of globular proteins using neural network models\".\nJournal of Molecular Biology\n.\n202\n(4):\n865–\n884.\ndoi\n:\n10.1016/0022-2836(88)90564-5\n.\nISSN\n0022-2836\n.\nPMID\n3172241\n.\n^\nMorgan, Nelson; Bourlard, Hervé; Renals, Steve; Cohen, Michael; Franco, Horacio (1 August 1993). \"Hybrid neural network/hidden markov model systems for continuous speech recognition\".\nInternational Journal of Pattern Recognition and Artificial Intelligence\n.\n07\n(4):\n899–\n916.\ndoi\n:\n10.1142/s0218001493000455\n.\nISSN\n0218-0014\n.\n^\nRobinson, T.\n(1992).\n\"A real-time recurrent error propagation network word recognition system\"\n.\nICASSP\n. Icassp'92:\n617–\n620.\nISBN\n978-0-7803-0532-8\n.\nArchived\nfrom the original on 2021-05-09\n. Retrieved\n2017-06-12\n.\n^\nWaibel, A.; Hanazawa, T.; Hinton, G.; Shikano, K.; Lang, K. J. (March 1989).\n\"Phoneme recognition using time-delay neural networks\"\n(PDF)\n.\nIEEE Transactions on Acoustics, Speech, and Signal Processing\n.\n37\n(3):\n328–\n339.\ndoi\n:\n10.1109/29.21701\n.\nhdl\n:\n10338.dmlcz/135496\n.\nISSN\n0096-3518\n.\nS2CID\n9563026\n.\nArchived\n(PDF)\nfrom the original on 2021-04-27\n. Retrieved\n2019-09-24\n.\n^\nBaker, J.; Deng, Li; Glass, Jim; Khudanpur, S.; Lee, C.-H.; Morgan, N.; O'Shaughnessy, D. (2009). \"Research Developments and Directions in Speech Recognition and Understanding, Part 1\".\nIEEE Signal Processing Magazine\n.\n26\n(3):\n75–\n80.\nBibcode\n:\n2009ISPM...26...75B\n.\ndoi\n:\n10.1109/msp.2009.932166\n.\nhdl\n:\n1721.1/51891\n.\nS2CID\n357467\n.\n^\nBengio, Y. (1991).\n\"Artificial Neural Networks and their Application to Speech/Sequence Recognition\"\n. McGill University Ph.D. thesis.\nArchived\nfrom the original on 2021-05-09\n. Retrieved\n2017-06-12\n.\n^\nDeng, L.; Hassanein, K.; Elmasry, M. (1994). \"Analysis of correlation structure for a neural predictive model with applications to speech recognition\".\nNeural Networks\n.\n7\n(2):\n331–\n339.\ndoi\n:\n10.1016/0893-6080(94)90027-2\n.\n^\nDoddington, G.; Przybocki, M.; Martin, A.; Reynolds, D. (2000). \"The NIST speaker recognition evaluation ± Overview, methodology, systems, results, perspective\".\nSpeech Communication\n.\n31\n(2):\n225–\n254.\ndoi\n:\n10.1016/S0167-6393(99)00080-1\n.\n^\na\nb\nHeck, L.; Konig, Y.; Sonmez, M.; Weintraub, M. (2000). \"Robustness to Telephone Handset Distortion in Speaker Recognition by Discriminative Feature Design\".\nSpeech Communication\n.\n31\n(2):\n181–\n192.\ndoi\n:\n10.1016/s0167-6393(99)00077-1\n.\n^\nL.P Heck and R. Teunen. \"Secure and Convenient Transactions with Nuance Verifier\". Nuance Users Conference, April 1998.\n^\n\"Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR (PDF Download Available)\"\n.\nResearchGate\n.\nArchived\nfrom the original on 9 May 2021\n. Retrieved\n14 June\n2017\n.\n^\na\nb\nGraves, Alex; Eck, Douglas; Beringer, Nicole; Schmidhuber, Jürgen (2003).\n\"Biologically Plausible Speech Recognition with LSTM Neural Nets\"\n(PDF)\n.\n1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland\n. pp.\n175–\n184. Archived from\nthe original\n(PDF)\non 2017-07-06\n. Retrieved\n2016-04-09\n.\n^\nGraves, Alex\n; Fernández, Santiago; Gomez, Faustino;\nSchmidhuber, Jürgen\n(2006). \"Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks\".\nProceedings of the International Conference on Machine Learning, ICML 2006\n:\n369–\n376.\nCiteSeerX\n10.1.1.75.6306\n.\n^\nSantiago Fernandez, Alex Graves, and Jürgen Schmidhuber (2007).\nAn application of recurrent neural networks to discriminative keyword spotting\nArchived\n2018-11-18 at the\nWayback Machine\n. Proceedings of ICANN (2), pp. 220–229.\n^\nGraves, Alex; and Schmidhuber, Jürgen;\nOffline Handwriting Recognition with Multidimensional Recurrent Neural Networks\n, in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.),\nAdvances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC\n, Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552\n^\nHinton, Geoffrey E. (1 October 2007).\n\"Learning multiple layers of representation\"\n.\nTrends in Cognitive Sciences\n.\n11\n(10):\n428–\n434.\ndoi\n:\n10.1016/j.tics.2007.09.004\n.\nISSN\n1364-6613\n.\nPMID\n17921042\n.\nS2CID\n15066318\n.\nArchived\nfrom the original on 11 October 2013\n. Retrieved\n12 June\n2017\n.\n^\nHinton, G. E.\n; Osindero, S.; Teh, Y. W. (2006).\n\"A Fast Learning Algorithm for Deep Belief Nets\"\n(PDF)\n.\nNeural Computation\n.\n18\n(7):\n1527–\n1554.\ndoi\n:\n10.1162/neco.2006.18.7.1527\n.\nPMID\n16764513\n.\nS2CID\n2309950\n.\nArchived\n(PDF)\nfrom the original on 2015-12-23\n. Retrieved\n2011-07-20\n.\n^\nG. E. Hinton., \"\nLearning multiple layers of representation\n\".\nArchived\n2018-05-22 at the\nWayback Machine\n.\nTrends in Cognitive Sciences\n, 11, pp. 428–434, 2007.\n^\nHinton, Geoffrey E. (October 2007).\n\"Learning multiple layers of representation\"\n.\nTrends in Cognitive Sciences\n.\n11\n(10):\n428–\n434.\ndoi\n:\n10.1016/j.tics.2007.09.004\n.\nPMID\n17921042\n.\n^\nHinton, Geoffrey E.; Osindero, Simon; Teh, Yee-Whye (July 2006).\n\"A Fast Learning Algorithm for Deep Belief Nets\"\n.\nNeural Computation\n.\n18\n(7):\n1527–\n1554.\ndoi\n:\n10.1162/neco.2006.18.7.1527\n.\nISSN\n0899-7667\n.\nPMID\n16764513\n.\n^\nHinton, Geoffrey E. (2009-05-31).\n\"Deep belief networks\"\n.\nScholarpedia\n.\n4\n(5): 5947.\nBibcode\n:\n2009SchpJ...4.5947H\n.\ndoi\n:\n10.4249/scholarpedia.5947\n.\nISSN\n1941-6016\n.\n^\nYann LeCun\n(2016). Slides on Deep Learning\nOnline\nArchived\n2016-04-23 at the\nWayback Machine\n^\na\nb\nc\nHinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.;\nSainath, T.\n; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups\".\nIEEE Signal Processing Magazine\n.\n29\n(6):\n82–\n97.\nBibcode\n:\n2012ISPM...29...82H\n.\ndoi\n:\n10.1109/msp.2012.2205597\n.\nS2CID\n206485943\n.\n^\na\nb\nc\nDeng, L.; Hinton, G.; Kingsbury, B. (May 2013).\n\"New types of deep neural network learning for speech recognition and related applications: An overview (ICASSP)\"\n(PDF)\n. Microsoft.\nArchived\n(PDF)\nfrom the original on 2017-09-26\n. Retrieved\n27 December\n2023\n.\n^\na\nb\nc\nYu, D.; Deng, L. (2014).\nAutomatic Speech Recognition: A Deep Learning Approach (Publisher: Springer)\n. Springer.\nISBN\n978-1-4471-5779-3\n.\n^\n\"Deng receives prestigious IEEE Technical Achievement Award - Microsoft Research\"\n.\nMicrosoft Research\n. 3 December 2015.\nArchived\nfrom the original on 16 March 2018\n. Retrieved\n16 March\n2018\n.\n^\na\nb\nLi, Deng (September 2014).\n\"Keynote talk: 'Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing'\n\"\n.\nInterspeech\n.\nArchived\nfrom the original on 2017-09-26\n. Retrieved\n2017-06-12\n.\n^\nYu, D.; Deng, L. (2010).\n\"Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition\"\n.\nNIPS Workshop on Deep Learning and Unsupervised Feature Learning\n.\nArchived\nfrom the original on 2017-10-12\n. Retrieved\n2017-06-14\n.\n^\nSeide, F.; Li, G.; Yu, D. (2011).\n\"Conversational speech transcription using context-dependent deep neural networks\"\n.\nInterspeech 2011\n. pp.\n437–\n440.\ndoi\n:\n10.21437/Interspeech.2011-169\n.\nS2CID\n398770\n.\nArchived\nfrom the original on 2017-10-12\n. Retrieved\n2017-06-14\n.\n^\nDeng, Li; Li, Jinyu; Huang, Jui-Ting; Yao, Kaisheng; Yu, Dong; Seide, Frank; Seltzer, Mike; Zweig, Geoff; He, Xiaodong (1 May 2013).\n\"Recent Advances in Deep Learning for Speech Research at Microsoft\"\n.\nMicrosoft Research\n.\nArchived\nfrom the original on 12 October 2017\n. Retrieved\n14 June\n2017\n.\n^\na\nb\nOh, K.-S.; Jung, K. (2004). \"GPU implementation of neural networks\".\nPattern Recognition\n.\n37\n(6):\n1311–\n1314.\nBibcode\n:\n2004PatRe..37.1311O\n.\ndoi\n:\n10.1016/j.patcog.2004.01.013\n.\n^\na\nb\nChellapilla, Kumar; Puri, Sidd; Simard, Patrice (2006),\nHigh performance convolutional neural networks for document processing\n,\narchived\nfrom the original on 2020-05-18\n, retrieved\n2021-02-14\n^\nSze, Vivienne\n; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel (2017). \"Efficient Processing of Deep Neural Networks: A Tutorial and Survey\".\narXiv\n:\n1703.09039\n[\ncs.CV\n].\n^\nRaina, Rajat; Madhavan, Anand; Ng, Andrew Y. (2009-06-14).\n\"Large-scale deep unsupervised learning using graphics processors\"\n.\nProceedings of the 26th Annual International Conference on Machine Learning\n. ICML '09. New York, NY, USA: Association for Computing Machinery. pp.\n873–\n880.\ndoi\n:\n10.1145/1553374.1553486\n.\nISBN\n978-1-60558-516-1\n.\n^\nCireşan, Dan Claudiu; Meier, Ueli; Gambardella, Luca Maria; Schmidhuber, Jürgen (21 September 2010). \"Deep, Big, Simple Neural Nets for Handwritten Digit Recognition\".\nNeural Computation\n.\n22\n(12):\n3207–\n3220.\narXiv\n:\n1003.0358\n.\ndoi\n:\n10.1162/neco_a_00052\n.\nISSN\n0899-7667\n.\nPMID\n20858131\n.\nS2CID\n1918673\n.\n^\nCiresan, D. C.; Meier, U.; Masci, J.; Gambardella, L.M.; Schmidhuber, J. (2011).\n\"Flexible, High Performance Convolutional Neural Networks for Image Classification\"\n(PDF)\n.\nInternational Joint Conference on Artificial Intelligence\n.\ndoi\n:\n10.5591/978-1-57735-516-8/ijcai11-210\n.\nArchived\n(PDF)\nfrom the original on 2014-09-29\n. Retrieved\n2017-06-13\n.\n^\nCiresan, Dan; Giusti, Alessandro; Gambardella, Luca M.; Schmidhuber, Jürgen (2012). Pereira, F.; Burges, C. J. C.; Bottou, L.; Weinberger, K. Q. (eds.).\nAdvances in Neural Information Processing Systems 25\n(PDF)\n. Curran Associates, Inc. pp.\n2843–\n2851.\nArchived\n(PDF)\nfrom the original on 2017-08-09\n. Retrieved\n2017-06-13\n.\n^\nCiresan, D.; Giusti, A.; Gambardella, L.M.; Schmidhuber, J. (2013). \"Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks\".\nMedical Image Computing and Computer-Assisted Intervention – MICCAI 2013\n. Lecture Notes in Computer Science. Vol. 7908. pp.\n411–\n418.\ndoi\n:\n10.1007/978-3-642-40763-5_51\n.\nISBN\n978-3-642-38708-1\n.\nPMID\n24579167\n.\n^\nNg, Andrew; Dean, Jeff (2012). \"Building High-level Features Using Large Scale Unsupervised Learning\".\narXiv\n:\n1112.6209\n[\ncs.LG\n].\n^\nSimonyan, Karen; Andrew, Zisserman (2014). \"Very Deep Convolution Networks for Large Scale Image Recognition\".\narXiv\n:\n1409.1556\n[\ncs.CV\n].\n^\nSzegedy, Christian (2015).\n\"Going deeper with convolutions\"\n(PDF)\n.\nCvpr2015\n.\narXiv\n:\n1409.4842\n.\n^\nVinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2014). \"Show and Tell: A Neural Image Caption Generator\".\narXiv\n:\n1411.4555\n[\ncs.CV\n].\n.\n^\nFang, Hao; Gupta, Saurabh; Iandola, Forrest; Srivastava, Rupesh; Deng, Li; Dollár, Piotr; Gao, Jianfeng; He, Xiaodong; Mitchell, Margaret; Platt, John C; Lawrence Zitnick, C; Zweig, Geoffrey (2014). \"From Captions to Visual Concepts and Back\".\narXiv\n:\n1411.4952\n[\ncs.CV\n].\n.\n^\nKiros, Ryan; Salakhutdinov, Ruslan; Zemel, Richard S (2014). \"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\".\narXiv\n:\n1411.2539\n[\ncs.LG\n].\n.\n^\nSimonyan, Karen; Zisserman, Andrew (2015-04-10),\nVery Deep Convolutional Networks for Large-Scale Image Recognition\n,\narXiv\n:\n1409.1556\n^\nHe, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\".\narXiv\n:\n1502.01852\n[\ncs.CV\n].\n^\nHe, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (10 Dec 2015).\nDeep Residual Learning for Image Recognition\n.\narXiv\n:\n1512.03385\n.\n^\nHe, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). \"Deep Residual Learning for Image Recognition\".\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n. Las Vegas, NV, USA: IEEE. pp.\n770–\n778.\narXiv\n:\n1512.03385\n.\ndoi\n:\n10.1109/CVPR.2016.90\n.\nISBN\n978-1-4673-8851-1\n.\n^\nGatys, Leon A.; Ecker, Alexander S.; Bethge, Matthias (26 August 2015). \"A Neural Algorithm of Artistic Style\".\narXiv\n:\n1508.06576\n[\ncs.CV\n].\n^\nGoodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014).\nGenerative Adversarial Networks\n(PDF)\n. Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp.\n2672–\n2680.\nArchived\n(PDF)\nfrom the original on 22 November 2019\n. Retrieved\n20 August\n2019\n.\n^\n\"GAN 2.0: NVIDIA's Hyperrealistic Face Generator\"\n.\nSyncedReview.com\n. December 14, 2018\n. Retrieved\nOctober 3,\n2019\n.\n^\nKarras, T.; Aila, T.; Laine, S.; Lehtinen, J. (26 February 2018). \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\".\narXiv\n:\n1710.10196\n[\ncs.NE\n].\n^\n\"Prepare, Don't Panic: Synthetic Media and Deepfakes\"\n. witness.org.\nArchived\nfrom the original on 2 December 2020\n. Retrieved\n25 November\n2020\n.\n^\nSohl-Dickstein, Jascha; Weiss, Eric; Maheswaranathan, Niru; Ganguli, Surya (2015-06-01).\n\"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\"\n(PDF)\n.\nProceedings of the 32nd International Conference on Machine Learning\n.\n37\n. PMLR:\n2256–\n2265.\narXiv\n:\n1503.03585\n.\n^\nGoogle Research Blog. The neural networks behind Google Voice transcription. August 11, 2015. By Françoise Beaufays\nhttp://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html\n^\na\nb\nSak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 2015).\n\"Google voice search: faster and more accurate\"\n.\nArchived\nfrom the original on 2016-03-09\n. Retrieved\n2016-04-09\n.\n^\nSingh, Premjeet; Saha, Goutam; Sahidullah, Md (2021). \"Non-linear frequency warping using constant-Q transformation for speech emotion recognition\".\n2021 International Conference on Computer Communication and Informatics (ICCCI)\n. pp.\n1–\n4.\narXiv\n:\n2102.04029\n.\ndoi\n:\n10.1109/ICCCI50826.2021.9402569\n.\nISBN\n978-1-7281-5875-4\n.\nS2CID\n231846518\n.\n^\nSak, Hasim; Senior, Andrew; Beaufays, Francoise (2014).\n\"Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 24 April 2018.\n^\nLi, Xiangang; Wu, Xihong (2014). \"Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition\".\narXiv\n:\n1410.4281\n[\ncs.CL\n].\n^\nZen, Heiga; Sak, Hasim (2015).\n\"Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis\"\n(PDF)\n.\nGoogle.com\n. ICASSP. pp.\n4470–\n4474.\nArchived\n(PDF)\nfrom the original on 2021-05-09\n. Retrieved\n2017-06-13\n.\n^\n\"2018 ACM A.M. Turing Award Laureates\"\n.\nawards.acm.org\n. Retrieved\n2024-08-07\n.\n^\nFerrie, C., & Kaiser, S. (2019).\nNeural Networks for Babies\n. Sourcebooks.\nISBN\n978-1-4926-7120-6\n.\n{{\ncite book\n}}\n:  CS1 maint: multiple names: authors list (\nlink\n)\n^\nSilver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda (January 2016). \"Mastering the game of Go with deep neural networks and tree search\".\nNature\n.\n529\n(7587):\n484–\n489.\nBibcode\n:\n2016Natur.529..484S\n.\ndoi\n:\n10.1038/nature16961\n.\nISSN\n1476-4687\n.\nPMID\n26819042\n.\nS2CID\n515925\n.\n^\nA Guide to Deep Learning and Neural Networks\n,\narchived\nfrom the original on 2020-11-02\n, retrieved\n2020-11-16\n^\na\nb\nKumar, Nishant; Raubal, Martin (2021).\n\"Applications of deep learning in congestion detection, prediction and alleviation: A survey\"\n.\nTransportation Research Part C: Emerging Technologies\n.\n133\n103432.\narXiv\n:\n2102.09759\n.\nBibcode\n:\n2021TRPC..13303432K\n.\ndoi\n:\n10.1016/j.trc.2021.103432\n.\nhdl\n:\n10230/42143\n.\nS2CID\n240420107\n.\n^\nSzegedy, Christian; Toshev, Alexander; Erhan, Dumitru (2013).\n\"Deep neural networks for object detection\"\n.\nAdvances in Neural Information Processing Systems\n:\n2553–\n2561.\nArchived\nfrom the original on 2017-06-29\n. Retrieved\n2017-06-13\n.\n^\nRolnick, David; Tegmark, Max (2018).\n\"The power of deeper networks for expressing natural functions\"\n.\nInternational Conference on Learning Representations\n. ICLR 2018.\nArchived\nfrom the original on 2021-01-07\n. Retrieved\n2021-01-05\n.\n^\nHof, Robert D.\n\"Is Artificial Intelligence Finally Coming into Its Own?\"\n.\nMIT Technology Review\n. Archived from\nthe original\non 31 March 2019\n. Retrieved\n10 July\n2018\n.\n^\na\nb\nGers, Felix A.; Schmidhuber, Jürgen (2001).\n\"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages\"\n.\nIEEE Transactions on Neural Networks\n.\n12\n(6):\n1333–\n1340.\nBibcode\n:\n2001ITNN...12.1333G\n.\ndoi\n:\n10.1109/72.963769\n.\nPMID\n18249962\n.\nS2CID\n10192330\n.\nArchived\nfrom the original on 2020-01-26\n. Retrieved\n2020-02-25\n.\n^\na\nb\nc\nSutskever, L.; Vinyals, O.; Le, Q. (2014).\n\"Sequence to Sequence Learning with Neural Networks\"\n(PDF)\n.\nProc. NIPS\n.\narXiv\n:\n1409.3215\n.\nBibcode\n:\n2014arXiv1409.3215S\n.\nArchived\n(PDF)\nfrom the original on 2021-05-09\n. Retrieved\n2017-06-13\n.\n^\na\nb\nJozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). \"Exploring the Limits of Language Modeling\".\narXiv\n:\n1602.02410\n[\ncs.CL\n].\n^\na\nb\nGillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). \"Multilingual Language Processing from Bytes\".\narXiv\n:\n1512.00103\n[\ncs.CL\n].\n^\nMikolov, T.; et al. (2010).\n\"Recurrent neural network based language model\"\n(PDF)\n.\nInterspeech\n:\n1045–\n1048.\ndoi\n:\n10.21437/Interspeech.2010-343\n.\nS2CID\n17048224\n.\nArchived\n(PDF)\nfrom the original on 2017-05-16\n. Retrieved\n2017-06-13\n.\n^\nHochreiter, Sepp; Schmidhuber, Jürgen (1 November 1997). \"Long Short-Term Memory\".\nNeural Computation\n.\n9\n(8):\n1735–\n1780.\ndoi\n:\n10.1162/neco.1997.9.8.1735\n.\nISSN\n0899-7667\n.\nPMID\n9377276\n.\nS2CID\n1915014\n.\n^\na\nb\n\"Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)\"\n.\nResearchGate\n.\nArchived\nfrom the original on 9 May 2021\n. Retrieved\n13 June\n2017\n.\n^\nLeCun, Y.; et al. (1998).\n\"Gradient-based learning applied to document recognition\"\n.\nProceedings of the IEEE\n.\n86\n(11):\n2278–\n2324.\ndoi\n:\n10.1109/5.726791\n.\nS2CID\n14542261\n.\n^\nSainath, Tara N.\n; Mohamed, Abdel-Rahman; Kingsbury, Brian;\nRamabhadran, Bhuvana\n(2013). \"Deep convolutional neural networks for LVCSR\".\n2013 IEEE International Conference on Acoustics, Speech and Signal Processing\n. pp.",
      "scraped_at": "2025-12-16T17:25:48.346546",
      "status": "success",
      "content_length": 138234,
      "topic": "deep_learning"
    },
    {
      "title": "Neural network (machine learning) - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Artificial_neural_network",
      "content": "Neural network (machine learning) - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nTraining\n2\nHistory\nToggle History subsection\n2.1\nEarly work\n2.2\nDeep learning breakthroughs in the 1960s and 1970s\n2.3\nBackpropagation\n2.4\nConvolutional neural networks\n2.5\nRecurrent neural networks\n2.6\nDeep learning\n3\nModels\nToggle Models subsection\n3.1\nArtificial neurons\n3.2\nOrganization\n3.3\nHyperparameter\n3.4\nLearning\n3.4.1\nLearning rate\n3.4.2\nCost function\n3.4.3\nBackpropagation\n3.5\nLearning paradigms\n3.5.1\nSupervised learning\n3.5.2\nUnsupervised learning\n3.5.3\nReinforcement learning\n3.5.4\nSelf-learning\n3.5.5\nNeuroevolution\n3.6\nStochastic neural network\n3.7\nTopological deep learning\n3.8\nOther\n3.8.1\nModes\n4\nTypes\n5\nNetwork design\n6\nMonitoring and concept drift detection of ANNs\n7\nApplications\n8\nTheoretical properties\nToggle Theoretical properties subsection\n8.1\nComputational power\n8.2\nCapacity\n8.3\nConvergence\n8.4\nGeneralization and statistics\n9\nCriticism\nToggle Criticism subsection\n9.1\nTraining\n9.2\nTheory\n9.3\nHardware\n9.4\nPractical counterexamples\n9.5\nHybrid approaches\n9.6\nDataset bias\n10\nGallery\n11\nRecent advancements and future directions\nToggle Recent advancements and future directions subsection\n11.1\nImage processing\n11.2\nSpeech recognition\n11.3\nNatural language processing\n11.4\nControl systems\n11.5\nFinance\n11.6\nMedicine\n11.7\nContent creation\n12\nSee also\n13\nReferences\n14\nBibliography\n15\nExternal links\nToggle the table of contents\nNeural network (machine learning)\n69 languages\nالعربية\nԱրեւմտահայերէն\nAzərbaycanca\nবাংলা\n閩南語 / Bân-lâm-gí\nБългарски\nBosanski\nCatalà\nЧӑвашла\nČeština\nDansk\nالدارجة\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nՀայերեն\nहिन्दी\nHrvatski\nIdo\nBahasa Indonesia\nInterlingua\nÍslenska\nItaliano\nעברית\nქართული\nLatina\nLatviešu\nLietuvių\nLigure\nMagyar\nМакедонски\nMalagasy\nമലയാളം\nBahasa Melayu\nNederlands\n日本語\nNorsk bokmål\nNorsk nynorsk\nଓଡ଼ିଆ\nPolski\nPortuguês\nRomână\nRuna Simi\nРусский\nSimple English\nSlovenčina\nŚlůnski\nکوردی\nСрпски / srpski\nSrpskohrvatski / српскохрватски\nSuomi\nSvenska\nதமிழ்\nไทย\nTürkçe\nУкраїнська\nاردو\nTiếng Việt\n吴语\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikibooks\nWikiversity\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\n(Redirected from\nArtificial neural network\n)\nComputational model used in machine learning, based on connected, hierarchical functions\nThis article is about the computational models used for artificial intelligence. For other uses, see\nNeural network (disambiguation)\n.\nAn artificial neural network is an interconnected group of nodes, inspired by a simplification of\nneurons\nin a\nbrain\n. Here, each circular node represents an\nartificial neuron\nand an arrow represents a connection from the output of one artificial neuron to the input of another.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nIn\nmachine learning\n, a\nneural network\nor\nneural net\n(\nNN\n), also called\nartificial neural network\n(\nANN\n), is a\ncomputational model\ninspired by the structure and functions of\nbiological neural networks\n.\n[\n1\n]\n[\n2\n]\nA neural network consists of connected units or nodes called\nartificial neurons\n, which loosely model the\nneurons\nin the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance. These are connected by\nedges\n, which model the\nsynapses\nin the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a\nreal number\n, and the output of each neuron is computed by some non-linear function of the totality of its inputs, called the\nactivation function\n. The strength of the signal at each connection is determined by a\nweight\n, which adjusts during the learning process.\nTypically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the\ninput layer\n) to the last layer (the\noutput layer\n), possibly passing through multiple intermediate layers (\nhidden layers\n). A network is typically called a deep neural network if it has at least two hidden layers.\n[\n3\n]\nArtificial neural networks are used for various tasks, including\npredictive modeling\n,\nadaptive control\n, and solving problems in\nartificial intelligence\n. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\nTraining\n[\nedit\n]\nNeural networks are typically trained through\nempirical risk minimization\n, which is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.\n[\n4\n]\nGradient-based methods such as\nbackpropagation\nare usually used to estimate the parameters of the network.\n[\n4\n]\nDuring the training phase, ANNs learn from\nlabeled\ntraining data by iteratively updating their parameters to minimize a defined\nloss function\n.\n[\n5\n]\nThis method allows the network to generalize to unseen data.\nSimplified example of training a neural network in object detection: The network is trained by multiple images that are known to depict\nstarfish\nand\nsea urchins\n, which are correlated with \"nodes\" that represent visual\nfeatures\n. The starfish match with a ringed texture and a star outline, whereas most sea urchins match with a striped texture and oval shape. However, the instance of a ring textured sea urchin creates a weakly weighted association between them.\nSubsequent run of the network on an input image (left):\n[\n6\n]\nThe network correctly detects the starfish. However, the weakly weighted association between ringed texture and sea urchin also confers a weak signal to the latter from one of two intermediate nodes. In addition, a shell that was not included in the training gives a weak signal for the oval shape, also resulting in a weak signal for the sea urchin output. These weak signals may result in a\nfalse positive\nresult for sea urchin.\nIn reality, textures and outlines would not be represented by single nodes, but rather by associated weight patterns of multiple nodes.\nHistory\n[\nedit\n]\nMain article:\nHistory of artificial neural networks\nEarly work\n[\nedit\n]\nToday's deep neural networks are based on early work in\nstatistics\nover 200 years ago. The simplest kind of\nfeedforward neural network\n(FNN) is a linear network, which consists of a single layer of output nodes with linear activation functions; the inputs are fed directly to the outputs via a series of weights. The sum of the products of the weights and the inputs is calculated at each node. The\nmean squared errors\nbetween these calculated outputs and the given target values are minimized by creating an adjustment to the weights. This technique has been known for over two centuries as the\nmethod of least squares\nor\nlinear regression\n. It was used as a means of finding a good rough linear fit to a set of points by\nLegendre\n(1805) and\nGauss\n(1795) for the prediction of planetary movement.\n[\n7\n]\n[\n8\n]\n[\n9\n]\n[\n10\n]\n[\n11\n]\nHistorically, digital computers such as the\nvon Neumann model\noperate via the execution of explicit instructions with access to memory by a number of processors. Some neural networks, on the other hand, originated from efforts to model information processing in biological systems through the framework of\nconnectionism\n. Unlike the von Neumann model, connectionist computing does not separate memory and processing.\nWarren McCulloch\nand\nWalter Pitts\n[\n12\n]\n(1943) considered a non-learning computational model for neural networks.\n[\n13\n]\nThis model paved the way for research to split into two approaches. One approach focused on biological processes while the other focused on the application of neural networks to artificial intelligence.\nIn the late 1940s,\nD. O. Hebb\n[\n14\n]\nproposed a learning\nhypothesis\nbased on the mechanism of\nneural plasticity\nthat became known as\nHebbian learning\n. It was used in many early neural networks, such as Rosenblatt's\nperceptron\nand the\nHopfield network\n. Farley and\nClark\n[\n15\n]\n(1954) used computational machines to simulate a Hebbian network. Other neural network computational machines were created by\nRochester\n, Holland, Habit and Duda (1956).\n[\n16\n]\nIn 1958, psychologist\nFrank Rosenblatt\ndescribed the perceptron, one of the first implemented artificial neural networks,\n[\n17\n]\n[\n18\n]\n[\n19\n]\n[\n20\n]\nfunded by the United States\nOffice of Naval Research\n.\n[\n21\n]\nR. D. Joseph (1960)\n[\n22\n]\nmentions an even earlier perceptron-like device by Farley and Clark:\n[\n10\n]\n\"Farley and Clark of MIT Lincoln Laboratory actually preceded Rosenblatt in the development of a perceptron-like device.\" However, \"they dropped the subject.\"\nThe perceptron raised public excitement for research in Artificial Neural Networks, causing the US government to drastically increase funding. This contributed to \"the Golden Age of AI\" fueled by the optimistic claims made by computer scientists regarding the ability of perceptrons to emulate human intelligence.\n[\n23\n]\nThe first perceptrons did not have adaptive hidden units. However, Joseph (1960)\n[\n22\n]\nalso discussed\nmultilayer perceptrons\nwith an adaptive hidden layer. Rosenblatt (1962)\n[\n24\n]\n: section 16\ncited and adopted these ideas, also crediting work by H. D. Block and B. W. Knight. Unfortunately, these early efforts did not lead to a working learning algorithm for hidden units, i.e.,\ndeep learning\n.\nDeep learning breakthroughs in the 1960s and 1970s\n[\nedit\n]\nFundamental research was conducted on ANNs in the 1960s and 1970s. The first working deep learning algorithm was the\nGroup method of data handling\n, a method to train arbitrarily deep neural networks, published by\nAlexey Ivakhnenko\nand Lapa in the\nSoviet Union\n(1965). They regarded it as a form of polynomial regression,\n[\n25\n]\nor a generalization of Rosenblatt's perceptron.\n[\n26\n]\nA 1971 paper described a deep network with eight layers trained by this method,\n[\n27\n]\nwhich is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates.\"\n[\n10\n]\nThe first deep learning\nmultilayer perceptron\ntrained by\nstochastic gradient descent\n[\n28\n]\nwas published in 1967 by\nShun'ichi Amari\n.\n[\n29\n]\nIn computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned\ninternal representations\nto classify non-linearily separable pattern classes.\n[\n10\n]\nSubsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\nIn 1969,\nKunihiko Fukushima\nintroduced the\nReLU\n(rectified linear unit) activation function.\n[\n10\n]\n[\n30\n]\n[\n31\n]\nThe rectifier has become the most popular activation function for deep learning.\n[\n32\n]\nNevertheless, research stagnated in the United States following the work of\nMinsky\nand\nPapert\n(1969),\n[\n33\n]\nwho emphasized that basic perceptrons were incapable of processing the exclusive-or circuit. This insight was irrelevant for the deep networks of Ivakhnenko (1965) and Amari (1967).\nIn 1976 transfer learning was introduced in neural networks learning.\n[\n34\n]\n[\n35\n]\nDeep learning architectures for\nconvolutional neural networks\n(CNNs) with convolutional layers and downsampling layers and weight replication began with the\nneocognitron\nintroduced by Kunihiko Fukushima in 1979, though not trained by backpropagation.\n[\n36\n]\n[\n37\n]\n[\n38\n]\nBackpropagation\n[\nedit\n]\nBackpropagation\nis an efficient application of the\nchain rule\nderived by\nGottfried Wilhelm Leibniz\nin 1673\n[\n39\n]\nto networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt,\n[\n24\n]\nbut he did not know how to implement this, although\nHenry J. Kelley\nhad a continuous precursor of backpropagation in 1960 in the context of\ncontrol theory\n.\n[\n40\n]\nIn 1970,\nSeppo Linnainmaa\npublished the modern form of backpropagation in his Master's\nthesis\n(1970).\n[\n41\n]\n[\n42\n]\n[\n10\n]\nG.M. Ostrovski et al. republished it in 1971.\n[\n43\n]\n[\n44\n]\nPaul Werbos\napplied backpropagation to neural networks in 1982\n[\n45\n]\n[\n46\n]\n(his 1974 PhD thesis, reprinted in a 1994 book,\n[\n47\n]\ndid not yet describe the algorithm\n[\n44\n]\n). In 1986,\nDavid E. Rumelhart\net al. popularised backpropagation but did not cite the original work.\n[\n48\n]\nConvolutional neural networks\n[\nedit\n]\nKunihiko Fukushima's\nconvolutional neural network\n(CNN) architecture of 1979\n[\n36\n]\nalso introduced\nmax pooling\n,\n[\n49\n]\na popular downsampling procedure for CNNs. CNNs have become an essential tool for\ncomputer vision\n.\nThe\ntime delay neural network\n(TDNN) was introduced in 1987 by\nAlex Waibel\nto apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.\n[\n50\n]\n[\n51\n]\nIn 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition.\n[\n52\n]\nIn 1989,\nYann LeCun\net al. created a CNN called\nLeNet\nfor\nrecognizing handwritten ZIP codes\non mail. Training required 3 days.\n[\n53\n]\nIn 1990, Wei Zhang implemented a CNN on\noptical computing\nhardware.\n[\n54\n]\nIn 1991, a CNN was applied to medical image object segmentation\n[\n55\n]\nand breast cancer detection in mammograms.\n[\n56\n]\nLeNet\n-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks digitized in 32×32 pixel images.\n[\n57\n]\nFrom 1988 onward,\n[\n58\n]\n[\n59\n]\nthe use of neural networks transformed the field of\nprotein structure prediction\n, in particular when the first cascading networks were trained on\nprofiles\n(matrices) produced by multiple\nsequence alignments\n.\n[\n60\n]\nRecurrent neural networks\n[\nedit\n]\nOne origin of RNN was\nstatistical mechanics\n. In 1972,\nShun'ichi Amari\nproposed to modify the weights of an\nIsing model\nby\nHebbian learning\nrule as a model of\nassociative memory\n, adding in the component of learning.\n[\n61\n]\nThis was popularized as the Hopfield network by\nJohn Hopfield\n(1982).\n[\n62\n]\nAnother origin of RNN was neuroscience. The word \"recurrent\" is used to describe loop-like structures in anatomy. In 1901,\nCajal\nobserved \"recurrent semicircles\" in the\ncerebellar cortex\n.\n[\n63\n]\nHebb\nconsidered \"reverberating circuit\" as an explanation for short-term memory.\n[\n64\n]\nThe McCulloch and Pitts paper (1943) considered neural networks that contain cycles, and noted that the current activity of such networks can be affected by activity indefinitely far in the past.\n[\n12\n]\nIn 1982 a recurrent neural network with an array architecture (rather than a multilayer perceptron architecture), namely a Crossbar Adaptive Array,\n[\n65\n]\n[\n66\n]\nused direct recurrent connections from the output to the supervisor (teaching) inputs. In addition of computing actions (decisions), it computed internal state evaluations (emotions) of the consequence situations. Eliminating the external supervisor, it introduced the self-learning method in neural networks.\nIn cognitive psychology, the journal American Psychologist in early 1980's carried out a debate on the relation between cognition and emotion. Zajonc in 1980 stated that emotion is computed first and is independent from cognition, while Lazarus in 1982 stated that cognition is computed first and is inseparable from emotion.\n[\n67\n]\n[\n68\n]\nIn 1982 the Crossbar Adaptive Array gave a neural network model of cognition-emotion relation.\n[\n65\n]\n[\n69\n]\nIt was an example of a debate where an AI system, a recurrent neural network, contributed to an issue in the same time addressed by cognitive psychology.\nTwo early influential works were the\nJordan network\n(1986) and the\nElman network\n(1990), which applied RNN to study\ncognitive psychology\n.\nIn the 1980s, backpropagation did not work well for deep RNNs. To overcome this problem, in 1991,\nJürgen Schmidhuber\nproposed the \"neural sequence chunker\" or \"neural history compressor\"\n[\n70\n]\n[\n71\n]\nwhich introduced the important concepts of self-supervised pre-training (the \"P\" in\nChatGPT\n) and neural\nknowledge distillation\n.\n[\n10\n]\nIn 1993, a neural history compressor system solved a \"Very Deep Learning\" task that required more than 1000 subsequent\nlayers\nin an RNN unfolded in time.\n[\n72\n]\nIn 1991,\nSepp Hochreiter\n's diploma thesis\n[\n73\n]\nidentified and analyzed the\nvanishing gradient problem\n[\n73\n]\n[\n74\n]\nand proposed recurrent\nresidual\nconnections to solve it. He and Schmidhuber introduced\nlong short-term memory\n(LSTM), which set accuracy records in multiple applications domains.\n[\n75\n]\n[\n76\n]\nThis was not yet the modern version of LSTM, which required the forget gate, which was introduced in 1999.\n[\n77\n]\nIt became the default choice for RNN architecture.\nDuring 1985–1995, inspired by statistical mechanics, several architectures and methods were developed by\nTerry Sejnowski\n,\nPeter Dayan\n,\nGeoffrey Hinton\n, etc., including the\nBoltzmann machine\n,\n[\n78\n]\nrestricted Boltzmann machine\n,\n[\n79\n]\nHelmholtz machine\n,\n[\n80\n]\nand the\nwake-sleep algorithm\n.\n[\n81\n]\nThese were designed for unsupervised learning of deep generative models.\nDeep learning\n[\nedit\n]\nBetween 2009 and 2012, ANNs began winning prizes in image recognition contests, approaching human level performance on various tasks, initially in\npattern recognition\nand\nhandwriting recognition\n.\n[\n82\n]\n[\n83\n]\nIn 2011, a CNN named\nDanNet\n[\n84\n]\n[\n85\n]\nby Dan Ciresan, Ueli Meier, Jonathan Masci,\nLuca Maria Gambardella\n, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3.\n[\n38\n]\nIt then won more contests.\n[\n86\n]\n[\n87\n]\nThey also showed how\nmax-pooling\nCNNs on GPU improved performance significantly.\n[\n88\n]\nIn October 2012,\nAlexNet\nby\nAlex Krizhevsky\n,\nIlya Sutskever\n, and Geoffrey Hinton\n[\n89\n]\nwon the large-scale\nImageNet competition\nby a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and\nAndrew Zisserman\n[\n90\n]\nand Google's\nInceptionv3\n.\n[\n91\n]\nIn 2012,\nNg\nand\nDean\ncreated a network that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images.\n[\n92\n]\nUnsupervised pre-training and increased computing power from\nGPUs\nand\ndistributed computing\nallowed the use of larger networks, particularly in image and visual recognition problems, which became known as \"deep learning\".\n[\n5\n]\nRadial basis function\nand wavelet networks were introduced in 2013. These can be shown to offer best approximation properties and have been applied in\nnonlinear system identification\nand classification applications.\n[\n93\n]\nGenerative adversarial network\n(GAN) (\nIan Goodfellow\net al., 2014)\n[\n94\n]\nbecame state of the art in generative modeling during 2014–2018 period. The GAN principle was originally published in 1991 by Jürgen Schmidhuber who called it \"artificial curiosity\": two neural networks contest with each other in the form of a\nzero-sum game\n, where one network's gain is the other network's loss.\n[\n95\n]\n[\n96\n]\nThe first network is a\ngenerative model\nthat models a\nprobability distribution\nover output patterns. The second network learns by\ngradient descent\nto predict the reactions of the environment to these patterns. Excellent image quality is achieved by\nNvidia\n's\nStyleGAN\n(2018)\n[\n97\n]\nbased on the Progressive GAN by Tero Karras et al.\n[\n98\n]\nHere, the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning\ndeepfakes\n.\n[\n99\n]\nDiffusion models\n(2015)\n[\n100\n]\neclipsed GANs in generative modeling since then, with systems such as\nDALL·E 2\n(2022) and\nStable Diffusion\n(2022).\nIn 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers.\n[\n101\n]\nStacking too many layers led to a steep reduction in\ntraining\naccuracy,\n[\n102\n]\nknown as the \"degradation\" problem.\n[\n103\n]\nIn 2015, two techniques were developed to train very deep networks: the\nhighway network\nwas published in May 2015,\n[\n104\n]\nand the residual neural network (ResNet) in December 2015.\n[\n105\n]\n[\n106\n]\nResNet behaves like an open-gated Highway Net.\nMain article:\nTransformer (deep learning architecture) § History\nDuring the 2010s, the\nseq2seq\nmodel was developed, and attention mechanisms were added. It led to the modern Transformer architecture in 2017 in\nAttention Is All You Need\n.\n[\n107\n]\nIt requires computation time that is quadratic in the size of the context window. Jürgen Schmidhuber's fast weight controller (1992)\n[\n108\n]\nscales linearly and was later shown to be equivalent to the unnormalized linear Transformer.\n[\n109\n]\n[\n110\n]\n[\n10\n]\nTransformers have increasingly become the model of choice for\nnatural language processing\n.\n[\n111\n]\nMany modern\nlarge language models\nsuch as\nChatGPT\n,\nGPT-4\n, and\nBERT\nuse this architecture.\nModels\n[\nedit\n]\nThis section\nmay be\nconfusing or unclear\nto readers\n.\nPlease help\nclarify the section\n. There might be a discussion about this on\nthe talk page\n.\n(\nApril 2017\n)\n(\nLearn how and when to remove this message\n)\nFurther information:\nMathematics of artificial neural networks\nNeuron and myelinated axon, with signal flow from inputs at dendrites to outputs at axon terminals\nANNs began as an attempt to exploit the architecture of the human brain to perform tasks that conventional algorithms had little success with. They soon reoriented towards improving empirical results, abandoning attempts to remain true to their biological precursors. ANNs have the ability to learn and model non-linearities and complex relationships. This is achieved by neurons being connected in various patterns, allowing the output of some neurons to become the input of others. The network forms a\ndirected\n,\nweighted graph\n.\n[\n112\n]\nAn artificial neural network consists of simulated neurons. Each neuron is connected to other\nnodes\nvia\nlinks\nlike a biological axon-synapse-dendrite connection. All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data. Each link has a weight, determining the strength of one node's influence on another,\n[\n113\n]\nallowing weights to choose the signal between neurons.\nArtificial neurons\n[\nedit\n]\nMain article:\nArtificial neuron\nANNs are composed of\nartificial neurons\nwhich are conceptually derived from biological\nneurons\n. Each artificial neuron has inputs and produces a single output which can be sent to multiple other neurons.\n[\n114\n]\nThe inputs can be the feature values of a sample of external data, such as images or documents, or they can be the outputs of other neurons. The outputs of the final\noutput neurons\nof the neural net accomplish the task, such as recognizing an object in an image.\n[\ncitation needed\n]\nTo find the output of the neuron we take the weighted sum of all the inputs, weighted by the\nweights\nof the\nconnections\nfrom the inputs to the neuron. We add a\nbias\nterm to this sum.\n[\n115\n]\nThis weighted sum is sometimes called the\nactivation\n. This weighted sum is then passed through a (usually nonlinear) activation function to produce the output. The initial inputs are external data, such as images and documents. The ultimate outputs accomplish the task, such as recognizing an object in an image.\n[\n116\n]\nOrganization\n[\nedit\n]\nThe neurons are typically organized into multiple layers, especially in deep learning. Neurons of one layer connect only to neurons of the immediately preceding and immediately following layers. The layer that receives external data is the\ninput layer\n. The layer that produces the ultimate result is the\noutput layer\n. In between them are zero or more\nhidden layers\n. Single layer and unlayered networks are also used. Between two layers, multiple connection patterns are possible. They can be 'fully connected', with every neuron in one layer connecting to every neuron in the next layer. They can be\npooling\n, where a group of neurons in one layer connects to a single neuron in the next layer, thereby reducing the number of neurons in that layer.\n[\n117\n]\nNeurons with only such connections form a\ndirected acyclic graph\nand are known as\nfeedforward networks\n.\n[\n118\n]\nAlternatively, networks that allow connections between neurons in the same or previous layers are known as\nrecurrent networks\n.\n[\n119\n]\nHyperparameter\n[\nedit\n]\nMain article:\nHyperparameter (machine learning)\nA\nhyperparameter\nis a constant\nparameter\ndefining any configurable part of the learning process, whose value is set prior to training.\n[\n120\n]\nExamples of hyperparameters include\nlearning rate\n, batch size and regularization parameters.\n[\n121\n]\n. The performance of a neural network is strongly influenced by the choice of hyperparameter values, and thus the hyperparameters are often optimized as part of the training process, a process called hyperparameter tuning or hyperparameter optimization.\n[\n122\n]\nLearning\n[\nedit\n]\nThis section includes a\nlist of references\n,\nrelated reading\n, or\nexternal links\n,\nbut its sources remain unclear because it lacks\ninline citations\n.\nPlease help\nimprove\nthis section by\nintroducing\nmore precise citations.\n(\nAugust 2019\n)\n(\nLearn how and when to remove this message\n)\nSee also:\nMathematical optimization\n,\nEstimation theory\n, and\nMachine learning\nLearning is the adaptation of the network to better handle a task by considering sample observations. Learning involves adjusting the weights (and optional thresholds) of the network to improve the accuracy of the result. This is done by minimizing the observed errors. Learning is complete when examining additional observations does not usefully reduce the error rate. Even after learning, the error rate typically does not reach 0. If after learning, the error rate is too high, the network typically must be redesigned. Practically this is done by defining a\ncost function\nthat is evaluated periodically during learning. As long as its output continues to decline, learning continues. The cost is frequently defined as a\nstatistic\nwhose value can only be approximated. The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small. Learning attempts to reduce the total of the differences across the observations. Most learning models can be viewed as a straightforward application of\noptimization\ntheory and\nstatistical estimation\n.\n[\n112\n]\n[\n123\n]\nLearning rate\n[\nedit\n]\nMain article:\nLearning rate\nThe learning rate defines the size of the corrective steps that the model takes to adjust for errors in each observation.\n[\n124\n]\nA high learning rate shortens the training time, but with lower ultimate accuracy, while a lower learning rate takes longer, but with the potential for greater accuracy. Optimizations such as\nQuickprop\nare primarily aimed at speeding up error minimization, while other improvements mainly try to increase reliability. In order to avoid\noscillation\ninside the network such as alternating connection weights, and to improve the rate of convergence, refinements use an\nadaptive learning rate\nthat increases or decreases as appropriate.\n[\n125\n]\nThe concept of momentum allows the balance between the gradient and the previous change to be weighted such that the weight adjustment depends to some degree on the previous change. A momentum close to 0 emphasizes the gradient, while a value close to 1 emphasizes the last change.\n[\ncitation needed\n]\nCost function\n[\nedit\n]\nWhile it is possible to define a cost function\nad hoc\n, frequently the choice is determined by the function's desirable properties (such as\nconvexity\n) because it arises from the model (e.g. in a probabilistic model, the model's\nposterior probability\ncan be used as an inverse cost).\n[\ncitation needed\n]\nBackpropagation\n[\nedit\n]\nMain article:\nBackpropagation\nBackpropagation is a method used to adjust the connection weights to compensate for each error found during learning. The error amount is effectively divided among the connections. Technically, backpropagation calculates the\ngradient\n(the derivative) of the\ncost function\nassociated with a given state with respect to the weights. The weight updates can be done via stochastic gradient descent or other methods, such as\nextreme learning machines\n,\n[\n126\n]\n\"no-prop\" networks,\n[\n127\n]\ntraining without backtracking,\n[\n128\n]\n\"weightless\" networks,\n[\n129\n]\n[\n130\n]\nand\nnon-connectionist neural networks\n.\n[\ncitation needed\n]\nLearning paradigms\n[\nedit\n]\nThis section includes a\nlist of references\n,\nrelated reading\n, or\nexternal links\n,\nbut its sources remain unclear because it lacks\ninline citations\n.\nPlease help\nimprove\nthis section by\nintroducing\nmore precise citations.\n(\nAugust 2019\n)\n(\nLearn how and when to remove this message\n)\nMachine learning is commonly separated into three main learning paradigms,\nsupervised learning\n,\n[\n131\n]\nunsupervised learning\n[\n132\n]\nand\nreinforcement learning\n.\n[\n133\n]\nEach corresponds to a particular learning task.\nSupervised learning\n[\nedit\n]\nSupervised learning\nuses a set of paired inputs and desired outputs. The learning task is to produce the desired output for each input. In this case, the cost function is related to eliminating incorrect deductions.\n[\n134\n]\nA commonly used cost is the\nmean-squared error\n, which tries to minimize the average squared error between the network's output and the desired output. Tasks suited for supervised learning are\npattern recognition\n(also known as classification) and\nregression\n(also known as function approximation). Supervised learning is also applicable to sequential data (e.g., for handwriting, speech and\ngesture recognition\n). This can be thought of as learning with a \"teacher\", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.\nUnsupervised learning\n[\nedit\n]\nIn\nunsupervised learning\n, input data is given along with the cost function, some function of the data\nx\n{\\displaystyle \\textstyle x}\nand the network's output. The cost function is dependent on the task (the model domain) and any\na priori\nassumptions (the implicit properties of the model, its parameters and the observed variables). As a trivial example, consider the model\nf\n(\nx\n)\n=\na\n{\\displaystyle \\textstyle f(x)=a}\nwhere\na\n{\\displaystyle \\textstyle a}\nis a constant and the cost\nC\n=\nE\n[\n(\nx\n−\nf\n(\nx\n)\n)\n2\n]\n{\\displaystyle \\textstyle C=E[(x-f(x))^{2}]}\n. Minimizing this cost produces a value of\na\n{\\displaystyle \\textstyle a}\nthat is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in\ncompression\nit could be related to the\nmutual information\nbetween\nx\n{\\displaystyle \\textstyle x}\nand\nf\n(\nx\n)\n{\\displaystyle \\textstyle f(x)}\n, whereas in statistical modeling, it could be related to the\nposterior probability\nof the model given the data (note that in both of those examples, those quantities would be maximized rather than minimized). Tasks that fall within the paradigm of unsupervised learning are in general\nestimation\nproblems; the applications include\nclustering\n, the estimation of\nstatistical distributions\n,\ncompression\nand\nfiltering\n.\nReinforcement learning\n[\nedit\n]\nMain article:\nReinforcement learning\nSee also:\nStochastic control\nIn applications such as playing video games, an actor takes a string of actions, receiving a generally unpredictable response from the environment after each one. The goal is to win the game, i.e., generate the most positive (lowest cost) responses. In\nreinforcement learning\n, the aim is to weight the network (devise a policy) to perform actions that minimize long-term (expected cumulative) cost. At each point in time the agent performs an action and the environment generates an observation and an\ninstantaneous\ncost, according to some (usually unknown) rules. The rules and the long-term cost usually only can be estimated. At any juncture, the agent decides whether to explore new actions to uncover their costs or to exploit prior learning to proceed more quickly.\nFormally, the environment is modeled as a\nMarkov decision process\n(MDP) with states\ns\n1\n,\n.\n.\n.\n,\ns\nn\n∈\nS\n{\\displaystyle \\textstyle {s_{1},...,s_{n}}\\in S}\nand actions\na\n1\n,\n.\n.\n.\n,\na\nm\n∈\nA\n{\\displaystyle \\textstyle {a_{1},...,a_{m}}\\in A}\n. Because the state transitions are not known, probability distributions are used instead: the instantaneous cost distribution\nP\n(\nc\nt\n|\ns\nt\n)\n{\\displaystyle \\textstyle P(c_{t}|s_{t})}\n, the observation distribution\nP\n(\nx\nt\n|\ns\nt\n)\n{\\displaystyle \\textstyle P(x_{t}|s_{t})}\nand the transition distribution\nP\n(\ns\nt\n+\n1\n|\ns\nt\n,\na\nt\n)\n{\\displaystyle \\textstyle P(s_{t+1}|s_{t},a_{t})}\n, while a policy is defined as the conditional distribution over actions given the observations. Taken together, the two define a\nMarkov chain\n(MC). The aim is to discover the lowest-cost MC.\nANNs serve as the learning component in such applications.\n[\n135\n]\n[\n136\n]\nDynamic programming\ncoupled with ANNs (giving\nneurodynamic\nprogramming)\n[\n137\n]\nhas been applied to problems such as those involved in\nvehicle routing\n,\n[\n138\n]\nvideo games,\nnatural resource management\n[\n139\n]\n[\n140\n]\nand\nmedicine\n[\n141\n]\nbecause of ANNs ability to mitigate losses of accuracy even when reducing the\ndiscretization\ngrid density for numerically approximating the solution of control problems. Tasks that fall within the paradigm of reinforcement learning are control problems,\ngames\nand other sequential decision making tasks.\nSelf-learning\n[\nedit\n]\nSelf-learning in neural networks was introduced in 1982 along with a neural network capable of self-learning named\ncrossbar adaptive array\n(CAA).\n[\n142\n]\nIt is a system with only one input, situation s, and only one output, action (or behavior) a. It has neither external advice input nor external reinforcement input from the environment. The CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about encountered situations. The system is driven by the interaction between cognition and emotion.\n[\n143\n]\nGiven the memory matrix, W =||w(a,s)||, the crossbar self-learning algorithm in each iteration performs the following computation:\nIn situation s perform action a;\n Receive consequence situation s';\n Compute emotion of being in consequence situation v(s');\n Update crossbar memory w'(a,s) = w(a,s) + v(s').\nThe backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is behavioral environment where it behaves, and the other is genetic environment, where from it receives initial emotions (only once) about to be encountered situations in the behavioral environment. Having received the genome vector (species vector) from the genetic environment, the CAA will learn a goal-seeking behavior, in the behavioral environment that contains both desirable and undesirable situations.\n[\n144\n]\nNeuroevolution\n[\nedit\n]\nMain article:\nNeuroevolution\nNeuroevolution\ncan create neural network topologies and weights using\nevolutionary computation\n. It is competitive with sophisticated gradient descent approaches.\n[\n145\n]\n[\n146\n]\nOne advantage of neuroevolution is that it may be less prone to get caught in \"dead ends\".\n[\n147\n]\nStochastic neural network\n[\nedit\n]\nStochastic neural networks\noriginating from\nSherrington–Kirkpatrick models\nare a type of artificial neural network built by introducing random variations into the network, either by giving the network's artificial neurons\nstochastic\ntransfer functions\n[\ncitation needed\n]\n, or by giving them stochastic weights. This makes them useful tools for\noptimization\nproblems, since the random fluctuations help the network escape from\nlocal minima\n.\n[\n148\n]\nStochastic neural networks trained using a\nBayesian\napproach are known as\nBayesian neural networks\n.\n[\n149\n]\nTopological deep learning\n[\nedit\n]\nTopological deep learning\n, first introduced in 2017,\n[\n150\n]\nis an emerging approach in\nmachine learning\nthat integrates topology with deep neural networks to address highly intricate and high-order data. Initially rooted in\nalgebraic topology\n, TDL has since evolved into a versatile framework incorporating tools from other mathematical disciplines, such as\ndifferential topology\nand\ngeometric topology\n. As a successful example of mathematical deep learning, TDL continues to inspire advancements in mathematical\nartificial intelligence\n, fostering a mutually beneficial relationship between AI and\nmathematics\n.\nOther\n[\nedit\n]\nIn a\nBayesian\nframework, a distribution over the set of allowed models is chosen to minimize the cost.\nEvolutionary methods\n,\n[\n151\n]\ngene expression programming\n,\n[\n152\n]\nsimulated annealing\n,\n[\n153\n]\nexpectation–maximization\n,\nnon-parametric methods\nand\nparticle swarm optimization\n[\n154\n]\nare other learning algorithms. Convergent recursion is a learning algorithm for\ncerebellar model articulation controller\n(CMAC) neural networks.\n[\n155\n]\n[\n156\n]\nModes\n[\nedit\n]\nThis section includes a\nlist of references\n,\nrelated reading\n, or\nexternal links\n,\nbut its sources remain unclear because it lacks\ninline citations\n.\nPlease help\nimprove\nthis section by\nintroducing\nmore precise citations.\n(\nAugust 2019\n)\n(\nLearn how and when to remove this message\n)\nTwo modes of learning are available: stochastic and batch. In stochastic learning, each input creates a weight adjustment. In batch learning, weights are adjusted based on a batch of inputs, accumulating errors over the batch. Stochastic learning introduces \"noise\" into the process, using the local gradient calculated from one data point; this reduces the chance of the network getting stuck in local minima. However, batch learning typically yields a faster, more stable descent to a local minimum, since each update is performed in the direction of the batch's average error. A common compromise is to use \"mini-batches\", small batches with samples in each batch selected stochastically from the entire data set.\nTypes\n[\nedit\n]\nMain article:\nTypes of artificial neural networks\nANNs have evolved into a broad family of techniques that have advanced the state of the art across multiple domains. The simplest types have one or more static components, including number of units, number of layers, unit weights and\ntopology\n. Dynamic types allow one or more of these to evolve via learning. The latter is much more complicated but can shorten learning periods and produce better results. Some types allow/require learning to be \"supervised\" by the operator, while others operate independently. Some types operate purely in hardware, while others are purely software and run on general purpose computers.\nSome of the main breakthroughs include:\nConvolutional neural networks that have proven particularly successful in processing visual and other two-dimensional data;\n[\n157\n]\n[\n158\n]\nwhere long short-term memory avoids the\nvanishing gradient problem\n[\n159\n]\nand can handle signals that have a mix of low and high frequency components aiding large-vocabulary speech recognition,\n[\n160\n]\n[\n161\n]\ntext-to-speech synthesis\n,\n[\n162\n]\n[\n163\n]\n[\n164\n]\nand photo-real talking heads.\n[\n165\n]\nConvolutional Neural Networks have also been applied to fraud detection\n[\n166\n]\n[\n167\n]\n.\nCompetitive networks such as\ngenerative adversarial networks\nin which multiple networks (of varying structure) compete with each other, on tasks such as winning a game\n[\n168\n]\nor on deceiving the opponent about the authenticity of an input.\n[\n94\n]\nNetwork design\n[\nedit\n]\nUsing artificial neural networks requires an understanding of their characteristics.\nChoice of model: This depends on the data representation and the application. Model parameters include the number, type, and connectedness of network layers, as well as the size of each and the connection type (full, pooling, etc.). Overly complex models learn slowly.\nLearning algorithm\n: Numerous trade-offs exist between learning algorithms. Almost any algorithm will work well with the correct hyperparameters\n[\n169\n]\nfor training on a particular data set. However, selecting and tuning an algorithm for training on unseen data requires significant experimentation.\nRobustness\n: If the model, cost function and learning algorithm are selected appropriately, the resulting ANN can become robust.\nNeural architecture search\n(NAS) uses machine learning to automate ANN design. Various approaches to NAS have designed networks that compare well with hand-designed systems. The basic search algorithm is to propose a candidate model, evaluate it against a dataset, and use the results as feedback to teach the NAS network.\n[\n170\n]\nAvailable systems include\nAutoML\nand AutoKeras.\n[\n171\n]\nscikit-learn library\nprovides functions to help with building a deep network from scratch. We can then implement a deep network with\nTensorFlow\nor\nKeras\n.\nHyperparameters must also be defined as part of the design (they are not learned), governing matters such as how many neurons are in each layer, learning rate, step, stride, depth, receptive field and padding (for CNNs), etc.\n[\n172\n]\nThe\nPython\ncode snippet provides an overview of the training function, which uses the training dataset, number of hidden layer units, learning rate, and number of iterations as parameters:\n[\ncitation needed\n]\ndef\ntrain\n(\nX\n,\ny\n,\nn_hidden\n,\nlearning_rate\n,\nn_iter\n):\n\"\"\"Training function.\nArgs:\nX: Argument X.\ny: Argument y.\nn_hidden: The number of hidden layer units.\nlearning_rate: The learning rate.\nn_iter: The number of iterations.\nReturns:\ndict: A dictionary.\n\"\"\"\nm\n,\nn_input\n=\nX\n.\nshape\n# 1. random initialize weights and biases\nw1\n=\nnp\n.\nrandom\n.\nrandn\n(\nn_input\n,\nn_hidden\n)\nb1\n=\nnp\n.\nzeros\n((\n1\n,\nn_hidden\n))\nw2\n=\nnp\n.\nrandom\n.\nrandn\n(\nn_hidden\n,\n1\n)\nb2\n=\nnp\n.\nzeros\n((\n1\n,\n1\n))\n# 2. in each iteration, feed all layers with the latest weights and biases\nfor\ni\nin\nrange\n(\nn_iter\n+\n1\n):\nz2\n=\nnp\n.\ndot\n(\nX\n,\nw1\n)\n+\nb1\na2\n=\nsigmoid\n(\nz2\n)\nz3\n=\nnp\n.\ndot\n(\na2\n,\nw2\n)\n+\nb2\na3\n=\nz3\ndz3\n=\na3\n-\ny\ndw2\n=\nnp\n.\ndot\n(\na2\n.\nT\n,\ndz3\n)\ndb2\n=\nnp\n.\nsum\n(\ndz3\n,\naxis\n=\n0\n,\nkeepdims\n=\nTrue\n)\ndz2\n=\nnp\n.\ndot\n(\ndz3\n,\nw2\n.\nT\n)\n*\nsigmoid_derivative\n(\nz2\n)\ndw1\n=\nnp\n.\ndot\n(\nX\n.\nY\n,\ndz2\n)\ndb1\n=\nnp\n.\nsum\n(\ndz2\n,\naxis\n=\n0\n)\n# 3. update weights and biases with gradients\nw1\n-=\nlearning_rate\n*\ndw1\n/\nm\nw2\n-=\nlearning_rate\n*\ndw2\n/\nm\nb1\n-=\nlearning_rate\n*\ndb1\n/\nm\nb2\n-=\nlearning_rate\n*\ndb2\n/\nm\nif\ni\n%\n1000\n==\n0\n:\nprint\n(\n\"Epoch\"\n,\ni\n,\n\"loss: \"\n,\nnp\n.\nmean\n(\nnp\n.\nsquare\n(\ndz3\n)))\nmodel\n=\n{\n\"w1\"\n:\nw1\n,\n\"b1\"\n:\nb1\n,\n\"w2\"\n:\nw2\n,\n\"b2\"\n:\nb2\n}\nreturn\nmodel\nMonitoring and concept drift detection of ANNs\n[\nedit\n]\nWhen neural networks are deployed in real-world applications, the statistical properties of the input data may change over time, a phenomenon known as\nconcept drift\nor\nnon-stationarity\n. Drift can reduce predictive accuracy and lead to unreliable or biased decisions if it is not detected and corrected. In practice, this means that the model's accuracy in deployment may differ substantially from the levels observed during training or cross-validation.\nSeveral strategies have been developed to monitor neural networks for drift and degradation:\nError-based monitoring\n: comparing current predictions against ground-truth labels when they become available. This approach directly quantifies predictive performance but may be impractical when labels are delayed or costly to obtain.\nData distribution monitoring\n: detecting changes in the input data distribution using statistical tests, divergence measures, or density-ratio estimation.\nRepresentation monitoring\n: tracking the distribution of internal\nembeddings\nor hidden-layer features. Shifts in the latent representation can indicate nonstationarity even when labels are unavailable. Statistical methods such as\nstatistical process control\ncharts have been adapted for this purpose.\n[\n173\n]\nApplications\n[\nedit\n]\nBecause of their ability to model and reproduce nonlinear processes, artificial neural networks have found applications in many disciplines. These include:\nFunction approximation\n,\n[\n174\n]\nor\nregression analysis\n,\n[\n175\n]\n(including\ntime series prediction\n,\nfitness approximation\n,\n[\n176\n]\nand modeling)\nData processing\n[\n177\n]\n(including filtering, clustering,\nblind source separation\n,\n[\n178\n]\nand compression)\nNonlinear system identification\n[\n93\n]\nand control (including vehicle control, trajectory prediction,\n[\n179\n]\nadaptive control\n,\nprocess control\n, and\nnatural resource management\n)\nPattern recognition\n(including radar systems,\nface identification\n, signal classification,\n[\n180\n]\nnovelty detection\n,\n3D reconstruction\n,\n[\n181\n]\nobject recognition, and sequential decision making\n[\n182\n]\n)\nSequence recognition (including\ngesture\n,\nspeech\n, and handwritten and printed text recognition\n[\n183\n]\n)\nSensor data analysis\n[\n184\n]\n(including\nimage analysis\n)\nRobotics\n(including directing manipulators and\nprostheses\n)\nData mining\n(including\nknowledge discovery in databases\n)\nFinance\n[\n185\n]\n(such as\nex-ante\nmodels for specific financial long-run forecasts and\nartificial financial markets\n)\nQuantum chemistry\n[\n186\n]\nGeneral game playing\n[\n187\n]\nGenerative AI\n[\n188\n]\nData visualization\nMachine translation\nSocial network filtering\n[\n189\n]\nE-mail spam\nfiltering\nMedical diagnosis\n[\n190\n]\nANNs have been used to diagnose several types of cancers\n[\n191\n]\n[\n192\n]\nand to distinguish highly invasive cancer cell lines from less invasive lines using only cell shape information.\n[\n193\n]\n[\n194\n]\nANNs have been used to accelerate reliability analysis of infrastructures subject to natural disasters\n[\n195\n]\n[\n196\n]\nand to predict foundation settlements.\n[\n197\n]\nIt can also be useful to mitigate flood by the use of ANNs for modelling rainfall-runoff.\n[\n198\n]\nANNs have also been used for building black-box models in\ngeoscience\n:\nhydrology\n,\n[\n199\n]\n[\n200\n]\nocean modelling and\ncoastal engineering\n,\n[\n201\n]\n[\n202\n]\nand\ngeomorphology\n.\n[\n203\n]\nANNs have been employed in\ncybersecurity\n, with the objective to discriminate between legitimate activities and malicious ones. For example, machine learning has been used for classifying Android malware,\n[\n204\n]\nfor identifying domains belonging to threat actors and for detecting URLs posing a security risk.\n[\n205\n]\nResearch is underway on ANN systems designed for penetration testing, for detecting botnets,\n[\n206\n]\ncredit cards frauds\n[\n207\n]\nand network intrusions.\nANNs have been proposed as a tool to solve\npartial differential equations\nin physics\n[\n208\n]\n[\n209\n]\n[\n210\n]\nand simulate the properties of many-body\nopen quantum systems\n.\n[\n211\n]\n[\n212\n]\n[\n213\n]\n[\n214\n]\nIn brain research ANNs have studied short-term behavior of\nindividual neurons\n,\n[\n215\n]\nthe dynamics of neural circuitry arise from interactions between individual neurons and how behavior can arise from abstract neural modules that represent complete subsystems. Studies considered long-and short-term plasticity of neural systems and their relation to learning and memory from the individual neuron to the system level.\nIt is possible to create a profile of a user's interests from pictures, using artificial neural networks trained for object recognition.\n[\n216\n]\nBeyond their traditional applications, artificial neural networks are increasingly being utilized in interdisciplinary research, such as materials science. For instance, graph neural networks (GNNs) have demonstrated their capability in scaling deep learning for the discovery of new stable materials by efficiently predicting the total energy of crystals. This application underscores the adaptability and potential of ANNs in tackling complex problems beyond the realms of predictive modeling and artificial intelligence, opening new pathways for scientific discovery and innovation.\n[\n217\n]\nTheoretical properties\n[\nedit\n]\nComputational power\n[\nedit\n]\nThe\nmultilayer perceptron\nis a\nuniversal function\napproximator, as proven by the\nuniversal approximation theorem\n. However, the proof is not constructive regarding the number of neurons required, the network topology, the weights and the learning parameters.\nA specific recurrent architecture with\nrational\n-valued weights (as opposed to full precision real number-valued weights) has the power of a\nuniversal Turing machine\n,\n[\n218\n]\nusing a finite number of neurons and standard linear connections. Further, the use of\nirrational\nvalues for weights results in a machine with\nsuper-Turing\npower.\n[\n219\n]\n[\n220\n]\n[\nfailed verification\n]\nCapacity\n[\nedit\n]\nA model's \"capacity\" property corresponds to its ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.\nTwo notions of capacity are known by the community. The information capacity and the VC Dimension. The information capacity of a perceptron is intensively discussed in\nSir David MacKay\n's book\n[\n221\n]\nwhich summarizes work by\nThomas Cover\n.\n[\n222\n]\nThe capacity of a network of standard neurons (not convolutional) can be derived by four rules\n[\n223\n]\nthat derive from understanding a neuron as an electrical element. The information capacity captures the functions modelable by the network given any data as input. The second notion, is the\nVC dimension\n. VC Dimension uses the principles of\nmeasure theory\nand finds the maximum capacity under the best possible circumstances. This is, given input data in a specific form. As noted in,\n[\n221\n]\nthe VC Dimension for arbitrary inputs is half the information capacity of a perceptron. The VC Dimension for arbitrary points is sometimes referred to as Memory Capacity.\n[\n224\n]\nConvergence\n[\nedit\n]\nModels may not consistently converge on a single solution, firstly because local minima may exist, depending on the cost function and the model. Secondly, the optimization method used might not guarantee to converge when it begins far from any local minimum. Thirdly, for sufficiently large data or parameters, some methods become impractical.\nAnother issue worthy to mention is that training may cross some\nsaddle point\nwhich may lead the convergence to the wrong direction.\nThe convergence behavior of certain types of ANN architectures are more understood than others. When the width of network approaches to infinity, the ANN is well described by its first order\nTaylor expansion\nthroughout training, and so inherits the\nconvergence\nbehavior of\naffine models\n.\n[\n225\n]\n[\n226\n]\nAnother example is when parameters are small, it is observed that ANNs often fit target functions from low to high frequencies. This behavior is referred to as the spectral bias, or frequency principle, of neural networks.\n[\n227\n]\n[\n228\n]\n[\n229\n]\n[\n230\n]\nThis phenomenon is the opposite to the behavior of some well studied iterative numerical schemes such as\nJacobi method\n. Deeper neural networks have been observed to be more biased towards low frequency functions.\n[\n231\n]\nGeneralization and statistics\n[\nedit\n]\nThis section includes a\nlist of references\n,\nrelated reading\n, or\nexternal links\n,\nbut its sources remain unclear because it lacks\ninline citations\n.\nPlease help\nimprove\nthis section by\nintroducing\nmore precise citations.\n(\nAugust 2019\n)\n(\nLearn how and when to remove this message\n)\nApplications whose goal is to create a system that generalizes well to unseen examples, face the possibility of\nover-training\n. This arises in convoluted or over-specified systems when the network capacity significantly exceeds the needed free parameters.\nTwo approaches address over-training. The first is to use\ncross-validation\nand similar techniques to check for the presence of over-training and to select hyperparameters to minimize the generalization error. The second is to use some form of\nregularization\n. This concept emerges in a probabilistic (Bayesian) framework, where regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the goal is to minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the training set and the predicted error in unseen data due to overfitting.\nConfidence analysis of a neural network\nSupervised neural networks that use a\nmean squared error\n(MSE) cost function can use formal statistical methods to determine the confidence of the trained model. The MSE on a validation set can be used as an estimate for variance. This value can then be used to calculate the\nconfidence interval\nof network output, assuming a\nnormal distribution\n. A confidence analysis made this way is statistically valid as long as the output\nprobability distribution\nstays the same and the network is not modified.\nBy assigning a\nsoftmax activation function\n, a generalization of the\nlogistic function\n, on the output layer of the neural network (or a softmax component in a component-based network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is useful in classification as it gives a certainty measure on classifications.\nThe softmax activation function is:\ny\ni\n=\ne\nx\ni\n∑\nj\n=\n1\nc\ne\nx\nj\n{\\displaystyle y_{i}={\\frac {e^{x_{i}}}{\\sum _{j=1}^{c}e^{x_{j}}}}}\nCriticism\n[\nedit\n]\nTraining\n[\nedit\n]\nA common criticism of neural networks, particularly in robotics, is that they require too many training samples for real-world operation.\n[\n232\n]\nAny learning machine needs sufficient representative examples in order to capture the underlying structure that allows it to generalize to new cases. Potential solutions include randomly shuffling training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example, grouping examples in so-called mini-batches and/or introducing a recursive least squares algorithm for\nCMAC\n.\n[\n155\n]\nDean Pomerleau uses a neural network to train a robotic vehicle to drive on multiple types of roads (single lane, multi-lane, dirt, etc.), and a large amount of his research is devoted to extrapolating multiple training scenarios from a single training experience, and preserving past training diversity so that the system does not become overtrained (if, for example, it is presented with a series of right turns—it should not learn to always turn right).\n[\n233\n]\nTheory\n[\nedit\n]\nA central claim\n[\ncitation needed\n]\nof ANNs is that they embody new and powerful general principles for processing information. These principles are\nill-defined\n. This allows simple statistical association (the basic function of artificial neural networks) to be described as learning or recognition. In 1997,\nAlexander Dewdney\n, a former\nScientific American\ncolumnist, commented that as a result, artificial neural networks have a\nsomething-for-nothing quality, one that imparts a peculiar aura of laziness and a distinct lack of curiosity about just how good these computing systems are. No human hand (or mind) intervenes; solutions are found as if by magic; and no one, it seems, has learned anything.\n[\n234\n]\nOne response to Dewdney is that neural networks have been successfully used to handle many complex and diverse tasks, ranging from autonomously flying aircraft\n[\n235\n]\nto detecting credit card fraud to mastering the game of\nGo\n.\nTechnology writer Roger Bridgman commented:\nNeural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be \"an opaque, unreadable table...valueless as a scientific resource\".\nIn spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.\n[\n236\n]\nAlthough it is true that analyzing what has been learned by an artificial neural network is difficult, it is much easier to do so than to analyze what has been learned by a biological neural network. Moreover, recent emphasis on the\nexplainability\nof AI has contributed towards the development of methods, notably those based on\nattention\nmechanisms, for visualizing and explaining learned neural networks. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering generic principles that allow a learning machine to be successful. For example, Bengio and LeCun (2007) wrote an article regarding local vs non-local learning, as well as shallow vs deep architecture.\n[\n237\n]\nBiological brains use both shallow and deep circuits as reported by brain anatomy,\n[\n238\n]\ndisplaying a wide variety of invariance. Weng\n[\n239\n]\nargued that the brain self-wires largely according to signal statistics and therefore, a serial cascade cannot catch all major statistical dependencies.\nHardware\n[\nedit\n]\nLarge and effective neural networks require considerable computing resources.\n[\n240\n]\nWhile the brain has hardware tailored to the task of processing signals through a\ngraph\nof neurons, simulating even a simplified neuron on\nvon Neumann architecture\nmay consume vast amounts of\nmemory\nand storage. Furthermore, the designer often needs to transmit signals through many of these connections and their associated neurons –  which require enormous\nCPU\npower and time.\n[\ncitation needed\n]\nSome argue that the resurgence of neural networks in the twenty-first century is largely attributable to advances in hardware: from 1991 to 2015, computing power, especially as delivered by\nGPGPUs\n(on\nGPUs\n), has increased around a million-fold, making the standard backpropagation algorithm feasible for training networks that are several layers deeper than before.\n[\n38\n]\nThe use of accelerators such as\nFPGAs\nand GPUs can reduce training times from months to days.\n[\n240\n]\n[\n241\n]\nNeuromorphic engineering\nor a\nphysical neural network\naddresses the hardware difficulty directly, by constructing non-von-Neumann chips to directly implement neural networks in circuitry. Another type of chip optimized for neural network processing is called a\nTensor Processing Unit\n, or TPU.\n[\n242\n]\nPractical counterexamples\n[\nedit\n]\nAnalyzing what has been learned by an ANN is much easier than analyzing what has been learned by a biological neural network. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering general principles that allow a learning machine to be successful. For example, local vs. non-local learning and shallow vs. deep architecture.\n[\n243\n]\nHybrid approaches\n[\nedit\n]\nAdvocates of\nhybrid\nmodels (combining neural networks and symbolic approaches) say that such a mixture can better capture the mechanisms of the human mind.\n[\n244\n]\n[\n245\n]\nDataset bias\n[\nedit\n]\nNeural networks are dependent on the quality of the data they are trained on, thus low quality data with imbalanced representativeness can lead to the model learning and perpetuating societal biases.\n[\n246\n]\n[\n247\n]\nThese inherited biases become especially critical when the ANNs are integrated into real-world scenarios where the training data may be imbalanced due to the scarcity of data for a specific race, gender or other attribute.\n[\n246\n]\nThis imbalance can result in the model having inadequate representation and understanding of underrepresented groups, leading to discriminatory outcomes that exacerbate societal inequalities, especially in applications like\nfacial recognition\n, hiring processes, and\nlaw enforcement\n.\n[\n247\n]\n[\n248\n]\nFor example, in 2018,\nAmazon\nhad to scrap a recruiting tool because the model favored men over women for jobs in software engineering due to the higher number of male workers in the field.\n[\n248\n]\nThe program would penalize any resume with the word \"woman\" or the name of any women's college. However, the use of\nsynthetic data\ncan help reduce dataset bias and increase representation in datasets.\n[\n249\n]\nGallery\n[\nedit\n]\nA single-layer feedforward artificial neural network. Arrows originating from\nx\n2\n{\\displaystyle x_{2}}\nare omitted for clarity. There are\np\ninputs to this network and\nq\noutputs. In this system, the value of the\nq\nth output,\ny\nq\n{\\displaystyle y_{q}}\n, is calculated as\ny\nq\n=\nK\n⋅\n(\n∑\ni\n(\nx\ni\nw\ni\nq\n)\n−\nb\nq\n)\n.\n{\\displaystyle y_{q}=K\\cdot \\left(\\sum _{i}(x_{i}w_{iq})-b_{q}\\right).}\nA two-layer feedforward artificial neural network\nAn artificial neural network\nAn ANN dependency graph\nA single-layer feedforward artificial neural network with 4 inputs, 6 hidden nodes and 2 outputs. Given position state and direction, it outputs wheel based control values.\nA two-layer feedforward artificial neural network with 8 inputs, 2x8 hidden nodes and 2 outputs. Given position state, direction and other environment values, it outputs thruster based control values.\nParallel pipeline structure of CMAC neural network. This learning algorithm can converge in one step.\nRecent advancements and future directions\n[\nedit\n]\nArtificial neural networks (ANNs) have undergone significant advancements, particularly in their ability to model complex systems, handle large data sets, and adapt to various types of applications. Their evolution over the past few decades has been marked by a broad range of applications in fields such as image processing, speech recognition, natural language processing, finance, and medicine.\n[\ncitation needed\n]\nImage processing\n[\nedit\n]\nIn the realm of image processing, ANNs are employed in tasks such as image classification, object recognition, and image segmentation. For instance, deep convolutional neural networks (CNNs) have been important in handwritten digit recognition, achieving state-of-the-art performance.\n[\n250\n]\nThis demonstrates the ability of ANNs to effectively process and interpret complex visual information, leading to advancements in fields ranging from automated surveillance to medical imaging.\n[\n250\n]\nSpeech recognition\n[\nedit\n]\nBy modeling speech signals, ANNs are used for tasks like speaker identification and speech-to-text conversion. Deep neural network architectures have introduced significant improvements in large vocabulary continuous speech recognition, outperforming traditional techniques.\n[\n250\n]\n[\n251\n]\nThese advancements have enabled the development of more accurate and efficient voice-activated systems, enhancing user interfaces in technology products.\n[\ncitation needed\n]\nNatural language processing\n[\nedit\n]\nIn natural language processing, ANNs are used for tasks such as text classification, sentiment analysis, and machine translation. They have enabled the development of models that can accurately translate between languages, understand the context and sentiment in textual data, and categorize text based on content.\n[\n250\n]\n[\n251\n]\nThis has implications for automated customer service, content moderation, and language understanding technologies.\n[\n252\n]\nControl systems\n[\nedit\n]\nIn the domain of control systems, ANNs are used to model dynamic systems for tasks such as system identification, control design, and optimization. For instance, deep feedforward neural networks are important in system identification and control applications.\n[\n253\n]\nFinance\n[\nedit\n]\nFurther information:\nApplications of artificial intelligence § Trading and investment\nANNs are used for\nstock market prediction\nand\ncredit scoring\n:\nIn investing, ANNs can process vast amounts of financial data, recognize complex patterns, and forecast stock market trends, aiding investors and risk managers in making informed decisions.\n[\n250\n]\nIn credit scoring, ANNs offer data-driven, personalized assessments of creditworthiness, improving the accuracy of default predictions and automating the lending process.\n[\n251\n]\nANNs require high-quality data and careful tuning, and their \"black-box\" nature can pose challenges in interpretation. Nevertheless, ongoing advancements suggest that ANNs continue to play a role in finance, offering valuable insights and enhancing\nrisk management strategies\n.\n[\ncitation needed\n]\nMedicine\n[\nedit\n]\nANNs are able to process and analyze vast medical datasets. They enhance diagnostic accuracy, especially by interpreting complex\nmedical imaging\nfor early disease detection, and by predicting patient outcomes for personalized treatment planning.\n[\n251\n]\nIn\ndrug discovery\n, ANNs speed up the identification of potential drug candidates and predict their efficacy and safety, significantly reducing development time and costs.\n[\n250\n]\nAdditionally, their application in personalized medicine and healthcare data analysis allows tailored therapies and efficient patient care management.\n[\n251\n]\nOngoing research is aimed at addressing remaining challenges such as data privacy and model interpretability, as well as expanding the scope of ANN applications in medicine.\n[\ncitation needed\n]\nContent creation\n[\nedit\n]\nANNs such as generative adversarial networks (GAN) and\ntransformers\nare used for\ncontent creation\nacross numerous industries.\n[\n254\n]\nThis is because deep learning models are able to learn the style of an artist or musician from huge datasets and generate completely new artworks and music compositions. For instance,\nDALL-E\nis a deep neural network trained on 650 million pairs of images and texts across the internet that can create artworks based on text entered by the user.\n[\n255\n]\nIn the field of music, transformers are used to create original music for commercials and documentaries through companies such as\nAIVA\nand\nJukedeck\n.\n[\n256\n]\nIn the marketing industry, generative models are used to create personalized advertisements for consumers.\n[\n254\n]\nAdditionally, major film companies are partnering with technology companies to analyze the financial success of a film, such as the partnership between Warner Bros and technology company Cinelytic established in 2020.\n[\n257\n]\nFurthermore, neural networks have found uses in video game creation, where non-player characters (NPCs) can make decisions based on all the characters currently in the game.\n[\n258\n]\nSee also\n[\nedit\n]\nADALINE\nAutoencoder\nBio-inspired computing\nBlue Brain Project\nCatastrophic interference\nCognitive architecture\nConnectionist expert system\nConnectomics\nDeep image prior\nDigital morphogenesis\nEfficiently updatable neural network\nEvolutionary algorithm\nFamily of curves\nGenetic algorithm\nHyperdimensional computing\nIn situ adaptive tabulation\nLarge width limits of neural networks\nList of machine learning concepts\nMemristor\nMind uploading\nNeural gas\nNeural network software\nOptical neural network\nParallel distributed processing\nPhilosophy of artificial intelligence\nPredictive analytics\nQuantum neural network\nSupport vector machine\nSpiking neural network\nStochastic parrot\nTensor product network\nTopological deep learning\nReferences\n[\nedit\n]\n^\nHardesty L (14 April 2017).\n\"Explained: Neural networks\"\n. MIT News Office.\nArchived\nfrom the original on 18 March 2024\n. Retrieved\n2 June\n2022\n.\n^\nYang Z, Yang Z (2014).\nComprehensive Biomedical Physics\n. Karolinska Institute, Stockholm, Sweden: Elsevier. p. 1.\nISBN\n978-0-444-53633-4\n.\nArchived\nfrom the original on 28 July 2022\n. Retrieved\n28 July\n2022\n.\n^\nBishop CM (17 August 2006).\nPattern Recognition and Machine Learning\n(PDF)\n. New York: Springer.\nISBN\n978-0-387-31073-2\n.\n^\na\nb\nVapnik VN, Vapnik VN (1998).\nThe nature of statistical learning theory\n(Corrected 2nd print. ed.). New York Berlin Heidelberg: Springer.\nISBN\n978-0-387-94559-0\n.\n^\na\nb\nIan Goodfellow and Yoshua Bengio and Aaron Courville (2016).\nDeep Learning\n. MIT Press.\nArchived\nfrom the original on 16 April 2016\n. Retrieved\n1 June\n2016\n.\n^\nFerrie, C., Kaiser, S. (2019).\nNeural Networks for Babies\n. Sourcebooks.\nISBN\n978-1-4926-7120-6\n.\n^\nMansfield Merriman, \"A List of Writings Relating to the Method of Least Squares\"\n^\nStigler SM (1981).\n\"Gauss and the Invention of Least Squares\"\n.\nAnn. Stat\n.\n9\n(3):\n465–\n474.\nBibcode\n:\n1981AnSta...945451S\n.\ndoi\n:\n10.1214/aos/1176345451\n.\n^\nBretscher O (1995).\nLinear Algebra With Applications\n(3rd ed.). Upper Saddle River, NJ: Prentice Hall.\n^\na\nb\nc\nd\ne\nf\ng\nh\nSchmidhuber J\n(2022). \"Annotated History of Modern AI and Deep Learning\".\narXiv\n:\n2212.11279\n[\ncs.NE\n].\n^\nStigler SM\n(1986).\nThe History of Statistics: The Measurement of Uncertainty before 1900\n. Cambridge: Harvard.\nISBN\n0-674-40340-1\n.\n^\na\nb\nMcCulloch WS, Pitts W (December 1943).\n\"A logical calculus of the ideas immanent in nervous activity\"\n.\nThe Bulletin of Mathematical Biophysics\n.\n5\n(4):\n115–\n133.\nBibcode\n:\n1943BMaB....5..115M\n.\ndoi\n:\n10.1007/BF02478259\n.\nISSN\n0007-4985\n.\nArchived\nfrom the original on 12 October 2024\n. Retrieved\n7 August\n2024\n.\n^\nKleene S (1956).\n\"Representation of Events in Nerve Nets and Finite Automata\"\n.\nAnnals of Mathematics Studies\n. No. 34. Princeton University Press. pp.\n3–\n41.\nArchived\nfrom the original on 19 May 2024\n. Retrieved\n17 June\n2017\n.\n^\nHebb D (2005) [1st Pub. 1949].\nThe Organization of Behavior\n. Taylor & Francis.\nISBN\n978-1-135-63190-1\n.\n^\nFarley B, W.A. Clark (1954). \"Simulation of Self-Organizing Systems by Digital Computer\".\nIRE Transactions on Information Theory\n.\n4\n(4):\n76–\n84.\nBibcode\n:\n1954TIPIT...4...76F\n.\ndoi\n:\n10.1109/TIT.1954.1057468\n.\n^\nRochester N, J.H. Holland, L.H. Habit, W.L. Duda (1956). \"Tests on a cell assembly theory of the action of the brain, using a large digital computer\".\nIRE Transactions on Information Theory\n.\n2\n(3):\n80–\n93.\nBibcode\n:\n1956IRTIT...2...80R\n.\ndoi\n:\n10.1109/TIT.1956.1056810\n.\n^\nHaykin (2008) Neural Networks and Learning Machines, 3rd edition\n^\nRosenblatt F (1958). \"The Perceptron: A Probabilistic Model For Information Storage And Organization in the Brain\".\nPsychological Review\n.\n65\n(6):\n386–\n408.\nCiteSeerX\n10.1.1.588.3775\n.\ndoi\n:\n10.1037/h0042519\n.\nPMID\n13602029\n.\nS2CID\n12781225\n.\n^\nWerbos P (1975).\nBeyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences\n.\n^\nRosenblatt F (1957). \"The Perceptron—a perceiving and recognizing automaton\".\nReport 85-460-1\n. Cornell Aeronautical Laboratory.\n^\nOlazaran M (1996). \"A Sociological Study of the Official History of the Perceptrons Controversy\".\nSocial Studies of Science\n.\n26\n(3):\n611–\n659.\ndoi\n:\n10.1177/030631296026003005\n.\nJSTOR\n285702\n.\nS2CID\n16786738\n.\n^\na\nb\nJoseph RD (1960).\nContributions to Perceptron Theory, Cornell Aeronautical Laboratory Report No. VG-11 96--G-7, Buffalo\n.\n^\nRussel, Stuart, Norvig, Peter (2010).\nArtificial Intelligence A Modern Approach\n(PDF)\n(3rd ed.). United States of America: Pearson Education. pp.\n16–\n28.\nISBN\n978-0-13-604259-4\n. Archived from\nthe original\n(PDF)\non 17 January 2023\n. Retrieved\n9 December\n2023\n.\n^\na\nb\nRosenblatt F\n(1962).\nPrinciples of Neurodynamics\n. Spartan, New York.\n^\nIvakhnenko AG, Lapa VG (1967).\nCybernetics and Forecasting Techniques\n. American Elsevier Publishing Co.\nISBN\n978-0-444-00020-0\n.\n^\nIvakhnenko A (March 1970).\n\"Heuristic self-organization in problems of engineering cybernetics\"\n.\nAutomatica\n.\n6\n(2):\n207–\n219.\nBibcode\n:\n1970Autom...6..207I\n.\ndoi\n:\n10.1016/0005-1098(70)90092-0\n.\nArchived\nfrom the original on 12 August 2024\n. Retrieved\n7 August\n2024\n.\n^\nIvakhnenko A (1971).\n\"Polynomial theory of complex systems\"\n(PDF)\n.\nIEEE Transactions on Systems, Man, and Cybernetics\n. SMC-1 (4):\n364–\n378.\nBibcode\n:\n1971ITSMC...1..364I\n.\ndoi\n:\n10.1109/TSMC.1971.4308320\n.\nArchived\n(PDF)\nfrom the original on 29 August 2017\n. Retrieved\n5 November\n2019\n.\n^\nRobbins H\n, Monro S (1951).\n\"A Stochastic Approximation Method\"\n.\nThe Annals of Mathematical Statistics\n.\n22\n(3): 400.\ndoi\n:\n10.1214/aoms/1177729586\n.\n^\nAmari S\n(1967). \"A theory of adaptive pattern classifier\".\nIEEE Transactions\n.\nEC\n(16):\n279–\n307.\n^\nFukushima K (1969). \"Visual feature extraction by a multilayered network of analog threshold elements\".\nIEEE Transactions on Systems Science and Cybernetics\n.\n5\n(4):\n322–\n333.\nBibcode\n:\n1969ITSSC...5..322F\n.\ndoi\n:\n10.1109/TSSC.1969.300225\n.\n^\nSonoda S, Murata N (2017). \"Neural network with unbounded activation functions is universal approximator\".\nApplied and Computational Harmonic Analysis\n.\n43\n(2):\n233–\n268.\narXiv\n:\n1505.03654\n.\ndoi\n:\n10.1016/j.acha.2015.12.005\n.\nS2CID\n12149203\n.\n^\nRamachandran P, Barret Z, Quoc VL (16 October 2017). \"Searching for Activation Functions\".\narXiv\n:\n1710.05941\n[\ncs.NE\n].\n^\nMinsky M, Papert S (1969).\nPerceptrons: An Introduction to Computational Geometry\n. MIT Press.\nISBN\n978-0-262-63022-1\n.\n^\nBozinovski S. and Fulgosi A. (1976). \"The influence of pattern similarity and transfer learning on the base perceptron training\" (original in Croatian) Proceedings of Symposium Informatica 3-121-5, Bled.\n^\nBozinovski S.(2020) \"Reminder of the first paper on transfer learning in neural networks, 1976\". Informatica 44: 291–302.\n^\na\nb\nFukushima K (1979).\n\"Neural network model for a mechanism of pattern recognition unaffected by shift in position—Neocognitron\"\n.\nTrans. IECE (In Japanese)\n. J62-A (10):\n658–\n665.\ndoi\n:\n10.1007/bf00344251\n.\nPMID\n7370364\n.\nS2CID\n206775608\n.\n^\nFukushima K (1980).\n\"Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\"\n.\nBiol. Cybern\n.\n36\n(4):\n193–\n202.\ndoi\n:\n10.1007/bf00344251\n.\nPMID\n7370364\n.\nS2CID\n206775608\n.\n^\na\nb\nc\nSchmidhuber J (2015). \"Deep Learning in Neural Networks: An Overview\".\nNeural Networks\n.\n61\n:\n85–\n117.\narXiv\n:\n1404.7828\n.\nBibcode\n:\n2015NN.....61...85S\n.\ndoi\n:\n10.1016/j.neunet.2014.09.003\n.\nPMID\n25462637\n.\nS2CID\n11715509\n.\n^\nLeibniz GW (1920).\nThe Early Mathematical Manuscripts of Leibniz: Translated from the Latin Texts Published by Carl Immanuel Gerhardt with Critical and Historical Notes (Leibniz published the chain rule in a 1676 memoir)\n. Open court publishing Company.\nISBN\n978-0-598-81846-1\n.\n{{\ncite book\n}}\n:\nISBN / Date incompatibility (\nhelp\n)\n^\nKelley HJ\n(1960). \"Gradient theory of optimal flight paths\".\nARS Journal\n.\n30\n(10):\n947–\n954.\ndoi\n:\n10.2514/8.5282\n.\n^\nLinnainmaa S\n(1970).\nThe representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors\n(Masters) (in Finnish). University of Helsinki. p. 6–7.\n^\nLinnainmaa S\n(1976). \"Taylor expansion of the accumulated rounding error\".\nBIT Numerical Mathematics\n.\n16\n(2):\n146–\n160.\ndoi\n:\n10.1007/bf01931367\n.\nS2CID\n122357351\n.\n^\nOstrovski, G.M., Volin,Y.M., and Boris, W.W. (1971). On the computation of derivatives. Wiss. Z. Tech. Hochschule for Chemistry, 13:382–384.\n^\na\nb\nSchmidhuber J\n(25 October 2014).\n\"Who Invented Backpropagation?\"\n. IDSIA, Switzerland.\nArchived\nfrom the original on 30 July 2024\n. Retrieved\n14 September\n2024\n.\n^\nWerbos P\n(1982).\n\"Applications of advances in nonlinear sensitivity analysis\"\n(PDF)\n.\nSystem modeling and optimization\n. Springer. pp.\n762–\n770.\nArchived\n(PDF)\nfrom the original on 14 April 2016\n. Retrieved\n2 July\n2017\n.\n^\nAnderson JA, Rosenfeld E, eds. (2000).\nTalking Nets: An Oral History of Neural Networks\n. The MIT Press.\ndoi\n:\n10.7551/mitpress/6626.003.0016\n.\nISBN\n978-0-262-26715-1\n.\nArchived\nfrom the original on 12 October 2024\n. Retrieved\n7 August\n2024\n.\n^\nWerbos PJ (1994).\nThe Roots of Backpropagation: From Ordered Derivatives to Neural Networks and Political Forecasting\n. New York: John Wiley & Sons.\nISBN\n0-471-59897-6\n.\n^\nRumelhart DE, Hinton GE, Williams RJ (October 1986).\n\"Learning representations by back-propagating errors\"\n.\nNature\n.\n323\n(6088):\n533–\n536.\nBibcode\n:\n1986Natur.323..533R\n.\ndoi\n:\n10.1038/323533a0\n.\nISSN\n1476-4687\n.\nArchived\nfrom the original on 8 March 2021\n. Retrieved\n17 March\n2021\n.\n^\nFukushima K, Miyake S (1 January 1982).\n\"Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position\"\n.\nPattern Recognition\n.\n15\n(6):\n455–\n469.\nBibcode\n:\n1982PatRe..15..455F\n.\ndoi\n:\n10.1016/0031-3203(82)90024-3\n.\nISSN\n0031-3203\n.\nArchived\nfrom the original on 12 October 2024\n. Retrieved\n9 September\n2024\n.\n^\nWaibel A (December 1987).\nPhoneme Recognition Using Time-Delay Neural Networks\n(PDF)\n. Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE). Tokyo, Japan.\nArchived\n(PDF)\nfrom the original on 17 September 2024\n. Retrieved\n20 September\n2024\n.\n^\nAlexander Waibel\net al.,\nPhoneme Recognition Using Time-Delay Neural Networks\nArchived\n11 December 2024 at the\nWayback Machine\nIEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. – 339 March 1989.\n^\nZhang W (1988).\n\"Shift-invariant pattern recognition neural network and its optical architecture\"\n.\nProceedings of Annual Conference of the Japan Society of Applied Physics\n.\nArchived\nfrom the original on 23 June 2020\n. Retrieved\n12 April\n2023\n.\n^\nLeCun\net al.\n, \"Backpropagation Applied to Handwritten Zip Code Recognition\",\nNeural Computation\n, 1, pp. 541–551, 1989.\n^\nZhang W (1990).\n\"Parallel distributed processing model with local space-invariant interconnections and its optical architecture\"\n.\nApplied Optics\n.\n29\n(32):\n4790–\n7.\nBibcode\n:\n1990ApOpt..29.4790Z\n.\ndoi\n:\n10.1364/AO.29.004790\n.\nPMID\n20577468\n.\nArchived\nfrom the original on 6 February 2017\n. Retrieved\n12 April\n2023\n.\n^\nZhang W (1991).\n\"Image processing of human corneal endothelium based on a learning network\"\n.\nApplied Optics\n.\n30\n(29):\n4211–\n7.\nBibcode\n:\n1991ApOpt..30.4211Z\n.\ndoi\n:\n10.1364/AO.30.004211\n.\nPMID\n20706526\n.\nArchived\nfrom the original on 19 June 2024\n. Retrieved\n20 September\n2024\n.\n^\nZhang W (1994).\n\"Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network\"\n.\nMedical Physics\n.\n21\n(4):\n517–\n24.\nBibcode\n:\n1994MedPh..21..517Z\n.\ndoi\n:\n10.1118/1.597177\n.\nPMID\n8058017\n.\nArchived\nfrom the original on 20 June 2024\n. Retrieved\n20 September\n2024\n.\n^\nLeCun Y, Léon Bottou, Yoshua Bengio, Patrick Haffner (1998).\n\"Gradient-based learning applied to document recognition\"\n(PDF)\n.\nProceedings of the IEEE\n.\n86\n(11):\n2278–\n2324.\nBibcode\n:\n1998IEEEP..86.2278L\n.\nCiteSeerX\n10.1.1.32.9552\n.\ndoi\n:\n10.1109/5.726791\n.\nS2CID\n14542261\n. Archived from\nthe original\n(PDF)\non 30 October 2023\n. Retrieved\n7 October\n2016\n.\n^\nQian, Ning, and Terrence J. Sejnowski. \"Predicting the secondary structure of globular proteins using neural network models.\"\nJournal of molecular biology\n202, no. 4 (1988): 865–884.\n^\nBohr, Henrik, Jakob Bohr, Søren Brunak, Rodney MJ Cotterill, Benny Lautrup, Leif Nørskov, Ole H. Olsen, and Steffen B. Petersen. \"Protein secondary structure and homology by neural networks The α-helices in rhodopsin.\"\nFEBS letters\n241, (1988): 223–228\n^\nRost, Burkhard, and Chris Sander. \"Prediction of protein secondary structure at better than 70% accuracy.\"\nJournal of molecular biology\n232, no. 2 (1993): 584–599.\n^\nAmari SI (November 1972). \"Learning Patterns and Pattern Sequences by Self-Organizing Nets of Threshold Elements\".\nIEEE Transactions on Computers\n.\nC-21\n(11):\n1197–\n1206.\nBibcode\n:\n1972ITCmp.100.1197A\n.\ndoi\n:\n10.1109/T-C.1972.223477\n.\nISSN\n0018-9340\n.\n^\nHopfield JJ (1982).\n\"Neural networks and physical systems with emergent collective computational abilities\"\n.\nProceedings of the National Academy of Sciences\n.\n79\n(8):\n2554–\n2558.\nBibcode\n:\n1982PNAS...79.2554H\n.\ndoi\n:\n10.1073/pnas.79.8.2554\n.\nPMC\n346238\n.\nPMID\n6953413\n.\n^\nEspinosa-Sanchez JM, Gomez-Marin A, de Castro F (5 July 2023).\n\"The Importance of Cajal's and Lorente de Nó's Neuroscience to the Birth of Cybernetics\"\n.\nThe Neuroscientist\n.\n31\n(1):\n14–\n30.\ndoi\n:\n10.1177/10738584231179932\n.\nhdl\n:\n10261/348372\n.\nISSN\n1073-8584\n.\nPMID\n37403768\n.\nArchived\nfrom the original on 12 October 2024\n. Retrieved\n7 August\n2024\n.\n^\n\"reverberating circuit\"\n.\nOxford Reference\n.\nArchived\nfrom the original on 12 October 2024\n. Retrieved\n27 July\n2024\n.\n^\na\nb\nBozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402. ISBN 978-0-444-86488-8\n^\nBozinovski S. (1995) \"Neuro genetic agents and structural theory of self-reinforcement learning systems\". CMPSCI Technical Report 95-107, University of Massachusetts at Amherst\n[1]\nArchived\n8 October 2024 at the\nWayback Machine\n^\nZajonc R (1980).\n\"Feeling and thinking: Preferences need no inferences\"\n.\nAmerican Psychologist\n.\n35\n(2):\n151–\n175.\ndoi\n:\n10.1037/0003-066X.35.2.151\n.\n^\nLazarus R. (1982) \"Thoughts on the relations between emotion and cognition\" American Psychologist 37 (9): 1019-1024\n^\nBozinovski, S. (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981\" Procedia Computer Science p. 255-263 (\nhttps://core.ac.uk/download/pdf/81973924.pdf\nArchived\n23 March 2019 at the\nWayback Machine\n)\n^\nSchmidhuber J\n(April 1991).\n\"Neural Sequence Chunkers\"\n(PDF)\n.\nTR FKI-148, TU Munich\n.\nArchived\n(PDF)\nfrom the original on 14 September 2024\n. Retrieved\n21 September\n2024\n.\n^\nSchmidhuber J (1992).\n\"Learning complex, extended sequences using the principle of history compression (based on TR FKI-148, 1991)\"\n(PDF)\n.\nNeural Computation\n.\n4\n(2):\n234–\n242.\ndoi\n:\n10.1162/neco.1992.4.2.234\n.\nS2CID\n18271205\n.\nArchived\n(PDF)\nfrom the original on 14 September 2024\n. Retrieved\n21 September\n2024\n.\n^\nSchmidhuber J (1993).\nHabilitation thesis: System modeling and optimization\n(PDF)\n.\nArchived\n(PDF)\nfrom the original on 7 August 2024\n. Retrieved\n21 September\n2024\n.\nPage 150 ff demonstrates credit assignment across the equivalent of 1,200 layers in an unfolded RNN.\n^\na\nb\nS. Hochreiter., \"\nUntersuchungen zu dynamischen neuronalen Netzen\n\",\nArchived\n6 March 2015 at the\nWayback Machine\n,\nDiploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber\n, 1991.\n^\nHochreiter S, et al. (15 January 2001).\n\"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies\"\n. In Kolen JF, Kremer SC (eds.).\nA Field Guide to Dynamical Recurrent Networks\n. John Wiley & Sons.\nISBN\n978-0-7803-5369-5\n.\nArchived\nfrom the original on 19 May 2024\n. Retrieved\n26 June\n2017\n.\n^\nSepp Hochreiter\n,\nJürgen Schmidhuber\n(21 August 1995),\nLong Short Term Memory\n,\nWikidata\nQ98967430\n^\nHochreiter S\n, Schmidhuber J (1 November 1997). \"Long Short-Term Memory\".\nNeural Computation\n.\n9\n(8):\n1735–\n1780.\ndoi\n:\n10.1162/neco.1997.9.8.1735\n.\nPMID\n9377276\n.\nS2CID\n1915014\n.\n^\nGers F, Schmidhuber J, Cummins F (1999). \"Learning to forget: Continual prediction with LSTM\".\n9th International Conference on Artificial Neural Networks: ICANN '99\n. Vol. 1999. pp.\n850–\n855.\ndoi\n:\n10.1049/cp:19991218\n.\nISBN\n0-85296-721-7\n.\n^\nAckley DH, Hinton GE, Sejnowski TJ (1 January 1985).\n\"A learning algorithm for boltzmann machines\"\n.\nCognitive Science\n.\n9\n(1):\n147–\n169.\ndoi\n:\n10.1016/S0364-0213(85)80012-4\n.\nISSN\n0364-0213\n.\nArchived\nfrom the original on 17 September 2024\n. Retrieved\n7 August\n2024\n.\n^\nSmolensky P (1986).\n\"Chapter 6: Information Processing in Dynamical Systems: Foundations of Harmony Theory\"\n(PDF)\n. In Rumelhart DE, McLelland JL (eds.).\nParallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations\n. MIT Press. pp.\n194–281\n.\nISBN\n0-262-68053-X\n.\nArchived\n(PDF)\nfrom the original on 14 July 2023\n. Retrieved\n7 August\n2024\n.\n^\nPeter D\n,\nHinton GE\n,\nNeal RM\n,\nZemel RS\n(1995). \"The Helmholtz machine\".\nNeural Computation\n.\n7\n(5):\n889–\n904.\ndoi\n:\n10.1162/neco.1995.7.5.889\n.\nhdl\n:\n21.11116/0000-0002-D6D3-E\n.\nPMID\n7584891\n.\nS2CID\n1890561\n.\n^\nHinton GE\n,\nDayan P\n,\nFrey BJ\n, Neal R (26 May 1995). \"The wake-sleep algorithm for unsupervised neural networks\".\nScience\n.\n268\n(5214):\n1158–\n1161.\nBibcode\n:\n1995Sci...268.1158H\n.\ndoi\n:\n10.1126/science.7761831\n.\nPMID\n7761831\n.\nS2CID\n871473\n.\n^\n2012 Kurzweil AI Interview\nArchived\n31 August 2018 at the\nWayback Machine\nwith Juergen Schmidhuber on the eight competitions won by his Deep Learning team 2009–2012\n^\n\"How bio-inspired deep learning keeps winning competitions | KurzweilAI\"\n.\nkurzweilai.net\n. Archived from\nthe original\non 31 August 2018\n. Retrieved\n16 June\n2017\n.\n^\nCireşan DC, Meier U, Gambardella LM, Schmidhuber J (21 September 2010). \"Deep, Big, Simple Neural Nets for Handwritten Digit Recognition\".\nNeural Computation\n.\n22\n(12):\n3207–\n3220.\narXiv\n:\n1003.0358\n.\nBibcode\n:\n2010NeCom..22.3207C\n.\ndoi\n:\n10.1162/neco_a_00052\n.\nISSN\n0899-7667\n.\nPMID\n20858131\n.\nS2CID\n1918673\n.\n^\nCiresan DC, Meier U, Masci J, Gambardella L, Schmidhuber J (2011).\n\"Flexible, High Performance Convolutional Neural Networks for Image Classification\"\n(PDF)\n.\nInternational Joint Conference on Artificial Intelligence\n.\ndoi\n:\n10.5591/978-1-57735-516-8/ijcai11-210\n.\nArchived\n(PDF)\nfrom the original on 29 September 2014\n. Retrieved\n13 June\n2017\n.\n^\nCiresan D, Giusti A, Gambardella LM, Schmidhuber J (2012). Pereira F, Burges CJ, Bottou L, Weinberger KQ (eds.).\nAdvances in Neural Information Processing Systems 25\n(PDF)\n. Curran Associates, Inc. pp.\n2843–\n2851.\nArchived\n(PDF)\nfrom the original on 9 August 2017\n. Retrieved\n13 June\n2017\n.\n^\nCiresan D, Giusti A, Gambardella L, Schmidhuber J (2013). \"Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks\".\nMedical Image Computing and Computer-Assisted Intervention – MICCAI 2013\n. Lecture Notes in Computer Science. Vol. 7908. pp.\n411–\n418.\ndoi\n:\n10.1007/978-3-642-40763-5_51\n.\nISBN\n978-3-642-38708-1\n.\nPMID\n24579167\n.\n^\nCiresan D, Meier U, Schmidhuber J (2012). \"Multi-column deep neural networks for image classification\".\n2012 IEEE Conference on Computer Vision and Pattern Recognition\n. pp.\n3642–\n3649.\narXiv\n:\n1202.2745\n.\ndoi\n:\n10.1109/cvpr.2012.6248110\n.\nISBN\n978-1-4673-1228-8\n.\nS2CID\n2161592\n.\n^\nKrizhevsky A, Sutskever I, Hinton G (2012).\n\"ImageNet Classification with Deep Convolutional Neural Networks\"\n(PDF)\n.\nNIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada\n.\nArchived\n(PDF)\nfrom the original on 10 January 2017\n. Retrieved\n24 May\n2017\n.\n^\nSimonyan K, Andrew Z (2014). \"Very Deep Convolution Networks for Large Scale Image Recognition\".\narXiv\n:\n1409.1556\n[\ncs.CV\n].\n^\nSzegedy C (2015).\n\"Going deeper with convolutions\"\n(PDF)\n.\nCvpr2015\n.\narXiv\n:\n1409.4842\n.\nArchived\n(PDF)\nfrom the original on 30 September 2024\n. Retrieved\n7 August\n2024\n.\n^\nNg A, Dean J (2012). \"Building High-level Features Using Large Scale Unsupervised Learning\".\narXiv\n:\n1112.6209\n[\ncs.LG\n].\n^\na\nb\nBillings SA (2013).\nNonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains\n. Wiley.\nISBN\n978-1-119-94359-4\n.\n^\na\nb\nGoodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, et al. (2014).\nGenerative Adversarial Networks\n(PDF)\n. Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp.\n2672–\n2680.\nArchived\n(PDF)\nfrom the original on 22 November 2019\n. Retrieved\n20 August\n2019\n.\n^\nSchmidhuber J\n(1991). \"A possibility for implementing curiosity and boredom in model-building neural controllers\".\nProc. SAB'1991\n. MIT Press/Bradford Books. pp.\n222–\n227.\n^\nSchmidhuber J\n(2020). \"Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)\".\nNeural Networks\n.\n127\n:\n58–\n66.\narXiv\n:\n1906.04493\n.\ndoi\n:\n10.1016/j.neunet.2020.04.008\n.\nPMID\n32334341\n.\nS2CID\n216056336\n.\n^\n\"GAN 2.0: NVIDIA's Hyperrealistic Face Generator\"\n.\nSyncedReview.com\n. 14 December 2018.\nArchived\nfrom the original on 12 September 2024\n. Retrieved\n3 October\n2019\n.\n^\nKarras T, Aila T, Laine S, Lehtinen J (26 February 2018). \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\".\narXiv\n:\n1710.10196\n[\ncs.NE\n].\n^\n\"Prepare, Don't Panic: Synthetic Media and Deepfakes\"\n. witness.org.\nArchived\nfrom the original on 2 December 2020\n. Retrieved\n25 November\n2020\n.\n^\nSohl-Dickstein J, Weiss E, Maheswaranathan N, Ganguli S (1 June 2015).\n\"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\"\n(PDF)\n.\nProceedings of the 32nd International Conference on Machine Learning\n.\n37\n. PMLR:\n2256–\n2265.\narXiv\n:\n1503.03585\n.\nArchived\n(PDF)\nfrom the original on 21 September 2024\n. Retrieved\n7 August\n2024\n.\n^\nSimonyan K, Zisserman A (10 April 2015),\nVery Deep Convolutional Networks for Large-Scale Image Recognition\n,\narXiv\n:\n1409.1556\n^\nHe K, Zhang X, Ren S, Sun J (2016). \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\".\narXiv\n:\n1502.01852\n[\ncs.CV\n].\n^\nHe K, Zhang X, Ren S, Sun J (10 December 2015).\nDeep Residual Learning for Image Recognition\n.\narXiv\n:\n1512.03385\n.\n^\nSrivastava RK, Greff K, Schmidhuber J (2 May 2015). \"Highway Networks\".\narXiv\n:\n1505.00387\n[\ncs.LG\n].\n^\nHe K, Zhang X, Ren S, Sun J (2016). \"Deep Residual Learning for Image Recognition\".\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n. IEEE. pp.\n770–\n778.\narXiv\n:\n1512.03385\n.\ndoi\n:\n10.1109/CVPR.2016.90\n.\nISBN\n978-1-4673-8851-1\n.\n^\nLinn A (10 December 2015).\n\"Microsoft researchers win ImageNet computer vision challenge\"\n.\nThe AI Blog\n.\nArchived\nfrom the original on 21 May 2023\n. Retrieved\n29 June\n2024\n.\n^\nVaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. (12 June 2017). \"Attention Is All You Need\".\narXiv\n:\n1706.03762\n[\ncs.CL\n].\n^\nSchmidhuber J\n(1992).\n\"Learning to control fast-weight memories: an alternative to recurrent nets\"\n(PDF)\n.\nNeural Computation\n.\n4\n(1):\n131–\n139.\ndoi\n:\n10.1162/neco.1992.4.1.131\n.\nS2CID\n16683347\n.\n^\nKatharopoulos A, Vyas A, Pappas N, Fleuret F (2020).\n\"Transformers are RNNs: Fast autoregressive Transformers with linear attention\"\n.\nICML 2020\n. PMLR. pp.\n5156–\n5165.\nArchived\nfrom the original on 11 July 2023\n. Retrieved\n21 September\n2024\n.\n^\nSchlag I, Irie K,\nSchmidhuber J\n(2021). \"Linear Transformers Are Secretly Fast Weight Programmers\".\nICML 2021\n. Springer. pp.\n9355–\n9366.\n^\nWolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A, et al. (2020). \"Transformers: State-of-the-Art Natural Language Processing\".\nProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\n. pp.\n38–\n45.\ndoi\n:\n10.18653/v1/2020.emnlp-demos.6\n.\nS2CID\n208117506\n.\n^\na\nb\nZell A (2003). \"chapter 5.2\".\nSimulation neuronaler Netze\n[\nSimulation of Neural Networks\n] (in German) (1st ed.). Addison-Wesley.\nISBN\n978-3-89319-554-1\n.\nOCLC\n249017987\n.\n^\nArtificial intelligence\n(3rd ed.). Addison-Wesley Pub. Co. 1992.\nISBN\n0-201-53377-4\n.\n^\nAbbod MF (2007). \"Application of Artificial Intelligence to the Management of Urological Cancer\".\nThe Journal of Urology\n.\n178\n(4):\n1150–\n1156.\ndoi\n:\n10.1016/j.juro.2007.05.122\n.\nPMID\n17698099\n.\n^\nDawson CW (1998).\n\"An artificial neural network approach to rainfall-runoff modelling\"\n.\nHydrological Sciences Journal\n.\n43\n(1):\n47–\n66.\nBibcode\n:\n1998HydSJ..43...47D\n.\ndoi\n:\n10.1080/02626669809492102\n.\n^\n\"The Machine Learning Dictionary\"\n.\ncse.unsw.edu.au\n. Archived from\nthe original\non 26 August 2018\n. Retrieved\n4 November\n2009\n.\n^\nCiresan D, Ueli Meier, Jonathan Masci, Luca M. Gambardella, Jurgen Schmidhuber (2011).\n\"Flexible, High Performance Convolutional Neural Networks for Image Classification\"\n(PDF)\n.\nProceedings of the Twenty-Second International Joint Conference on Artificial Intelligence-Volume Volume Two\n.\n2\n:\n1237–\n1242.\nArchived\n(PDF)\nfrom the original on 5 April 2022\n. Retrieved\n7 July\n2022\n.\n^\nZell A (1994).\nSimulation Neuronaler Netze\n[\nSimulation of Neural Networks\n] (in German) (1st ed.). Addison-Wesley. p. 73.\nISBN\n3-89319-554-8\n.\n^\nMiljanovic M (February–March 2012).\n\"Comparative analysis of Recurrent and Finite Impulse Response Neural Networks in Time Series Prediction\"\n(PDF)\n.\nIndian Journal of Computer and Engineering\n.\n3\n(1).\nArchived\n(PDF)\nfrom the original on 19 May 2024\n. Retrieved\n21 August\n2019\n.\n^\n\"What Is Hyperparameter Tuning? IBM\"\n.\nwww.ibm.com\n. 23 July 2024.\n^\nGoodfellow I, Bengio Y, Courville A (2016). \"8\".\nDeep learning\n. Cambridge, Mass: The MIT press. pp.\n271–\n274.\nISBN\n9780262035613\n. Retrieved\n26 October\n2025\n.\n^\nBischl B, Binder M, Lang M, Pielok T, Richter J, Coors S, et al. (March 2023). \"Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges\".\nWIREs Data Mining and Knowledge Discovery\n.\n13\n(2) e1484.\ndoi\n:\n10.1002/widm.1484\n.\n^\nKelleher JD, Mac Namee B, D'Arcy A (2020). \"7-8\".\nFundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies\n(2nd ed.). Cambridge, MA: The MIT Press.\nISBN\n978-0-262-36110-1\n.\nOCLC\n1162184998\n.\n^\nWei J (26 April 2019). \"Forget the Learning Rate, Decay Loss\".\narXiv\n:\n1905.00094\n[\ncs.LG\n].\n^\nLi Y, Fu Y, Li H, Zhang SW (1 June 2009). \"The Improved Training Algorithm of Back Propagation Neural Network with Self-adaptive Learning Rate\".\n2009 International Conference on Computational Intelligence and Natural Computing\n. Vol. 1. pp.\n73–\n76.\ndoi\n:\n10.1109/CINC.2009.111\n.\nISBN\n978-0-7695-3645-3\n.\nS2CID\n10557754\n.\n^\nHuang GB, Zhu QY, Siew CK (2006). \"Extreme learning machine: theory and applications\".\nNeurocomputing\n.\n70\n(1):\n489–\n501.\nCiteSeerX\n10.1.1.217.3692\n.\ndoi\n:\n10.1016/j.neucom.2005.12.126\n.\nS2CID\n116858\n.\n^\nWidrow B, et al. (2013). \"The no-prop algorithm: A new learning algorithm for multilayer neural networks\".\nNeural Networks\n.\n37\n:\n182–\n188.\ndoi\n:\n10.1016/j.neunet.2012.09.020\n.\nPMID\n23140797\n.\n^\nOllivier Y, Charpiat G (2015). \"Training recurrent networks without backtracking\".\narXiv\n:\n1507.07680\n[\ncs.NE\n].\n^\nHinton GE (2010).\n\"A Practical Guide to Training Restricted Boltzmann Machines\"\n.\nTech. Rep. UTML TR 2010-003\n.\nArchived\nfrom the original on 9 May 2021\n. Retrieved\n27 June\n2017\n.\n^\nESANN. 2009.\n[\nfull citation needed\n]\n^\nBernard E (2021).\nIntroduction to machine learning\n. Champaign: Wolfram Media. p. 9.\nISBN\n978-1-57955-048-6\n.\nArchived\nfrom the original on 19 May 2024\n. Retrieved\n22 March\n2023\n.\n^\nBernard E (2021).\nIntroduction to machine learning\n. Champaign: Wolfram Media. p. 12.\nISBN\n978-1-57955-048-6\n.\nArchived\nfrom the original on 19 May 2024\n. Retrieved\n22 March\n2023\n.\n^\nBernard E (2021).\nIntroduction to Machine Learning\n. Wolfram Media Inc. p. 9.\nISBN\n978-1-57955-048-6\n.\nArchived\nfrom the original on 19 May 2024\n. Retrieved\n28 July\n2022\n.\n^\nOjha VK, Abraham A, Snášel V (1 April 2017). \"Metaheuristic design of feedforward neural networks: A review of two decades of research\".\nEngineering Applications of Artificial Intelligence\n.\n60\n:\n97–\n116.\narXiv\n:\n1705.05584\n.\nBibcode\n:\n2017arXiv170505584O\n.\ndoi\n:\n10.1016/j.engappai.2017.01.013\n.\nS2CID\n27910748\n.\n^\nDominic, S., Das, R., Whitley, D., Anderson, C. (July 1991).\n\"Genetic reinforcement learning for neural networks\"\n.\nIJCNN-91-Seattle International Joint Conference on Neural Networks\n. IJCNN-91-Seattle International Joint Conference on Neural Networks. Seattle, Washington, US: IEEE. pp.\n71–\n76.\ndoi\n:\n10.1109/IJCNN.1991.155315\n.\nISBN\n0-7803-0164-1\n.\n^\nHoskins J, Himmelblau, D.M. (1992). \"Process control via artificial neural networks and reinforcement learning\".\nComputers & Chemical Engineering\n.\n16\n(4):\n241–\n251.\ndoi\n:\n10.1016/0098-1354(92)80045-B\n.\n^\nBertsekas D, Tsitsiklis J (1996).\nNeuro-dynamic programming\n. Athena Scientific. p. 512.\nISBN\n978-1-886529-10-6\n.\nArchived\nfrom the original on 29 June 2017\n. Retrieved\n17 June\n2017\n.\n^\nSecomandi N (2000). \"Comparing neuro-dynamic programming algorithms for the vehicle routing problem with stochastic demands\".\nComputers & Operations Research\n.\n27\n(\n11–\n12):\n1201–\n1225.\nCiteSeerX\n10.1.1.392.4034\n.\ndoi\n:\n10.1016/S0305-0548(99)00146-X\n.\n^\nde Rigo, D., Rizzoli, A. E., Soncini-Sessa, R., Weber, E., Zenesi, P. (2001).\n\"Neuro-dynamic programming for the efficient management of reservoir networks\"\n.\nProceedings of MODSIM 2001, International Congress on Modelling and Simulation\n. MODSIM 2001, International Congress on Modelling and Simulation. Canberra, Australia: Modelling and Simulation Society of Australia and New Zealand.\ndoi\n:\n10.5281/zenodo.7481\n.\nISBN\n0-86740-525-2\n.\nArchived\nfrom the original on 7 August 2013\n. Retrieved\n29 July\n2013\n.\n^\nDamas, M., Salmeron, M., Diaz, A., Ortega, J., Prieto, A., Olivares, G. (2000). \"Genetic algorithms and neuro-dynamic programming: application to water supply networks\".\nProceedings of 2000 Congress on Evolutionary Computation\n. 2000 Congress on Evolutionary Computation. Vol. 1. La Jolla, California, US: IEEE. pp.\n7–\n14.\ndoi\n:\n10.1109/CEC.2000.870269\n.\nISBN\n0-7803-6375-2\n.\n^\nDeng G, Ferris, M.C. (2008). \"Neuro-dynamic programming for fractionated radiotherapy planning\".\nOptimization in Medicine\n. Springer Optimization and Its Applications. Vol. 12. pp.\n47–\n70.\nCiteSeerX\n10.1.1.137.8288\n.\ndoi\n:\n10.1007/978-0-387-73299-2_3\n.\nISBN\n978-0-387-73298-5\n.\n^\nBozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In R. Trappl (ed.) Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. Nort",
      "scraped_at": "2025-12-16T17:25:52.903794",
      "status": "success",
      "content_length": 144638,
      "topic": "deep_learning"
    },
    {
      "title": "Transformer (deep learning) - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Transformer_(machine_learning)",
      "content": "Transformer (deep learning) - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\nToggle History subsection\n1.1\nPredecessors\n1.2\nAttention with seq2seq\n1.3\nParallelizing attention\n1.4\nAI boom era\n2\nTraining\nToggle Training subsection\n2.1\nMethods for stabilizing training\n2.2\nPretrain-finetune\n2.3\nTasks\n3\nArchitecture\nToggle Architecture subsection\n3.1\nTokenization\n3.2\nEmbedding\n3.3\nUn-embedding\n3.4\nPositional encoding\n3.5\nEncoder–decoder (overview)\n3.6\nFeedforward network\n3.7\nScaled dot-product attention\n3.7.1\nAttention head\n3.7.2\nMultihead attention\n3.7.3\nMasked attention\n3.8\nEncoder\n3.9\nDecoder\n4\nFull transformer architecture\nToggle Full transformer architecture subsection\n4.1\nSublayers\n4.2\nPseudocode\n4.3\nTerminology\n5\nSubsequent work\nToggle Subsequent work subsection\n5.1\nAlternative activation functions\n5.2\nAlternative normalizations\n5.3\nAlternative positional encodings\n5.3.1\nRoPE\n5.3.2\nALiBi\n5.3.3\nRelative Position Encodings\n5.4\nEfficient implementation\n5.4.1\nKV caching\n5.4.2\nFlashAttention\n5.4.3\nMulti-Query Attention\n5.4.4\nSpeculative decoding\n5.5\nSub-quadratic transformers\n5.5.1\nAlternative attention graphs\n5.5.2\nRandom Feature Attention\n5.6\nMultimodality\n6\nApplications\n7\nSee also\n8\nNotes\n9\nReferences\n10\nFurther reading\nToggle the table of contents\nTransformer (deep learning)\n30 languages\nالعربية\nCatalà\nČeština\nDeutsch\nEesti\nEspañol\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nՀայերեն\nItaliano\nעברית\n日本語\nNorsk nynorsk\nPolski\nQaraqalpaqsha\nРусский\nSimple English\nکوردی\nСрпски / srpski\nSvenska\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\n(Redirected from\nTransformer (machine learning)\n)\nAlgorithm for modelling sequential data\nA standard transformer architecture, showing on the left an encoder, and on the right a decoder. Note: it uses the pre-LN convention, which is different from the post-LN convention used in the original 2017 transformer.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nIn\ndeep learning\n, the\ntransformer\nis an\nartificial neural network\narchitecture based on the multi-head\nattention\nmechanism, in which text is converted to numerical representations called\ntokens\n, and each token is converted into a vector via lookup from a\nword embedding\ntable.\n[\n1\n]\nAt each layer, each\ntoken\nis then\ncontextualized\nwithin the scope of the\ncontext window\nwith other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier\nrecurrent neural architectures\n(RNNs) such as\nlong short-term memory\n(LSTM).\n[\n2\n]\nLater variations have been widely adopted for training\nlarge language models\n(LLMs) on large (language)\ndatasets\n.\n[\n3\n]\nThe modern version of the transformer was proposed in the 2017 paper \"\nAttention Is All You Need\n\" by researchers at\nGoogle\n, adding a mechanism called 'self attention' calculated with Q,K,V matrices.\n[\n1\n]\nThe predecessors of transformers were developed as an improvement over previous architectures for\nmachine translation\n,\n[\n4\n]\n[\n5\n]\nbut have found many applications since. They are used in large-scale\nnatural language processing\n,\ncomputer vision\n(\nvision transformers\n),\nreinforcement learning\n,\n[\n6\n]\n[\n7\n]\naudio\n,\n[\n8\n]\nmultimodal learning\n,\nrobotics\n,\n[\n9\n]\nand even playing\nchess\n.\n[\n10\n]\nIt has also led to the development of\npre-trained systems\n, such as\ngenerative pre-trained transformers\n(GPTs)\n[\n11\n]\nand\nBERT\n[\n12\n]\n(bidirectional encoder representations from transformers).\nHistory\n[\nedit\n]\nSee also:\nTimeline of machine learning\nPredecessors\n[\nedit\n]\nFor many years, sequence modelling and generation was done by using plain\nrecurrent neural networks\n(RNNs). A well-cited early example was the\nElman network\n(1990). In theory, the information from one token can propagate arbitrarily far down the sequence, but in practice the\nvanishing-gradient problem\nleaves the model's state at the end of a long sentence without precise, extractable information about preceding tokens.\nA key breakthrough was\nLSTM\n(1995),\n[\nnote 1\n]\nan RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an\nattention mechanism\nwhich used neurons that multiply the outputs of other neurons, so-called\nmultiplicative units\n.\n[\n13\n]\nNeural networks using multiplicative units were later called\nsigma-pi networks\n[\n14\n]\nor\nhigher-order networks\n.\n[\n15\n]\nLSTM became the standard architecture for long sequence modelling until the 2017 publication of transformers. However, LSTM still used sequential processing, like most other RNNs.\n[\nnote 2\n]\nSpecifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\nModern transformers overcome this problem, but unlike RNNs, they require computation time that is\nquadratic\nin the size of the context window. The linearly scaling\nfast weight\ncontroller (1992) learns to compute a weight matrix for further processing depending on the input.\n[\n16\n]\nOne of its two networks has \"fast weights\" or \"dynamic links\" (1981).\n[\n17\n]\n[\n18\n]\n[\n19\n]\nA slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries.\n[\n16\n]\nThis was later shown to be equivalent to the unnormalized linear transformer.\n[\n20\n]\n[\n21\n]\nAttention with seq2seq\n[\nedit\n]\nMain article:\nSeq2seq § History\nThe idea of encoder–decoder sequence transduction had been developed in the early 2010s; commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.\n[\n22\n]\n[\n23\n]\nA 380M-parameter model for machine translation uses two\nlong short-term memories\n(LSTM).\n[\n23\n]\nIts architecture consists of two parts. The\nencoder\nis an LSTM that takes in a sequence of tokens and turns it into a vector. The\ndecoder\nis another LSTM that converts the vector into a sequence of tokens. Similarly, another 130M-parameter model used\ngated recurrent units\n(GRU) instead of LSTM.\n[\n22\n]\nLater research showed that GRUs are neither better nor worse than LSTMs for seq2seq.\n[\n24\n]\n[\n25\n]\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only after the\nlast\nword of the source text was processed. Although in theory such a vector retains the information about the whole original sentence, in practice the information is poorly preserved. This is because the input is processed sequentially by one recurrent network into a\nfixed\n-size output vector, which is then processed by another recurrent network into an output. If the input is long, then the output vector would not be able to contain all relevant information, degrading the output. As evidence, reversing the input sentence improved seq2seq translation.\n[\n26\n]\nThe\nRNN search\nmodel introduced an attention mechanism to seq2seq for machine translation to solve the bottleneck problem (of the\nfixed-size\noutput vector), allowing the model to process long-distance dependencies more easily. The name is because it \"emulates searching through a source sentence during decoding a translation\".\n[\n4\n]\nThe relative performances were compared between global (that of\nRNN search\n) and local (sliding window) attention model architectures for machine translation, finding that mixed attention had higher quality than global attention, while local attention reduced translation time.\n[\n27\n]\nIn 2016,\nGoogle Translate\nwas revamped to\nGoogle Neural Machine Translation\n, which replaced the previous model based on\nstatistical machine translation\n. The new model was a seq2seq model where the encoder and the decoder were both 8 layers of bidirectional LSTM.\n[\n28\n]\nIt took nine months to develop, and it outperformed the statistical approach, which took ten years to develop.\n[\n29\n]\nParallelizing attention\n[\nedit\n]\nMain article:\nAttention (machine learning) § History\nSeq2seq models with attention (including self-attention) still suffered from the same issue with recurrent networks, which is that they are hard to\nparallelize\n, which prevented them from being accelerated on GPUs. In 2016,\ndecomposable attention\napplied a self-attention mechanism to\nfeedforward networks\n, which are easy to parallelize, and achieved\nSOTA\nresult in\ntextual entailment\nwith an order of magnitude fewer parameters than LSTMs.\n[\n30\n]\nOne of its authors, Jakob Uszkoreit, suspected that attention\nwithout\nrecurrence would be sufficient for language translation, thus the title \"attention is\nall\nyou need\".\n[\n31\n]\nThat hypothesis was against conventional wisdom at the time, and even his father\nHans Uszkoreit\n, a well-known computational linguist, was skeptical.\n[\n31\n]\nIn the same year, self-attention (called\nintra-attention or\nintra-sentence attention\n) was proposed for LSTMs.\n[\n32\n]\nIn 2017, the original (100M-sized) encoder–decoder transformer model was proposed in the \"\nAttention is all you need\n\" paper. At the time, the focus of the research was on improving\nseq2seq\nfor\nmachine translation\n, by removing its recurrence to process all tokens in parallel, but preserving its dot-product attention mechanism to keep its text processing performance.\n[\n1\n]\nThis led to the introduction of a multi-head attention model that was easier to parallelize due to the use of independent heads and the lack of recurrence. Its parallelizability was an important factor to its widespread use in large neural networks.\n[\n33\n]\nAI boom era\n[\nedit\n]\nAs early as spring 2017, even before the \"Attention is all you need\" preprint was published, one of the co-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia articles.\n[\n34\n]\nTransformer architecture is now used alongside many\ngenerative models\nthat contribute to the ongoing\nAI boom\n.\nIn language modelling,\nELMo\n(2018) was a bi-directional LSTM that produces contextualized\nword embeddings\n, improving upon the line of research from\nbag of words\nand\nword2vec\n. It was followed by\nBERT\n(2018), an encoder-only transformer model.\n[\n35\n]\nIn 2019 October, Google started using BERT to process search queries.\n[\n36\n]\nIn 2020, Google Translate replaced the previous RNN-encoder–RNN-decoder model by a transformer-encoder–RNN-decoder model.\n[\n37\n]\nStarting in 2018, the OpenAI\nGPT series\nof decoder-only transformers became state of the art in\nnatural language generation\n. In 2022, a chatbot based on GPT-3,\nChatGPT\n, became unexpectedly\n[\n38\n]\npopular, triggering a boom around\nlarge language models\n.\n[\n39\n]\n[\n40\n]\nSince 2020, transformers have been applied in modalities beyond text, including the\nvision transformer\n,\n[\n41\n]\nspeech recognition,\n[\n42\n]\nrobotics,\n[\n6\n]\nand\nmultimodal\n.\n[\n43\n]\nThe vision transformer, in turn, stimulated new developments in\nconvolutional neural networks\n.\n[\n44\n]\nImage and video generators like\nDALL-E\n(2021),\nStable Diffusion 3\n(2024),\n[\n45\n]\nand\nSora\n(2024), use transformers to analyse input data (like text prompts) by breaking it down into \"tokens\" and then calculating the relevance between each token using self-attention, which helps the model understand the context and relationships within the data.\nTraining\n[\nedit\n]\nMethods for stabilizing training\n[\nedit\n]\nThe plain transformer architecture had difficulty in converging. In the original paper,\n[\n1\n]\nthe authors recommended using\nlearning rate\nwarmup. That is, the learning rate should linearly scale up from 0 to maximal value for the first part of the training (usually recommended to be 2% of the total number of training steps), before decaying again.\nA 2020 paper found that using\nlayer normalization\nbefore\n(instead of after) multihead attention and feedforward layers stabilizes training, not requiring learning rate warmup.\n[\n46\n]\nPretrain-finetune\n[\nedit\n]\nTransformers typically are first pretrained by\nself-supervised learning\non a large generic dataset, followed by\nsupervised\nfine-tuning\non a small task-specific dataset. The pretrain dataset is typically an unlabeled large corpus, such as\nThe Pile\n. Tasks for pretraining and fine-tuning commonly include:\nlanguage modeling\n[\n12\n]\nnext-sentence prediction\n[\n12\n]\nquestion answering\n[\n3\n]\nreading comprehension\nsentiment analysis\n[\n1\n]\nparaphrasing\n[\n1\n]\nThe\nT5 transformer\nreport\n[\n47\n]\ndocuments a large number of\nnatural language\npretraining tasks. Some examples are:\nrestoring or repairing incomplete or corrupted text. For example, the input,\n\"Thank you ~~ me to your party ~~ week\",\nmight generate the output,\n\"Thank you\nfor inviting\nme to your party\nlast\nweek\".\ntranslation between natural languages (\nmachine translation\n)\njudging the pragmatic acceptability of natural language. For example, the following sentence might be judged \"not acceptable\",\n[\n48\n]\nbecause even though it is syntactically well-formed, it is improbable in ordinary human usage:\nThe course is jumping well.\nNote that while each of these tasks is trivial or obvious for human native speakers of the language (or languages), they have typically proved challenging for previous generations of machine learning architecture.\nTasks\n[\nedit\n]\nSee also:\nLarge language model § Evaluation\nIn general, there are 3 classes of language modelling tasks: \"masked\",\n[\n49\n]\n\"autoregressive\",\n[\n50\n]\nand \"prefixLM\".\n[\n51\n]\nThese classes are independent of a specific modeling architecture such as transformer, but they are often discussed in the context of transformer.\nIn a masked task,\n[\n49\n]\none or more of the tokens is masked out, and the model would produce a probability distribution predicting what the masked-out tokens are based on the context. The\nloss function\nfor the task is typically sum of\nlog-perplexities\nfor the masked-out tokens:\nLoss\n=\n−\n∑\nt\n∈\nmasked tokens\nln\n⁡\n(\nprobability of\nt\nconditional on its context\n)\n{\\displaystyle {\\text{Loss}}=-\\sum _{t\\in {\\text{masked tokens}}}\\ln({\\text{probability of }}t{\\text{ conditional on its context}})}\nand the model is trained to minimize this loss function. The\nBERT series of models\nare trained for masked token prediction and another task.\nIn an autoregressive task,\n[\n50\n]\nthe entire sequence is masked at first, and the model produces a probability distribution for the first token. Then the first token is revealed and the model predicts the second token, and so on. The loss function for the task is still typically the same. The\nGPT series of models\nare trained by autoregressive tasks.\nIn a prefixLM task,\n[\n51\n]\nthe sequence is divided into two parts. The first part is presented as context, and the model predicts the first token of the second part. Then that would be revealed, and the model predicts the second token, and so on. The loss function for the task is still typically the same. The\nT5 series of models\nare trained by prefixLM tasks.\nNote that \"masked\" as in \"masked language modelling\" is not \"masked\" as in \"\nmasked attention\n\", and \"prefixLM\" as in \n\"prefix language modeling\" is not \"prefixLM\" as in \"\nprefix language model\n\".\nArchitecture\n[\nedit\n]\nAll transformers have the same primary components:\nTokenizers, which convert text into tokens.\nEmbedding layer, which converts tokens and positions of the tokens into vector representations.\nTransformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information. These consist of alternating attention and feedforward layers. There are two major types of transformer layers: encoder layers and decoder layers, with further variants.\nUn-embedding layer, which converts the final vector representations back to a probability distribution over the tokens.\nThe following description follows exactly the transformer as described in the original paper. There are variants, described in the\nfollowing section\n.\nBy convention, we write all vectors as row vectors. For example, pushing a vector through a linear layer means multiplying it by a weight matrix on the right, as\nx\nW\n{\\displaystyle xW}\n.\nTokenization\n[\nedit\n]\nAs the transformer architecture natively consists of operations over numbers (matrix multiplications, dot products, activation functions) rather than over text, there must first be a mapping from any input text to some numerical representation. This happens in three steps.\nFirst, the input text is treated by a\npreprocessor\n, which performs both textual transformations and splits the text into coarse-grained segments called\npretokens\n. The latter is referred to as\npretokenization\n. Second, each pretoken is segmented further into\ntokens\nby a\ntokenizer\nthat expects to only see pretokens output by its preprocessor. Each token it produces is a string of one or more characters belonging to a finite set of strings called the\nvocabulary\nV\n{\\displaystyle V}\n. Third, because the vocabulary is finite and known beforehand, each token can be assigned an integer identifier, and this mapping is applied to the sequence of tokens to represent any input text as a numerical sequence. Since this mapping is bijective, the output side can produce a sequence of integer identifiers which can then be turned back into tokens. After undoing some of the preprocessing, the result is again legible text.\nTraining a tokenizer (sometimes referred to as\nvocabularization\n) means finding a suitable vocabulary\nV\n{\\displaystyle V}\n, but also learning how to use it, since any given string\ns\n{\\displaystyle s}\nof length\n|\ns\n|\n{\\displaystyle |s|}\nhas\n2\n|\ns\n|\n−\n1\n{\\displaystyle 2^{|s|-1}}\nhypothetical segmentations, some of which containing segments that are not in the vocabulary. The most important hyperparameter during vocabularization is the\nvocabulary size\n|\nV\n|\n{\\displaystyle |V|}\n: when it is small, the learned vocabulary generally consists of characters and smaller strings, and words will be segmented into many tokens. At larger sizes, it becomes affordable to dedicate tokens to full words, although depending on the preprocessor and tokenizer, it is not necessarily the case that large vocabularies will always use the largest token(s) available to segment a word.\nBecause tokens are not always full words, they may also be referred to as\nsubwords\nand tokenization algorithms may be referred to as\nsubword tokenizers\n. This is also to differentiate these systems from\ntraditional terminology\nused in older information retrieval and natural language processing systems, where \"tokenization\" was used to denote what is today called \"pretokenization\" (very crudely: splitting into words). In tokenizers that produce tokens that are\nnot\npart of the vocabulary, a special token that does belong to the vocabulary is used as a generic stand-in, written as \"[UNK]\" for \"unknown\". In principle, any string could be hidden by such an [UNK]. Indeed, in information retrieval, pretokenizers were themselves used as tokenizers (and also called \"tokenizers\") with a word-level vocabulary that contained an [UNK].\nCommonly used subword tokenization algorithms are\nbyte pair encoding\n(BPE) and the unigram language model (ULM), which each include a vocabularization algorithm and a dedicated segmentation algorithm. There also exist several segmentation algorithms that require no learning and can be applied given a vocabulary (produced by BPE or ULM, for example), like greedily recognising tokens in a pretoken by moving through it left-to-right. Well-known software implementations of subword tokenizers are\nHugging Face\n's\ntokenizers\nPython package implemented in Rust, and the\nsentencepiece\nPython package implemented in C++. The latter package is named as such because one of its configuration options allows disabling the built-in pretokenizer, hence effectively making entire sentences a pretoken and thus having the tokenizer see entire sentences, rather than individual words.\nEmbedding\n[\nedit\n]\nFurther information:\nWord embedding\nEach integer token identifier is converted into an embedding vector via a\nlookup table\n. Equivalently stated, it multiplies a\none-hot\nrepresentation of the token identifier by an embedding matrix\nM\n{\\displaystyle M}\n. For example, if the input token's identifier is\n3\n{\\displaystyle 3}\n, then the one-hot representation is\n[\n0\n,\n0\n,\n0\n,\n1\n,\n0\n,\n0\n,\n…\n]\n{\\displaystyle [0,0,0,1,0,0,\\dots ]}\n, and its embedding vector is\nE\nm\nb\ne\nd\n(\n3\n)\n=\n[\n0\n,\n0\n,\n0\n,\n1\n,\n0\n,\n0\n,\n…\n]\nM\n{\\displaystyle \\mathrm {Embed} (3)=[0,0,0,1,0,0,\\dots ]M}\nThe token embedding vectors are added to their respective positional encoding vectors (see below), producing the sequence of input vectors.\nThe dimension of an embedding vector is called\nhidden size\nor\nembedding size\nand written as\nd\nemb\n{\\displaystyle d_{\\text{emb}}}\n.\n[\n35\n]\nThis size is written as\nd\nmodel\n{\\displaystyle d_{\\text{model}}}\nin the original transformer paper.\n[\n1\n]\nUn-embedding\n[\nedit\n]\nAn un-embedding layer is almost the reverse of an embedding layer. Whereas an embedding layer converts a token identifier into a vector, an un-embedding layer converts a vector into a probability distribution over tokens.\nThe un-embedding layer is a linear-\nsoftmax\nlayer:\nU\nn\nE\nm\nb\ne\nd\n(\nx\n)\n=\ns\no\nf\nt\nm\na\nx\n(\nx\nW\n+\nb\n)\n{\\displaystyle \\mathrm {UnEmbed} (x)=\\mathrm {softmax} (xW+b)}\nThe matrix has shape\n(\nd\nemb\n,\n|\nV\n|\n)\n{\\displaystyle (d_{\\text{emb}},|V|)}\n. Some architectures use the transpose of the embedding matrix\nM\n{\\displaystyle M}\nas the un-embedding matrix\nW\n{\\displaystyle W}\nin order to avoid needing double the amount of embedding-related parameters and to avoid divergence during training. This practice is called\nweight tying\n.\n[\n52\n]\nPositional encoding\n[\nedit\n]\nIllustration of (absolute) positional encoding with parameters\nN\n=\n10000\n,\nd\n=\n100\n{\\displaystyle N=10000,d=100}\nA positional encoding is a fixed-size vector representation of the relative positions of tokens within a sequence: it provides the transformer model with information about\nwhere\nthe words are in the input sequence. This induces a\nbias\ntowards the order of the input sequence, so that, for example, the input sequence \"\nman bites dog\n\" is processed differently from \"dog bites man\".\nThe positional encoding is defined as a function of type\nf\n:\nR\n→\nR\nd\n{\\displaystyle f:\\mathbb {R} \\to \\mathbb {R} ^{d}}\n, where\nd\n{\\displaystyle d}\nis a positive even\ninteger\n. The full positional encoding defined in the original paper\n[\n1\n]\nis:\n(\nf\n(\nt\n)\n2\nk\n,\nf\n(\nt\n)\n2\nk\n+\n1\n)\n=\n(\nsin\n⁡\n(\nθ\n)\n,\ncos\n⁡\n(\nθ\n)\n)\n∀\nk\n∈\n{\n0\n,\n1\n,\n…\n,\nd\n/\n2\n−\n1\n}\n{\\displaystyle (f(t)_{2k},f(t)_{2k+1})=(\\sin(\\theta ),\\cos(\\theta ))\\quad \\forall k\\in \\{0,1,\\ldots ,d/2-1\\}}\nwhere\nθ\n=\nt\nr\nk\n,\nr\n=\nN\n2\n/\nd\n{\\displaystyle \\theta ={\\frac {t}{r^{k}}},r=N^{2/d}}\n.\nHere,\nN\n{\\displaystyle N}\nis a free parameter that should be significantly larger than the biggest\nk\n{\\displaystyle k}\nthat would be input into the positional encoding function. The original paper uses\nN\n=\n10000\n{\\displaystyle N=10000}\n.\nThe function is in a simpler form when written as a complex function of type\nf\n:\nR\n→\nC\nd\n/\n2\n{\\displaystyle f:\\mathbb {R} \\to \\mathbb {C} ^{d/2}}\nf\n(\nt\n)\n=\n(\ne\ni\nt\n/\nr\nk\n)\nk\n=\n0\n,\n1\n,\n…\n,\nd\n2\n−\n1\n{\\displaystyle f(t)=\\left(e^{it/r^{k}}\\right)_{k=0,1,\\ldots ,{\\frac {d}{2}}-1}}\nwhere\nr\n=\nN\n2\n/\nd\n{\\displaystyle r=N^{2/d}}\n.\nThe main reason for using this positional encoding function is that using it, shifts are linear transformations:\nf\n(\nt\n+\nΔ\nt\n)\n=\nd\ni\na\ng\n(\nf\n(\nΔ\nt\n)\n)\nf\n(\nt\n)\n{\\displaystyle f(t+\\Delta t)=\\mathrm {diag} (f(\\Delta t))f(t)}\nwhere\nΔ\nt\n∈\nR\n{\\displaystyle \\Delta t\\in \\mathbb {R} }\nis the distance one wishes to shift. This allows the transformer to take any encoded position, and find the encoding of the position n-steps-ahead or n-steps-behind, by a matrix multiplication.\nBy taking a linear sum, any convolution can also be implemented as linear transformations:\n∑\nj\nc\nj\nf\n(\nt\n+\nΔ\nt\nj\n)\n=\n(\n∑\nj\nc\nj\nd\ni\na\ng\n(\nf\n(\nΔ\nt\nj\n)\n)\n)\nf\n(\nt\n)\n{\\displaystyle \\sum _{j}c_{j}f(t+\\Delta t_{j})=\\left(\\sum _{j}c_{j}\\,\\mathrm {diag} (f(\\Delta t_{j}))\\right)f(t)}\nfor any constants\nc\nj\n{\\displaystyle c_{j}}\n. This allows the transformer to take any encoded position and find a linear sum of the encoded locations of its neighbors. This sum of encoded positions, when fed into the attention mechanism, would create attention weights on its neighbors, much like what happens in a\nconvolutional neural network\nlanguage model\n. In the author's words, \"we hypothesized it would allow the model to easily learn to attend by relative position.\"\nIn typical implementations, all operations are done over the real numbers, not the complex numbers, but since\ncomplex multiplication can be implemented as real 2-by-2 matrix multiplication\n, this is a mere notational difference.\nEncoder–decoder (overview)\n[\nedit\n]\nOne encoder–decoder block\nA transformer is composed of stacked encoder layers and decoder layers.\nLike earlier\nseq2seq\nmodels, the original transformer model used an\nencoder–decoder\narchitecture. The encoder consists of encoding layers that process all the input tokens together one layer after another, while the decoder consists of decoding layers that iteratively process the encoder's output and the decoder's output tokens so far.\nThe purpose of each encoder layer is to create contextualized representations of the tokens, where each representation corresponds to a token that \"mixes\" information from other input tokens via self-attention mechanism. Each decoder layer contains two attention sublayers: (1) cross-attention for incorporating the output of encoder (contextualized input token representations), and (2) self-attention for \"mixing\" information among the input tokens to the decoder (i.e. the tokens generated so far during inference time).\n[\n53\n]\n[\n54\n]\nBoth the encoder and decoder layers have a\nfeed-forward neural network\nfor additional processing of their outputs and contain residual connections and layer normalization steps.\n[\n54\n]\nThese feed-forward layers contain most of the parameters in a transformer model.\nFeedforward network\n[\nedit\n]\nThe feedforward network module. It is a two-layered network that maps\nd\nemb\n{\\displaystyle d_{\\text{emb}}}\n-dimensional vectors into\nd\nemb\n{\\displaystyle d_{\\text{emb}}}\n-dimensional vectors.\nThe feedforward network (FFN) modules in a transformer are 2-layered\nmultilayer perceptrons\n:\nF\nF\nN\n(\nx\n)\n=\nϕ\n(\nx\nW\n(\n1\n)\n+\nb\n(\n1\n)\n)\nW\n(\n2\n)\n+\nb\n(\n2\n)\n{\\displaystyle \\mathrm {FFN} (x)=\\phi (xW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}}\nwhere\nW\n(\n1\n)\n{\\displaystyle W^{(1)}}\nand\nW\n(\n2\n)\n{\\displaystyle W^{(2)}}\nare weight matrices and\nb\n(\n1\n)\n{\\displaystyle b^{(1)}}\nand\nb\n(\n2\n)\n{\\displaystyle b^{(2)}}\nare bias vectors, and\nϕ\n{\\displaystyle \\phi }\nis its activation function. The original transformer used\nReLU\nactivation.\nThe number of neurons in the middle layer is called\nintermediate size\n(GPT),\n[\n55\n]\nfilter size\n(BERT),\n[\n35\n]\nor\nfeedforward size\n(BERT).\n[\n35\n]\nIt is typically larger than the embedding size. For example, in both GPT-2 series and BERT series, the intermediate size of a model is 4 times its embedding size:\nd\nffn\n=\n4\nd\nemb\n{\\displaystyle d_{\\text{ffn}}=4d_{\\text{emb}}}\n.\nScaled dot-product attention\n[\nedit\n]\nMain article:\nDot-product attention\nAttention head\n[\nedit\n]\nScaled dot-product attention, block diagram\nExact dimension counts within an attention head module\nThe attention mechanism used in the transformer architecture are scaled\ndot-product\nattention\nunits. For each unit, the transformer model learns three weight matrices: the query weights\nW\nQ\n{\\displaystyle W^{Q}}\n, the key weights\nW\nK\n{\\displaystyle W^{K}}\n, and the value weights\nW\nV\n{\\displaystyle W^{V}}\n.\nThe module takes three sequences, a query sequence, a key sequence, and a value sequence. The query sequence is a sequence of length\nℓ\nseq, query\n{\\displaystyle \\ell _{\\text{seq, query}}}\n, and each entry is a vector of dimension\nd\nemb, query\n{\\displaystyle d_{\\text{emb, query}}}\n. Similarly for the key and value sequences.\nFor each vector\nx\ni\n,\nquery\n{\\displaystyle x_{i,{\\text{query}}}}\nin the query sequence, it is multiplied by a matrix\nW\nQ\n{\\displaystyle W^{Q}}\nto produce a query vector\nq\ni\n=\nx\ni\n,\nquery\nW\nQ\n{\\displaystyle q_{i}=x_{i,{\\text{query}}}W^{Q}}\n. The matrix of all query vectors is the query matrix:\nQ\n=\nX\nquery\nW\nQ\n{\\displaystyle Q=X_{\\text{query}}W^{Q}}\nSimilarly, we construct the key matrix\nK\n=\nX\nkey\nW\nK\n{\\displaystyle K=X_{\\text{key}}W^{K}}\nand the value matrix\nV\n=\nX\nvalue\nW\nV\n{\\displaystyle V=X_{\\text{value}}W^{V}}\n.\nIt is usually the case that all\nW\nQ\n,\nW\nK\n,\nW\nV\n{\\displaystyle W^{Q},W^{K},W^{V}}\nare square matrices, meaning\nd\nemb, query\n=\nd\nquery\n{\\displaystyle d_{\\text{emb, query}}=d_{\\text{query}}}\n, etc.\nAttention weights are calculated using the query and key vectors: the attention weight\na\ni\nj\n{\\displaystyle a_{ij}}\nfrom token\ni\n{\\displaystyle i}\nto token\nj\n{\\displaystyle j}\nis the\ndot product\nbetween\nq\ni\n{\\displaystyle q_{i}}\nand\nk\nj\n{\\displaystyle k_{j}}\n. The attention weights are divided by the square root of the dimension of the key vectors,\nd\nk\n{\\displaystyle {\\sqrt {d_{k}}}}\n, which stabilizes gradients during training, and passed through a\nsoftmax\nwhich normalizes the weights. The fact that\nW\nQ\n{\\displaystyle W^{Q}}\nand\nW\nK\n{\\displaystyle W^{K}}\nare different matrices allows attention to be non-symmetric: if token\ni\n{\\displaystyle i}\nattends to token\nj\n{\\displaystyle j}\n(i.e.\nq\ni\n⋅\nk\nj\n{\\displaystyle q_{i}\\cdot k_{j}}\nis large), this does not necessarily mean that token\nj\n{\\displaystyle j}\nwill attend to token\ni\n{\\displaystyle i}\n(i.e.\nq\nj\n⋅\nk\ni\n{\\displaystyle q_{j}\\cdot k_{i}}\ncould be small). The output of the attention unit for token\ni\n{\\displaystyle i}\nis the weighted sum of the value vectors of all tokens, weighted by\na\ni\nj\n{\\displaystyle a_{ij}}\n, the attention from token\ni\n{\\displaystyle i}\nto each token.\nThe attention calculation for all tokens can be expressed as one large matrix calculation using the\nsoftmax function\n, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices\nQ\n{\\displaystyle Q}\n,\nK\n{\\displaystyle K}\nand\nV\n{\\displaystyle V}\nare defined as the matrices where the\ni\n{\\displaystyle i}\nth rows are vectors\nq\ni\n{\\displaystyle q_{i}}\n,\nk\ni\n{\\displaystyle k_{i}}\n, and\nv\ni\n{\\displaystyle v_{i}}\nrespectively. Then we can represent the attention as\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\nwhere the softmax is applied over each of the rows of the matrix.\nThe number of dimensions in a query vector is\nquery size\nd\nquery\n{\\displaystyle d_{\\text{query}}}\nand similarly for the\nkey size\nd\nkey\n{\\displaystyle d_{\\text{key}}}\nand\nvalue size\nd\nvalue\n{\\displaystyle d_{\\text{value}}}\n. The output dimension of an attention head is its\nhead dimension\nd\nhead\n{\\displaystyle d_{\\text{head}}}\n. The attention mechanism requires the following three equalities to hold:\nℓ\nseq, key\n=\nℓ\nseq, value\n,\nd\nquery\n=\nd\nkey\n,\nd\nvalue\n=\nd\nhead\n{\\displaystyle \\ell _{\\text{seq, key}}=\\ell _{\\text{seq, value}},\\;d_{\\text{query}}=d_{\\text{key}},\\;d_{\\text{value}}=d_{\\text{head}}}\nbut is otherwise unconstrained.\nIf the attention head is used in a self-attention fashion, then\nX\nquery\n=\nX\nkey\n=\nX\nvalue\n{\\displaystyle X_{\\text{query}}=X_{\\text{key}}=X_{\\text{value}}}\n. If the attention head is used in a cross-attention fashion, then usually\nX\nquery\n≠\nX\nkey\n=\nX\nvalue\n{\\displaystyle X_{\\text{query}}\\neq X_{\\text{key}}=X_{\\text{value}}}\n. It is theoretically possible for all three to be different, but that is rarely the case in practice.\nMultihead attention\n[\nedit\n]\nMultihead attention, block diagram\nExact dimension counts within a multihead attention module\nOne set of\n(\nW\nQ\n,\nW\nK\n,\nW\nV\n)\n{\\displaystyle \\left(W^{Q},W^{K},W^{V}\\right)}\nmatrices is called an\nattention head\n, and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, multiple attention heads allow the model to do this for different definitions of \"relevance\". Specifically, the query and key projection matrices,\nW\nQ\n{\\displaystyle W^{Q}}\nand\nW\nK\n{\\displaystyle W^{K}}\n, which are involved in the attention score computation, defines the \"relevance\". Meanwhile, the value\nprojection matrix\nW\nV\n{\\displaystyle W^{V}}\n, in combination with the part of the output projection matrix\nW\nO\n{\\displaystyle W^{O}}\n, determines how the attended tokens influence what information is passed to subsequent layers and ultimately the output logits. In addition, the scope of attention, or the range of token relationships captured by each attention head, can expand as tokens pass through successive layers. This allows the model to capture more complex and long-range dependencies in deeper layers. Many transformer attention heads encode relevance relations that are meaningful to humans. For example, some attention heads can attend mostly to the next word, while others mainly attend from verbs to their direct objects.\n[\n56\n]\nThe computations for each attention head can be performed in\nparallel\n, which allows for fast processing. The outputs for the attention layer are concatenated to pass into the\nfeedforward neural network\nlayers.\nConcretely, let the multiple attention heads be indexed by\ni\n{\\displaystyle i}\n, then we have\nMultiheadAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\ni\n∈\n[\nn\nheads\n]\n(\nAttention\n(\nX\nW\ni\nQ\n,\nX\nW\ni\nK\n,\nX\nW\ni\nV\n)\n)\nW\nO\n{\\displaystyle {\\text{MultiheadAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V}))W^{O}}\nwhere the matrix\nX\n{\\displaystyle X}\nis the concatenation of word embeddings, and the matrices\nW\ni\nQ\n,\nW\ni\nK\n,\nW\ni\nV\n{\\displaystyle W_{i}^{Q},W_{i}^{K},W_{i}^{V}}\nare \"projection matrices\" owned by individual attention head\ni\n{\\displaystyle i}\n, and\nW\nO\n{\\displaystyle W^{O}}\nis a final projection matrix owned by the whole multihead attention head.\nIt is theoretically possible for each attention head to have a different head dimension\nd\nhead\n{\\displaystyle d_{\\text{head}}}\n, but that is rarely the case in practice.\nAs an example, in the smallest GPT-2 model, there are only self-attention mechanisms. It has the following dimensions:\nd\nemb\n=\n768\n,\nn\nhead\n=\n12\n,\nd\nhead\n=\n64\n{\\displaystyle d_{\\text{emb}}=768,n_{\\text{head}}=12,d_{\\text{head}}=64}\nSince\n12\n×\n64\n=\n768\n{\\displaystyle 12\\times 64=768}\n, its output projection matrix\nW\nO\n∈\nR\n(\n12\n×\n64\n)\n×\n768\n{\\displaystyle W^{O}\\in \\mathbb {R} ^{(12\\times 64)\\times 768}}\nis a square matrix.\nMasked attention\n[\nedit\n]\nThe transformer architecture is constructed to calculate output tokens iteratively. Assuming\nt\n=\n0\n{\\displaystyle t=0}\nrefers to the calculation of the first output token\ni\n=\n0\n{\\displaystyle i=0}\n, for step\nt\n>\n0\n{\\displaystyle t>0}\n, the output token\ni\n=\n0\n{\\displaystyle i=0}\nshall remain constant. This ensures properties of the model similar to\nautoregressive models\n.\n[\n1\n]\nTherefore, at every time step\nt\n{\\displaystyle t}\n, the calculation for all outputs\ni\n{\\displaystyle i}\nshould not have access to tokens at position\nj\n{\\displaystyle j}\nfor\nj\n>=\ni\n{\\displaystyle j>=i}\n(as it naturally is the case for time step\nt\n=\ni\n{\\displaystyle t=i}\n, when tokens\nj\n>\nt\n{\\displaystyle j>t}\nare not yet calculated). This behavior may be accomplished before the softmax stage by adding a mask matrix\nM\n{\\displaystyle M}\nthat is\n−\n∞\n{\\displaystyle -\\infty }\nat entries where the attention link must be cut, and\n0\n{\\displaystyle 0}\nat other places:\nMaskedAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nM\n+\nQ\nK\nT\nd\nk\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{MaskedAttention}}(Q,K,V)={\\text{softmax}}\\left(M+{\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\nThe following matrix is commonly used in decoder self-attention modules, called \"causal masking\":\nM\ncausal\n=\n[\n0\n−\n∞\n−\n∞\n…\n−\n∞\n0\n0\n−\n∞\n…\n−\n∞\n0\n0\n0\n…\n−\n∞\n⋮\n⋮\n⋮\n⋱\n⋮\n0\n0\n0\n…\n0\n]\n{\\displaystyle M_{\\text{causal}}={\\begin{bmatrix}0&-\\infty &-\\infty &\\dots &-\\infty \\\\0&0&-\\infty &\\dots &-\\infty \\\\0&0&0&\\dots &-\\infty \\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&0&\\dots &0\\end{bmatrix}}}\nIn words, it means that each token can pay attention to itself, and every token before it, but not any after it. A non-masked attention module can be thought of as a masked attention module where the mask has all entries zero. As an example of an uncommon use of mask matrix, the\nXLNet\nconsiders all masks of the form\nP\nM\ncausal\nP\n−\n1\n{\\displaystyle PM_{\\text{causal}}P^{-1}}\n, where\nP\n{\\displaystyle P}\nis a random\npermutation matrix\n.\n[\n57\n]\nEncoder\n[\nedit\n]\nOne encoder layer\nAn encoder consists of an embedding layer, followed by multiple encoder layers.\nEach encoder layer consists of two major components: a self-attention mechanism and a feed-forward layer. It takes an input as a sequence of input vectors, applies the self-attention mechanism, to produce an intermediate sequence of vectors, then applies the feed-forward layer for each vector individually. Schematically, we have:\ngiven input vectors\nh\n0\n,\nh\n1\n,\n…\ncombine them into a matrix\nH\n=\n[\nh\n0\nh\n1\n⋮\n]\nEncoderLayer\n(\nH\n)\n=\n[\nFFN\n(\nMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\n0\n)\nFFN\n(\nMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\n1\n)\n⋮\n]\n{\\displaystyle {\\begin{aligned}{\\text{given input vectors }}&h_{0},h_{1},\\dots \\\\{\\text{combine them into a matrix }}H&={\\begin{bmatrix}h_{0}\\\\h_{1}\\\\\\vdots \\end{bmatrix}}\\\\{\\text{EncoderLayer}}(H)&={\\begin{bmatrix}{\\text{FFN}}({\\text{MultiheadAttention}}(H,H,H)_{0})\\\\{\\text{FFN}}({\\text{MultiheadAttention}}(H,H,H)_{1})\\\\\\vdots \\end{bmatrix}}\\\\\\end{aligned}}}\nwhere\nFFN\n{\\displaystyle {\\text{FFN}}}\nstands for \"feed-forward network\". We can more succinctly write it as\nEncoderLayer\n(\nH\n)\n=\nFFN\n(\nMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\n)\n{\\displaystyle {\\text{EncoderLayer}}(H)={\\text{FFN}}({\\text{MultiheadAttention}}(H,H,H))}\nwith the implicit convention that the\nFFN\n{\\displaystyle {\\text{FFN}}}\nis applied to each row of the matrix individually.\nThe encoder layers are stacked. The first encoder layer takes the sequence of input vectors from the embedding layer, producing a sequence of vectors. This sequence of vectors is processed by the second encoder, and so on. The output from the final encoder layer is then used by the decoder.\nAs the encoder processes the entire input all at once, every token can attend to every other token (all-to-all attention), so there is no need for causal masking.\nDecoder\n[\nedit\n]\nOne decoder layer\nA decoder consists of an embedding layer, followed by multiple decoder layers, followed by an un-embedding layer.\nEach decoder consists of three major components: a causally masked self-attention mechanism, a cross-attention mechanism, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders. This mechanism can also be called the\nencoder–decoder attention\n.\n[\n1\n]\n[\n54\n]\nLike the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. The transformer must not use the current or future output to predict an output, so the output sequence must be partially masked to prevent this reverse information flow.\n[\n1\n]\nThis allows for\nautoregressive\ntext generation. For decoding, all-to-all attention is inappropriate, because a token cannot attend to tokens not yet generated. Thus, the self-attention module in the decoder is causally masked.\nIn contrast, the cross-attention mechanism attends to the output vectors of the encoder, which is computed before the decoder starts decoding. Consequently, there is no need for masking in the cross-attention mechanism.\nSchematically, we have:\nH\n′\n=\nMaskedMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\nDecoderLayer\n(\nH\n)\n=\nFFN\n(\nMultiheadAttention\n(\nH\n′\n,\nH\nE\n,\nH\nE\n)\n)\n{\\displaystyle {\\begin{aligned}H'&={\\text{MaskedMultiheadAttention}}(H,H,H)\\\\{\\text{DecoderLayer}}(H)&={\\text{FFN}}({\\text{MultiheadAttention}}(H',H^{E},H^{E}))\\end{aligned}}}\nwhere\nH\nE\n{\\displaystyle H^{E}}\nis the matrix with rows being the output vectors from the encoder.\nThe last decoder is followed by a final un-embedding layer to produce the output probabilities over the vocabulary. Then, one of the tokens is sampled according to the probability, and the decoder can be run again to produce the next token, etc., autoregressively generating output text.\nFull transformer architecture\n[\nedit\n]\nSublayers\n[\nedit\n]\n(a) One encoder layer and one decoder layer. (b) Two encoder layers and two decoder layers. The sublayers are labelled as well.\nEach encoder layer contains 2 sublayers: the self-attention and the feedforward network. Each decoder layer contains 3 sublayers: the causally masked self-attention, the cross-attention, and the feedforward network.\nTransformer encoder with norm-first and norm-last\nTransformer decoder with norm-first and norm-last\nBlock diagram for the full transformer architecture\nSchematic\nobject hierarchy\nfor the full transformer architecture, in\nobject-oriented programming\nstyle\nThe final points of detail are the\nresidual connections\nand\nlayer normalization\n, (denoted as \"LayerNorm\", or \"LN\" in the following), which while conceptually unnecessary, are necessary for numerical stability and convergence.\nThe residual connection, which is introduced to avoid vanishing gradient issues and stabilize the training process, can be expressed as follows: y = F(x) + x. The expression indicates that an output y is the sum of the transformation of input x (F(x)) and the input itself (x). Adding the input x can preserve the input information and avoid issues when the gradient of F(x) is close to zero.\nSimilarly to how the feedforward network modules are applied individually to each vector, the LayerNorm is also applied individually to each vector.\nThere are two common conventions in use: the\npost-LN\nand the\npre-LN\nconvention. In the post-LN convention, the output of each sublayer is\nL\na\ny\ne\nr\nN\no\nr\nm\n(\nx\n+\nS\nu\nb\nl\na\ny\ne\nr\n(\nx\n)\n)\n{\\displaystyle \\mathrm {LayerNorm} (x+\\mathrm {Sublayer} (x))}\nwhere\nS\nu\nb\nl\na\ny\ne\nr\n(\nx\n)\n{\\displaystyle \\mathrm {Sublayer} (x)}\nis the function implemented by the sublayer itself.\nIn the pre-LN convention, the output of each sublayer is\nx\n+\nS\nu\nb\nl\na\ny\ne\nr\n(\nL\na\ny\ne\nr\nN\no\nr\nm\n(\nx\n)\n)\n{\\displaystyle x+\\mathrm {Sublayer} (\\mathrm {LayerNorm} (x))}\nThe original 2017 transformer used the post-LN convention. It was difficult to train and required careful hyperparameter tuning and a \"warm-up\" in learning rate, where it starts small and gradually increases. The pre-LN convention, proposed several times in 2018,\n[\n58\n]\nwas found to be easier to train, requiring no warm-up, leading to faster convergence.\n[\n46\n]\nPseudocode\n[\nedit\n]\nThe following is the pseudocode for a standard pre-LN encoder–decoder transformer, adapted from\nFormal Algorithms for Transformers\n[\n59\n]\ninput:\nEncoder input t_e\n       Decoder input t_d\noutput:\nArray of probability distributions, with shape (decoder vocabulary size x length(decoder output sequence))\n\n/* encoder */\nz_e ← encoder.tokenizer(t_e)\nfor\neach\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← encoder.embedding(z_e[t]) + encoder.positional_embedding(t)\nfor\neach\nl\nin\n1:length(encoder.layers)\ndo\nlayer ← encoder.layers[l]\n\n    /* first sublayer */\n    z_e_copy ← copy(z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← layer.layer_norm(z_e[t])\n    z_e ← layer.multihead_attention(z_e, z_e, z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← z_e[t] + z_e_copy[t]\n\n    /* second sublayer */\n    z_e_copy ← copy(z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← layer.layer_norm(z_e[t])\n    z_e ← layer.feedforward(z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← z_e[t] + z_e_copy[t]\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← encoder.final_layer_norm(z_e[t])\n\n/* decoder */\nz_d ← decoder.tokenizer(t_d)\nfor\neach\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← decoder.embedding(z_d[t]) + decoder.positional_embedding(t)\nfor\neach\nl\nin\n1:length(decoder.layers)\ndo\nlayer ← decoder.layers[l]\n\n        /* first sublayer */\n        z_d_copy ← copy(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.masked_multihead_attention(z_d, z_d, z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← z_d[t] + z_d_copy[t]\n\n        /* second sublayer */\n        z_d_copy ← copy(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.multihead_attention(z_d, z_e, z_e)\nfor each\ni\nin\n1:length(z_d)\ndo\nz_d[t] ← z_d[t] + z_d_copy[t]\n\n        /* third sublayer */\n        z_d_copy ← copy(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.feedforward(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← z_d[t] + z_d_copy[t]\n\nz_d ← decoder.final_layer_norm(z_d)\n\noutput_distributions ← []\nfor each\nt\nin\n1:length(z_d)\ndo\noutput_distributions.append(decoder.unembed(z_d[t]))\nreturn\noutput_distributions\nTerminology\n[\nedit\n]\nThe transformer architecture, being modular, allows variations. Several common variations are described here.\n[\n60\n]\nAn \"encoder-only\" transformer applies the encoder to map an input text into a sequence of vectors that represent the input text. This is usually used for text embedding and\nrepresentation learning\nfor downstream applications.\nBERT\nis encoder-only. They are less often used currently, as they were found to be not significantly better than training an encoder–decoder transformer, then taking just the encoder.\n[\n51\n]\nThey are also referred to as \"all-to-all\" or \"BERT-like\".\nA \"decoder-only\" transformer is not literally decoder-only, since without an encoder, the cross-attention mechanism has nothing to attend to. Thus, the decoder layers in a decoder-only transformer is composed of just two sublayers: the causally masked self-attention, and the feedforward network. This is usually used for\ntext generation\nand\ninstruction following\n. The models in the\nGPT series\nand\nChinchilla series\nare decoder-only. They are also referred to as \"autoregressive\" or \"causal\".\nAn \"encoder–decoder\" transformer is generally the same as the original transformer, with 2 sublayers per encoder layer and 3 sublayers per decoder layer, etc. They might have minor architectural improvements, such as\nalternative activation functions\n,\nchanging the location of normalization\n, etc. This is also usually used for text generation and instruction following. The models in the\nT5 series\nare encoder–decoder.\n[\n60\n]\nA \"prefixLM\" (prefix language model) is a decoder-only architecture, but with prefix masking, which is different from causal masking. Specifically, it has mask of the form\n[\n60\n]\n: Figure 3\nM\nprefixLM\n=\n[\n0\n−\n∞\n0\nM\ncausal\n]\n{\\displaystyle M_{\\text{prefixLM}}={\\begin{bmatrix}\\mathbf {0} &-\\infty \\\\\\mathbf {0} &M_{\\text{causal}}\\end{bmatrix}}}\nwhere the first columns correspond to the \"prefix\", and the subsequent columns correspond to the autoregressively generated text based on the prefix. They resemble encoder–decoder models, but has less \"sparsity\". Such models are rarely used, though they are cited as theoretical possibilities and benchmarked comparisons.\n[\n51\n]\nThere are also mixed seq2seq models. For example, in 2020, Google Translate replaced the previous RNN-encoder–RNN-decoder model with a transformer-encoder–RNN-decoder model, as transformer-based decoders did not appear to significantly increase quality unlike the encoder, while the RNN decoder was much faster.\n[\n37\n]\nSubsequent work\n[\nedit\n]\nAlternative activation functions\n[\nedit\n]\nThe original transformer uses\nReLU\nactivation function\n. Other activation functions were developed. The\nLlama series\nand\nPaLM\nused SwiGLU;\n[\n61\n]\nboth GPT-1 and BERT\n[\n35\n]\nused GELU.\n[\n62\n]\nAlternative activation functions are often used in combination with\nGated Linear Units\nin the feedforward module.\n[\n61\n]\nAlternative normalizations\n[\nedit\n]\nThe normalization used in the transformer can be different from LayerNorm. One example is\nRMSNorm\n[\n63\n]\nwhich is used in the\nLlama series\n. Other examples include CapsuleNorm\n[\n64\n]\nScaleNorm,\n[\n65\n]\nor FixNorm.\n[\n65\n]\nAlternative positional encodings\n[\nedit\n]\nTransformers may use other positional encoding methods than sinusoidal.\n[\n66\n]\nThe original transformer paper reported using a learned positional encoding,\n[\n67\n]\nbut finding it not superior to the sinusoidal one.\n[\n1\n]\nLater,\n[\n68\n]\nfound that causal masking itself provides enough signal to a transformer decoder that it can learn to implicitly perform absolute positional encoding without the positional encoding module.\nRoPE\n[\nedit\n]\nRoPE (rotary positional embedding),\n[\n69\n]\nis best explained by considering a list of 2-dimensional vectors\n[\n(\nx\n1\n(\n1\n)\n,\nx\n1\n(\n2\n)\n)\n,\n(\nx\n2\n(\n1\n)\n,\nx\n2\n(\n2\n)\n)\n,\n(\nx\n3\n(\n1\n)\n,\nx\n3\n(\n2\n)\n)\n,\n.\n.\n.\n]\n{\\displaystyle [(x_{1}^{(1)},x_{1}^{(2)}),(x_{2}^{(1)},x_{2}^{(2)}),(x_{3}^{(1)},x_{3}^{(2)}),...]}\n. Now pick some angle\nθ\n{\\displaystyle \\theta }\n. Then RoPE encoding is\nRoPE\n(\nx\nm\n(\n1\n)\n,\nx\nm\n(\n2\n)\n,\nm\n)\n=\n(\ncos\n⁡\nm\nθ\n−\nsin\n⁡\nm\nθ\nsin\n⁡\nm\nθ\ncos\n⁡\nm\nθ\n)\n(\nx\nm\n(\n1\n)\nx\nm\n(\n2\n)\n)\n=\n(\nx\nm\n(\n1\n)\ncos\n⁡\nm\nθ\n−\nx\nm\n(\n2\n)\nsin\n⁡\nm\nθ\nx\nm\n(\n2\n)\ncos\n⁡\nm\nθ\n+\nx\nm\n(\n1\n)\nsin\n⁡\nm\nθ\n)\n{\\displaystyle {\\text{RoPE}}{\\big (}x_{m}^{(1)},x_{m}^{(2)},m{\\big )}={\\begin{pmatrix}\\cos m\\theta &-\\sin m\\theta \\\\\\sin m\\theta &\\cos m\\theta \\end{pmatrix}}{\\begin{pmatrix}x_{m}^{(1)}\\\\x_{m}^{(2)}\\\\\\end{pmatrix}}={\\begin{pmatrix}x_{m}^{(1)}\\cos m\\theta -x_{m}^{(2)}\\sin m\\theta \\\\x_{m}^{(2)}\\cos m\\theta +x_{m}^{(1)}\\sin m\\theta \\\\\\end{pmatrix}}}\nEquivalently, if we write the 2-dimensional vectors as complex numbers\nz\nm\n:=\nx\nm\n(\n1\n)\n+\ni\nx\nm\n(\n2\n)\n{\\displaystyle z_{m}:=x_{m}^{(1)}+ix_{m}^{(2)}}\n, then RoPE encoding is just multiplication by an angle:\nRoPE\n(\nz\nm\n,\nm\n)\n=\ne\ni\nm\nθ\nz\nm\n{\\displaystyle {\\text{RoPE}}{\\big (}z_{m},m{\\big )}=e^{im\\theta }z_{m}}\nFor a list of\n2\nn\n{\\displaystyle 2n}\n-dimensional vectors, a RoPE encoder is defined by a sequence of angles\nθ\n(\n1\n)\n,\n.\n.\n.\n,\nθ\n(\nn\n)\n{\\displaystyle \\theta ^{(1)},...,\\theta ^{(n)}}\n. Then the RoPE encoding is applied to each pair of coordinates.\nThe benefit of RoPE is that the dot-product between two vectors depends on their relative location only:\nRoPE\n(\nx\n,\nm\n)\nT\nRoPE\n(\ny\n,\nn\n)\n=\nRoPE\n(\nx\n,\nm\n+\nk\n)\nT\nRoPE\n(\ny\n,\nn\n+\nk\n)\n{\\displaystyle {\\text{RoPE}}{\\big (}x,m{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n{\\big )}={\\text{RoPE}}{\\big (}x,m+k{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n+k{\\big )}}\nfor any integer\nk\n{\\displaystyle k}\n.\nALiBi\n[\nedit\n]\nALiBi (Attention with Linear Biases)\n[\n70\n]\nis not a\nreplacement\nfor the positional encoder on the original transformer. Instead, it is an\nadditional\npositional encoder that is directly plugged into the attention mechanism. Specifically, the ALiBi attention mechanism is\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n+\ns\nB\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+sB\\right)V\\end{aligned}}}\nHere,\ns\n{\\displaystyle s}\nis a real number (\"scalar\"), and\nB\n{\\displaystyle B}\nis the\nlinear bias\nmatrix defined by\nB\n=\n(\n0\n1\n2\n3\n⋯\n−\n1\n0\n1\n2\n⋯\n−\n2\n−\n1\n0\n1\n⋯\n−\n3\n−\n2\n−\n1\n0\n⋯\n⋮\n⋮\n⋮\n⋮\n⋱\n)\n{\\displaystyle B={\\begin{pmatrix}0&1&2&3&\\cdots \\\\-1&0&1&2&\\cdots \\\\-2&-1&0&1&\\cdots \\\\-3&-2&-1&0&\\cdots \\\\\\vdots &\\vdots &\\vdots &\\vdots &\\ddots \\\\\\end{pmatrix}}}\nin other words,\nB\ni\n,\nj\n=\nj\n−\ni\n{\\displaystyle B_{i,j}=j-i}\n. The idea being that the linear bias matrix is a softened mask. Just as\n0\n{\\displaystyle 0}\nrepresent full attention paid, and\n−\n∞\n{\\displaystyle -\\infty }\nrepresents no attention paid, the linear bias matrix increases attention paid in one direction and decreases attention paid in the other direction.\nALiBi allows pretraining on short context windows, then fine-tuning on longer context windows. Since it is directly plugged into the attention mechanism, it can be combined with any positional encoder that is plugged into the \"bottom\" of the entire network (which is where the sinusoidal encoder on the original transformer, as well as RoPE and many others, are located).\nRelative Position Encodings\n[\nedit\n]\nRelative Position Encodings\n[\n71\n]\nis similar to ALiBi, but more generic:\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n+\nB\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+B\\right)V\\end{aligned}}}\nwhere\nB\n{\\displaystyle B}\nis a\nToeplitz matrix\n, that is,\nB\ni\n,\nj\n=\nB\ni\n′\n,\nj\n′\n{\\displaystyle B_{i,j}=B_{i',j'}}\nwhenever\ni\n−\nj\n=\ni\n′\n−\nj\n′\n{\\displaystyle i-j=i'-j'}\n. This is contrasted with the original sinusoidal positional encoding, which is an \"absolute positional encoding\".\n[\n72\n]\nEfficient implementation\n[\nedit\n]\nThe transformer model has been implemented in standard deep learning\nframeworks\nsuch as\nTensorFlow\nand\nPyTorch\n.\nTransformers\nis a library produced by\nHugging Face\nthat supplies transformer-based architectures and pretrained models.\n[\n11\n]\nKV caching\n[\nedit\n]\nWhen an autoregressive transformer is used for inference, such as generating text, the query vector is different at each step, but the already-computed key and value vectors are always the same. The\nKV caching\nmethod saves the computed key and value vectors at each attention block, so that they are not recomputed at each new token.\nPagedAttention\napplies\nmemory paging\nto KV caching.\n[\n73\n]\n[\n74\n]\n[\n75\n]\nIf a transformer is used with a baked-in prompt, such as [\"You are a customer support agent...\"], then the key and value vectors can be computed for the prompt, and saved on disk. The saving in compute is significant when the model is used for many short real-time interactions, such as in online chatbots.\nFlashAttention\n[\nedit\n]\nFlashAttention\n[\n76\n]\nis an algorithm that implements the transformer attention mechanism efficiently on a\nGPU\n. It is a communication-avoiding algorithm that performs\nmatrix multiplications in blocks\n, such that each block fits within the\ncache\nof a GPU, and by careful management of the blocks it minimizes data copying between GPU caches (as data movement is slow). See the page on\nsoftmax\nfor details.\nAn improved version, FlashAttention-2,\n[\n77\n]\n[\n78\n]\n[\n79\n]\nwas developed to cater to the rising demand for language models capable of handling longer context lengths. It offers enhancements in work partitioning and parallelism, enabling it to achieve up to 230 TFLOPs/s on\nA100\nGPUs (\nFP16\n/\nBF16\n), a 2x speed increase over the original FlashAttention.\nKey advancements in FlashAttention-2 include the reduction of non-matmul FLOPs, improved parallelism over the sequence length dimension, better work partitioning between GPU warps, and added support for head dimensions up to 256 and multi-query attention (MQA) and grouped-query attention (GQA).\n[\n80\n]\nBenchmarks revealed FlashAttention-2 to be up to 2x faster than FlashAttention and up to 9x faster than a standard attention implementation in PyTorch. Future developments include optimization for new hardware like\nH100\nGPUs and new data types like\nFP8\n.\nFlashAttention-4 focuses on\npipelining\nto increase instruction\nthroughput\n, and was developed to perform particularly well on\nBlackwell GPUs\n.\n[\n81\n]\nMulti-Query Attention\n[\nedit\n]\nComparison between several different forms of attention mechanism and the amount of KV caching necessary for each\nMulti-Query Attention changes the Multihead Attention mechanism.\n[\n82\n]\nWhereas normally,\nMultiheadAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\ni\n∈\n[\nn\nheads\n]\n(\nAttention\n(\nX\nW\ni\nQ\n,\nX\nW\ni\nK\n,\nX\nW\ni\nV\n)\n)\nW\nO\n{\\displaystyle {\\text{MultiheadAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V})\\right)W^{O}}\nwith Multi-Query Attention, there is just one\nW\nK\n,\nW\nV\n{\\displaystyle W^{K},W^{V}}\n, thus:\nMultiQueryAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\ni\n∈\n[\nn\nheads\n]\n(\nAttention\n(\nX\nW\ni\nQ\n,\nX\nW\nK\n,\nX\nW\nV\n)\n)\nW\nO\n{\\displaystyle {\\text{MultiQueryAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW^{K},XW^{V})\\right)W^{O}}\nThis has a neutral effect on model quality and training speed, but increases inference speed.\nMore generally, grouped-query attention (GQA) partitions attention heads into groups, each of which shares the key-value pair. MQA is GQA with one group, while standard Multihead Attention is GQA with the maximal number of groups.\n[\n83\n]\nThe architecture of V2, showing both MLA and a variant of\nmixture of experts\n[\n84\n]\n: Figure 2\nMultihead Latent Attention (MLA) is a\nlow-rank approximation\nto standard MHA. Specifically, each hidden vector, before entering the attention mechanism, is first projected to two low-dimensional spaces (\"latent space\"), one for query and one for key-value (KV vector). This design minimizes the KV cache, as only the low-dimensional KV vector needs to be cached.\n[\n84\n]\nSpeculative decoding\n[\nedit\n]\nSpeculative decoding\n[\n85\n]\n[\n86\n]\nis a method to accelerate token decoding. Similarly to\nspeculative execution\nin CPUs, future tokens are computed quickly, then verified. If the quickly computed tokens are incorrect, they are discarded and computed slowly.\nThe key factor in speculative decoding is that a transformer decoder can verify faster than it can decode, in the following sense.\nSuppose we have two transformer models like GPT-3 and GPT-3-small, both with a context window size of 512. To generate an entire context window autoregressively with greedy decoding with GPT-3, it must be run for 512 times, each time generating a token\nx\n1\n,\nx\n2\n,\n.\n.\n.\n,\nx\n512\n{\\displaystyle x_{1},x_{2},...,x_{512}}\n, taking time\n512\nT\nGPT-3\n{\\displaystyle 512T_{\\text{GPT-3}}}\n. However, if we had some educated guess for the values of these tokens, we could verify all of them in parallel, in one run of the model, by checking that each\nx\nt\n{\\displaystyle x_{t}}\nis indeed the token with the largest log-likelihood in the\nt\n{\\displaystyle t}\n-th output.\nIn speculative decoding, a smaller model or some other simple heuristic is used to generate a few speculative tokens that are subsequently verified by the larger model. For example, suppose we use GPT-3-small to generate four speculative tokens:\nx\n~\n1\n,\nx\n~\n2\n,\nx\n~\n3\n,\nx\n~\n4\n{\\displaystyle {\\tilde {x}}_{1},{\\tilde {x}}_{2},{\\tilde {x}}_{3},{\\tilde {x}}_{4}}\n. This only takes\n4\nT\nGPT-3-small\n{\\displaystyle 4T_{\\text{GPT-3-small}}}\n. These tokens are then run through the larger GPT-3 in one go. Suppose that\nx\n~\n1\n{\\displaystyle {\\tilde {x}}_{1}}\nand\nx\n~\n2\n{\\displaystyle {\\tilde {x}}_{2}}\nare verified by GPT-3 as what it would have picked, then those are kept, but\nx\n~\n3\n{\\displaystyle {\\tilde {x}}_{3}}\nis not, so\nx\n~\n3\n,\nx\n~\n4\n{\\displaystyle {\\tilde {x}}_{3},{\\tilde {x}}_{4}}\nare discarded, and GPT-3 is run on those. This would take\n4\nT\nGPT-3-small\n+\n3\nT\nGPT-3\n{\\displaystyle 4T_{\\text{GPT-3-small}}+3T_{\\text{GPT-3}}}\n, which might be shorter than\n4\nT\nGPT-3\n{\\displaystyle 4T_{\\text{GPT-3}}}\n.\nFor non-greedy decoding, similar ideas apply, except the speculative tokens are accepted or rejected stochastically, in a way that guarantees the final output distribution is the same as if speculative decoding was not used.\n[\n85\n]\n[\n87\n]\nMulti-token prediction\nIn Multi-Token Prediction, a single forward pass creates a final embedding vector, which then is un-embedded into a token probability. However, that vector can then be further processed by another transformer block to predict the\nnext\ntoken, and so on for arbitrarily many steps into the future. This trades off accuracy for speed, since each new token costs just one more transformer block, rather than the entire stack.\n[\n88\n]\n[\n89\n]\nSub-quadratic transformers\n[\nedit\n]\nTraining transformer-based architectures can be expensive, especially for long inputs.\n[\n90\n]\nMany methods have been developed to attempt to address the issue. In the image domain, Swin transformer is an efficient architecture that performs attention inside shifting windows.\n[\n91\n]\nIn the audio domain, SepTr decouples the attention in time and frequency domains.\n[\n92\n]\nLong Range Arena\n(2020)\n[\n93\n]\nis a standard benchmark for comparing the behavior of transformer architectures over long inputs.\nAlternative attention graphs\n[\nedit\n]\nThe standard attention graph is either all-to-all or causal, both of which scales as\nO\n(\nN\n2\n)\n{\\displaystyle O(N^{2})}\nwhere\nN\n{\\displaystyle N}\nis the number of tokens in a sequence.\nReformer (2020)\n[\n90\n]\n[\n94\n]\nreduces the computational load from\nO\n(\nN\n2\n)\n{\\displaystyle O(N^{2})}\nto\nO\n(\nN\nln\n⁡\nN\n)\n{\\displaystyle O(N\\ln N)}\nby using\nlocality-sensitive hashing\nand reversible layers.\n[\n95\n]\nSparse attention\n[\n96\n]\nuses attention graphs that grows slower than\nO\n(\nN\n2\n)\n{\\displaystyle O(N^{2})}\n. For example, BigBird (2020)\n[\n97\n]\nuses random\nsmall-world networks\nwhich grows as\nO\n(\nN\n)\n{\\displaystyle O(N)}\n.\nOrdinary transformers require a memory size that is quadratic in the size of the context window. Attention-free transformers\n[\n98\n]\nreduce this to a linear dependence while still retaining the advantages of a transformer by linking the key to the value.\nRandom Feature Attention\n[\nedit\n]\nRandom Feature Attention (2021)\n[\n99\n]\nuses\nFourier random features\n:\nφ\n(\nx\n)\n=\n1\nD\n[\ncos\n⁡\n⟨\nw\n1\n,\nx\n⟩\n,\nsin\n⁡\n⟨\nw\n1\n,\nx\n⟩\n,\n⋯\ncos\n⁡\n⟨\nw\nD\n,\nx\n⟩\n,\nsin\n⁡\n⟨\nw\nD\n,\nx\n⟩\n]\nT\n{\\displaystyle \\varphi (x)={\\frac {1}{\\sqrt {D}}}[\\cos \\langle w_{1},x\\rangle ,\\sin \\langle w_{1},x\\rangle ,\\cdots \\cos \\langle w_{D},x\\rangle ,\\sin \\langle w_{D},x\\rangle ]^{T}}\nwhere\nw\n1\n,\n.\n.\n.\n,\nw\nD\n{\\displaystyle w_{1},...,w_{D}}\nare independent samples from the normal distribution\nN\n(\n0\n,\nσ\n2\nI\n)\n{\\displaystyle N(0,\\sigma ^{2}I)}\n. This choice of parameters satisfy\nE\n[\n⟨\nφ\n(\nx\n)\n,\nφ\n(\ny\n)\n⟩\n]\n=\ne\n−\n‖\nx\n−\ny\n‖\n2\n2\nσ\n2\n{\\displaystyle \\mathbb {E} [\\langle \\varphi (x),\\varphi (y)\\rangle ]=e^{-{\\frac {\\|x-y\\|^{2}}{2\\sigma ^{2}}}}}\n, or\ne\n⟨\nx\n,\ny\n⟩\n/\nσ\n2\n=\nE\n[\n⟨\ne\n‖\nx\n‖\n2\n/\n2\nσ\n2\nφ\n(\nx\n)\n,\ne\n‖\ny\n‖\n2\n/\n2\nσ\n2\nφ\n(\ny\n)\n⟩\n]\n≈\n⟨\ne\n‖\nx\n‖\n2\n/\n2\nσ\n2\nφ\n(\nx\n)\n,\ne\n‖\ny\n‖\n2\n/\n2\nσ\n2\nφ\n(\ny\n)\n⟩\n{\\displaystyle e^{\\langle x,y\\rangle /\\sigma ^{2}}=\\mathbb {E} [\\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle ]\\approx \\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle }\nConsequently, the one-headed attention, with one query, can be written as\nAttention\n(\nq\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nq\nK\nT\nd\nk\n)\nV\n≈\nφ\n(\nq\n)\nT\n∑\ni\ne\n‖\nk\ni\n‖\n2\n/\n2\nσ\n2\nφ\n(\nk\ni\n)\nv\ni\nT\nφ\n(\nq\n)\nT\n∑\ni\ne\n‖\nk\ni\n‖\n2\n/\n2\nσ\n2\nφ\n(\nk\ni\n)\n{\\displaystyle {\\text{Attention}}(q,K,V)={\\text{softmax}}\\left({\\frac {qK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx {\\frac {\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})v_{i}^{T}}{\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})}}}\nwhere\nσ\n=\nd\nK\n1\n/\n4\n{\\displaystyle \\sigma =d_{K}^{1/4}}\n. Similarly for multiple queries, and for multihead attention.\nThis approximation can be computed in linear time, as we can compute the matrix\nφ\n(\nk\ni\n)\nv\ni\nT\n{\\displaystyle \\varphi (k_{i})v_{i}^{T}}\nfirst, then multiply it with the query. In essence, we have managed to obtain a more precise version of\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n)\nV\n≈\nQ\n(\nK\nT\nV\n/\nd\nk\n)\n{\\displaystyle {\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx Q(K^{T}V/{\\sqrt {d_{k}}})}\nPerformer (2022)\n[\n100\n]\nuses the same Random Feature Attention, but\nw\n1\n,\n.\n.\n.\n,\nw\nD\n{\\displaystyle w_{1},...,w_{D}}\nare first independently sampled from the normal distribution\nN\n(\n0\n,\nσ\n2\nI\n)\n{\\displaystyle N(0,\\sigma ^{2}I)}\n, then they are\nGram-Schmidt processed\n.\nMultimodality\n[\nedit\n]\nTransformers can also be used/adapted for modalities (input or output) beyond just text, usually by finding a way to \"tokenize\" the modality.\nMultimodal models can either be trained from scratch, or by finetuning. A 2022 study found that transformers pretrained only on natural language can be finetuned on only 0.03% of parameters and become competitive with\nLSTMs\non a variety of logical and visual tasks, demonstrating\ntransfer learning\n.\n[\n101\n]\nThe LLaVA was a vision-language model composed of a language model (Vicuna-13B)\n[\n102\n]\nand a vision model (\nViT\n-L/14), connected by a linear layer. Only the linear layer is finetuned.\n[\n103\n]\nVision transformers\n[\n41\n]\nadapt the transformer to computer vision by breaking down input images as a series of patches, turning them into vectors, and treating them like embedding vector of tokens in a standard transformer.\nConformer\n[\n42\n]\nand later\nWhisper\n[\n104\n]\nfollow the same pattern for\nspeech recognition\n, first turning the speech signal into a\nspectrogram\n, which is then treated like an image, i.e. broken down into a series of patches, turned into vectors and treated like embedding vector of tokens in a standard transformer.\nPerceivers\n[\n105\n]\n[\n106\n]\nare a variant of transformers designed for multimodality.\nFor image generation, notable architectures are\nDALL-E 1\n(2021), Parti (2022),\n[\n107\n]\nPhenaki (2023),\n[\n108\n]\nand Muse (2023).\n[\n109\n]\nUnlike later models, DALL-E is not a\ndiffusion model\n. Instead, it uses a decoder-only transformer that autoregressively generates a text, followed by the token representation of an image, which is then converted by a\nvariational autoencoder\nto an image.\n[\n110\n]\nParti is an encoder–decoder transformer, where the encoder processes a text prompt, and the decoder generates a token representation of an image.\n[\n111\n]\nMuse is an encoder-only transformer that is trained to predict masked image tokens from unmasked image tokens. During generation, all input tokens are masked, and the highest-confidence predictions are included for the next iteration, until all tokens are predicted.\n[\n109\n]\nPhenaki is a text-to-video model. It is a bidirectional masked transformer conditioned on pre-computed text tokens. The generated tokens are then decoded to a video.\n[\n108\n]\nApplications\n[\nedit\n]\nThe transformer has had great success in\nnatural language processing\n(NLP). Many\nlarge language models\nsuch as\nGPT-2\n,\nGPT-3\n,\nGPT-4\n,\nGemini\n, AlbertAGPT,\nClaude\n,\nBERT\n,\nGrok\n,\nXLNet\n,\nRoBERTa\nand\nChatGPT\ndemonstrate the ability of transformers to perform a wide variety of NLP-related subtasks and their related real-world applications, including:\nmachine translation\ntime series\nprediction\ndocument summarization\ndocument generation\nnamed entity recognition\n(NER)\n[\n112\n]\nwriting computer code\nbased on requirements expressed in natural language.\nspeech-to-text\nBeyond traditional NLP, the transformer architecture has had success in other applications, such as:\nbiological sequence analysis\nvideo understanding\nprotein folding\n(such as\nAlphaFold\n)\nevaluating\nchess board positions. Using static evaluation alone (that is, with no\nMinimax\nsearch) transformer achieved an\nElo\nof 2895, putting it at\ngrandmaster\nlevel.\n[\n10\n]\nSee also\n[\nedit\n]\nseq2seq\n– Family of machine learning approaches\nPerceiver\n– Variant of Transformer designed for multimodal data\nVision transformer\n– Machine learning model for vision processing\nLarge language model\n– Type of machine learning model\nBERT (language model)\n– Series of language models developed by Google AI\nGenerative pre-trained transformer\n– Type of large language model\nT5 (language model)\n– Series of large language models developed by Google AI\nNotes\n[\nedit\n]\n^\nGated recurrent units\n(2014) further reduced its complexity.\n^\nSome architectures, such as RWKV or state space models, avoid the issue.\nReferences\n[\nedit\n]\n^\na\nb\nc\nd\ne\nf\ng\nh\ni\nj\nk\nl\nVaswani, Ashish\n; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion;\nGomez, Aidan N\n; Kaiser, Łukasz; Polosukhin, Illia (2017).\n\"Attention is All you Need\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n30\n. Curran Associates, Inc.\n^\nHochreiter, Sepp\n;\nSchmidhuber, Jürgen\n(1 November 1997). \"Long Short-Term Memory\".\nNeural Computation\n.\n9\n(8):\n1735–\n1780.\ndoi\n:\n10.1162/neco.1997.9.8.1735\n.\nISSN\n0899-7667\n.\nPMID\n9377276\n.\nS2CID\n1915014\n.\n^\na\nb\n\"Better Language Models and Their Implications\"\n.\nOpenAI\n. 2019-02-14.\nArchived\nfrom the original on 2020-12-19\n. Retrieved\n2019-08-25\n.\n^\na\nb\nBahdanau; Cho, Kyunghyun; Bengio, Yoshua (September 1, 2014). \"Neural Machine Translation by Jointly Learning to Align and Translate\".\narXiv\n:\n1409.0473\n[\ncs.CL\n].\n^\nLuong, Minh-Thang; Pham, Hieu; Manning, Christopher D. (August 17, 2015). \"Effective Approaches to Attention-based Neural Machine Translation\".\narXiv\n:\n1508.04025\n[\ncs.CL\n].\n^\na\nb\nChen, Lili; Lu, Kevin; Rajeswaran, Aravind; Lee, Kimin; Grover, Aditya; Laskin, Michael; Abbeel, Pieter; Srinivas, Aravind; Mordatch, Igor (2021-06-24),\nDecision Transformer: Reinforcement Learning via Sequence Modeling\n,\narXiv\n:\n2106.01345\n^\nParisotto, Emilio; Song, Francis; Rae, Jack; Pascanu, Razvan; Gulcehre, Caglar; Jayakumar, Siddhant; Jaderberg, Max; Kaufman, Raphaël Lopez; Clark, Aidan; Noury, Seb; Botvinick, Matthew; Heess, Nicolas; Hadsell, Raia (2020-11-21).\n\"Stabilizing Transformers for Reinforcement Learning\"\n.\nProceedings of the 37th International Conference on Machine Learning\n. PMLR:\n7487–\n7498.\n^\nRadford, Alec; Jong Wook Kim; Xu, Tao; Brockman, Greg; McLeavey, Christine; Sutskever, Ilya (2022). \"Robust Speech Recognition via Large-Scale Weak Supervision\".\narXiv\n:\n2212.04356\n[\neess.AS\n].\n^\nMonastirsky, Maxim; Azulay, Osher; Sintov, Avishai (February 2023). \"Learning to Throw With a Handful of Samples Using Decision Transformers\".\nIEEE Robotics and Automation Letters\n.\n8\n(2):\n576–\n583.\nBibcode\n:\n2023IRAL....8..576M\n.\ndoi\n:\n10.1109/LRA.2022.3229266\n.\nISSN\n2377-3766\n.\n^\na\nb\nRuoss, Anian; Delétang, Grégoire; Medapati, Sourabh; Grau-Moya, Jordi; Wenliang, Li; Catt, Elliot; Reid, John; Genewein, Tim (2024-02-07). \"Grandmaster-Level Chess Without Search\".\narXiv\n:\n2402.04494v1\n[\ncs.LG\n].\n^\na\nb\nWolf, Thomas; Debut, Lysandre; Sanh, Victor; Chaumond, Julien; Delangue, Clement; Moi, Anthony; Cistac, Pierric; Rault, Tim; Louf, Remi; Funtowicz, Morgan; Davison, Joe; Shleifer, Sam; von Platen, Patrick; Ma, Clara; Jernite, Yacine; Plu, Julien; Xu, Canwen; Le Scao, Teven; Gugger, Sylvain; Drame, Mariama; Lhoest, Quentin; Rush, Alexander (2020). \"Transformers: State-of-the-Art Natural Language Processing\".\nProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\n. pp.\n38–\n45.\ndoi\n:\n10.18653/v1/2020.emnlp-demos.6\n.\nS2CID\n208117506\n.\n^\na\nb\nc\n\"Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing\"\n.\nGoogle AI Blog\n. 2 November 2018.\nArchived\nfrom the original on 2021-01-13\n. Retrieved\n2019-08-25\n.\n^\nFeldman, J. A.; Ballard, D. H. (1982-07-01).\n\"Connectionist models and their properties\"\n.\nCognitive Science\n.\n6\n(3):\n205–\n254.\ndoi\n:\n10.1016/S0364-0213(82)80001-3\n.\nISSN\n0364-0213\n.\n^\nRumelhart, David E.; McClelland, James L.; Hinton, Geoffrey E. (1987-07-29).\nParallel Distributed Processing, Volume 1: Explorations in the Microstructure of Cognition: Foundations, Chapter 2\n(PDF)\n. Cambridge, Mass: Bradford Books.\nISBN\n978-0-262-68053-0\n.\n^\nGiles, C. Lee; Maxwell, Tom (1987-12-01).\n\"Learning, invariance, and generalization in high-order neural networks\"\n.\nApplied Optics\n.\n26\n(23):\n4972–\n4978.\ndoi\n:\n10.1364/AO.26.004972\n.\nISSN\n0003-6935\n.\nPMID\n20523475\n.\n^\na\nb\nSchmidhuber, Jürgen\n(1992).\n\"Learning to control fast-weight memories: an alternative to recurrent nets\"\n(PDF)\n.\nNeural Computation\n.\n4\n(1):\n131–\n139.\ndoi\n:\n10.1162/neco.1992.4.1.131\n.\nS2CID\n16683347\n.\n^\nChristoph von der Malsburg: The correlation theory of brain function. Internal Report 81-2, MPI Biophysical Chemistry, 1981.\nhttp://cogprints.org/1380/1/vdM_correlation.pdf\nSee Reprint in Models of Neural Networks II, chapter 2, pages 95–119. Springer, Berlin, 1994.\n^\nJerome A. Feldman, \"Dynamic connections in neural networks,\" Biological Cybernetics, vol. 46, no. 1, pp. 27–39, Dec. 1982.\n^\nHinton, Geoffrey E.; Plaut, David C. (1987).\n\"Using Fast Weights to Deblur Old Memories\"\n.\nProceedings of the Annual Meeting of the Cognitive Science Society\n.\n9\n.\n^\nKatharopoulos, Angelos; Vyas, Apoorv; Pappas, Nikolaos; Fleuret, François (2020).\n\"Transformers are RNNs: Fast autoregressive Transformers with linear attention\"\n.\nICML 2020\n. PMLR. pp.\n5156–\n5165.\n^\nSchlag, Imanol; Irie, Kazuki;\nSchmidhuber, Jürgen\n(2021). \"Linear Transformers Are Secretly Fast Weight Programmers\".\nICML 2021\n. Springer. pp.\n9355–\n9366.\n^\na\nb\nCho, Kyunghyun; van Merriënboer, Bart; Gulcehre, Caglar; Bahdanau, Dzmitry; Bougares, Fethi; Schwenk, Holger; Bengio, Yoshua (October 2014).\n\"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation\"\n. In Moschitti, Alessandro; Pang, Bo; Daelemans, Walter (eds.).\nProceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n. Doha, Qatar: Association for Computational Linguistics. pp.\n1724–\n1734.\narXiv\n:\n1406.1078\n.\ndoi\n:\n10.3115/v1/D14-1179\n.\n^\na\nb\nSutskever, Ilya; Vinyals, Oriol; Le, Quoc Viet (14 Dec 2014). \"Sequence to sequence learning with neural networks\".\narXiv\n:\n1409.3215\n[\ncs.CL\n].\n[first version posted to arXiv on 10 Sep 2014]\n^\nChung, Junyoung; Gulcehre, Caglar; Cho, KyungHyun; Bengio, Yoshua (2014). \"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\".\narXiv\n:\n1412.3555\n[\ncs.NE\n].\n^\nGruber, N.; Jockisch, A. (2020), \"Are GRU cells more specific and LSTM cells more sensitive in motive classification of text?\",\nFrontiers in Artificial Intelligence\n,\n3\n40,\ndoi\n:\n10.3389/frai.2020.00040\n,\nPMC\n7861254\n,\nPMID\n33733157\n,\nS2CID\n220252321\n^\nSutskever, Ilya; Vinyals, Oriol; Le, Quoc V (2014).\n\"Sequence to Sequence Learning with Neural Networks\"\n.\nAdvances in Neural Information Processing Systems\n.\n27\n. Curran Associates, Inc.\narXiv\n:\n1409.3215\n.\n^\nLuong, Minh-Thang; Pham, Hieu; Manning, Christopher D. (2015). \"Effective Approaches to Attention-based Neural Machine Translation\".\narXiv\n:\n1508.04025\n[\ncs.CL\n].\n^\nWu, Yonghui; et al. (2016-09-01). \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\".\narXiv\n:\n1609.08144\n[\ncs.CL\n].\n^\nLewis-Kraus, Gideon (2016-12-14).\n\"The Great A.I. Awakening\"\n.\nThe New York Times\n.\nISSN\n0362-4331\n. Archived from\nthe original\non 24 May 2023\n. Retrieved\n2023-06-22\n.\n^\nParikh, Ankur P.; Täckström, Oscar; Das, Dipanjan; Uszkoreit, Jakob (2016-09-25). \"A Decomposable Attention Model for Natural Language Inference\".\narXiv\n:\n1606.01933\n[\ncs.CL\n].\n^\na\nb\nLevy, Steven.\n\"8 Google Employees Invented Modern AI. Here's the Inside Story\"\n.\nWired\n.\nISSN\n1059-1028\n.\nArchived\nfrom the original on 20 Mar 2024\n. Retrieved\n2024-08-06\n.\n^\nCheng, Jianpeng; Dong, Li; Lapata, Mirella (November 2016).\n\"Long Short-Term Memory-Networks for Machine Reading\"\n. In Su, Jian; Duh, Kevin; Carreras, Xavier (eds.).\nProceedings of the 2016 Conference on Empirical Methods in Natural Language Processing\n. Austin, Texas: Association for Computational Linguistics. pp.\n551–\n561.\ndoi\n:\n10.18653/v1/D16-1053\n.\n^\nPeng, Bo; Alcaide, Eric; Anthony, Quentin; Albalak, Alon; Arcadinho, Samuel; Biderman, Stella; Cao, Huanqi; Cheng, Xin; Chung, Michael (2023-12-10),\nRWKV: Reinventing RNNs for the transformer Era\n,\narXiv\n:\n2305.13048\n^\nMarche, Stephen (2024-08-23).\n\"Was Linguistic A.I. Created by Accident?\"\n.\nThe New Yorker\n.\nISSN\n0028-792X\n. Retrieved\n2024-08-27\n.\n^\na\nb\nc\nd\ne\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\".\narXiv\n:\n1810.04805v2\n[\ncs.CL\n].\n^\n\"Google: BERT now used on almost every English query\"\n.\nSearch Engine Land\n. 2020-10-15\n. Retrieved\n2020-11-24\n.\n^\na\nb\nCaswell, Isaac; Liang, Bowen (June 8, 2020).\n\"Recent Advances in Google Translate\"\n.\nGoogle Research\n.\nArchived\nfrom the original on 4 Jul 2024\n. Retrieved\n2024-08-07\n.\n^\n\"The inside story of how ChatGPT was built from the people who made it\"\n.\nMIT Technology Review\n. Retrieved\n2024-08-06\n.\n^\n\"Improving language understanding with unsupervised learning\"\n.\nopenai.com\n. June 11, 2018.\nArchived\nfrom the original on 2023-03-18\n. Retrieved\n2023-03-18\n.\n^\nfinetune-transformer-lm\n, OpenAI, June 11, 2018\n, retrieved\n2023-05-01\n^\na\nb\nDosovitskiy, Alexey; Beyer, Lucas; Kolesnikov, Alexander; Weissenborn, Dirk; Zhai, Xiaohua; Unterthiner, Thomas; Dehghani, Mostafa; Minderer, Matthias; Heigold, Georg; Gelly, Sylvain; Uszkoreit, Jakob (2021-06-03). \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\".\narXiv\n:\n2010.11929\n[\ncs.CV\n].\n^\na\nb\nGulati, Anmol; Qin, James; Chiu, Chung-Cheng; Parmar, Niki; Zhang, Yu; Yu, Jiahui; Han, Wei; Wang, Shibo; Zhang, Zhengdong; Wu, Yonghui; Pang, Ruoming (2020). \"Conformer: Convolution-augmented Transformer for Speech Recognition\".\narXiv\n:\n2005.08100\n[\neess.AS\n].\n^\nChoromanski, Krzysztof; Likhosherstov, Valerii; Dohan, David; Song, Xingyou; Gane, Andreea; Sarlos, Tamas; Hawkins, Peter; Davis, Jared; Mohiuddin, Afroz (2022-11-19),\nRethinking Attention with Performers\n,\narXiv\n:\n2009.14794\n^\nLiu, Zhuang; Mao, Hanzi; Wu, Chao-Yuan; Feichtenhofer, Christoph; Darrell, Trevor; Xie, Saining (2022).\nA ConvNet for the 2020s\n. Conference on Computer Vision and Pattern Recognition (\nCVPR\n). pp.\n11976–\n11986.\n^\nEsser, Patrick; Kulal, Sumith; Blattmann, Andreas; Entezari, Rahim; Müller, Jonas; Saini, Harry; Levi, Yam; Lorenz, Dominik; Sauer, Axel (2024-03-05),\nScaling Rectified Flow Transformers for High-Resolution Image Synthesis\n,\narXiv\n:\n2403.03206\n^\na\nb\nXiong, Ruibin; Yang, Yunchang; He, Di; Zheng, Kai; Zheng, Shuxin; Xing, Chen; Zhang, Huishuai; Lan, Yanyan; Wang, Liwei; Liu, Tie-Yan (2020-06-29). \"On Layer Normalization in the Transformer Architecture\".\narXiv\n:\n2002.04745\n[\ncs.LG\n].\n^\nRaffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2020-01-01).\n\"Exploring the limits of transfer learning with a unified text-to-text transformer\"\n.\nThe Journal of Machine Learning Research\n.\n21\n(1): 140:5485–140:5551.\narXiv\n:\n1910.10683\n.\nISSN\n1532-4435\n.\n^\nRaffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2019). \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\".\narXiv\n:\n1910.10683\n[\ncs.LG\n].\n^\na\nb\n\"Masked language modeling\"\n.\nhuggingface.co\n. Retrieved\n2023-10-05\n.\n^\na\nb\n\"Causal language modeling\"\n.\nhuggingface.co\n. Retrieved\n2023-10-05\n.\n^\na\nb\nc\nd\nTay, Yi; Dehghani, Mostafa; Tran, Vinh Q.; Garcia, Xavier; Wei, Jason; Wang, Xuezhi; Chung, Hyung Won; Shakeri, Siamak; Bahri, Dara (2023-02-28),\nUL2: Unifying Language Learning Paradigms\n,\narXiv\n:\n2205.05131\n^\nPress, Ofir; Wolf, Lior (2017-02-21),\nUsing the Output Embedding to Improve Language Models\n,\narXiv\n:\n1608.05859\n^\nLintz, Nathan (2016-04-18).\n\"Sequence Modeling with Neural Networks (Part 2): Attention Models\"\n.\nIndico\n.\nArchived\nfrom the original on 2020-10-21\n. Retrieved\n2019-10-15\n.\n^\na\nb\nc\nAlammar, Jay.\n\"The Illustrated transformer\"\n.\njalammar.github.io\n.\nArchived\nfrom the original on 2020-10-18\n. Retrieved\n2019-10-15\n.\n^\nTeam, Keras.\n\"Keras documentation: GPT2Backbone model\"\n.\nkeras.io\n. Retrieved\n2024-08-08\n.\n^\nClark, Kevin; Khandelwal, Urvashi; Levy, Omer; Manning, Christopher D. (August 2019).\n\"What Does BERT Look at? An Analysis of BERT's Attention\"\n.\nProceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP\n. Florence, Italy: Association for Computational Linguistics:\n276–\n286.\narXiv\n:\n1906.04341\n.\ndoi\n:\n10.18653/v1/W19-4828\n.\nArchived\nfrom the original on 2020-10-21\n. Retrieved\n2020-05-20\n.\n^\nYang, Zhilin; Dai, Zihang; Yang, Yiming; Carbonell, Jaime; Salakhutdinov, Russ R; Le, Quoc V (2019).\n\"XLNet: Generalized Autoregressive Pretraining for Language Understanding\"\n.\nAdvances in Neural Information Processing Systems\n.\n32\n. Curran Associates, Inc.\narXiv\n:\n1906.08237\n.\n^\nWang, Qiang; Li, Bei; Xiao, Tong; Zhu, Jingbo; Li, Changliang; Wong, Derek F.; Chao, Lidia S. (2019-06-04),\nLearning Deep Transformer Models for Machine Translation\n,\narXiv\n:\n1906.01787\n^\nPhuong, Mary; Hutter, Marcus (2022-07-19),\nFormal Algorithms for Transformers\n,\narXiv\n:\n2207.09238\n^\na\nb\nc\nRaffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2020).\n\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"\n.\nJournal of Machine Learning Research\n.\n21\n(140):\n1–\n67.\narXiv\n:\n1910.10683\n.\nISSN\n1533-7928\n.\n^\na\nb\nShazeer, Noam (2020-02-01). \"GLU Variants Improve Transformer\".\narXiv\n:\n2002.05202\n[\ncs.LG\n].\n^\nHendrycks, Dan; Gimpel, Kevin (2016-06-27). \"Gaussian Error Linear Units (GELUs)\".\narXiv\n:\n1606.08415v5\n[\ncs.LG\n].\n^\nZhang, Biao; Sennrich, Rico (2019).\n\"Root Mean Square Layer Normalization\"\n.\nAdvances in Neural Information Processing Systems\n.\n32\n. Curran Associates, Inc.\narXiv\n:\n1910.07467\n.\n^\nTembine, Hamidou, Manzoor Ahmed Khan, and Issa Bamia. 2024. \"Mean-Field-Type Transformers\" Mathematics 12, no. 22: 3506.\nhttps://doi.org/10.3390/math12223506\n^\na\nb\nNguyen, Toan Q.; Salazar, Julian (2019-11-02). Niehues, Jan; Cattoni, Rolando; Stüker, Sebastian; Negri, Matteo; Turchi, Marco; Ha, Thanh-Le; Salesky, Elizabeth; Sanabria, Ramon; Barrault, Loic (eds.).\n\"Transformers without Tears: Improving the Normalization of Self-Attention\"\n.\nProceedings of the 16th International Conference on Spoken Language Translation\n. Hong Kong: Association for Computational Linguistics.\narXiv\n:\n1910.05895\n.\ndoi\n:\n10.5281/zenodo.3525484\n.\n^\nDufter, Philipp; Schmitt, Martin; Schütze, Hinrich (2022-06-06).\n\"Position Information in transformers: An Overview\"\n.\nComputational Linguistics\n.\n48\n(3):\n733–\n763.\narXiv\n:\n2102.11090\n.\ndoi\n:\n10.1162/coli_a_00445\n.\nISSN\n0891-2017\n.\nS2CID\n231986066\n.\n^\nGehring, Jonas; Auli, Michael; Grangier, David; Yarats, Denis; Dauphin, Yann N. (2017-07-17).\n\"Convolutional Sequence to Sequence Learning\"\n.\nProceedings of the 34th International Conference on Machine Learning\n. PMLR:\n1243–\n1252.\n^\nHaviv, Adi; Ram, Ori; Press, Ofir; Izsak, Peter; Levy, Omer (2022-12-05),\nTransformer Language Models without Positional Encodings Still Learn Positional Information\n,\narXiv\n:\n2203.16634\n^\nSu, Jianlin; Lu, Yu; Pan, Shengfeng; Murtadha, Ahmed; Wen, Bo; Liu, Yunfeng (2021-04-01). \"RoFormer: Enhanced Transformer with Rotary Position Embedding\".\narXiv\n:\n2104.09864\n[\ncs.CL\n].\n^\nPress, Ofir; Smith, Noah A.; Lewis, Mike (2021-08-01). \"Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation\".\narXiv\n:\n2108.12409\n[\ncs.CL\n].\n^\nShaw, Peter; Uszkoreit, Jakob; Vaswani, Ashish (2018). \"Self-Attention with Relative Position Representations\".\narXiv\n:\n1803.02155\n[\ncs.CL\n].\n^\nKe, Guolin; He, Di; Liu, Tie-Yan (2021-03-15),\nRethinking Positional Encoding in Language Pre-training\n,\narXiv\n:\n2006.15595\n^\nKwon, Woosuk; Li, Zhuohan; Zhuang, Siyuan; Sheng, Ying; Zheng, Lianmin; Yu, Cody Hao; Gonzalez, Joseph; Zhang, Hao; Stoica, Ion (2023-10-23).\n\"Efficient Memory Management for Large Language Model Serving with PagedAttention\"\n.\nProceedings of the 29th Symposium on Operating Systems Principles\n. SOSP '23. New York, NY, USA: Association for Computing Machinery. pp.\n611–\n626.\narXiv\n:\n2309.06180\n.\ndoi\n:\n10.1145/3600006.3613165\n.\nISBN\n979-8-4007-0229-7\n.\n^\nvllm-project/vllm\n, vLLM, 2024-06-20\n, retrieved\n2024-06-20\n^\nZhuohan Li, Woosuk Kwon; Zhuang, Siyuan; Sheng, Ying; Zheng, Lianmin; Yu, Cody; Gonzalez, Joey; Zhang, Hao; Stoica, Ion (2023-06-20).\n\"vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention\"\n.\nvLLM Blog\n. Retrieved\n2024-06-20\n.\n^\nDao, Tri; Fu, Dan; Ermon, Stefano; Rudra, Atri; Ré, Christopher (2022-12-06).\n\"FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\"\n.\nAdvances in Neural Information Processing Systems\n.\n35\n:\n16344–\n16359.\narXiv\n:\n2205.14135\n.\n^\n\"Stanford CRFM\"\n.\ncrfm.stanford.edu\n. Retrieved\n2023-07-18\n.\n^\n\"FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning\"\n.\nPrinceton NLP\n. 2023-06-17\n. Retrieved\n2023-07-18\n.\n^\n\"Introducing Together AI Chief Scientist Tri Dao, as he releases FlashAttention-2 to speed up model training and inference\"\n.\nTOGETHER\n. Retrieved\n2023-07-18\n.\n^\nAinslie, Joshua; Lee-Thorp, James; de Jong, Michiel; Zemlyanskiy, Yury; Lebrón, Federico; Sanghai, Sumit (2023-12-23). \"GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\".\narXiv\n:\n2305.13245\n[\ncs.CL\n].\n^\n\"We reverse-engineered Flash Attention 4\"\n.\nModal\n. Retrieved\n2025-09-26\n.\n^\nChowdhery, Aakanksha; Narang, Sharan; Devlin, Jacob; Bosma, Maarten; Mishra, Gaurav; Roberts, Adam; Barham, Paul; Chung, Hyung Won; Sutton, Charles; Gehrmann, Sebastian; Schuh, Parker; Shi, Kensen; Tsvyashchenko, Sasha; Maynez, Joshua; Rao, Abhishek (2022-04-01). \"PaLM: Scaling Language Modeling with Pathways\".\narXiv\n:\n2204.02311\n[\ncs.CL\n].\n^\nAinslie, Joshua; Lee-Thorp, James; de Jong, Michiel; Zemlyanskiy, Yury; Lebrón, Federico; Sanghai, Sumit (2023-12-23),\nGQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\n,\narXiv\n:\n2305.13245\n^\na\nb\nDeepSeek-AI; Liu, Aixin; Feng, Bei; Wang, Bin; Wang, Bingxuan; Liu, Bo; Zhao, Chenggang; Dengr, Chengqi; Ruan, Chong (19 June 2024),\nDeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model\n,\narXiv\n:\n2405.04434\n.\n^\na\nb\nLeviathan, Yaniv; Kalman, Matan; Matias, Yossi (2023-05-18),\nFast Inference from Transformers via Speculative Decoding\n,\narXiv\n:\n2211.17192\n^\nFu, Yao (2023-12-13).\n\"Towards 100x Speedup: Full Stack Transformer Inference Optimization\"\n.\n^\nChen, Charlie; Borgeaud, Sebastian; Irving, Geoffrey; Lespiau, Jean-Baptiste; Sifre, Laurent; Jumper, John (2023-02-02),\nAccelerating Large Language Model Decoding with Speculative Sampling\n,\narXiv\n:\n2302.01318\n^\nGloeckle, Fabian; Badr Youbi Idrissi; Rozière, Baptiste; Lopez-Paz, David; Synnaeve, Gabriel (2024). \"Better & Faster Large Language Models via Multi-token Prediction\".\narXiv\n:\n2404.19737\n[\ncs.CL\n].\n^\nDeepSeek-AI; et al. (2024). \"DeepSeek-V3 Technical Report\".\narXiv\n:\n2412.19437\n[\ncs.CL\n].\n^\na\nb\nKitaev, Nikita; Kaiser, Łukasz; Levskaya, Anselm (2020). \"Reformer: The Efficient Transformer\".\narXiv\n:\n2001.04451\n[\ncs.LG\n].\n^\nLiu, Ze; Lin, Yutong; Cao, Yue; Hu, Han; Wei, Yixuan; Zhang, Zheng; Lin, Stephen; Guo, Baining (2021). \"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\".\n2021 IEEE/CVF International Conference on Computer Vision (ICCV)\n. IEEE. pp.\n9992–\n10002.\narXiv\n:\n2103.14030\n.\ndoi\n:\n10.1109/ICCV48922.2021.00986\n.\nISBN\n978-1-6654-2812-5\n.\n^\nRistea, Nicolaea Catalin; Ionescu, Radu Tudor; Khan, Fahad Shahbaz (2022-09-18).\n\"SepTr: Separable Transformer for Audio Spectrogram Processing\"\n.\nInterspeech\n. ISCA:\n4103–\n4107.\narXiv\n:\n2203.09581\n.\ndoi\n:\n10.21437/Interspeech.2022-249\n.\n^\nTay, Yi; Dehghani, Mostafa; Abnar, Samira; Shen, Yikang; Bahri, Dara; Pham, Philip; Rao, Jinfeng; Yang, Liu; Ruder, Sebastian; Metzler, Donald (2020-11-08). \"Long Range Arena: A Benchmark for Efficient Transformers\".\narXiv\n:\n2011.04006\n[\ncs.LG\n].\n^\n\"Reformer: The Efficient Transformer\"\n.\nGoogle AI Blog\n. 16 January 2020.\nArchived\nfrom the original on 2020-10-22\n. Retrieved\n2020-10-22\n.\n^\nGomez, Aidan N; Ren, Mengye; Urtasun, Raquel; Grosse, Roger B (2017).\n\"The Reversible Residual Network: Backpropagation Without Storing Activations\"\n.\nAdvances in Neural Information Processing Systems\n.\n30\n. Curran Associates, Inc.\narXiv\n:\n1707.04585\n.\n^\nChild, Rewon; Gray, Scott; Radford, Alec; Sutskever, Ilya (2019-04-23),\nGenerating Long Sequences with Sparse Transformers\n,\narXiv\n:\n1904.10509\n^\n\"Constructing Transformers For Longer Sequences with Sparse Attention Methods\"\n.\nGoogle AI Blog\n. 25 March 2021.\nArchived\nfrom the original on 2021-09-18\n. Retrieved\n2021-05-28\n.\n^\nZhai, Shuangfei; Talbott, Walter; Srivastava, Nitish; Huang, Chen; Goh, Hanlin; Zhang, Ruixiang; Susskind, Josh (2021-09-21). \"An Attention Free Transformer\".\narXiv\n:\n2105.14103\n[\ncs.LG\n].\n^\nPeng, Hao; Pappas, Nikolaos; Yogatama, Dani; Schwartz, Roy; Smith, Noah A.; Kong, Lingpeng (2021-03-19). \"Random Feature Attention\".\narXiv\n:\n2103.02143\n[\ncs.CL\n].\n^\nChoromanski, Krzysztof; Likhosherstov, Valerii; Dohan, David; Song, Xingyou; Gane, Andreea; Sarlos, Tamas; Hawkins, Peter; Davis, Jared; Belanger, David; Colwell, Lucy; Weller, Adrian (2020-09-30). \"Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers\".\narXiv\n:\n2006.03555\n[\ncs.LG\n].\n^\nLu, Kevin; Grover, Aditya; Abbeel, Pieter; Mordatch, Igor (2022-06-28).\n\"Frozen Pretrained Transformers as Universal Computation Engines\"\n.\nProceedings of the AAAI Conference on Artificial Intelligence\n.\n36\n(7):\n7628–\n7636.\ndoi\n:\n10.1609/aaai.v36i7.20729\n.\nISSN\n2374-3468\n.\n^\n\"Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality | LMSYS Org\"\n.\nlmsys.org\n. Retrieved\n2024-08-11\n.\n^\nLiu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-12-15).\n\"Visual Instruction Tuning\"\n.\nAdvances in Neural Information Processing Systems\n.\n36\n:\n34892–\n34916.\n^\nRadford, Alec; Kim, Jong Wook; Xu, Tao; Brockman, Greg; McLeavey, Christine; Sutskever, Ilya (2022). \"Robust Speech Recognition via Large-Scale Weak Supervision\".\narXiv\n:\n2212.04356\n[\neess.AS\n].\n^\nJaegle, Andrew; Gimeno, Felix; Brock, Andrew; Zisserman, Andrew; Vinyals, Oriol; Carreira, Joao (2021-06-22). \"Perceiver: General Perception with Iterative Attention\".\narXiv\n:\n2103.03206\n[\ncs.CV\n].\n^\nJaegle, Andrew; Borgeaud, Sebastian; Alayrac, Jean-Baptiste; Doersch, Carl; Ionescu, Catalin; Ding, David; Koppula, Skanda; Zoran, Daniel; Brock, Andrew; Shelhamer, Evan; Hénaff, Olivier (2021-08-02). \"Perceiver IO: A General Architecture for Structured Inputs & Outputs\".\narXiv\n:\n2107.14795\n[\ncs.LG\n].\n^\n\"Parti: Pathways Autoregressive Text-to-Image Model\"\n.\nsites.research.google\n. Retrieved\n2024-08-09\n.\n^\na\nb\nVillegas, Ruben; Babaeizadeh, Mohammad; Kindermans, Pieter-Jan; Moraldo, Hernan; Zhang, Han; Saffar, Mohammad Taghi; Castro, Santiago; Kunze, Julius; Erhan, Dumitru (2022-09-29). \"Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions\".\narXiv\n:\n2210.02399\n[\ncs.CV\n].\n^\na\nb\nChang, Huiwen; Zhang, Han; Barber, Jarred; Maschinot, A. J.; Lezama, Jose; Jiang, Lu; Yang, Ming-Hsuan; Murphy, Kevin; Freeman, William T. (2023-01-02). \"Muse: Text-To-Image Generation via Masked Generative Transformers\".\narXiv\n:\n2301.00704\n[\ncs.CV\n].\n^\nRamesh, Aditya; Pavlov, Mikhail; Goh, Gabriel; Gray, Scott; Voss, Chelsea; Radford, Alec; Chen, Mark; Sutskever, Ilya (2021-02-26),\nZero-Shot Text-to-Image Generation\n,\narXiv\n:\n2102.12092\n^\nYu, Jiahui; Xu, Yuanzhong; Koh, Jing Yu; Luong, Thang; Baid, Gunjan; Wang, Zirui; Vasudevan, Vijay; Ku, Alexander; Yang, Yinfei (2022-06-21),\nScaling Autoregressive Models for Content-Rich Text-to-Image Generation\n,\narXiv\n:\n2206.10789\n^\nKariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Mathé, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023).\n\"Precision information extraction for rare disease epidemiology at scale\"\n.\nJournal of Translational Medicine\n.\n21\n(1): 157.\ndoi\n:\n10.1186/s12967-023-04011-y\n.\nPMC\n9972634\n.\nPMID\n36855134\n.\nFurther reading\n[\nedit\n]\nAlexander Rush,\nThe Annotated transformer\nArchived\n2021-09-22 at the\nWayback Machine\n, Harvard NLP group, 3 April 2018\nPhuong, Mary; Hutter, Marcus (2022). \"Formal Algorithms for Transformers\".\narXiv\n:\n2207.09238\n[\ncs.LG\n].\nFerrando, Javier; Sarti, Gabriele; Bisazza, Arianna; Costa-jussà, Marta R. (2024-05-01). \"A Primer on the Inner Workings of Transformer-based Language Models\".\narXiv\n:\n2405.00208\n[\ncs.CL\n].\nLeech, Gavin (2024-11-06).\n\"Transformer++\"\n.\nargmin gravitas\n. Archived from\nthe original\non 2025-02-26\n. Retrieved\n2025-05-08\n.\nKitamura, Felipe; Moreno Júdice de Mattos Farina, Eduardo; Pedro Mazuco, João; Moy, Linda; M. Prevedello, Luciano (2025-08-25).\n\"Texts Are More than Notes, They Are Data: A Glimpse into How Machines Understand Text\"\n.\nRadiology\n.\n316\n(2) e243217.\ndoi\n:\n10.1148/radiol.243217\n.\nPMID\n40892454\n.\nv\nt\ne\nGoogle AI\nGoogle\nGoogle Brain\nGoogle DeepMind\nComputer\nprograms\nAlphaGo\nVersions\nAlphaGo\n(2015)\nMaster\n(2016)\nAlphaGo Zero\n(2017)\nAlphaZero\n(2017)\nMuZero\n(2019)\nCompetitions\nFan Hui\n(2015)\nLee Sedol\n(2016)\nKe Jie\n(2017)\nIn popular culture\nAlphaGo\n(2017)\nThe MANIAC\n(2023)\nOther\nAlphaFold\n(2018)\nAlphaStar\n(2019)\nAlphaDev\n(2023)\nAlphaGeometry\n(2024)\nAlphaGenome\n(2025)\nMachine\nlearning\nNeural networks\nInception\n(2014)\nWaveNet\n(2016)\nMobileNet\n(2017)\nTransformer\n(2017)\nEfficientNet\n(2019)\nGato\n(2022)\nOther\nQuantum Artificial Intelligence Lab\nTensorFlow\nTensor Processing Unit\nGenerative\nAI\nChatbots\nAssistant\n(2016)\nSparrow\n(2022)\nGemini\n(2023)\nNano Banana\n(2025)\nModels\nBERT\n(2018)\nXLNet\n(2019)\nT5\n(2019)\nLaMDA\n(2021)\nChinchilla\n(2022)\nPaLM\n(2022)\nImagen\n(2023)\nGemini\n(2023)\nVideoPoet\n(2024)\nGemma\n(2024)\nVeo\n(2024)\nOther\nDreamBooth\n(2022)\nNotebookLM\n(2023)\nVids\n(2024)\nGemini Robotics\n(2025)\nAntigravity\n(2025)\nSee also\n\"\nAttention Is All You Need\n\"\nFuture of Go Summit\nGenerative pre-trained transformer\nGoogle Labs\nGoogle Pixel\nGoogle Workspace\nRobot Constitution\nCategory\nCommons\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Transformer_(deep_learning)&oldid=1327414157\n\"\nCategories\n:\nGoogle software\nNeural network architectures\n2017 in artificial intelligence\nHidden categories:\nArticles with short description\nShort description is different from Wikidata\nWebarchive template wayback links\nThis page was last edited on 14 December 2025, at 06:23\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nTransformer (deep learning)\n30 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:25:57.485167",
      "status": "success",
      "content_length": 99935,
      "topic": "deep_learning"
    },
    {
      "title": "Convolutional neural network - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Convolutional_neural_network",
      "content": "Convolutional neural network - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nArchitecture\nToggle Architecture subsection\n1.1\nConvolutional layers\n1.2\nPooling layers\n1.3\nFully connected layers\n1.4\nReceptive field\n1.5\nWeights\n1.6\nDeconvolutional\n2\nHistory\nToggle History subsection\n2.1\nReceptive fields in the visual cortex\n2.2\nFukushima's analog threshold elements in a vision model\n2.3\nNeocognitron, origin of the trainable CNN architecture\n2.4\nConvolution in time\n2.5\nTime delay neural networks\n2.6\nImage recognition with CNNs trained by gradient descent\n2.6.1\nMax pooling\n2.6.2\nLeNet-5\n2.7\nShift-invariant neural network\n2.8\nGPU implementations\n3\nDistinguishing features\n4\nBuilding blocks\nToggle Building blocks subsection\n4.1\nConvolutional layer\n4.1.1\nLocal connectivity\n4.1.2\nSpatial arrangement\n4.1.3\nParameter sharing\n4.2\nPooling layer\n4.2.1\nChannel max pooling\n4.3\nReLU layer\n4.4\nFully connected layer\n4.5\nLoss layer\n5\nHyperparameters\nToggle Hyperparameters subsection\n5.1\nPadding\n5.2\nStride\n5.3\nNumber of filters\n5.4\nFilter (or kernel) size\n5.5\nPooling type and size\n5.6\nDilation\n6\nTranslation equivariance and aliasing\n7\nEvaluation\n8\nRegularization methods\nToggle Regularization methods subsection\n8.1\nEmpirical\n8.1.1\nDropout\n8.1.2\nDropConnect\n8.1.3\nStochastic pooling\n8.1.4\nArtificial data\n8.2\nExplicit\n8.2.1\nEarly stopping\n8.2.2\nNumber of parameters\n8.2.3\nWeight decay\n8.2.4\nMax norm constraints\n9\nHierarchical coordinate frames\n10\nApplications\nToggle Applications subsection\n10.1\nImage recognition\n10.2\nVideo analysis\n10.3\nNatural language processing\n10.4\nAnomaly detection\n10.5\nDrug discovery\n10.6\nCheckers game\n10.7\nGo\n10.8\nTime series forecasting\n10.9\nCultural heritage and 3D-datasets\n11\nFine-tuning\n12\nHuman interpretable explanations\n13\nRelated architectures\nToggle Related architectures subsection\n13.1\nDeep Q-networks\n13.2\nDeep belief networks\n13.3\nNeural abstraction pyramid\n14\nNotable libraries\n15\nSee also\n16\nNotes\n17\nReferences\n18\nExternal links\nToggle the table of contents\nConvolutional neural network\n30 languages\nالعربية\nتۆرکجه\nCatalà\nDeutsch\nEesti\nEspañol\nEuskara\nفارسی\nFrançais\nGalego\n한국어\nहिन्दी\nBahasa Indonesia\nItaliano\nעברית\nLietuvių\n日本語\nPolski\nPortuguês\nRuna Simi\nРусский\nSimple English\nСрпски / srpski\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n吴语\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nType of artificial neural network\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nA\nconvolutional neural network\n(\nCNN\n) is a type of\nfeedforward neural network\nthat learns\nfeatures\nvia filter (or\nkernel\n) optimization. This type of\ndeep learning\nnetwork has been applied to process and make\npredictions\nfrom many different types of data including text, images and audio.\n[\n1\n]\nCNNs are the de-facto standard in deep learning-based approaches to\ncomputer vision\n[\n2\n]\nand\nimage processing\n, and have only recently been replaced—in some cases—by newer deep learning architectures such as the\ntransformer\n.\nVanishing gradients\nand exploding gradients, seen during\nbackpropagation\nin earlier neural networks, are prevented by the\nregularization\nthat comes from using shared weights over fewer connections.\n[\n3\n]\n[\n4\n]\nFor example, for\neach\nneuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded\nconvolution\n(or cross-correlation) kernels,\n[\n5\n]\n[\n6\n]\nonly 25 weights for each convolutional layer are required to process 5x5-sized tiles.\n[\n7\n]\n[\n8\n]\nHigher-layer features are extracted from wider context windows, compared to lower-layer features.\nSome applications of CNNs include:\nimage and video recognition\n,\n[\n9\n]\nrecommender systems\n,\n[\n10\n]\nimage classification\n,\nimage segmentation\n,\nmedical image analysis\n,\nnatural language processing\n,\n[\n11\n]\nbrain–computer interfaces\n,\n[\n12\n]\nand\nfinancial\ntime series\n.\n[\n13\n]\nCNNs are also known as\nshift invariant\nor\nspace invariant artificial neural networks\n, based on the shared-weight architecture of the\nconvolution\nkernels or filters that slide along input features and provide translation-\nequivariant\nresponses known as feature maps.\n[\n14\n]\n[\n15\n]\nCounter-intuitively, most convolutional neural networks are not\ninvariant to translation\n, due to the downsampling operation they apply to the input.\n[\n16\n]\nFeedforward neural networks\nare usually fully connected networks, that is, each neuron in one\nlayer\nis connected to all neurons in the next\nlayer\n. The \"full connectivity\" of these networks makes them prone to\noverfitting\ndata. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\n[\n17\n]\nConvolutional networks were\ninspired\nby\nbiological\nprocesses\n[\n18\n]\n[\n19\n]\n[\n20\n]\n[\n21\n]\nin that the connectivity pattern between\nneurons\nresembles the organization of the animal\nvisual cortex\n. Individual\ncortical neurons\nrespond to stimuli only in a restricted region of the\nvisual field\nknown as the\nreceptive field\n. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\nCNNs use relatively little pre-processing compared to other\nimage classification algorithms\n. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are\nhand-engineered\n. This simplifies and automates the process, enhancing efficiency and scalability overcoming human-intervention bottlenecks.\nArchitecture\n[\nedit\n]\nMain article:\nLayer (deep learning)\nComparison of the\nLeNet\n(1995) and\nAlexNet\n(2012) convolution, pooling and dense layers\nA convolutional neural network consists of an input layer,\nhidden layers\nand an output layer. In a convolutional neural network, the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a\ndot product\nof the convolution kernel with the layer's input matrix. This product is usually the\nFrobenius inner product\n, and its activation function is commonly\nReLU\n. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as\npooling layers\n, fully connected layers, and normalization layers.\nHere it should be noted how close a convolutional neural network is to a\nmatched filter\n.\n[\n22\n]\nConvolutional layers\n[\nedit\n]\nIn a CNN, the input is a\ntensor\nwith shape:\n(number of inputs) × (input height) × (input width) × (input\nchannels\n)\nAfter passing through a convolutional layer, the image becomes abstracted to a feature map, also called an activation map, with shape:\n(number of inputs) × (feature map height) × (feature map width) × (feature map\nchannels\n).\nConvolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus.\n[\n23\n]\nEach convolutional neuron processes data only for its\nreceptive field\n.\n1D convolutional neural network feed forward example\nAlthough\nfully connected feedforward neural networks\ncan be used to learn features and classify data, this architecture is generally impractical for larger inputs (e.g., high-resolution images), which would require massive numbers of neurons because each pixel is a relevant input feature. A fully connected layer for an image of size 100 × 100 has 10,000 weights for\neach\nneuron in the second layer. Convolution reduces the number of free parameters, allowing the network to be deeper.\n[\n7\n]\nFor example, using a 5 × 5 tiling region, each with the same shared weights, requires only 25 neurons. Using shared weights means there are many fewer parameters, which helps avoid the vanishing gradients and exploding gradients problems seen during\nbackpropagation\nin earlier neural networks.\n[\n3\n]\n[\n4\n]\nTo speed processing, standard convolutional layers can be replaced by depthwise separable convolutional layers,\n[\n24\n]\nwhich are based on a depthwise convolution followed by a pointwise convolution. The\ndepthwise convolution\nis a spatial convolution applied independently over each channel of the input tensor, while the\npointwise convolution\nis a standard convolution restricted to the use of\n1\n×\n1\n{\\displaystyle 1\\times 1}\nkernels.\nPooling layers\n[\nedit\n]\nConvolutional networks may include local and/or global pooling layers along with traditional convolutional layers. Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, tiling sizes such as 2 × 2 are commonly used. Global pooling acts on all the neurons of the feature map.\n[\n25\n]\n[\n26\n]\nThere are two common types of pooling in popular use: max and average.\nMax pooling\nuses the maximum value of each local cluster of neurons in the feature map,\n[\n27\n]\n[\n28\n]\nwhile\naverage pooling\ntakes the average value.\nFully connected layers\n[\nedit\n]\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is the same as a traditional\nmultilayer perceptron\nneural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.\nReceptive field\n[\nedit\n]\nIn neural networks, each neuron receives input from some number of locations in the previous layer. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron's\nreceptive field\n. Typically the area is a square (e.g. 5 by 5 neurons). Whereas, in a fully connected layer, the receptive field is the\nentire previous layer\n. Thus, in each convolutional layer, each neuron takes input from a larger area in the input than previous layers. This is due to applying the convolution over and over, which takes the value of a pixel into account, as well as its surrounding pixels. When using dilated layers, the number of pixels in the receptive field remains constant, but the field is more sparsely populated as its dimensions grow when combining the effect of several layers.\nTo manipulate the receptive field size as desired, there are some alternatives to the standard convolutional layer. For example, atrous or dilated convolution\n[\n29\n]\n[\n30\n]\nexpands the receptive field size without increasing the number of parameters by interleaving visible and blind regions. Moreover, a single dilated convolutional layer can comprise filters with multiple dilation ratios,\n[\n31\n]\nthus having a variable receptive field size.\nWeights\n[\nedit\n]\nEach neuron in a neural network computes an output value by applying a specific function to the input values received from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning consists of iteratively adjusting these biases and weights.\nThe vectors of weights and biases are called\nfilters\nand represent particular\nfeatures\nof the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces the\nmemory footprint\nbecause a single bias and a single vector of weights are used across all receptive fields that share that filter, as opposed to each receptive field having its own bias and vector weighting.\n[\n32\n]\nDeconvolutional\n[\nedit\n]\nA deconvolutional neural network is essentially the reverse of a CNN. It consists of deconvolutional layers and unpooling layers.\n[\n33\n]\nA deconvolutional layer is the transpose of a convolutional layer. Specifically, a convolutional layer can be written as a multiplication with a matrix, and a deconvolutional layer is multiplication with the transpose of that matrix.\n[\n34\n]\nAn unpooling layer expands the layer. The max-unpooling layer is the simplest, as it simply copies each entry multiple times. For example, a 2-by-2 max-unpooling layer is\n[\nx\n]\n↦\n[\nx\nx\nx\nx\n]\n{\\displaystyle [x]\\mapsto {\\begin{bmatrix}x&x\\\\x&x\\end{bmatrix}}}\n.\nDeconvolution layers are used in image generators. By default, it creates periodic checkerboard artifact, which can be fixed by upscale-then-convolve.\n[\n35\n]\nHistory\n[\nedit\n]\nCNN are often compared to the way the brain achieves vision processing in living\norganisms\n.\n[\n36\n]\nReceptive fields in the visual cortex\n[\nedit\n]\nMain article:\nSurround suppression\nWork by\nHubel\nand\nWiesel\nin the 1950s and 1960s showed that cat\nvisual cortices\ncontain neurons that individually respond to small regions of the\nvisual field\n. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its\nreceptive field\n.\n[\n37\n]\nNeighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space.\n[\ncitation needed\n]\nThe cortex in each hemisphere represents the contralateral\nvisual field\n.\n[\ncitation needed\n]\nTheir 1968 paper identified two basic visual cell types in the brain:\n[\n19\n]\nsimple cells\n, whose output is maximized by straight edges having particular orientations within their receptive field\ncomplex cells\n, which have larger\nreceptive fields\n, whose output is insensitive to the exact position of the edges in the field.\nHubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.\n[\n38\n]\n[\n37\n]\nFukushima's analog threshold elements in a vision model\n[\nedit\n]\nIn 1969,\nKunihiko Fukushima\nintroduced a multilayer visual feature detection network, inspired by the above-mentioned work of Hubel and Wiesel, in which \"All the elements in one layer have the same set of interconnecting coefficients; the arrangement of the elements and their interconnections are all homogeneous over a given layer.\"  This is the essential core of a convolutional network, but the weights were not trained.  In the same paper, Fukushima also introduced the\nReLU\n(rectified linear unit)\nactivation function\n.\n[\n39\n]\n[\n40\n]\nNeocognitron, origin of the trainable CNN architecture\n[\nedit\n]\nThe \"\nneocognitron\n\"\n[\n18\n]\nwas introduced by Fukushima in 1980.\n[\n20\n]\n[\n28\n]\n[\n41\n]\nThe neocognitron introduced the two basic types of layers:\n\"S-layer\": a shared-weights receptive-field layer, later known as a convolutional layer, which contains units whose receptive fields cover a patch of the previous layer. A shared-weights receptive-field group (a \"plane\" in neocognitron terminology) is often called a filter, and a layer typically has several such filters.\n\"C-layer\": a downsampling layer that contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes a weighted average of the activations of the units in its patch, and applies inhibition (divisive normalization) pooled from a somewhat larger patch and across different filters in a layer, and applies a saturating activation function. The patch weights are nonnegative and are not trainable in the original neocognitron. The downsampling and competitive inhibition help to classify features and objects in visual scenes even when the objects are shifted.\nSeveral\nsupervised\nand\nunsupervised learning\nalgorithms have been proposed over the decades to train the weights of a neocognitron.\n[\n18\n]\nToday, however, the CNN architecture is usually trained through\nbackpropagation\n.\nFukushima's ReLU activation function was not used in his neocognitron since all the weights were nonnegative; lateral inhibition was used instead. The rectifier has become a very popular activation function for CNNs and\ndeep neural networks\nin general.\n[\n42\n]\nConvolution in time\n[\nedit\n]\nThe term \"convolution\" first appears in neural networks in a paper by Toshiteru Homma, Les Atlas, and Robert Marks II at the first\nConference on Neural Information Processing Systems\nin 1987. Their paper replaced multiplication with convolution in time, inherently providing shift invariance, motivated by and connecting more directly to the\nsignal-processing concept of a filter\n, and demonstrated it on a speech recognition task.\n[\n8\n]\nThey also pointed out that as a data-trainable system, convolution is essentially equivalent to correlation since reversal of the weights does not affect the final learned function (\"For convenience, we denote * as correlation instead of convolution. Note that convolving a(t) with b(t) is equivalent to correlating a(-t) with b(t).\").\n[\n8\n]\nModern CNN implementations typically do correlation and call it convolution, for convenience, as they did here.\nTime delay neural networks\n[\nedit\n]\nThe\ntime delay neural network\n(TDNN) was introduced in 1987 by\nAlex Waibel\net al. for phoneme recognition and was an early convolutional network exhibiting shift-invariance.\n[\n43\n]\nA TDNN is a 1-D convolutional neural net where the convolution is performed along the time axis of the data. It is the first CNN utilizing weight sharing in combination with a training by gradient descent, using\nbackpropagation\n.\n[\n44\n]\nThus, while also using a pyramidal structure as in the neocognitron, it performed a global optimization of the weights instead of a local one.\n[\n43\n]\nTDNNs are convolutional networks that share weights along the temporal dimension.\n[\n45\n]\nThey allow speech signals to be processed time-invariantly. In 1990 Hampshire and Waibel introduced a variant that performs a two-dimensional convolution.\n[\n46\n]\nSince these TDNNs operated on spectrograms, the resulting phoneme recognition system was invariant to both time and frequency shifts, as with images processed by a neocognitron.\nTDNNs improved the performance of far-distance speech recognition.\n[\n47\n]\nImage recognition with CNNs trained by gradient descent\n[\nedit\n]\nDenker et al. (1989) designed a 2-D CNN system to recognize hand-written\nZIP Code\nnumbers.\n[\n48\n]\nHowever, the lack of an efficient training method to determine the\nkernel\ncoefficients of the involved convolutions meant that all the coefficients had to be laboriously hand-designed.\n[\n49\n]\nFollowing the advances in the training of 1-D CNNs by Waibel et al. (1987),\nYann LeCun\net al. (1989)\n[\n49\n]\nused back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types. \nWei Zhang et al. (1988)\n[\n14\n]\n[\n15\n]\nused back-propagation to train the convolution kernels of a CNN for alphabets recognition. The model was called shift-invariant pattern recognition neural network before the name CNN was coined later in the early 1990s. Wei Zhang et al. also applied the same CNN without the last fully connected layer for medical image object segmentation (1991)\n[\n50\n]\nand breast cancer detection in mammograms (1994).\n[\n51\n]\nThis approach became a foundation of modern\ncomputer vision\n.\nMax pooling\n[\nedit\n]\nIn 1990 Yamaguchi et al. introduced the concept of max pooling, a fixed filtering operation that calculates and propagates the maximum value of a given region. They did so by combining TDNNs with max pooling to realize a speaker-independent isolated word recognition system.\n[\n27\n]\nIn their system they used several TDNNs per word, one for each\nsyllable\n. The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.\nIn a variant of the neocognitron called the\ncresceptron\n, instead of using Fukushima's spatial averaging with inhibition and saturation, J. Weng et al. in 1993 used max pooling, where a downsampling unit computes the maximum of the activations of the units in its patch,\n[\n52\n]\nintroducing this method into the vision field.\nMax pooling is often used in modern CNNs.\n[\n53\n]\nLeNet-5\n[\nedit\n]\nMain article:\nLeNet\nLeNet-5, a pioneering 7-level convolutional network by\nLeCun\net al. in 1995,\n[\n54\n]\nclassifies hand-written numbers on\nchecks\ndigitized in 32×32 pixel images. The ability to process higher-resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.\nIt was superior than other commercial courtesy amount reading systems (as of 1995). The system was integrated in\nNCR\n's check reading systems, and fielded in several American banks since June 1996, reading millions of checks per day.\n[\n55\n]\nShift-invariant neural network\n[\nedit\n]\nA shift-invariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988.\n[\n14\n]\n[\n15\n]\nIt is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer. The model was trained with back-propagation. The training algorithm was further improved in 1991\n[\n56\n]\nto improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation (1991)\n[\n50\n]\nand automatic detection of breast cancer in\nmammograms (1994)\n.\n[\n51\n]\nA different convolution-based design was proposed in 1988\n[\n57\n]\nfor application to decomposition of one-dimensional\nelectromyography\nconvolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.\n[\n58\n]\n[\n59\n]\nGPU implementations\n[\nedit\n]\nAlthough CNNs were invented in the 1980s, their breakthrough in the 2000s required fast implementations on\ngraphics processing units\n(GPUs).\nIn 2004, it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on\nCPU\n.\n[\n60\n]\nIn 2005, another paper also emphasised the value of\nGPGPU\nfor\nmachine learning\n.\n[\n61\n]\nThe first GPU-implementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU.\n[\n62\n]\nIn the same period, GPUs were also used for unsupervised training of\ndeep belief networks\n.\n[\n63\n]\n[\n64\n]\n[\n65\n]\n[\n66\n]\nIn 2010, Dan Ciresan et al. at\nIDSIA\ntrained deep feedforward networks on GPUs.\n[\n67\n]\nIn 2011, they extended this to CNNs, accelerating by 60 compared to training CPU.\n[\n25\n]\nIn 2011, the network won an image recognition contest where they achieved superhuman performance for the first time.\n[\n68\n]\nThen they won more competitions and achieved state of the art on several benchmarks.\n[\n69\n]\n[\n53\n]\n[\n28\n]\nSubsequently,\nAlexNet\n, a similar GPU-based CNN by Alex Krizhevsky et al. won the\nImageNet Large Scale Visual Recognition Challenge\n2012.\n[\n70\n]\nIt was an early catalytic event for the\nAI boom\n.\nCompared to the training of CNNs using\nGPUs\n, not much attention was given to CPU. (Viebke et al 2019) parallelizes CNN by thread- and\nSIMD\n-level parallelism that is available on the\nIntel Xeon Phi\n.\n[\n71\n]\n[\n72\n]\nDistinguishing features\n[\nedit\n]\nIn the past, traditional\nmultilayer perceptron\n(MLP) models were used for image recognition.\n[\nexample needed\n]\nHowever, the full connectivity between nodes caused the\ncurse of dimensionality\n, and was computationally intractable with higher-resolution images. A 1000×1000-pixel image with\nRGB color\nchannels has 3 million weights per fully-connected neuron, which is too high to feasibly process efficiently at scale.\nCNN layers arranged in 3 dimensions\nFor example, in\nCIFAR-10\n, images are only of size 32×32×3 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in the first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200×200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.\nAlso, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores\nlocality of reference\nin data with a grid-topology (such as images), both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by\nspatially local\ninput patterns.\nConvolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a\nvisual cortex\n. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:\n3D volumes of neurons. The layers of a CNN have neurons arranged in\n3 dimensions\n: width, height and depth.\n[\n73\n]\nWhere each neuron inside a convolutional layer is connected to only a small region of the layer before it, called a receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture.\nLocal connectivity: following the concept of receptive fields, CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned \"filters\" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to nonlinear filters that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas.\nShared weights: In CNNs, each filter is replicated across the entire visual field. These replicated units share the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting activation map to be\nequivariant\nunder shifts of the locations of input features in the visual field, i.e. they grant translational\nequivariance\n—given that the layer has a stride of one.\n[\n74\n]\nPooling: In a CNN's\npooling layers\n, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps, the pooling operation grants a degree of local\ntranslational invariance\nto the features contained therein, allowing the CNN to be more robust to variations in their positions.\n[\n16\n]\nTogether, these properties allow CNNs to achieve better generalization on\nvision problems\n. Weight sharing dramatically reduces the number of\nfree parameters\nlearned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.\nBuilding blocks\n[\nedit\n]\nA CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume (e.g. holding the class scores) through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below.\nNeurons of a convolutional layer (blue), connected to their receptive field (red)\nConvolutional layer\n[\nedit\n]\nA worked example of performing a convolution. The convolution has stride 1, zero-padding, with kernel size 3-by-3. The convolution kernel is a\ndiscrete Laplacian operator\n.\nThe convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or\nkernels\n), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is\nconvolved\nacross the width and height of the input volume, computing the\ndot product\nbetween the filter entries and the input, producing a 2-dimensional\nactivation map\nof that filter. As a result, the network learns filters that activate when it detects some specific type of\nfeature\nat some spatial position in the input.\n[\n75\n]\n[\nnb 1\n]\nStacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input. Each entry in an activation map use the same set of parameters that define the filter.\nSelf-supervised learning\nhas been adapted for use in convolutional layers by using sparse patches with a high-mask ratio and a global response normalization layer.\n[\ncitation needed\n]\nLocal connectivity\n[\nedit\n]\nTypical CNN architecture\nWhen dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a\nsparse local connectivity\npattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.\nThe extent of this connectivity is a\nhyperparameter\ncalled the\nreceptive field\nof the neuron. The connections are\nlocal in space\n(along width and height), but always extend along the entire depth of the input volume. Such an architecture ensures that the learned filters produce the strongest response to a spatially local input pattern.\n[\n76\n]\nSpatial arrangement\n[\nedit\n]\nThree\nhyperparameters\ncontrol the size of the output volume of the convolutional layer: the depth,\nstride\n, and padding size:\nThe\ndepth\nof the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example, if the first convolutional layer takes the raw image as input, then different neurons along the depth dimension may activate in the presence of various oriented edges, or blobs of color.\nStride\ncontrols how depth columns around the width and height are allocated. If the stride is 1, then we move the filters one pixel at a time. This leads to heavily\noverlapping\nreceptive fields between the columns, and to large output volumes. For any integer\nS\n>\n0\n,\n{\\textstyle S>0,}\na stride\nS\nmeans that the filter is translated\nS\nunits at a time per output. In practice,\nS\n≥\n3\n{\\textstyle S\\geq 3}\nis rare. A greater stride means smaller overlap of receptive fields and smaller spatial dimensions of the output volume.\n[\n77\n]\nSometimes, it is convenient to pad the input with zeros (or other values, such as the average of the region) on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volume's spatial size. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume, this is commonly referred to as \"same\" padding.\nThree example padding conditions. Replication condition means that the pixel outside is padded with the closest pixel inside. The reflection padding is where the pixel outside is padded with the pixel inside, reflected across the boundary of the image. The circular padding is where the pixel outside wraps around to the other side of the image.\nThe spatial size of the output volume is a function of the input volume size\nW\n{\\displaystyle W}\n, the kernel field size\nK\n{\\displaystyle K}\nof the convolutional layer neurons, the stride\nS\n{\\displaystyle S}\n, and the amount of zero padding\nP\n{\\displaystyle P}\non the border. The number of neurons that \"fit\" in a given volume is then:\nW\n−\nK\n+\n2\nP\nS\n+\n1.\n{\\displaystyle {\\frac {W-K+2P}{S}}+1.}\nIf this number is not an\ninteger\n, then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a\nsymmetric\nway. In general, setting zero padding to be\nP\n=\n(\nK\n−\n1\n)\n/\n2\n{\\textstyle P=(K-1)/2}\nwhen the stride is\nS\n=\n1\n{\\displaystyle S=1}\nensures that the input volume and output volume will have the same size spatially. However, it is not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding.\nParameter sharing\n[\nedit\n]\nA parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on the assumption that if a patch feature is useful to compute at some spatial position, then it should also be useful to compute at other positions. Denoting a single 2-dimensional slice of depth as a\ndepth slice\n, the neurons in each depth slice are constrained to use the same weights and bias.\nSince all neurons in a single depth slice share the same parameters, the forward pass in each depth slice of the convolutional layer can be computed as a\nconvolution\nof the neuron's weights with the input volume.\n[\nnb 2\n]\nTherefore, it is common to refer to the sets of weights as a filter (or a\nkernel\n), which is convolved with the input. The result of this convolution is an\nactivation map\n, and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the\ntranslation invariance\nof the CNN architecture.\n[\n16\n]\nSometimes, the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure; for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image: we might expect different eye-specific or hair-specific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a \"locally connected layer\".\nPooling layer\n[\nedit\n]\nMain article:\nPooling layer\nWorked example of 2x2 maxpooling with stride 2\nMax pooling with a 2x2 filter and stride = 2\nAnother important concept of CNNs is pooling, which is used as a form of non-linear\ndown-sampling\n. Pooling provides downsampling because it reduces the spatial dimensions (height and width) of the input feature maps while retaining the most important information. There are several non-linear functions to implement pooling, where\nmax pooling\nand\naverage pooling\nare the most common. Pooling aggregates information from small regions of the input creating\npartitions\nof the input feature map, typically using a fixed-size window (like 2x2) and applying a stride (often 2) to move the window across the input.\n[\n78\n]\nNote that without using a stride greater than 1, pooling would not perform downsampling, as it would simply move the pooling window across the input one step at a time, without reducing the size of the feature map. In other words, the stride is what actually causes the downsampling by determining how much the pooling window moves over the input.\nIntuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters,\nmemory footprint\nand amount of computation in the network, and hence to also control\noverfitting\n. This is known as down-sampling. It is common to periodically insert a pooling layer between successive convolutional layers (each one typically followed by an activation function, such as a\nReLU layer\n) in a CNN architecture.\n[\n75\n]\n: 460–461\nWhile pooling layers contribute to local translation invariance, they do not provide global translation invariance in a CNN, unless a form of global pooling is used.\n[\n16\n]\n[\n74\n]\nThe pooling layer commonly operates independently on every depth, or slice, of the input and resizes it spatially. A very common form of max pooling is a layer with filters of size 2×2, applied with a stride of 2, which subsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations:\nf\nX\n,\nY\n(\nS\n)\n=\nmax\na\n,\nb\n=\n0\n1\nS\n2\nX\n+\na\n,\n2\nY\n+\nb\n.\n{\\displaystyle f_{X,Y}(S)=\\max _{a,b=0}^{1}S_{2X+a,2Y+b}.}\nIn this case, every\nmax operation\nis over 4 numbers. The depth dimension remains unchanged (this is true for other forms of pooling as well).\nIn addition to max pooling, pooling units can use other functions, such as\naverage\npooling or\nℓ\n2\n-norm\npooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which generally performs better in practice.\n[\n79\n]\nDue to the effects of fast spatial reduction of the size of the representation,\n[\nwhich?\n]\nthere is a recent trend towards using smaller filters\n[\n80\n]\nor discarding pooling layers altogether.\n[\n81\n]\nRoI pooling to size 2x2. In this example region proposal (an input parameter) has size 7x5.\nChannel max pooling\n[\nedit\n]\nA channel max pooling (CMP) operation layer conducts the MP operation along the channel side among the corresponding positions of the consecutive feature maps for the purpose of redundant information elimination. The CMP makes the significant features gather together within fewer channels, which is important for fine-grained image classification that needs more discriminating features. Meanwhile, another advantage of the CMP operation is to make the channel number of feature maps smaller before it connects to the first fully connected (FC) layer. Similar to the MP operation, we denote the input feature maps and output feature maps of a CMP layer as F ∈ R(C×M×N) and C ∈ R(c×M×N), respectively, where C and c are the channel numbers of the input and output feature maps, M and N are the widths and the height of the feature maps, respectively. Note that the CMP operation only changes the channel number of the feature maps. The width and the height of the feature maps are not changed, which is different from the MP operation.\n[\n82\n]\nSee\n[\n83\n]\n[\n84\n]\nfor reviews for pooling methods.\nReLU layer\n[\nedit\n]\nReLU is the abbreviation of\nrectified linear unit\n. It was proposed by\nAlston Householder\nin 1941,\n[\n85\n]\nand used in CNN by\nKunihiko Fukushima\nin 1969.\n[\n39\n]\nReLU applies the non-saturating\nactivation function\nf\n(\nx\n)\n=\nmax\n(\n0\n,\nx\n)\n{\\textstyle f(x)=\\max(0,x)}\n.\n[\n70\n]\nIt effectively removes negative values from an activation map by setting them to zero.\n[\n86\n]\nIt introduces\nnonlinearity\nto the\ndecision function\nand in the overall network without affecting the receptive fields of the convolution layers.\nIn 2011, Xavier Glorot, Antoine Bordes and\nYoshua Bengio\nfound that ReLU enables better training of deeper networks,\n[\n87\n]\ncompared to widely used activation functions prior to 2011.\nOther functions can also be used to increase nonlinearity, for example the saturating\nhyperbolic tangent\nf\n(\nx\n)\n=\ntanh\n⁡\n(\nx\n)\n{\\displaystyle f(x)=\\tanh(x)}\n,\nf\n(\nx\n)\n=\n|\ntanh\n⁡\n(\nx\n)\n|\n{\\displaystyle f(x)=|\\tanh(x)|}\n, and the\nsigmoid function\nσ\n(\nx\n)\n=\n(\n1\n+\ne\n−\nx\n)\n−\n1\n{\\textstyle \\sigma (x)=(1+e^{-x})^{-1}}\n. ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to\ngeneralization\naccuracy.\n[\n88\n]\nFully connected layer\n[\nedit\n]\nAfter several convolutional and max pooling layers, the final classification is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional)\nartificial neural networks\n. Their activations can thus be computed as an\naffine transformation\n, with\nmatrix multiplication\nfollowed by a bias offset (\nvector addition\nof a learned or fixed bias term).\nLoss layer\n[\nedit\n]\nMain articles:\nLoss function\nand\nLoss functions for classification\nThe \"loss layer\", or \"\nloss function\n\", exemplifies how\ntraining\npenalizes the deviation between the predicted output of the network, and the\ntrue\ndata labels (during supervised learning). Various\nloss functions\ncan be used, depending on the specific task.\nThe\nSoftmax\nloss function is used for predicting a single class of\nK\nmutually exclusive classes.\n[\nnb 3\n]\nSigmoid\ncross-entropy\nloss is used for predicting\nK\nindependent probability values in\n[\n0\n,\n1\n]\n{\\displaystyle [0,1]}\n.\nEuclidean\nloss is used for\nregressing\nto\nreal-valued\nlabels\n(\n−\n∞\n,\n∞\n)\n{\\displaystyle (-\\infty ,\\infty )}\n.\nHyperparameters\n[\nedit\n]\nThis section\nneeds additional citations for\nverification\n.\nPlease help\nimprove this article\nby\nadding citations to reliable sources\nin this section. Unsourced material may be challenged and removed.\n(\nJune 2017\n)\n(\nLearn how and when to remove this message\n)\nHyperparameters are various settings that are used to control the learning process. CNNs use more\nhyperparameters\nthan a standard multilayer perceptron (MLP).\nPadding\n[\nedit\n]\nPadding is the addition of (typically) 0-valued pixels on the borders of an image. This is done so that the border pixels are not undervalued (lost) from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example, a convolutional layer using 3x3 kernels would receive a 2-pixel pad, that is 1 pixel on each side of the image.\n[\ncitation needed\n]\nStride\n[\nedit\n]\nThe stride is the number of pixels that the analysis window moves on each iteration. A stride of 2 means that each kernel is offset by 2 pixels from its predecessor.\nNumber of filters\n[\nedit\n]\nSince feature map size decreases with depth, layers near the input layer tend to have fewer filters while higher layers can have more. To equalize computation at each layer, the product of feature values\nv\na\nwith pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next.\nThe number of feature maps directly controls the capacity and depends on the number of available examples and task complexity.\nFilter (or kernel) size\n[\nedit\n]\nCommon filter sizes found in the literature vary greatly, and are usually chosen based on the data set. Typical filter sizes range from 1x1 to 7x7. As two famous examples,\nAlexNet\nused 3x3, 5x5, and 11x11.\nInceptionv3\nused 1x1, 3x3, and 5x5.\nThe challenge is to find the right level of granularity so as to create abstractions at the proper scale, given a particular data set, and without\noverfitting\n.\nPooling type and size\n[\nedit\n]\nMax pooling\nis typically used, often with a 2x2 dimension. This implies that the input is drastically\ndownsampled\n, reducing processing cost.\nGreater pooling\nreduces the dimension\nof the signal, and may result in unacceptable\ninformation loss\n. Often, non-overlapping pooling windows perform best.\n[\n79\n]\nDilation\n[\nedit\n]\nDilation involves ignoring pixels within a kernel. This reduces processing memory potentially without significant signal loss. A dilation of 2 on a 3x3 kernel expands the kernel to 5x5, while still processing 9 (evenly spaced) pixels. Specifically, the processed pixels after the dilation are the cells (1,1), (1,3), (1,5), (3,1), (3,3), (3,5), (5,1), (5,3), (5,5), where (i,j) denotes the cell of the i-th row and j-th column in the expanded 5x5 kernel. Accordingly, dilation of 4 expands the kernel to 7x7.\n[\ncitation needed\n]\nTranslation equivariance and aliasing\n[\nedit\n]\nIt is commonly assumed that CNNs are invariant to shifts of the input. Convolution or pooling layers within a CNN that do not have a stride greater than one are indeed\nequivariant\nto translations of the input.\n[\n74\n]\nHowever, layers with a stride greater than one ignore the\nNyquist–Shannon sampling theorem\nand might lead to\naliasing\nof the input signal\n[\n74\n]\nWhile, in principle, CNNs are capable of implementing anti-aliasing filters, it has been observed that this does not happen in practice,\n[\n89\n]\nand therefore yield models that are not equivariant to translations.\nFurthermore, if a CNN makes use of fully connected layers, translation equivariance does not imply translation invariance, as the fully connected layers are not invariant to shifts of the input.\n[\n90\n]\n[\n16\n]\nOne solution for complete translation invariance is avoiding any down-sampling throughout the network and applying global average pooling at the last layer.\n[\n74\n]\nAdditionally, several other partial solutions have been proposed, such as\nanti-aliasing\nbefore downsampling operations,\n[\n91\n]\nspatial transformer networks,\n[\n92\n]\ndata augmentation\n, subsampling combined with pooling,\n[\n16\n]\nand\ncapsule neural networks\n.\n[\n93\n]\nEvaluation\n[\nedit\n]\nThe accuracy of the final model is typically estimated on a sub-part of the dataset set apart at the start, often called a test set. Alternatively, methods such as\nk\n-fold cross-validation\nare applied. Other strategies include using\nconformal prediction\n.\n[\n94\n]\n[\n95\n]\nRegularization methods\n[\nedit\n]\nMain article:\nRegularization (mathematics)\nThis section\nneeds additional citations for\nverification\n.\nPlease help\nimprove this article\nby\nadding citations to reliable sources\nin this section. Unsourced material may be challenged and removed.\n(\nJune 2017\n)\n(\nLearn how and when to remove this message\n)\nRegularization\nis a process of introducing additional information to solve an\nill-posed problem\nor to prevent\noverfitting\n. CNNs use various types of regularization.\nEmpirical\n[\nedit\n]\nDropout\n[\nedit\n]\nBecause networks have so many parameters, they are prone to overfitting. One method to reduce overfitting is\ndropout\n, introduced in 2014.\n[\n96\n]\nAt each training stage, individual nodes are either \"dropped out\" of the net (ignored) with probability\n1\n−\np\n{\\displaystyle 1-p}\nor kept with probability\np\n{\\displaystyle p}\n, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights.\nIn the training stages,\np\n{\\displaystyle p}\nis usually 0.5; for input nodes, it is typically much higher because information is directly lost when input nodes are ignored.\nAt testing time after training has finished, we would ideally like to find a sample average of all possible\n2\nn\n{\\displaystyle 2^{n}}\ndropped-out networks; unfortunately this is unfeasible for large values of\nn\n{\\displaystyle n}\n. However, we can find an approximation by using the full network with each node's output weighted by a factor of\np\n{\\displaystyle p}\n, so the\nexpected value\nof the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method: although it effectively generates\n2\nn\n{\\displaystyle 2^{n}}\nneural nets, and as such allows for model combination, at test time only a single network needs to be tested.\nBy avoiding training all nodes on all training data, dropout decreases overfitting. The method also significantly improves training speed. This makes the model combination practical, even for\ndeep neural networks\n. The technique seems to reduce node interactions, leading them to learn more robust features\n[\nclarification needed\n]\nthat better generalize to new data.\nDropConnect\n[\nedit\n]\nDropConnect is the generalization of dropout in which each connection, rather than each output unit, can be dropped with probability\n1\n−\np\n{\\displaystyle 1-p}\n. Each unit thus receives input from a random subset of units in the previous layer.\n[\n97\n]\nDropConnect is similar to dropout as it introduces dynamic sparsity within the model, but differs in that the sparsity is on the weights, rather than the output vectors of a layer. In other words, the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.\nStochastic pooling\n[\nedit\n]\nA major drawback to dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected.\nEven before dropout, in 2013 a technique called stochastic pooling,\n[\n98\n]\nthe conventional\ndeterministic\npooling operations were replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a\nmultinomial distribution\n, given by the activities within the pooling region. This approach is free of hyperparameters and can be combined with other regularization approaches, such as dropout and\ndata augmentation\n.\nAn alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local\ndeformations\n. This is similar to explicit\nelastic deformations\nof the input images,\n[\n99\n]\nwhich delivers excellent performance on the\nMNIST data set\n.\n[\n99\n]\nUsing stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.\nArtificial data\n[\nedit\n]\nMain article:\nData augmentation\nBecause the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train, especially considering that some part should be spared for later testing, two approaches are to either generate new data from scratch (if possible) or perturb existing data to create new ones. The latter one is used since mid-1990s.\n[\n54\n]\nFor example, input images can be cropped, rotated, or rescaled to create new examples with the same labels as the original training set.\n[\n100\n]\nExplicit\n[\nedit\n]\nEarly stopping\n[\nedit\n]\nMain article:\nEarly stopping\nOne of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted.\nNumber of parameters\n[\nedit\n]\nAnother simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks, the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and thus limits the amount of overfitting. This is equivalent to a \"\nzero norm\n\".\nWeight decay\n[\nedit\n]\nA simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights (\nL1 norm\n) or squared magnitude (\nL2 norm\n) of the weight vector, to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constant('alpha' hyperparameter), thus increasing the penalty for large weight vectors.\nL2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot.\nL1 regularization is also common. It makes the weight vectors sparse during optimization. In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs. L1 with L2 regularization can be combined; this is called\nelastic net regularization\n.\nMax norm constraints\n[\nedit\n]\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use\nprojected gradient descent\nto enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector\nw\n→\n{\\displaystyle {\\vec {w}}}\nof every neuron to satisfy\n‖\nw\n→\n‖\n2\n<\nc\n{\\displaystyle \\|{\\vec {w}}\\|_{2}<c}\n. Typical values of\nc\n{\\displaystyle c}\nare order of 3–4. Some papers report improvements\n[\n101\n]\nwhen using this form of regularization.\nHierarchical coordinate frames\n[\nedit\n]\nPooling loses the precise spatial relationships between high-level parts (such as nose and mouth in a face image). These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools, helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint, such as a different orientation or scale. On the other hand, people are very good at extrapolating; after seeing a new shape once they can recognize it from a different viewpoint.\n[\n102\n]\nAn earlier common way to deal with this problem is to train the network on transformed data in different orientations, scales, lighting, etc. so that the network can cope with these variations. This is computationally intensive for large data-sets. The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the\nretina\n. The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features' coordinate frame.\n[\n103\n]\nThus, one way to represent something is to embed the coordinate frame within it. This allows large features to be recognized by using the consistency of the poses of their parts (e.g. nose and mouth poses make a consistent prediction of the pose of the whole face). This approach ensures that the higher-level entity (e.g. face) is present when the lower-level (e.g. nose and mouth) agree on its prediction of the pose. The vectors of neuronal activity that represent pose (\"pose vectors\") allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human\nvisual system\nimposes coordinate frames in order to represent shapes.\n[\n104\n]\nApplications\n[\nedit\n]\nImage recognition\n[\nedit\n]\nCNNs are often used in\nimage recognition\nsystems. In 2012, an\nerror rate\nof 0.23% on the\nMNIST database\nwas reported.\n[\n28\n]\nAnother paper on using CNN for image classification reported that the learning process was \"surprisingly fast\"; in the same paper, the best published results as of 2011 were achieved in the MNIST database and the NORB database.\n[\n25\n]\nSubsequently, a similar CNN called\nAlexNet\n[\n105\n]\nwon the\nImageNet Large Scale Visual Recognition Challenge\n2012.\nWhen applied to\nfacial recognition\n, CNNs achieved a large decrease in error rate.\n[\n106\n]\nAnother paper reported a 97.6% recognition rate on \"5,600 still images of more than 10 subjects\".\n[\n21\n]\nCNNs were used to assess\nvideo quality\nin an objective way after manual training; the resulting system had a very low\nroot mean square error\n.\n[\n107\n]\nThe\nImageNet Large Scale Visual Recognition Challenge\nis a benchmark in object classification and detection, with millions of images and hundreds of object classes. In the ILSVRC 2014,\n[\n108\n]\na large-scale visual recognition challenge, almost every highly ranked team used CNN as their basic framework. The winner\nGoogLeNet\n[\n109\n]\n(the foundation of\nDeepDream\n) increased the mean average\nprecision\nof object detection to 0.439329, and reduced classification error to 0.06656, the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans.\n[\n110\n]\nThe best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters, an increasingly common phenomenon with modern digital cameras. By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained categories such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this.\n[\ncitation needed\n]\nIn 2015, a many-layered CNN demonstrated the ability to spot faces from a wide range of angles, including upside down, even when partially occluded, with competitive performance. The network was trained on a database of 200,000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50,000 iterations.\n[\n111\n]\nVideo analysis\n[\nedit\n]\nCompared to image data domains, there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another (temporal) dimension. However, some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space.\n[\n112\n]\n[\n113\n]\nAnother way is to fuse the features of two convolutional neural networks, one for the spatial and one for the temporal stream.\n[\n114\n]\n[\n115\n]\n[\n116\n]\nLong short-term memory\n(LSTM)\nrecurrent\nunits are typically incorporated after the CNN to account for inter-frame or inter-clip dependencies.\n[\n117\n]\n[\n118\n]\nUnsupervised learning\nschemes for training spatio-temporal features have been introduced, based on Convolutional Gated Restricted\nBoltzmann Machines\n[\n119\n]\nand Independent Subspace Analysis.\n[\n120\n]\nIts application can be seen in\ntext-to-video model\n.\n[\ncitation needed\n]\nNatural language processing\n[\nedit\n]\nCNNs have also been explored for\nnatural language processing\n. CNN models are effective for various NLP problems and achieved excellent results in\nsemantic parsing\n,\n[\n121\n]\nsearch query retrieval,\n[\n122\n]\nsentence modeling,\n[\n123\n]\nclassification,\n[\n124\n]\nprediction\n[\n125\n]\nand other traditional NLP tasks.\n[\n126\n]\nCompared to traditional language processing methods such as\nrecurrent neural networks\n, CNNs can represent different contextual realities of language that do not rely on a series-sequence assumption, while RNNs are better suitable when classical time series modeling is required.\n[\n127\n]\n[\n128\n]\n[\n129\n]\n[\n130\n]\nAnomaly detection\n[\nedit\n]\nA CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.\n[\n131\n]\nDrug discovery\n[\nedit\n]\nCNNs have been used in\ndrug discovery\n. Predicting the interaction between molecules and biological\nproteins\ncan identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for\nstructure-based drug design\n.\n[\n132\n]\nThe system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures,\n[\n133\n]\nAtomNet discovers chemical features, such as\naromaticity\n,\nsp\n3\ncarbons\n, and\nhydrogen bonding\n. Subsequently, AtomNet was used to predict novel candidate\nbiomolecules\nfor multiple disease targets, most notably treatments for the\nEbola virus\n[\n134\n]\nand\nmultiple sclerosis\n.\n[\n135\n]\nCheckers game\n[\nedit\n]\nCNNs have been used in the game of\ncheckers\n. From 1999 to 2001,\nFogel\nand Chellapilla published papers showing how a convolutional neural network could learn to play checkers using co-evolution. The learning process did not use prior human professional games, but rather focused on a minimal set of information contained in the checkerboard: the location and type of pieces, and the difference in number of pieces between the two sides. Ultimately, the program (\nBlondie24\n) was tested on 165 games against players and ranked in the highest 0.4%.\n[\n136\n]\n[\n137\n]\nIt also earned a win against the program\nChinook\nat its \"expert\" level of play.\n[\n138\n]\nGo\n[\nedit\n]\nCNNs have been used in\ncomputer Go\n. In December 2014, Clark and\nStorkey\npublished a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform\nGNU Go\nand win some games against\nMonte Carlo tree search\nFuego 1.1 in a fraction of the time it took Fuego to play.\n[\n139\n]\nLater it was announced that a large 12-layer convolutional neural network had correctly predicted the professional move in 55% of positions, equalling the accuracy of a\n6 dan\nhuman player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GNU Go in 97% of games, and matched the performance of the\nMonte Carlo tree search\nprogram Fuego simulating ten thousand playouts (about a million positions) per move.\n[\n140\n]\nA couple of CNNs for choosing moves to try (\"policy network\") and evaluating positions (\"value network\") driving MCTS were used by\nAlphaGo\n, the first to beat the best human player at the time.\n[\n141\n]\nTime series forecasting\n[\nedit\n]\nRecurrent neural networks are generally considered the best neural network architectures for time series forecasting (and sequence modeling in general), but recent studies show that convolutional networks can perform comparably or even better.\n[\n142\n]\n[\n13\n]\nDilated convolutions\n[\n143\n]\nmight enable one-dimensional convolutional neural networks to effectively learn time series dependences.\n[\n144\n]\nConvolutions can be implemented more efficiently than RNN-based solutions, and they do not suffer from vanishing (or exploding) gradients.\n[\n145\n]\nConvolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from.\n[\n146\n]\nCNNs can also be applied to further tasks in time series analysis (e.g., time series classification\n[\n147\n]\nor quantile forecasting\n[\n148\n]\n).\nCultural heritage and 3D-datasets\n[\nedit\n]\nAs archaeological findings such as\nclay tablets\nwith\ncuneiform writing\nare increasingly acquired using\n3D scanners\n, benchmark datasets are becoming available, including\nHeiCuBeDa\n[\n149\n]\nproviding almost 2000 normalized 2-D and 3-D datasets prepared with the\nGigaMesh Software Framework\n.\n[\n150\n]\nSo\ncurvature\n-based measures are used in conjunction with geometric neural networks (GNNs), e.g. for period classification of those clay tablets being among the oldest documents of human history.\n[\n151\n]\n[\n152\n]\nFine-tuning\n[\nedit\n]\nFor many applications, training data is not very available. Convolutional neural networks usually require a large amount of training data in order to avoid\noverfitting\n. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights, this is known as\ntransfer learning\n. Furthermore, this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.\n[\n153\n]\nHuman interpretable explanations\n[\nedit\n]\nEnd-to-end training and prediction are common practice in\ncomputer vision\n. However, human interpretable explanations are required for\ncritical systems\nsuch as\nself-driving cars\n.\n[\n154\n]\nWith recent advances in\nvisual salience\n,\nspatial attention\n, and\ntemporal attention\n, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\n[\n155\n]\n[\n156\n]\nRelated architectures\n[\nedit\n]\nDeep Q-networks\n[\nedit\n]\nA deep Q-network (DQN) is a type of deep learning model that combines a deep neural network with\nQ-learning\n, a form of\nreinforcement learning\n. Unlike earlier reinforcement learning agents, DQNs that utilize CNNs can learn directly from high-dimensional sensory inputs via reinforcement learning.\n[\n157\n]\nPreliminary results were presented in 2014, with an accompanying paper in February 2015.\n[\n158\n]\nThe research described an application to\nAtari 2600\ngaming. Other deep reinforcement learning models preceded it.\n[\n159\n]\nDeep belief networks\n[\nedit\n]\nMain article:\nDeep belief network\nConvolutional deep belief networks\n(CDBN) have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore, they exploit the 2D structure of images, like CNNs do, and make use of pre-training like\ndeep belief networks\n. They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR\n[\n160\n]\nhave been obtained using CDBNs.\n[\n161\n]\nNeural abstraction pyramid\nNeural abstraction pyramid\n[\nedit\n]\nThe feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid\n[\n162\n]\nby lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated, e.g., for semantic segmentation, image reconstruction, and object localization tasks.\nNotable libraries\n[\nedit\n]\nCaffe\n: A library for convolutional neural networks. Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in\nC++\n, and has\nPython\nand\nMATLAB\nwrappers.\nDeeplearning4j\n: Deep learning in\nJava\nand\nScala\non multi-GPU-enabled\nSpark\n. A general-purpose deep learning library for the JVM production stack running on a C++ scientific computing engine. Allows the creation of custom layers. Integrates with Hadoop and Kafka.\nDlib\n: A toolkit for making real world machine learning and data analysis applications in C++.\nMicrosoft Cognitive Toolkit\n: A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes. It supports full-fledged interfaces for training in C++ and Python and with additional support for model inference in\nC#\nand Java.\nTensorFlow\n:\nApache 2.0\n-licensed Theano-like library with support for CPU, GPU, Google's proprietary\ntensor processing unit\n(TPU),\n[\n163\n]\nand mobile devices.\nTheano\n: The reference deep-learning library for Python with an API largely compatible with the popular\nNumPy\nlibrary. Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to\nCUDA\ncode for a fast,\non-the-GPU\nimplementation.\nTorch\n: A\nscientific computing\nframework with wide support for machine learning algorithms, written in\nC\nand\nLua\n.\nSee also\n[\nedit\n]\nAttention (machine learning)\nConvolution\nDeep learning\nNatural-language processing\nNeocognitron\nScale-invariant feature transform\nTime delay neural network\nVision processing unit\nNotes\n[\nedit\n]\n^\nWhen applied to other types of data than image data, such as sound data, \"spatial position\" may variously correspond to different points in the\ntime domain\n,\nfrequency domain\n, or other\nmathematical spaces\n.\n^\nhence the name \"convolutional layer\"\n^\nSo-called\ncategorical data\n.\nReferences\n[\nedit\n]\n^\nLeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (2015-05-28).\n\"Deep learning\"\n.\nNature\n.\n521\n(7553):\n436–\n444.\nBibcode\n:\n2015Natur.521..436L\n.\ndoi\n:\n10.1038/nature14539\n.\nISSN\n1476-4687\n.\nPMID\n26017442\n.\n^\nLeCun, Y.; Boser, B.; Denker, J. S.; Henderson, D.; Howard, R. E.; Hubbard, W.; Jackel, L. D. (December 1989).\n\"Backpropagation Applied to Handwritten Zip Code Recognition\"\n.\nNeural Computation\n.\n1\n(4):\n541–\n551.\ndoi\n:\n10.1162/neco.1989.1.4.541\n.\nISSN\n0899-7667\n.\n^\na\nb\nVenkatesan, Ragav; Li, Baoxin (2017-10-23).\nConvolutional Neural Networks in Visual Computing: A Concise Guide\n. CRC Press.\nISBN\n978-1-351-65032-8\n.\nArchived\nfrom the original on 2023-10-16\n. Retrieved\n2020-12-13\n.\n^\na\nb\nBalas, Valentina E.; Kumar, Raghvendra; Srivastava, Rajshree (2019-11-19).\nRecent Trends and Advances in Artificial Intelligence and Internet of Things\n. Springer Nature.\nISBN\n978-3-030-32644-9\n.\nArchived\nfrom the original on 2023-10-16\n. Retrieved\n2020-12-13\n.\n^\nZhang, Yingjie; Soon, Hong Geok; Ye, Dongsen; Fuh, Jerry Ying Hsi; Zhu, Kunpeng (September 2020). \"Powder-Bed Fusion Process Monitoring by Machine Vision With Hybrid Convolutional Neural Networks\".\nIEEE Transactions on Industrial Informatics\n.\n16\n(9):\n5769–\n5779.\nBibcode\n:\n2020ITII...16.5769Z\n.\ndoi\n:\n10.1109/TII.2019.2956078\n.\nISSN\n1941-0050\n.\nS2CID\n213010088\n.\n^\nChervyakov, N.I.; Lyakhov, P.A.; Deryabin, M.A.; Nagornov, N.N.; Valueva, M.V.; Valuev, G.V. (September 2020).\n\"Residue Number System-Based Solution for Reducing the Hardware Cost of a Convolutional Neural Network\"\n.\nNeurocomputing\n.\n407\n:\n439–\n453.\ndoi\n:\n10.1016/j.neucom.2020.04.018\n.\nS2CID\n219470398\n.\nArchived\nfrom the original on 2023-06-29\n. Retrieved\n2023-08-12\n.\nConvolutional neural networks represent deep learning architectures that are currently used in a wide range of applications, including computer vision, speech recognition, malware dedection, time series analysis in finance, and many others.\n^\na\nb\nAghdam, Hamed Habibi; Heravi, Elnaz Jahani (2017-05-30).\nGuide to convolutional neural networks: a practical application to traffic-sign detection and classification\n. Cham, Switzerland: Springer.\nISBN\n978-3-319-57549-0\n.\nOCLC\n987790957\n.\n^\na\nb\nc\nHomma, Toshiteru; Les Atlas; Robert Marks II (1987).\n\"An Artificial Neural Network for Spatio-Temporal Bipolar Patterns: Application to Phoneme Classification\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n1\n:\n31–\n40.\nArchived\n(PDF)\nfrom the original on 2022-03-31\n. Retrieved\n2022-03-31\n.\nThe notion of convolution or correlation used in the models presented is popular in engineering disciplines and has been applied extensively to designing filters, control systems, etc.\n^\nValueva, M.V.; Nagornov, N.N.; Lyakhov, P.A.; Valuev, G.V.; Chervyakov, N.I. (2020). \"Application of the residue number system to reduce hardware costs of the convolutional neural network implementation\".\nMathematics and Computers in Simulation\n.\n177\n. Elsevier BV:\n232–\n243.\ndoi\n:\n10.1016/j.matcom.2020.04.031\n.\nISSN\n0378-4754\n.\nS2CID\n218955622\n.\nConvolutional neural networks are a promising tool for solving the problem of pattern recognition.\n^\nvan den Oord, Aaron; Dieleman, Sander; Schrauwen, Benjamin (2013-01-01). Burges, C. J. C.; Bottou, L.; Welling, M.; Ghahramani, Z.; Weinberger, K. Q. (eds.).\nDeep content-based music recommendation\n(PDF)\n. Curran Associates, Inc. pp.\n2643–\n2651.\nArchived\n(PDF)\nfrom the original on 2022-03-07\n. Retrieved\n2022-03-31\n.\n^\nCollobert, Ronan; Weston, Jason (2008-01-01). \"A unified architecture for natural language processing\".\nProceedings of the 25th international conference on Machine learning - ICML '08\n. New York, NY, US: ACM. pp.\n160–\n167.\ndoi\n:\n10.1145/1390156.1390177\n.\nISBN\n978-1-60558-205-4\n.\nS2CID\n2617020\n.\n^\nAvilov, Oleksii; Rimbert, Sebastien; Popov, Anton; Bougrain, Laurent (July 2020).\n\"Deep Learning Techniques to Improve Intraoperative Awareness Detection from Electroencephalographic Signals\"\n.\n2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\n(PDF)\n. Vol. 2020. Montreal, QC, Canada: IEEE. pp.\n142–\n145.\ndoi\n:\n10.1109/EMBC44109.2020.9176228\n.\nISBN\n978-1-7281-1990-8\n.\nPMID\n33017950\n.\nS2CID\n221386616\n.\nArchived\n(PDF)\nfrom the original on 2022-05-19\n. Retrieved\n2023-07-21\n.\n^\na\nb\nTsantekidis, Avraam; Passalis, Nikolaos; Tefas, Anastasios; Kanniainen, Juho; Gabbouj, Moncef; Iosifidis, Alexandros (July 2017). \"Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks\".\n2017 IEEE 19th Conference on Business Informatics (CBI)\n. Thessaloniki, Greece: IEEE. pp.\n7–\n12.\ndoi\n:\n10.1109/CBI.2017.23\n.\nISBN\n978-1-5386-3035-8\n.\nS2CID\n4950757\n.\n^\na\nb\nc\nZhang, Wei (1988).\n\"Shift-invariant pattern recognition neural network and its optical architecture\"\n.\nProceedings of Annual Conference of the Japan Society of Applied Physics\n.\nArchived\nfrom the original on 2020-06-23\n. Retrieved\n2020-06-22\n.\n^\na\nb\nc\nZhang, Wei (1990).\n\"Parallel distributed processing model with local space-invariant interconnections and its optical architecture\"\n.\nApplied Optics\n.\n29\n(32):\n4790–\n7.\nBibcode\n:\n1990ApOpt..29.4790Z\n.\ndoi\n:\n10.1364/AO.29.004790\n.\nPMID\n20577468\n.\nArchived\nfrom the original on 2017-02-06\n. Retrieved\n2016-09-22\n.\n^\na\nb\nc\nd\ne\nf\nMouton, Coenraad; Myburgh, Johannes C.; Davel, Marelie H. (2020).\n\"Stride and Translation Invariance in CNNs\"\n. In Gerber, Aurona (ed.).\nArtificial Intelligence Research\n. Communications in Computer and Information Science. Vol. 1342. Cham: Springer International Publishing. pp.\n267–\n281.\narXiv\n:\n2103.10097\n.\ndoi\n:\n10.1007/978-3-030-66151-9_17\n.\nISBN\n978-3-030-66151-9\n.\nS2CID\n232269854\n.\nArchived\nfrom the original on 2021-06-27\n. Retrieved\n2021-03-26\n.\n^\nKurtzman, Thomas (August 20, 2019).\n\"Hidden bias in the DUD-E dataset leads to misleading performance of deep learning in structure-based virtual screening\"\n.\nPLOS ONE\n.\n14\n(8) e0220113.\nBibcode\n:\n2019PLoSO..1420113C\n.\ndoi\n:\n10.1371/journal.pone.0220113\n.\nPMC\n6701836\n.\nPMID\n31430292\n.\n^\na\nb\nc\nFukushima, K. (2007).\n\"Neocognitron\"\n.\nScholarpedia\n.\n2\n(1): 1717.\nBibcode\n:\n2007SchpJ...2.1717F\n.\ndoi\n:\n10.4249/scholarpedia.1717\n.\n^\na\nb\nHubel, D. H.; Wiesel, T. N. (1968-03-01).\n\"Receptive fields and functional architecture of monkey striate cortex\"\n.\nThe Journal of Physiology\n.\n195\n(1):\n215–\n243.\ndoi\n:\n10.1113/jphysiol.1968.sp008455\n.\nISSN\n0022-3751\n.\nPMC\n1557912\n.\nPMID\n4966457\n.\n^\na\nb\nFukushima, Kunihiko (1980).\n\"Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position\"\n(PDF)\n.\nBiological Cybernetics\n.\n36\n(4):\n193–\n202.\ndoi\n:\n10.1007/BF00344251\n.\nPMID\n7370364\n.\nS2CID\n206775608\n.\nArchived\n(PDF)\nfrom the original on 3 June 2014\n. Retrieved\n16 November\n2013\n.\n^\na\nb\nMatusugu, Masakazu; Katsuhiko Mori; Yusuke Mitari; Yuji Kaneda (2003).\n\"Subject independent facial expression recognition with robust face detection using a convolutional neural network\"\n(PDF)\n.\nNeural Networks\n.\n16\n(5):\n555–\n559.\ndoi\n:\n10.1016/S0893-6080(03)00115-1\n.\nPMID\n12850007\n.\nArchived\n(PDF)\nfrom the original on 13 December 2013\n. Retrieved\n17 November\n2013\n.\n^\nConvolutional Neural Networks Demystified: A Matched Filtering Perspective Based Tutorial\nhttps://arxiv.org/abs/2108.11663v3\n^\n\"Convolutional Neural Networks (LeNet) – DeepLearning 0.1 documentation\"\n.\nDeepLearning 0.1\n. LISA Lab. Archived from\nthe original\non 28 December 2017\n. Retrieved\n31 August\n2013\n.\n^\nChollet, François (2017-04-04). \"Xception: Deep Learning with Depthwise Separable Convolutions\".\narXiv\n:\n1610.02357\n[\ncs.CV\n].\n^\na\nb\nc\nCiresan, Dan; Ueli Meier; Jonathan Masci; Luca M. Gambardella; Jurgen Schmidhuber (2011).\n\"Flexible, High Performance Convolutional Neural Networks for Image Classification\"\n(PDF)\n.\nProceedings of the Twenty-Second International Joint Conference on Artificial Intelligence-Volume Volume Two\n.\n2\n:\n1237–\n1242.\nArchived\n(PDF)\nfrom the original on 5 April 2022\n. Retrieved\n17 November\n2013\n.\n^\nKrizhevsky\n, Alex.\n\"ImageNet Classification with Deep Convolutional Neural Networks\"\n(PDF)\n.\nArchived\n(PDF)\nfrom the original on 25 April 2021\n. Retrieved\n17 November\n2013\n.\n^\na\nb\nYamaguchi, Kouichi; Sakamoto, Kenji; Akabane, Toshio; Fujimoto, Yoshiji (November 1990).\nA Neural Network for Speaker-Independent Isolated Word Recognition\n. First International Conference on Spoken Language Processing (ICSLP 90). Kobe, Japan. Archived from\nthe original\non 2021-03-07\n. Retrieved\n2019-09-04\n.\n^\na\nb\nc\nd\nCiresan, Dan; Meier, Ueli; Schmidhuber, Jürgen (June 2012). \"Multi-column deep neural networks for image classification\".\n2012 IEEE Conference on Computer Vision and Pattern Recognition\n. New York, NY:\nInstitute of Electrical and Electronics Engineers\n(IEEE). pp.\n3642–\n3649.\narXiv\n:\n1202.2745\n.\nCiteSeerX\n10.1.1.300.3283\n.\ndoi\n:\n10.1109/CVPR.2012.6248110\n.\nISBN\n978-1-4673-1226-4\n.\nOCLC\n812295155\n.\nS2CID\n2161592\n.\n^\nYu, Fisher; Koltun, Vladlen (2016-04-30). \"Multi-Scale Context Aggregation by Dilated Convolutions\".\narXiv\n:\n1511.07122\n[\ncs.CV\n].\n^\nChen, Liang-Chieh; Papandreou, George; Schroff, Florian; Adam, Hartwig (2017-12-05). \"Rethinking Atrous Convolution for Semantic Image Segmentation\".\narXiv\n:\n1706.05587\n[\ncs.CV\n].\n^\nDuta, Ionut Cosmin; Georgescu, Mariana Iuliana; Ionescu, Radu Tudor (2021-08-16). \"Contextual Convolutional Neural Networks\".\narXiv\n:\n2108.07387\n[\ncs.CV\n].\n^\nLeCun, Yann.\n\"LeNet-5, convolutional neural networks\"\n.\nArchived\nfrom the original on 24 February 2021\n. Retrieved\n16 November\n2013\n.\n^\nZeiler, Matthew D.; Taylor, Graham W.; Fergus, Rob (November 2011).\n\"Adaptive deconvolutional networks for mid and high level feature learning\"\n.\n2011 International Conference on Computer Vision\n. IEEE. pp.\n2018–\n2025.\ndoi\n:\n10.1109/iccv.2011.6126474\n.\nISBN\n978-1-4577-1102-2\n.\n^\nDumoulin, Vincent; Visin, Francesco (2018-01-11),\nA guide to convolution arithmetic for deep learning\n,\narXiv\n:\n1603.07285\n^\nOdena, Augustus; Dumoulin, Vincent; Olah, Chris (2016-10-17).\n\"Deconvolution and Checkerboard Artifacts\"\n.\nDistill\n.\n1\n(10) e3.\ndoi\n:\n10.23915/distill.00003\n.\nISSN\n2476-0757\n.\n^\nvan Dyck, Leonard Elia; Kwitt, Roland; Denzler, Sebastian Jochen; Gruber, Walter Roland (2021).\n\"Comparing Object Recognition in Humans and Deep Convolutional Neural Networks—An Eye Tracking Study\"\n.\nFrontiers in Neuroscience\n.\n15\n750639.\ndoi\n:\n10.3389/fnins.2021.750639\n.\nISSN\n1662-453X\n.\nPMC\n8526843\n.\nPMID\n34690686\n.\n^\na\nb\nHubel, DH; Wiesel, TN (October 1959).\n\"Receptive fields of single neurones in the cat's striate cortex\"\n.\nJ. Physiol\n.\n148\n(3):\n574–\n91.\ndoi\n:\n10.1113/jphysiol.1959.sp006308\n.\nPMC\n1363130\n.\nPMID\n14403679\n.\n^\nDavid H. Hubel and Torsten N. Wiesel (2005).\nBrain and visual perception: the story of a 25-year collaboration\n. Oxford University Press US. p. 106.\nISBN\n978-0-19-517618-6\n.\nArchived\nfrom the original on 2023-10-16\n. Retrieved\n2019-01-18\n.\n^\na\nb\nFukushima, K. (1969). \"Visual feature extraction by a multilayered network of analog threshold elements\".\nIEEE Transactions on Systems Science and Cybernetics\n.\n5\n(4):\n322–\n333.\ndoi\n:\n10.1109/TSSC.1969.300225\n.\n^\nSchmidhuber, Juergen\n(2022). \"Annotated History of Modern AI and Deep Learning\".\narXiv\n:\n2212.11279\n[\ncs.NE\n].\n^\nLeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (2015).\n\"Deep learning\"\n(PDF)\n.\nNature\n.\n521\n(7553):\n436–\n444.\nBibcode\n:\n2015Natur.521..436L\n.\ndoi\n:\n10.1038/nature14539\n.\nPMID\n26017442\n.\nS2CID\n3074096\n.\n^\nRamachandran, Prajit; Barret, Zoph; Quoc, V. Le (October 16, 2017). \"Searching for Activation Functions\".\narXiv\n:\n1710.05941\n[\ncs.NE\n].\n^\na\nb\nWaibel, Alex (18 December 1987).\nPhoneme Recognition Using Time-Delay Neural Networks\n(PDF)\n. Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE). Tokyo, Japan.\n^\nAlexander Waibel\net al.,\nPhoneme Recognition Using Time-Delay Neural Networks\nArchived\n2021-02-25 at the\nWayback Machine\nIEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. - 339 March 1989.\n^\nLeCun, Yann; Bengio, Yoshua (1995).\n\"Convolutional networks for images, speech, and time series\"\n. In Arbib, Michael A. (ed.).\nThe handbook of brain theory and neural networks\n(Second ed.). The MIT press. pp.\n276–\n278.\nArchived\nfrom the original on 2020-07-28\n. Retrieved\n2019-12-03\n.\n^\nJohn B. Hampshire and Alexander Waibel,\nConnectionist Architectures for Multi-Speaker Phoneme Recognition\nArchived\n2022-03-31 at the\nWayback Machine\n,  Advances in Neural Information Processing Systems, 1990, Morgan Kaufmann.\n^\nKo, Tom; Peddinti, Vijayaditya; Povey, Daniel; Seltzer, Michael L.; Khudanpur, Sanjeev (March 2018).\nA Study on Data Augmentation of Reverberant Speech for Robust Speech Recognition\n(PDF)\n. The 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017). New Orleans, LA, US.\nArchived\n(PDF)\nfrom the original on 2018-07-08\n. Retrieved\n2019-09-04\n.\n^\nDenker, J S, Gardner, W R, Graf, H. P, Henderson, D, Howard, R E, Hubbard, W, Jackel, L D, BaIrd, H S, and Guyon (1989)\nNeural network recognizer for hand-written zip code digits\nArchived\n2018-08-04 at the\nWayback Machine\n, AT&T Bell Laboratories\n^\na\nb\nY. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, L. D. Jackel,\nBackpropagation Applied to Handwritten Zip Code Recognition\nArchived\n2020-01-10 at the\nWayback Machine\n; AT&T Bell Laboratories\n^\na\nb\nZhang, Wei (1991).\n\"Image processing of human corneal endothelium based on a learning network\"\n.\nApplied Optics\n.\n30\n(29):\n4211–\n7.\nBibcode\n:\n1991ApOpt..30.4211Z\n.\ndoi\n:\n10.1364/AO.30.004211\n.\nPMID\n20706526\n.\nArchived\nfrom the original on 2017-02-06\n. Retrieved\n2016-09-22\n.\n^\na\nb\nZhang, Wei (1994).\n\"Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network\"\n.\nMedical Physics\n.\n21\n(4):\n517–\n24.\nBibcode\n:\n1994MedPh..21..517Z\n.\ndoi\n:\n10.1118/1.597177\n.\nPMID\n8058017\n.\nArchived\nfrom the original on 2017-02-06\n. Retrieved\n2016-09-22\n.\n^\nWeng, J; Ahuja, N; Huang, TS (1993). \"Learning recognition and segmentation of 3-D objects from 2-D images\".\n1993 (4th) International Conference on Computer Vision\n. IEEE. pp.\n121–\n128.\ndoi\n:\n10.1109/ICCV.1993.378228\n.\nISBN\n0-8186-3870-2\n.\nS2CID\n8619176\n.\n^\na\nb\nSchmidhuber, Jürgen (2015).\n\"Deep Learning\"\n.\nScholarpedia\n.\n10\n(11):\n1527–\n54.\nCiteSeerX\n10.1.1.76.1541\n.\ndoi\n:\n10.1162/neco.2006.18.7.1527\n.\nPMID\n16764513\n.\nS2CID\n2309950\n.\nArchived\nfrom the original on 2016-04-19\n. Retrieved\n2019-01-20\n.\n^\na\nb\nLecun, Y.; Jackel, L. D.; Bottou, L.; Cortes, C.; Denker, J. S.; Drucker, H.; Guyon, I.; Muller, U. A.; Sackinger, E.; Simard, P.; Vapnik, V. (August 1995).\nLearning algorithms for classification: A comparison on handwritten digit recognition\n(PDF)\n. World Scientific. pp.\n261–\n276.\ndoi\n:\n10.1142/2808\n.\nISBN\n978-981-02-2324-3\n.\nArchived\n(PDF)\nfrom the original on 2 May 2023.\n^\nLecun, Y.; Bottou, L.; Bengio, Y.; Haffner, P. (November 1998). \"Gradient-based learning applied to document recognition\".\nProceedings of the IEEE\n.\n86\n(11):\n2278–\n2324.\ndoi\n:\n10.1109/5.726791\n.\n^\nZhang, Wei (1991).\n\"Error Back Propagation with Minimum-Entropy Weights: A Technique for Better Generalization of 2-D Shift-Invariant NNs\"\n.\nProceedings of the International Joint Conference on Neural Networks\n.\nArchived\nfrom the original on 2017-02-06\n. Retrieved\n2016-09-22\n.\n^\nDaniel Graupe, Ruey Wen Liu, George S Moschytz.\"\nApplications of neural networks to medical signal processing\nArchived\n2020-07-28 at the\nWayback Machine\n\". In Proc. 27th IEEE Decision and Control Conf.,  pp. 343–347, 1988.\n^\nDaniel Graupe, Boris Vern, G. Gruener, Aaron Field, and Qiu Huang. \"\nDecomposition of surface EMG signals into single fiber action potentials by means of neural network\nArchived\n2019-09-04 at the\nWayback Machine\n\". Proc. IEEE International Symp. on Circuits and Systems, pp. 1008–1011, 1989.\n^\nQiu Huang, Daniel Graupe, Yi Fang Huang, Ruey Wen Liu.\"\nIdentification of firing patterns of neuronal signals\n[\ndead link\n]\n.\" In Proc. 28th IEEE Decision and Control Conf., pp. 266–271, 1989.\nhttps://ieeexplore.ieee.org/document/70115\nArchived\n2022-03-31 at the\nWayback Machine\n^\nOh, KS; Jung, K (2004). \"GPU implementation of neural networks\".\nPattern Recognition\n.\n37\n(6):\n1311–\n1314.\nBibcode\n:\n2004PatRe..37.1311O\n.\ndoi\n:\n10.1016/j.patcog.2004.01.013\n.\n^\nDave Steinkraus; Patrice Simard; Ian Buck (2005).\n\"Using GPUs for Machine Learning Algorithms\"\n.\n12th International Conference on Document Analysis and Recognition (ICDAR 2005)\n. pp.\n1115–\n1119.\ndoi\n:\n10.1109/ICDAR.2005.251\n.\nArchived\nfrom the original on 2022-03-31\n. Retrieved\n2022-03-31\n.\n^\nKumar Chellapilla; Sid Puri; Patrice Simard (2006).\n\"High Performance Convolutional Neural Networks for Document Processing\"\n. In Lorette, Guy (ed.).\nTenth International Workshop on Frontiers in Handwriting Recognition\n. Suvisoft.\nArchived\nfrom the original on 2020-05-18\n. Retrieved\n2016-03-14\n.\n^\nHinton, GE; Osindero, S; Teh, YW (Jul 2006). \"A fast learning algorithm for deep belief nets\".\nNeural Computation\n.\n18\n(7):\n1527–\n54.\nCiteSeerX\n10.1.1.76.1541\n.\ndoi\n:\n10.1162/neco.2006.18.7.1527\n.\nPMID\n16764513\n.\nS2CID\n2309950\n.\n^\nBengio, Yoshua; Lamblin, Pascal; Popovici, Dan; Larochelle, Hugo (2007).\n\"Greedy Layer-Wise Training of Deep Networks\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n:\n153–\n160.\nArchived\n(PDF)\nfrom the original on 2022-06-02\n. Retrieved\n2022-03-31\n.\n^\nRanzato, MarcAurelio; Poultney, Christopher; Chopra, Sumit; LeCun, Yann (2007).\n\"Efficient Learning of Sparse Representations with an Energy-Based Model\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\nArchived\n(PDF)\nfrom the original on 2016-03-22\n. Retrieved\n2014-06-26\n.\n^\nRaina, R; Madhavan, A; Ng, Andrew (14 June 2009).\n\"Large-scale deep unsupervised learning using graphics processors\"\n(PDF)\n.\nProceedings of the 26th Annual International Conference on Machine Learning\n. ICML '09: Proceedings of the 26th Annual International Conference on Machine Learning. pp.\n873–\n880.\ndoi\n:\n10.1145/1553374.1553486\n.\nISBN\n978-1-60558-516-1\n.\nS2CID\n392458\n.\nArchived\n(PDF)\nfrom the original on 8 December 2020\n. Retrieved\n22 December\n2023\n.\n^\nCiresan, Dan; Meier, Ueli; Gambardella, Luca; Schmidhuber, Jürgen (2010). \"Deep big simple neural nets for handwritten digit recognition\".\nNeural Computation\n.\n22\n(12):\n3207–\n3220.\narXiv\n:\n1003.0358\n.\ndoi\n:\n10.1162/NECO_a_00052\n.\nPMID\n20858131\n.\nS2CID\n1918673\n.\n^\n\"IJCNN 2011 Competition result table\"\n.\nOFFICIAL IJCNN2011 COMPETITION\n. 2010.\nArchived\nfrom the original on 2021-01-17\n. Retrieved\n2019-01-14\n.\n^\nSchmidhuber, Jürgen (17 March 2017).\n\"History of computer vision contests won by deep CNNs on GPU\"\n.\nArchived\nfrom the original on 19 December 2018\n. Retrieved\n14 January\n2019\n.\n^\na\nb\nKrizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E. (2017-05-24).\n\"ImageNet classification with deep convolutional neural networks\"\n(PDF)\n.\nCommunications of the ACM\n.\n60\n(6):\n84–\n90.\ndoi\n:\n10.1145/3065386\n.\nISSN\n0001-0782\n.\nS2CID\n195908774\n.\nArchived\n(PDF)\nfrom the original on 2017-05-16\n. Retrieved\n2018-12-04\n.\n^\nViebke, Andre; Memeti, Suejb; Pllana, Sabri; Abraham, Ajith (2019). \"CHAOS: a parallelization scheme for training convolutional neural networks on Intel Xeon Phi\".\nThe Journal of Supercomputing\n.\n75\n(1):\n197–\n227.\narXiv\n:\n1702.07908\n.\ndoi\n:\n10.1007/s11227-017-1994-x\n.\nS2CID\n14135321\n.\n^\nViebke, Andre; Pllana, Sabri (2015).\n\"The Potential of the Intel (R) Xeon Phi for Supervised Deep Learning\"\n.\n2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems\n.\nIEEE Xplore\n. IEEE 2015. pp.\n758–\n765.\ndoi\n:\n10.1109/HPCC-CSS-ICESS.2015.45\n.\nISBN\n978-1-4799-8937-9\n.\nS2CID\n15411954\n.\nArchived\nfrom the original on 2023-03-06\n. Retrieved\n2022-03-31\n.\n^\nHinton, Geoffrey (2012).\n\"ImageNet Classification with Deep Convolutional Neural Networks\"\n.\nNIPS'12: Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1\n.\n1\n:\n1097–\n1105.\nArchived\nfrom the original on 2019-12-20\n. Retrieved\n2021-03-26\n– via ACM.\n^\na\nb\nc\nd\ne\nAzulay, Aharon; Weiss, Yair (2019).\n\"Why do deep convolutional networks generalize so poorly to small image transformations?\"\n.\nJournal of Machine Learning Research\n.\n20\n(184):\n1–\n25.\nISSN\n1533-7928\n.\nArchived\nfrom the original on 2022-03-31\n. Retrieved\n2022-03-31\n.\n^\na\nb\nGéron, Aurélien (2019).\nHands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow\n. Sebastopol, CA: O'Reilly Media.\nISBN\n978-1-492-03264-9\n.\n, pp. 448\n^\nLi, Zewen; Liu, Fan; Yang, Wenjie; Peng, Shouheng; Zhou, Jun (December 2022). \"A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects\".\nIEEE Transactions on Neural Networks and Learning Systems\n.\n33\n(12):\n6999–\n7019.\narXiv\n:\n2004.02806\n.\nBibcode\n:\n2022ITNNL..33.6999L\n.\ndoi\n:\n10.1109/TNNLS.2021.3084827\n.\nhdl\n:\n10072/405164\n.\nPMID\n34111009\n.\n^\n\"CS231n Convolutional Neural Networks for Visual Recognition\"\n.\ncs231n.github.io\n.\nArchived\nfrom the original on 2019-10-23\n. Retrieved\n2017-04-25\n.\n^\nNirthika, Rajendran; Manivannan, Siyamalan; Ramanan, Amirthalingam; Wang, Ruixuan (2022-04-01).\n\"Pooling in convolutional neural networks for medical image analysis: a survey and an empirical study\"\n.\nNeural Computing and Applications\n.\n34\n(7):\n5321–\n5347.\ndoi\n:\n10.1007/s00521-022-06953-8\n.\nISSN\n1433-3058\n.\nPMC\n8804673\n.\nPMID\n35125669\n.\n^\na\nb\nScherer, Dominik; Müller, Andreas C.; Behnke, Sven (2010).\n\"Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition\"\n(PDF)\n.\nArtificial Neural Networks (ICANN), 20th International Conference on\n. Thessaloniki, Greece: Springer. pp.\n92–\n101.\nArchived\n(PDF)\nfrom the original on 2018-04-03\n. Retrieved\n2016-12-28\n.\n^\nGraham, Benjamin (2014-12-18). \"Fractional Max-Pooling\".\narXiv\n:\n1412.6071\n[\ncs.CV\n].\n^\nSpringenberg, Jost Tobias; Dosovitskiy, Alexey; Brox, Thomas; Riedmiller, Martin (2014-12-21). \"Striving for Simplicity: The All Convolutional Net\".\narXiv\n:\n1412.6806\n[\ncs.LG\n].\n^\nMa, Zhanyu; Chang, Dongliang; Xie, Jiyang; Ding, Yifeng; Wen, Shaoguo; Li, Xiaoxu; Si, Zhongwei; Guo, Jun (2019). \"Fine-Grained Vehicle Classification With Channel Max Pooling Modified CNNs\".\nIEEE Transactions on Vehicular Technology\n.\n68\n(4). Institute of Electrical and Electronics Engineers (IEEE):\n3224–\n3233.\nBibcode\n:\n2019ITVT...68.3224M\n.\ndoi\n:\n10.1109/tvt.2019.2899972\n.\nISSN\n0018-9545\n.\nS2CID\n86674074\n.\n^\nZafar, Afia; Aamir, Muhammad; Mohd Nawi, Nazri; Arshad, Ali; Riaz, Saman; Alruban, Abdulrahman; Dutta, Ashit Kumar; Almotairi, Sultan (2022-08-29).\n\"A Comparison of Pooling Methods for Convolutional Neural Networks\"\n.\nApplied Sciences\n.\n12\n(17): 8643.\ndoi\n:\n10.3390/app12178643\n.\nISSN\n2076-3417\n.\n^\nGholamalinezhad, Hossein; Khosravi, Hossein (2020-09-16),\nPooling Methods in Deep Neural Networks, a Review\n,\narXiv\n:\n2009.07485\n^\nHouseholder, Alston S. (June 1941).\n\"A theory of steady-state activity in nerve-fiber networks: I. Definitions and preliminary lemmas\"\n.\nThe Bulletin of Mathematical Biophysics\n.\n3\n(2):\n63–\n69.\ndoi\n:\n10.1007/BF02478220\n.\nISSN\n0007-4985\n.\n^\nRomanuke, Vadim (2017).\n\"Appropriate number and allocation of ReLUs in convolutional neural networks\"\n.\nResearch Bulletin of NTUU \"Kyiv Polytechnic Institute\"\n.\n1\n(1):\n69–\n78.\ndoi\n:\n10.20535/1810-0546.2017.1.88156\n.\n^\nXavier Glorot; Antoine Bordes;\nYoshua Bengio\n(2011).\nDeep sparse rectifier neural networks\n(PDF)\n. AISTATS. Archived from\nthe original\n(PDF)\non 2016-12-13\n. Retrieved\n2023-04-10\n.\nRectifier and softplus activation functions. The second one is a smooth version of the first.\n^\nKrizhevsky, A.; Sutskever, I.; Hinton, G. E. (2012).\n\"Imagenet classification with deep convolutional neural networks\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n1\n:\n1097–\n1105.\nArchived\n(PDF)\nfrom the original on 2022-03-31\n. Retrieved\n2022-03-31\n.\n^\nRibeiro, Antonio H.; Schön, Thomas B. (2021). \"How Convolutional Neural Networks Deal with Aliasing\".\nICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n. pp.\n2755–\n2759.\narXiv\n:\n2102.07757\n.\ndoi\n:\n10.1109/ICASSP39728.2021.9414627\n.\nISBN\n978-1-7281-7605-5\n.\nS2CID\n231925012\n.\n^\nMyburgh, Johannes C.; Mouton, Coenraad; Davel, Marelie H. (2020).\n\"Tracking Translation Invariance in CNNS\"\n. In Gerber, Aurona (ed.).\nArtificial Intelligence Research\n. Communications in Computer and Information Science. Vol. 1342. Cham: Springer International Publishing. pp.\n282–\n295.\narXiv\n:\n2104.05997\n.\ndoi\n:\n10.1007/978-3-030-66151-9_18\n.\nISBN\n978-3-030-66151-9\n.\nS2CID\n233219976\n.\nArchived\nfrom the original on 2022-01-22\n. Retrieved\n2021-03-26\n.\n^\nRichard, Zhang (2019-04-25).\nMaking Convolutional Networks Shift-Invariant Again\n.\nOCLC\n1106340711\n.\n^\nJadeberg, Max; Simonyan, Karen; Zisserman, Andrew; Kavukcuoglu, Koray (2015).\n\"Spatial Transformer Networks\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n28\n.\nArchived\n(PDF)\nfrom the original on 2021-07-25\n. Retrieved\n2021-03-26\n– via NIPS.\n^\nSabour, Sara; Frosst, Nicholas; Hinton, Geoffrey E. (2017-10-26).\nDynamic Routing Between Capsules\n.\nOCLC\n1106278545\n.\n^\nMatiz, Sergio;\nBarner, Kenneth E.\n(2019-06-01).\n\"Inductive conformal predictor for convolutional neural networks: Applications to active learning for image classification\"\n.\nPattern Recognition\n.\n90\n:\n172–\n182.\nBibcode\n:\n2019PatRe..90..172M\n.\ndoi\n:\n10.1016/j.patcog.2019.01.035\n.\nISSN\n0031-3203\n.\nS2CID\n127253432\n.\nArchived\nfrom the original on 2021-09-29\n. Retrieved\n2021-09-29\n.\n^\nWieslander, Håkan; Harrison, Philip J.; Skogberg, Gabriel; Jackson, Sonya; Fridén, Markus; Karlsson, Johan; Spjuth, Ola; Wählby, Carolina (February 2021).\n\"Deep Learning With Conformal Prediction for Hierarchical Analysis of Large-Scale Whole-Slide Tissue Images\"\n.\nIEEE Journal of Biomedical and Health Informatics\n.\n25\n(2):\n371–\n380.\nBibcode\n:\n2021IJBHI..25..371W\n.\ndoi\n:\n10.1109/JBHI.2020.2996300\n.\nISSN\n2168-2208\n.\nPMID\n32750907\n.\nS2CID\n219885788\n.\n^\nSrivastava, Nitish; C. Geoffrey Hinton; Alex Krizhevsky; Ilya Sutskever; Ruslan Salakhutdinov (2014).\n\"Dropout: A Simple Way to Prevent Neural Networks from overfitting\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n15\n(1):\n1929–\n1958.\nArchived\n(PDF)\nfrom the original on 2016-01-19\n. Retrieved\n2015-01-03\n.\n^\n\"Regularization of Neural Networks using DropConnect | ICML 2013 | JMLR W&CP\"\n.\njmlr.org\n:\n1058–\n1066. 2013-02-13.\nArchived\nfrom the original on 2017-08-12\n. Retrieved\n2015-12-17\n.\n^\nZeiler, Matthew D.; Fergus, Rob (2013-01-15). \"Stochastic Pooling for Regularization of Deep Convolutional Neural Networks\".\narXiv\n:\n1301.3557\n[\ncs.LG\n].\n^\na\nb\nPlatt, John; Steinkraus, Dave; Simard, Patrice Y. (August 2003).\n\"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis – Microsoft Research\"\n.\nMicrosoft Research\n.\nArchived\nfrom the original on 2017-11-07\n. Retrieved\n2015-12-17\n.\n^\nHinton, Geoffrey E.; Srivastava, Nitish; Krizhevsky, Alex; Sutskever, Ilya; Salakhutdinov, Ruslan R. (2012). \"Improving neural networks by preventing co-adaptation of feature detectors\".\narXiv\n:\n1207.0580\n[\ncs.NE\n].\n^\n\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\"\n.\njmlr.org\n.\nArchived\nfrom the original on 2016-03-05\n. Retrieved\n2015-12-17\n.\n^\nHinton, Geoffrey (1979). \"Some demonstrations of the effects of structural descriptions in mental imagery\".\nCognitive Science\n.\n3\n(3):\n231–\n250.\ndoi\n:\n10.1016/s0364-0213(79)80008-7\n.\n^\nRock, Irvin. \"The frame of reference.\" The legacy of Solomon Asch: Essays in cognition and social psychology (1990): 243–268.\n^\nJ. Hinton, Coursera lectures on Neural Networks, 2012, Url:\nhttps://www.coursera.org/learn/neural-networks\nArchived\n2016-12-31 at the\nWayback Machine\n^\nDave Gershgorn (18 June 2018).\n\"The inside story of how AI got good enough to dominate Silicon Valley\"\n.\nQuartz\n.\nArchived\nfrom the original on 12 December 2019\n. Retrieved\n5 October\n2018\n.\n^\nLawrence, Steve; C. Lee Giles; Ah Chung Tsoi; Andrew D. Back (1997). \"Face Recognition: A Convolutional Neural Network Approach\".\nIEEE Transactions on Neural Networks\n.\n8\n(1):\n98–\n113.\nCiteSeerX\n10.1.1.92.5813\n.\ndoi\n:\n10.1109/72.554195\n.\nPMID\n18255614\n.\nS2CID\n2883848\n.\n^\nLe Callet, Patrick; Christian Viard-Gaudin; Dominique Barba (2006).\n\"A Convolutional Neural Network Approach for Objective Video Quality Assessment\"\n(PDF)\n.\nIEEE Transactions on Neural Networks\n.\n17\n(5):\n1316–\n1327.\nBibcode\n:\n2006ITNN...17.1316L\n.\ndoi\n:\n10.1109/TNN.2006.879766\n.\nPMID\n17001990\n.\nS2CID\n221185563\n.\nArchived\n(PDF)\nfrom the original on 24 February 2021\n. Retrieved\n17 November\n2013\n.\n^\n\"ImageNet Large Scale Visual Recognition Competition 2014 (ILSVRC2014)\"\n.\nArchived\nfrom the original on 5 February 2016\n. Retrieved\n30 January\n2016\n.\n^\nSzegedy, Christian; Liu, Wei; Jia, Yangqing; Sermanet, Pierre; Reed, Scott E.; Anguelov, Dragomir; Erhan, Dumitru; Vanhoucke, Vincent; Rabinovich, Andrew (2015). \"Going deeper with convolutions\".\nIEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7–12, 2015\n. IEEE Computer Society. pp.\n1–\n9.\narXiv\n:\n1409.4842\n.\ndoi\n:\n10.1109/CVPR.2015.7298594\n.\nISBN\n978-1-4673-6964-0\n.\n^\nRussakovsky, Olga\n; D",
      "scraped_at": "2025-12-16T17:26:01.344171",
      "status": "success",
      "content_length": 117234,
      "topic": "deep_learning"
    },
    {
      "title": "Recurrent neural network - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Recurrent_neural_network",
      "content": "Recurrent neural network - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\nToggle History subsection\n1.1\nBefore modern\n1.2\nModern\n2\nConfigurations\nToggle Configurations subsection\n2.1\nStandard\n2.2\nStacked RNN\n2.3\nBidirectional\n2.4\nEncoder-decoder\n2.5\nPixelRNN\n3\nArchitectures\nToggle Architectures subsection\n3.1\nFully recurrent\n3.2\nHopfield\n3.3\nElman networks and Jordan networks\n3.4\nLong short-term memory\n3.5\nGated recurrent unit\n3.5.1\nBidirectional associative memory\n3.6\nEcho state\n3.7\nRecursive\n3.8\nNeural Turing machines\n4\nTraining\nToggle Training subsection\n4.1\nTeacher forcing\n4.2\nGradient descent\n4.3\nConnectionist temporal classification\n4.4\nGlobal optimization methods\n5\nOther architectures\nToggle Other architectures subsection\n5.1\nIndependently RNN (IndRNN)\n5.2\nNeural history compressor\n5.3\nSecond order RNNs\n5.4\nHierarchical recurrent neural network\n5.5\nRecurrent multilayer perceptron network\n5.6\nMultiple timescales model\n5.7\nMemristive networks\n5.8\nContinuous-time\n6\nLibraries\n7\nApplications\n8\nReferences\n9\nFurther reading\nToggle the table of contents\nRecurrent neural network\n29 languages\nالعربية\nবাংলা\nCatalà\nČeština\nDeutsch\nEesti\nEspañol\nEuskara\nفارسی\nFrançais\nGalego\n한국어\nItaliano\nМакедонски\n日本語\nPolski\nRuna Simi\nРусский\nSimple English\nSlovenčina\nСрпски / srpski\nSuomi\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n吴语\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nClass of artificial neural network\nNot to be confused with\nRecursive neural network\nor\nFeedback neural network\n.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nIn\nartificial neural networks\n,\nrecurrent neural networks\n(\nRNNs\n) are designed for processing sequential data, such as text, speech, and\ntime series\n,\n[\n1\n]\nwhere the order of elements is important. Unlike\nfeedforward neural networks\n, which process inputs independently, RNNs utilize recurrent connections, where the output of a neuron at one time step is fed back as input to the network at the next time step. This enables RNNs to capture temporal dependencies and patterns within sequences.\nThe fundamental building block of RNN is the\nrecurrent unit\n, which maintains a\nhidden state\n—a form of memory that is updated at each time step based on the current input and the previous hidden state. This feedback mechanism allows the network to learn from past inputs and incorporate that knowledge into its current processing. RNNs have been successfully applied to tasks such as unsegmented, connected\nhandwriting recognition\n,\n[\n2\n]\nspeech recognition\n,\n[\n3\n]\n[\n4\n]\nnatural language processing\n, and\nneural machine translation\n.\n[\n5\n]\n[\n6\n]\nHowever, traditional RNNs suffer from the\nvanishing gradient problem\n, which limits their ability to learn long-range dependencies. This issue was addressed by the development of the\nlong short-term memory\n(LSTM) architecture in 1997, making it the standard RNN variant for handling long-term dependencies. Later,\ngated recurrent units\n(GRUs) were introduced as a more computationally efficient alternative.\nIn recent years,\ntransformers\n, which rely on self-attention mechanisms instead of recurrence, have become the dominant architecture for many sequence-processing tasks, particularly in natural language processing, due to their superior handling of long-range dependencies and greater parallelizability. Nevertheless, RNNs remain relevant for applications where computational efficiency, real-time processing, or the inherent sequential nature of data is crucial.\nHistory\n[\nedit\n]\nBefore modern\n[\nedit\n]\nOne origin of RNN was neuroscience. The word \"recurrent\" is used to describe loop-like structures in\nanatomy\n. In 1901,\nCajal\nobserved \"recurrent semicircles\" in the\ncerebellar cortex\nformed by\nparallel fiber\n,\nPurkinje cells\n, and\ngranule cells\n.\n[\n7\n]\n[\n8\n]\nIn 1933,\nLorente de Nó\ndiscovered \"recurrent, reciprocal connections\" by\nGolgi's method\n, and proposed that excitatory loops explain certain aspects of the\nvestibulo-ocular reflex\n.\n[\n9\n]\n[\n10\n]\nDuring 1940s, multiple people proposed the existence of feedback in the brain, which was a contrast to the previous understanding of the neural system as a purely feedforward structure.\nHebb\nconsidered \"reverberating circuit\" as an explanation for short-term memory.\n[\n11\n]\nThe McCulloch and Pitts paper (1943), which proposed the\nMcCulloch-Pitts neuron\nmodel, considered networks that contains cycles. The current activity of such networks can be affected by activity indefinitely far in the past.\n[\n12\n]\nThey were both interested in closed loops as possible explanations for e.g.\nepilepsy\nand\ncausalgia\n.\n[\n13\n]\n[\n14\n]\nRecurrent inhibition\nwas proposed in 1946 as a negative feedback mechanism in motor control. Neural feedback loops were a common topic of discussion at the\nMacy conferences\n.\n[\n15\n]\nSee\n[\n16\n]\nfor an extensive review of recurrent neural network models in neuroscience.\nA close-loop cross-coupled perceptron network\n[\n17\n]\n: 403, Fig. 47\nFrank Rosenblatt\nin 1960 published \"close-loop cross-coupled perceptrons\", which are 3-layered\nperceptron\nnetworks whose middle layer contains recurrent connections that change by a\nHebbian learning\nrule.\n[\n18\n]\n: 73–75\nLater, in\nPrinciples of Neurodynamics\n(1961), he described \"closed-loop cross-coupled\" and \"back-coupled\" perceptron networks, and made theoretical and experimental studies for Hebbian learning in these networks,\n[\n17\n]\n: Chapter 19, 21\nand noted that a fully cross-coupled perceptron network is equivalent to an infinitely deep feedforward network.\n[\n17\n]\n: Section 19.11\nSimilar networks were published by Kaoru Nakano in 1971,\n[\n19\n]\n[\n20\n]\nShun'ichi Amari\nin 1972,\n[\n21\n]\nand\nWilliam A. Little\n(\nde\n)\nin 1974,\n[\n22\n]\nwho was acknowledged by Hopfield in his 1982 paper.\nAnother origin of RNN was\nstatistical mechanics\n. The\nIsing model\nwas developed by\nWilhelm Lenz\n[\n23\n]\nand\nErnst Ising\n[\n24\n]\nin the 1920s\n[\n25\n]\nas a simple statistical mechanical model of magnets at equilibrium.\nGlauber\nin 1963 studied the Ising model evolving in time, as a process towards equilibrium (\nGlauber dynamics\n), adding in the component of time.\n[\n26\n]\nThe\nSherrington–Kirkpatrick model\nof spin glass, published in 1975,\n[\n27\n]\nis the Hopfield network with random initialization. Sherrington and Kirkpatrick found that it is highly likely for the energy function of the SK model to have many local minima. In the 1982 paper, Hopfield applied this recently developed theory to study the Hopfield network with binary activation functions.\n[\n28\n]\nIn a 1984 paper he extended this to continuous activation functions.\n[\n29\n]\nIt became a standard model for the study of neural networks through statistical mechanics.\n[\n30\n]\n[\n31\n]\nModern\n[\nedit\n]\nModern RNN networks are mainly based on two architectures: LSTM and BRNN.\n[\n32\n]\nAt the resurgence of neural networks in the 1980s, recurrent networks were studied again. They were sometimes called \"iterated nets\".\n[\n33\n]\nTwo early influential works were the\nJordan network\n(1986) and the\nElman network\n(1990), which applied RNN to study\ncognitive psychology\n. In 1993, a neural history compressor system solved a \"Very Deep Learning\" task that required more than 1000 subsequent\nlayers\nin an RNN unfolded in time.\n[\n34\n]\nLong short-term memory\n(LSTM) networks were invented by\nHochreiter\nand\nSchmidhuber\nin 1995 and set accuracy records in multiple applications domains.\n[\n35\n]\n[\n36\n]\nIt became the default choice for RNN architecture.\nBidirectional recurrent neural networks\n(BRNN) use two RNNs that process the same input in opposite directions.\n[\n37\n]\nThese two are often combined, giving the bidirectional LSTM architecture.\nAround 2006, bidirectional LSTM started to revolutionize\nspeech recognition\n, outperforming traditional models in certain speech applications.\n[\n38\n]\n[\n39\n]\nThey also improved large-vocabulary speech recognition\n[\n3\n]\n[\n4\n]\nand\ntext-to-speech\nsynthesis\n[\n40\n]\nand was used in\nGoogle voice search\n, and dictation on\nAndroid devices\n.\n[\n41\n]\nThey broke records for improved\nmachine translation\n,\n[\n42\n]\nlanguage modeling\n[\n43\n]\nand Multilingual Language Processing.\n[\n44\n]\nAlso, LSTM combined with\nconvolutional neural networks\n(CNNs) improved\nautomatic image captioning\n.\n[\n45\n]\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s. The papers most commonly cited as the originators that produced seq2seq are two papers from 2014.\n[\n46\n]\n[\n47\n]\nA\nseq2seq\narchitecture employs two RNN, typically LSTM, an \"encoder\" and a \"decoder\", for sequence transduction, such as machine translation. They became state of the art in machine translation, and was instrumental in the development of\nattention mechanisms\nand\ntransformers\n.\nConfigurations\n[\nedit\n]\nMain article:\nLayer (deep learning)\nAn RNN-based model can be factored into two parts: configuration and architecture. Multiple RNNs can be combined in a data flow, and the data flow itself is the configuration. Each RNN itself may have any architecture, including LSTM, GRU, etc.\nStandard\n[\nedit\n]\nCompressed (left) and unfolded (right) basic recurrent neural network\nRNNs come in many variants. Abstractly speaking, an RNN is a function\nf\nθ\n{\\displaystyle f_{\\theta }}\nof type\n(\nx\nt\n,\nh\nt\n)\n↦\n(\ny\nt\n,\nh\nt\n+\n1\n)\n{\\displaystyle (x_{t},h_{t})\\mapsto (y_{t},h_{t+1})}\n, where\nx\nt\n{\\displaystyle x_{t}}\n: input vector;\nh\nt\n{\\displaystyle h_{t}}\n: hidden vector;\ny\nt\n{\\displaystyle y_{t}}\n: output vector;\nθ\n{\\displaystyle \\theta }\n: neural network parameters.\nIn words, it is a neural network that maps an input\nx\nt\n{\\displaystyle x_{t}}\ninto an output\ny\nt\n{\\displaystyle y_{t}}\n, with the hidden vector\nh\nt\n{\\displaystyle h_{t}}\nplaying the role of \"memory\", a partial record of all previous input-output pairs. At each step, it transforms input to an output, and modifies its \"memory\" to help it to better perform future processing.\nThe illustration to the right may be misleading to many because practical neural network topologies are frequently organized in \"layers\" and the drawing gives that appearance. However, what appears to be\nlayers\nare, in fact, different steps in time, \"unfolded\" to produce the appearance of\nlayers\n.\nStacked RNN\n[\nedit\n]\nStacked RNN\nA\nstacked RNN\n, or\ndeep RNN\n, is composed of multiple RNNs stacked one above the other. Abstractly, it is structured as follows\nLayer 1 has hidden vector\nh\n1\n,\nt\n{\\displaystyle h_{1,t}}\n, parameters\nθ\n1\n{\\displaystyle \\theta _{1}}\n, and maps\nf\nθ\n1\n:\n(\nx\n0\n,\nt\n,\nh\n1\n,\nt\n)\n↦\n(\nx\n1\n,\nt\n,\nh\n1\n,\nt\n+\n1\n)\n{\\displaystyle f_{\\theta _{1}}:(x_{0,t},h_{1,t})\\mapsto (x_{1,t},h_{1,t+1})}\n.\nLayer 2 has hidden vector\nh\n2\n,\nt\n{\\displaystyle h_{2,t}}\n, parameters\nθ\n2\n{\\displaystyle \\theta _{2}}\n, and maps\nf\nθ\n2\n:\n(\nx\n1\n,\nt\n,\nh\n2\n,\nt\n)\n↦\n(\nx\n2\n,\nt\n,\nh\n2\n,\nt\n+\n1\n)\n{\\displaystyle f_{\\theta _{2}}:(x_{1,t},h_{2,t})\\mapsto (x_{2,t},h_{2,t+1})}\n.\n...\nLayer\nn\n{\\displaystyle n}\nhas hidden vector\nh\nn\n,\nt\n{\\displaystyle h_{n,t}}\n, parameters\nθ\nn\n{\\displaystyle \\theta _{n}}\n, and maps\nf\nθ\nn\n:\n(\nx\nn\n−\n1\n,\nt\n,\nh\nn\n,\nt\n)\n↦\n(\nx\nn\n,\nt\n,\nh\nn\n,\nt\n+\n1\n)\n{\\displaystyle f_{\\theta _{n}}:(x_{n-1,t},h_{n,t})\\mapsto (x_{n,t},h_{n,t+1})}\n.\nEach layer operates as a stand-alone RNN, and each layer's output sequence is used as the input sequence to the layer above. There is no conceptual limit to the depth of stacked RNN.\nBidirectional\n[\nedit\n]\nMain article:\nBidirectional recurrent neural networks\nBidirectional RNN\nA\nbidirectional RNN\n(biRNN) is composed of two RNNs, one processing the input sequence in one direction, and another in the opposite direction. Abstractly, it is structured as follows:\nThe forward RNN processes in one direction:\nf\nθ\n(\nx\n0\n,\nh\n0\n)\n=\n(\ny\n0\n,\nh\n1\n)\n,\nf\nθ\n(\nx\n1\n,\nh\n1\n)\n=\n(\ny\n1\n,\nh\n2\n)\n,\n…\n{\\displaystyle f_{\\theta }(x_{0},h_{0})=(y_{0},h_{1}),f_{\\theta }(x_{1},h_{1})=(y_{1},h_{2}),\\dots }\nThe backward RNN processes in the opposite direction:\nf\nθ\n′\n′\n(\nx\nN\n,\nh\nN\n′\n)\n=\n(\ny\nN\n′\n,\nh\nN\n−\n1\n′\n)\n,\nf\nθ\n′\n′\n(\nx\nN\n−\n1\n,\nh\nN\n−\n1\n′\n)\n=\n(\ny\nN\n−\n1\n′\n,\nh\nN\n−\n2\n′\n)\n,\n…\n{\\displaystyle f'_{\\theta '}(x_{N},h_{N}')=(y'_{N},h_{N-1}'),f'_{\\theta '}(x_{N-1},h_{N-1}')=(y'_{N-1},h_{N-2}'),\\dots }\nThe two output sequences are then concatenated to give the total output:\n(\n(\ny\n0\n,\ny\n0\n′\n)\n,\n(\ny\n1\n,\ny\n1\n′\n)\n,\n…\n,\n(\ny\nN\n,\ny\nN\n′\n)\n)\n{\\displaystyle ((y_{0},y_{0}'),(y_{1},y_{1}'),\\dots ,(y_{N},y_{N}'))}\n.\nBidirectional RNN allows the model to process a token both in the context of what came before it and what came after it. By stacking multiple bidirectional RNNs together, the model can process a token increasingly contextually. The\nELMo\nmodel (2018)\n[\n48\n]\nis a stacked bidirectional\nLSTM\nwhich takes character-level as inputs and produces word-level embeddings.\nEncoder-decoder\n[\nedit\n]\nMain article:\nseq2seq\nA decoder without an encoder\nEncoder-decoder RNN without attention mechanism\nEncoder-decoder RNN with attention mechanism\nTwo RNNs can be run front-to-back in an\nencoder-decoder\nconfiguration. The encoder RNN processes an input sequence into a sequence of hidden vectors, and the decoder RNN processes the sequence of hidden vectors to an output sequence, with an optional\nattention mechanism\n. This was used to construct state of the art\nneural machine translators\nduring the 2014–2017 period. This was an instrumental step towards the development of\ntransformers\n.\n[\n49\n]\nPixelRNN\n[\nedit\n]\nAn RNN may process data with more than one dimension. PixelRNN processes two-dimensional data, with many possible directions.\n[\n50\n]\nFor example, the row-by-row direction processes an\nn\n×\nn\n{\\displaystyle n\\times n}\ngrid of vectors\nx\ni\n,\nj\n{\\displaystyle x_{i,j}}\nin the following order:\nx\n1\n,\n1\n,\nx\n1\n,\n2\n,\n…\n,\nx\n1\n,\nn\n,\nx\n2\n,\n1\n,\nx\n2\n,\n2\n,\n…\n,\nx\n2\n,\nn\n,\n…\n,\nx\nn\n,\nn\n{\\displaystyle x_{1,1},x_{1,2},\\dots ,x_{1,n},x_{2,1},x_{2,2},\\dots ,x_{2,n},\\dots ,x_{n,n}}\nThe\ndiagonal BiLSTM\nuses two LSTMs to process the same grid. One processes it from the top-left corner to the bottom-right, such that it processes\nx\ni\n,\nj\n{\\displaystyle x_{i,j}}\ndepending on its hidden state and cell state on the top and the left side:\nh\ni\n−\n1\n,\nj\n,\nc\ni\n−\n1\n,\nj\n{\\displaystyle h_{i-1,j},c_{i-1,j}}\nand\nh\ni\n,\nj\n−\n1\n,\nc\ni\n,\nj\n−\n1\n{\\displaystyle h_{i,j-1},c_{i,j-1}}\n. The other processes it from the top-right corner to the bottom-left.\nArchitectures\n[\nedit\n]\nFully recurrent\n[\nedit\n]\nA fully connected RNN with 4 neurons\nFully recurrent neural networks\n(FRNN) connect the outputs of all neurons to the inputs of all neurons. In other words, it is a\nfully connected network\n. This is the most general neural network topology, because all other topologies can be represented by setting some connection weights to zero to simulate the lack of connections between those neurons.\nA simple Elman network where\nσ\nh\n=\ntanh\n,\nσ\ny\n=\nIdentity\n{\\displaystyle \\sigma _{h}=\\tanh ,\\sigma _{y}={\\text{Identity}}}\nHopfield\n[\nedit\n]\nMain article:\nHopfield network\nThe\nHopfield network\nis an RNN in which all connections across layers are equally sized. It requires\nstationary\ninputs and is thus not a general RNN, as it does not process sequences of patterns. However, it guarantees that it will converge. If the connections are trained using\nHebbian learning\n, then the Hopfield network can perform as\nrobust\ncontent-addressable memory\n, resistant to connection alteration.\nElman networks and Jordan networks\n[\nedit\n]\nThe Elman network\nAn\nElman\nnetwork\nis a three-layer network (arranged horizontally as\nx\n,\ny\n, and\nz\nin the illustration) with the addition of a set of context units (\nu\nin the illustration). The middle (hidden) layer is connected to these context units fixed with a weight of one.\n[\n51\n]\nAt each time step, the input is fed forward and a\nlearning rule\nis applied. The fixed back-connections save a copy of the previous values of the hidden units in the context units (since they propagate over the connections before the learning rule is applied). Thus the network can maintain a sort of state, allowing it to perform tasks such as sequence-prediction that are beyond the power of a standard\nmultilayer perceptron\n.\nJordan\nnetworks\nare similar to Elman networks. The context units are fed from the output layer instead of the hidden layer. The context units in a Jordan network are also called the state layer. They have a recurrent connection to themselves.\n[\n51\n]\nElman and Jordan networks are also known as \"Simple recurrent networks\" (SRN).\nElman network\n[\n52\n]\nh\nt\n=\nσ\nh\n(\nW\nh\nx\nt\n+\nU\nh\nh\nt\n−\n1\n+\nb\nh\n)\ny\nt\n=\nσ\ny\n(\nW\ny\nh\nt\n+\nb\ny\n)\n{\\displaystyle {\\begin{aligned}h_{t}&=\\sigma _{h}(W_{h}x_{t}+U_{h}h_{t-1}+b_{h})\\\\y_{t}&=\\sigma _{y}(W_{y}h_{t}+b_{y})\\end{aligned}}}\nJordan network\n[\n53\n]\nh\nt\n=\nσ\nh\n(\nW\nh\nx\nt\n+\nU\nh\ns\nt\n+\nb\nh\n)\ny\nt\n=\nσ\ny\n(\nW\ny\nh\nt\n+\nb\ny\n)\ns\nt\n=\nσ\ns\n(\nW\ns\n,\ns\ns\nt\n−\n1\n+\nW\ns\n,\ny\ny\nt\n−\n1\n+\nb\ns\n)\n{\\displaystyle {\\begin{aligned}h_{t}&=\\sigma _{h}(W_{h}x_{t}+U_{h}s_{t}+b_{h})\\\\y_{t}&=\\sigma _{y}(W_{y}h_{t}+b_{y})\\\\s_{t}&=\\sigma _{s}(W_{s,s}s_{t-1}+W_{s,y}y_{t-1}+b_{s})\\end{aligned}}}\nVariables and functions\nx\nt\n{\\displaystyle x_{t}}\n: input vector\nh\nt\n{\\displaystyle h_{t}}\n: hidden layer vector\ns\nt\n{\\displaystyle s_{t}}\n: \"state\" vector,\ny\nt\n{\\displaystyle y_{t}}\n: output vector\nW\n{\\displaystyle W}\n,\nU\n{\\displaystyle U}\nand\nb\n{\\displaystyle b}\n: parameter matrices and vector\nσ\n{\\displaystyle \\sigma }\n:\nActivation functions\nLong short-term memory\n[\nedit\n]\nMain article:\nLong short-term memory\nLong short-term memory unit\nLong short-term memory\n(LSTM) is the most widely used RNN architecture. It was designed to solve the\nvanishing gradient problem\n. LSTM is normally augmented by recurrent gates called \"forget gates\".\n[\n54\n]\nLSTM prevents backpropagated errors from vanishing or exploding.\n[\n55\n]\nInstead, errors can flow backward through unlimited numbers of virtual layers unfolded in space. That is, LSTM can learn tasks that require memories of events that happened thousands or even millions of discrete time steps earlier. Problem-specific LSTM-like topologies can be evolved.\n[\n56\n]\nLSTM works even given long delays between significant events and can handle signals that mix low and high-frequency components.\nMany applications use stacks of LSTMs,\n[\n57\n]\nfor which it is called \"deep LSTM\". LSTM can learn to recognize\ncontext-sensitive languages\nunlike previous models based on\nhidden Markov models\n(HMM) and similar concepts.\n[\n58\n]\nGated recurrent unit\n[\nedit\n]\nMain article:\nGated recurrent unit\nGated recurrent unit\nGated recurrent unit\n(GRU), introduced in 2014, was designed as a simplification of LSTM. They are used in the full form and several further simplified variants.\n[\n59\n]\n[\n60\n]\nThey have fewer parameters than LSTM, as they lack an output gate.\n[\n61\n]\nTheir performance on polyphonic music modeling and speech signal modeling was found to be similar to that of long short-term memory.\n[\n62\n]\nThere does not appear to be particular performance difference between LSTM and GRU.\n[\n62\n]\n[\n63\n]\nBidirectional associative memory\n[\nedit\n]\nMain article:\nBidirectional associative memory\nIntroduced by\nBart Kosko\n,\n[\n64\n]\na bidirectional associative memory (BAM) network is a variant of a Hopfield network that stores associative data as a vector. The bidirectionality comes from passing information through a matrix and its\ntranspose\n. Typically,\nbipolar encoding\nis preferred to binary encoding of the associative pairs. Recently, stochastic BAM models using\nMarkov\nstepping are optimized for increased network stability and relevance to real-world applications.\n[\n65\n]\nA BAM network has two layers, either of which can be driven as an input to recall an association and produce an output on the other layer.\n[\n66\n]\nEcho state\n[\nedit\n]\nMain article:\nEcho state network\nEcho state networks\n(ESN) have a sparsely connected random hidden layer. The weights of output neurons are the only part of the network that can change (be trained). ESNs are good at reproducing certain\ntime series\n.\n[\n67\n]\nA variant for\nspiking neurons\nis known as a\nliquid state machine\n.\n[\n68\n]\nRecursive\n[\nedit\n]\nMain article:\nRecursive neural network\nA\nrecursive neural network\n[\n69\n]\nis created by applying the same set of weights\nrecursively\nover a differentiable graph-like structure by traversing the structure in\ntopological order\n. Such networks are typically also trained by the reverse mode of\nautomatic differentiation\n.\n[\n70\n]\n[\n71\n]\nThey can process\ndistributed representations\nof structure, such as\nlogical terms\n. A special case of recursive neural networks is the RNN whose structure corresponds to a linear chain. Recursive neural networks have been applied to\nnatural language processing\n.\n[\n72\n]\nThe\nrecursive neural tensor network\nuses a\ntensor\n-based composition function for all nodes in the tree.\n[\n73\n]\nNeural Turing machines\n[\nedit\n]\nMain articles:\nNeural Turing machine\nand\nDifferentiable neural computer\nNeural Turing machines\n(NTMs) are a method of extending recurrent neural networks by coupling them to external\nmemory\nresources with which they interact. The combined system is analogous to a\nTuring machine\nor\nVon Neumann architecture\nbut is\ndifferentiable\nend-to-end, allowing it to be efficiently trained with\ngradient descent\n.\n[\n74\n]\nDifferentiable neural computers\n(DNCs) are an extension of neural Turing machines, allowing for the usage of fuzzy amounts of each memory address and a record of chronology.\n[\n75\n]\nNeural network pushdown automata\n(NNPDA) are similar to NTMs, but tapes are replaced by analog stacks that are differentiable and trained. In this way, they are similar in complexity to recognizers of\ncontext free grammars\n(CFGs).\n[\n76\n]\nRecurrent neural networks are\nTuring complete\nand can run arbitrary programs to process arbitrary sequences of inputs.\n[\n77\n]\nTraining\n[\nedit\n]\nTeacher forcing\n[\nedit\n]\nEncoder-decoder RNN without attention mechanism. Teacher forcing is shown in red.\nAn RNN can be trained into a conditionally\ngenerative model\nof sequences, aka\nautoregression\n.\nConcretely, let us consider the problem of machine translation, that is, given a sequence\n(\nx\n1\n,\nx\n2\n,\n…\n,\nx\nn\n)\n{\\displaystyle (x_{1},x_{2},\\dots ,x_{n})}\nof English words, the model is to produce a sequence\n(\ny\n1\n,\n…\n,\ny\nm\n)\n{\\displaystyle (y_{1},\\dots ,y_{m})}\nof French words. It is to be solved by a\nseq2seq\nmodel.\nNow, during training, the encoder half of the model would first ingest\n(\nx\n1\n,\nx\n2\n,\n…\n,\nx\nn\n)\n{\\displaystyle (x_{1},x_{2},\\dots ,x_{n})}\n, then the decoder half would start generating a sequence\n(\ny\n^\n1\n,\ny\n^\n2\n,\n…\n,\ny\n^\nl\n)\n{\\displaystyle ({\\hat {y}}_{1},{\\hat {y}}_{2},\\dots ,{\\hat {y}}_{l})}\n. The problem is that if the model makes a mistake early on, say at\ny\n^\n2\n{\\displaystyle {\\hat {y}}_{2}}\n, then subsequent tokens are likely to also be mistakes. This makes it inefficient for the model to obtain a learning signal, since the model would mostly learn to shift\ny\n^\n2\n{\\displaystyle {\\hat {y}}_{2}}\ntowards\ny\n2\n{\\displaystyle y_{2}}\n, but not the others.\nTeacher forcing\nmakes it so that the decoder uses the correct output sequence for generating the next entry in the sequence. So for example, it would see\n(\ny\n1\n,\n…\n,\ny\nk\n)\n{\\displaystyle (y_{1},\\dots ,y_{k})}\nin order to generate\ny\n^\nk\n+\n1\n{\\displaystyle {\\hat {y}}_{k+1}}\n.\nGradient descent\n[\nedit\n]\nMain articles:\nGradient descent\nand\nVanishing gradient problem\nGradient descent is a\nfirst-order\niterative\noptimization\nalgorithm\nfor finding the minimum of a function. In neural networks, it can be used to minimize the error term by changing each weight in proportion to the derivative of the error with respect to that weight, provided the non-linear\nactivation functions\nare\ndifferentiable\n.\nThe standard method for training RNN by gradient descent is the \"\nbackpropagation through time\n\" (BPTT) algorithm, which is a special case of the general algorithm of\nbackpropagation\n. A more computationally expensive online variant is called \"Real-Time Recurrent Learning\" or RTRL,\n[\n78\n]\n[\n79\n]\nwhich is an instance of\nautomatic differentiation\nin the forward accumulation mode with stacked tangent vectors. Unlike BPTT, this algorithm is\nlocal\nin time but not local in space.\nIn this context, local in space means that a unit's weight vector can be updated using only information stored in the connected units and the unit itself such that update complexity of a single unit is linear in the dimensionality of the weight vector. Local in time means that the updates take place continually (on-line) and depend only on the most recent time step rather than on multiple time steps within a given time horizon as in BPTT. Biological neural networks appear to be local with respect to both time and space.\n[\n80\n]\n[\n81\n]\nFor recursively computing the partial derivatives, RTRL has a time-complexity of O(number of hidden x number of weights) per time step for computing the\nJacobian matrices\n, while BPTT only takes O(number of weights) per time step, at the cost of storing all forward activations within the given time horizon.\n[\n82\n]\nAn online hybrid between BPTT and RTRL with intermediate complexity exists,\n[\n83\n]\n[\n84\n]\nalong with variants for continuous time.\n[\n85\n]\nA major problem with gradient descent for standard RNN architectures is that\nerror gradients vanish\nexponentially quickly with the size of the time lag between important events.\n[\n55\n]\n[\n86\n]\nLSTM combined with a BPTT/RTRL hybrid learning method attempts to overcome these problems.\n[\n36\n]\nThis problem is also solved in the independently recurrent neural network (IndRNN)\n[\n87\n]\nby reducing the context of a neuron to its own past state and the cross-neuron information can then be explored in the following layers. Memories of different ranges including long-term memory can be learned without the gradient vanishing and exploding problems.\nThe\nonline algorithm\ncalled\ncausal recursive backpropagation\n(CRBP), implements and combines BPTT and RTRL paradigms for locally recurrent networks.\n[\n88\n]\nIt works with the most general locally recurrent networks. The CRBP algorithm can minimize the global error term. This fact improves the stability of the algorithm, providing a unifying view of gradient calculation techniques for recurrent networks with local feedback.\nOne approach to gradient information computation in RNNs with arbitrary architectures is based on signal-flow graphs diagrammatic derivation.\n[\n89\n]\nIt uses the BPTT batch algorithm, based on Lee's theorem for network sensitivity calculations.\n[\n90\n]\nIt was proposed by Wan and Beaufays, while its fast online version was proposed by Campolucci, Uncini and Piazza.\n[\n90\n]\nConnectionist temporal classification\n[\nedit\n]\nThe\nconnectionist temporal classification\n(CTC)\n[\n91\n]\nis a specialized loss function for training RNNs for sequence modeling problems where the timing is variable.\n[\n92\n]\nGlobal optimization methods\n[\nedit\n]\nTraining the weights in a neural network can be modeled as a non-linear\nglobal optimization\nproblem. A target function can be formed to evaluate the fitness or error of a particular weight vector as follows: First, the weights in the network are set according to the weight vector. Next, the network is evaluated against the training sequence. Typically, the sum-squared difference between the predictions and the target values specified in the training sequence is used to represent the error of the current weight vector. Arbitrary global optimization techniques may then be used to minimize this target function.\nThe most common global optimization method for training RNNs is\ngenetic algorithms\n, especially in unstructured networks.\n[\n93\n]\n[\n94\n]\n[\n95\n]\nInitially, the genetic algorithm is encoded with the neural network weights in a predefined manner where one gene in the\nchromosome\nrepresents one weight link. The whole network is represented as a single chromosome. The fitness function is evaluated as follows:\nEach weight encoded in the chromosome is assigned to the respective weight link of the network.\nThe training set is presented to the network which propagates the input signals forward.\nThe mean-squared error is returned to the fitness function.\nThis function drives the genetic selection process.\nMany chromosomes make up the population; therefore, many different neural networks are evolved until a stopping criterion is satisfied. A common stopping scheme can be:\nWhen the neural network has learned a certain percentage of the training data.\nWhen the minimum value of the mean-squared-error is satisfied.\nWhen the maximum number of training generations has been reached.\nThe fitness function evaluates the stopping criterion as it receives the mean-squared error reciprocal from each network during training. Therefore, the goal of the genetic algorithm is to maximize the fitness function, reducing the mean-squared error.\nOther global (and/or evolutionary) optimization techniques may be used to seek a good set of weights, such as\nsimulated annealing\nor\nparticle swarm optimization\n.\nOther architectures\n[\nedit\n]\nIndependently RNN (IndRNN)\n[\nedit\n]\nThe independently recurrent neural network (IndRNN)\n[\n87\n]\naddresses the gradient vanishing and exploding problems in the traditional fully connected RNN. Each neuron in one layer only receives its own past state as context information (instead of full connectivity to all other neurons in this layer) and thus neurons are independent of each other's history. The gradient backpropagation can be regulated to avoid gradient vanishing and exploding in order to keep long or short-term memory. The cross-neuron information is explored in the next layers. IndRNN can be robustly trained with non-saturated nonlinear functions such as\nReLU\n. Deep networks can be trained using\nskip connections\n.\nNeural history compressor\n[\nedit\n]\nThe\nneural history compressor\nis an unsupervised stack of RNNs.\n[\n96\n]\nAt the input level, it learns to predict its next input from the previous inputs. Only unpredictable inputs of some RNN in the hierarchy become inputs to the next higher level RNN, which therefore recomputes its internal state only rarely. Each higher level RNN thus studies a compressed representation of the information in the RNN below. This is done such that the input sequence can be precisely reconstructed from the representation at the highest level.\nThe system effectively minimizes the description length or the negative\nlogarithm\nof the probability of the data.\n[\n97\n]\nGiven a lot of learnable predictability in the incoming data sequence, the highest level RNN can use supervised learning to easily classify even deep sequences with long intervals between important events.\nIt is possible to distill the RNN hierarchy into two RNNs: the \"conscious\" chunker (higher level) and the \"subconscious\" automatizer (lower level).\n[\n96\n]\nOnce the chunker has learned to predict and compress inputs that are unpredictable by the automatizer, then the automatizer can be forced in the next learning phase to predict or imitate through additional units the hidden units of the more slowly changing chunker. This makes it easy for the automatizer to learn appropriate, rarely changing memories across long intervals. In turn, this helps the automatizer to make many of its once unpredictable inputs predictable, such that the chunker can focus on the remaining unpredictable events.\n[\n96\n]\nA\ngenerative model\npartially overcame the\nvanishing gradient problem\n[\n55\n]\nof\nautomatic differentiation\nor\nbackpropagation\nin neural networks in 1992. In 1993, such a system solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.\n[\n34\n]\nSecond order RNNs\n[\nedit\n]\nSecond-order RNNs use higher order weights\nw\ni\nj\nk\n{\\displaystyle w{}_{ijk}}\ninstead of the standard\nw\ni\nj\n{\\displaystyle w{}_{ij}}\nweights, and states can be a product. This allows a direct mapping to a\nfinite-state machine\nboth in training, and representation.\n[\n98\n]\n[\n99\n]\nLong short-term memory is an example of this but has no such formal mappings or proof of stability.\nHierarchical recurrent neural network\n[\nedit\n]\nHierarchical recurrent neural networks (HRNN) connect their neurons in various ways to decompose hierarchical behavior into useful subprograms.\n[\n96\n]\n[\n100\n]\nSuch hierarchical structures of cognition are present in theories of memory presented by philosopher\nHenri Bergson\n, whose philosophical views have inspired hierarchical models.\n[\n101\n]\nHierarchical recurrent neural networks are useful in\nforecasting\n, helping to predict disaggregated inflation components of the\nconsumer price index\n(CPI). The HRNN model leverages information from higher levels in the CPI hierarchy to enhance lower-level predictions. Evaluation of a substantial dataset from the US CPI-U index demonstrates the superior performance of the HRNN model compared to various established\ninflation\nprediction methods.\n[\n102\n]\nRecurrent multilayer perceptron network\n[\nedit\n]\nGenerally, a recurrent multilayer perceptron network (RMLP network) consists of cascaded subnetworks, each containing multiple layers of nodes. Each subnetwork is feed-forward except for the last layer, which can have feedback connections. Each of these subnets is connected only by feed-forward connections.\n[\n103\n]\nMultiple timescales model\n[\nedit\n]\nA multiple timescales recurrent neural network (MTRNN) is a neural-based computational model that can simulate the functional hierarchy of the brain through self-organization depending on the spatial connection between neurons and on distinct types of neuron activities, each with distinct time properties.\n[\n104\n]\n[\n105\n]\nWith such varied neuronal activities, continuous sequences of any set of behaviors are segmented into reusable primitives, which in turn are flexibly integrated into diverse sequential behaviors. The biological approval of such a type of hierarchy was discussed in the\nmemory-prediction\ntheory of brain function by\nHawkins\nin his book\nOn Intelligence\n.\n[\ncitation needed\n]\nSuch a hierarchy also agrees with theories of memory posited by philosopher\nHenri Bergson\n, which have been incorporated into an MTRNN model.\n[\n101\n]\n[\n106\n]\nMemristive networks\n[\nedit\n]\nGreg Snider of\nHP Labs\ndescribes a system of cortical computing with memristive nanodevices.\n[\n107\n]\nThe\nmemristors\n(memory resistors) are implemented by thin film materials in which the resistance is electrically tuned via the transport of ions or oxygen vacancies within the film.\nDARPA\n's\nSyNAPSE project\nhas funded IBM Research and HP Labs, in collaboration with the Boston University Department of Cognitive and Neural Systems (CNS), to develop neuromorphic architectures that may be based on memristive systems.\nMemristive networks\nare a particular type of\nphysical neural network\nthat have very similar properties to (Little-)Hopfield networks, as they have continuous dynamics, a limited memory capacity and natural relaxation via the minimization of a function which is asymptotic to the\nIsing model\n. In this sense, the dynamics of a memristive circuit have the advantage compared to a Resistor-Capacitor network to have a more interesting non-linear behavior. From this point of view, engineering analog memristive networks account for a peculiar type of\nneuromorphic engineering\nin which the device behavior depends on the circuit wiring or topology.\nThe evolution of these networks can be studied analytically using variations of the\nCaravelli-Traversa-Di Ventra equation\n.\n[\n108\n]\nContinuous-time\n[\nedit\n]\nA continuous-time recurrent neural network (CTRNN) uses a system of\nordinary differential equations\nto model the effects on a neuron of the incoming inputs. They are typically analyzed by\ndynamical systems theory\n. Many RNN models in neuroscience are continuous-time.\n[\n16\n]\nFor a neuron\ni\n{\\displaystyle i}\nin the network with activation\ny\ni\n{\\displaystyle y_{i}}\n, the rate of change of activation is given by:\nτ\ni\ny\n˙\ni\n=\n−\ny\ni\n+\n∑\nj\n=\n1\nn\nw\nj\ni\nσ\n(\ny\nj\n−\nΘ\nj\n)\n+\nI\ni\n(\nt\n)\n{\\displaystyle \\tau _{i}{\\dot {y}}_{i}=-y_{i}+\\sum _{j=1}^{n}w_{ji}\\sigma (y_{j}-\\Theta _{j})+I_{i}(t)}\nWhere:\nτ\ni\n{\\displaystyle \\tau _{i}}\n: Time constant of\npostsynaptic\nnode\ny\ni\n{\\displaystyle y_{i}}\n: Activation of postsynaptic node\ny\n˙\ni\n{\\displaystyle {\\dot {y}}_{i}}\n: Rate of change of activation of postsynaptic node\nw\nj\ni\n{\\displaystyle w{}_{ji}}\n: Weight of connection from pre to postsynaptic node\nσ\n(\nx\n)\n{\\displaystyle \\sigma (x)}\n:\nSigmoid\nof x e.g.\nσ\n(\nx\n)\n=\n1\n/\n(\n1\n+\ne\n−\nx\n)\n{\\displaystyle \\sigma (x)=1/(1+e^{-x})}\n.\ny\nj\n{\\displaystyle y_{j}}\n: Activation of presynaptic node\nΘ\nj\n{\\displaystyle \\Theta _{j}}\n: Bias of presynaptic node\nI\ni\n(\nt\n)\n{\\displaystyle I_{i}(t)}\n: Input (if any) to node\nCTRNNs have been applied to\nevolutionary robotics\nwhere they have been used to address vision,\n[\n109\n]\nco-operation,\n[\n110\n]\nand minimal cognitive behaviour.\n[\n111\n]\nNote that, by the\nShannon sampling theorem\n, discrete-time recurrent neural networks can be viewed as continuous-time recurrent neural networks where the differential equations have transformed into equivalent\ndifference equations\n.\n[\n112\n]\nThis transformation can be thought of as occurring after the post-synaptic node activation functions\ny\ni\n(\nt\n)\n{\\displaystyle y_{i}(t)}\nhave been\nlow-pass filtered\nbut prior to sampling.\nThey are in fact\nrecursive neural networks\nwith a particular structure: that of a linear chain. Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step.\nFrom a time-series perspective, RNNs can appear as nonlinear versions of\nfinite impulse response\nand\ninfinite impulse response\nfilters and also as a\nnonlinear autoregressive exogenous model\n(NARX).\n[\n113\n]\nRNN has infinite impulse response whereas\nconvolutional neural network\nhas\nfinite impulse response\n. Both classes of networks exhibit temporal\ndynamic behavior\n.\n[\n114\n]\nA finite impulse recurrent network is a\ndirected acyclic graph\nthat can be unrolled and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a\ndirected cyclic graph\nthat cannot be unrolled.\nThe effect of memory-based learning for the recognition of sequences can also be implemented by a more biological-based model which uses the silencing mechanism exhibited in neurons with a relatively high frequency\nspiking activity\n.\n[\n115\n]\nAdditional stored states and the storage under direct control by the network can be added to both\ninfinite-impulse\nand\nfinite-impulse\nnetworks. Another network or graph can also replace the storage if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated states or gated memory and are part of\nlong short-term memory\nnetworks (LSTMs) and\ngated recurrent units\n. This is also called Feedback Neural Network (FNN).\nLibraries\n[\nedit\n]\nModern libraries provide runtime-optimized implementations of the above functionality or allow to speed up the slow loop by\njust-in-time compilation\n.\nApache Singa\nCaffe\n: Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in\nC++\n, and has\nPython\nand\nMATLAB\nwrappers.\nChainer\n: Fully in Python, production support for CPU, GPU, distributed training.\nDeeplearning4j\n: Deep learning in\nJava\nand\nScala\non multi-GPU-enabled\nSpark\n.\nFlux\n: includes interfaces for RNNs, including GRUs and LSTMs, written in\nJulia\n.\nKeras\n: High-level API, providing a wrapper to many other deep learning libraries.\nMicrosoft Cognitive Toolkit\nMXNet\n: an open-source deep learning framework used to train and deploy deep neural networks.\nPyTorch\n: Tensors and Dynamic neural networks in Python with GPU acceleration.\nTensorFlow\n: Apache 2.0-licensed Theano-like library with support for CPU, GPU and Google's proprietary\nTPU\n,\n[\n116\n]\nmobile\nTheano\n: A deep-learning library for Python with an API largely compatible with the\nNumPy\nlibrary.\nTorch\n: A scientific computing framework with support for machine learning algorithms, written in\nC\nand\nLua\n.\nApplications\n[\nedit\n]\nApplications of recurrent neural networks include:\nMachine translation\n[\n42\n]\nRobot control\n[\n117\n]\nTime series prediction\n[\n118\n]\n[\n119\n]\n[\n120\n]\nSpeech recognition\n[\n121\n]\n[\n39\n]\n[\n122\n]\nSpeech synthesis\n[\n123\n]\nBrain–computer interfaces\n[\n124\n]\nTime series anomaly detection\n[\n125\n]\nText-to-Video model\n[\n126\n]\nRhythm learning\n[\n127\n]\nMusic composition\n[\n128\n]\nGrammar learning\n[\n129\n]\n[\n58\n]\n[\n130\n]\nHandwriting recognition\n[\n131\n]\n[\n132\n]\nHuman action recognition\n[\n133\n]\nProtein homology detection\n[\n134\n]\nPredicting subcellular localization of proteins\n[\n135\n]\nSeveral prediction tasks in the area of business process management\n[\n136\n]\nPrediction in medical care pathways\n[\n137\n]\nPredictions of fusion plasma disruptions in reactors (Fusion Recurrent Neural Network (FRNN) code)\n[\n138\n]\nReferences\n[\nedit\n]\n^\nTealab, Ahmed (2018-12-01).\n\"Time series forecasting using artificial neural networks methodologies: A systematic review\"\n.\nFuture Computing and Informatics Journal\n.\n3\n(2):\n334–\n340.\ndoi\n:\n10.1016/j.fcij.2018.10.003\n.\nISSN\n2314-7288\n.\n^\nGraves, Alex\n; Liwicki, Marcus; Fernandez, Santiago; Bertolami, Roman; Bunke, Horst;\nSchmidhuber, Jürgen\n(2009).\n\"A Novel Connectionist System for Improved Unconstrained Handwriting Recognition\"\n(PDF)\n.\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n.\n31\n(5):\n855–\n868.\nCiteSeerX\n10.1.1.139.4502\n.\ndoi\n:\n10.1109/tpami.2008.137\n.\nPMID\n19299860\n.\nS2CID\n14635907\n.\n^\na\nb\nSak, Haşim; Senior, Andrew; Beaufays, Françoise (2014).\n\"Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling\"\n(PDF)\n. Google Research.\n^\na\nb\nLi, Xiangang; Wu, Xihong (2014-10-15). \"Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition\".\narXiv\n:\n1410.4281\n[\ncs.CL\n].\n^\nDupond, Samuel (2019).\n\"A thorough review on the current advance of neural network structures\"\n.\nAnnual Reviews in Control\n.\n14\n:\n200–\n230.\n^\nAbiodun, Oludare Isaac; Jantan, Aman; Omolara, Abiodun Esther; Dada, Kemi Victoria; Mohamed, Nachaat Abdelatif; Arshad, Humaira (2018-11-01).\n\"State-of-the-art in artificial neural network applications: A survey\"\n.\nHeliyon\n.\n4\n(11) e00938.\nBibcode\n:\n2018Heliy...400938A\n.\ndoi\n:\n10.1016/j.heliyon.2018.e00938\n.\nISSN\n2405-8440\n.\nPMC\n6260436\n.\nPMID\n30519653\n.\n^\nEspinosa-Sanchez, Juan Manuel; Gomez-Marin, Alex; de Castro, Fernando (2023-07-05).\n\"The Importance of Cajal's and Lorente de Nó's Neuroscience to the Birth of Cybernetics\"\n.\nThe Neuroscientist\n.\n31\n(1):\n14–\n30.\ndoi\n:\n10.1177/10738584231179932\n.\nhdl\n:\n10261/348372\n.\nISSN\n1073-8584\n.\nPMID\n37403768\n.\n^\nRamón y Cajal, Santiago (1909).\nHistologie du système nerveux de l'homme & des vertébrés\n. Vol. II. Foyle Special Collections Library King's College London. Paris : A. Maloine. p. 149.\n^\nde NÓ, R. Lorente (1933-08-01).\n\"Vestibulo-Ocular Reflex Arc\"\n.\nArchives of Neurology and Psychiatry\n.\n30\n(2): 245.\ndoi\n:\n10.1001/archneurpsyc.1933.02240140009001\n.\nISSN\n0096-6754\n.\n^\nLarriva-Sahd, Jorge A. (2014-12-03).\n\"Some predictions of Rafael Lorente de Nó 80 years later\"\n.\nFrontiers in Neuroanatomy\n.\n8\n: 147.\ndoi\n:\n10.3389/fnana.2014.00147\n.\nISSN\n1662-5129\n.\nPMC\n4253658\n.\nPMID\n25520630\n.\n^\n\"reverberating circuit\"\n.\nOxford Reference\n. Retrieved\n2024-07-27\n.\n^\nMcCulloch, Warren S.; Pitts, Walter (December 1943).\n\"A logical calculus of the ideas immanent in nervous activity\"\n.\nThe Bulletin of Mathematical Biophysics\n.\n5\n(4):\n115–\n133.\ndoi\n:\n10.1007/BF02478259\n.\nISSN\n0007-4985\n.\n^\nMoreno-Díaz, Roberto; Moreno-Díaz, Arminda (April 2007).\n\"On the legacy of W.S. McCulloch\"\n.\nBiosystems\n.\n88\n(3):\n185–\n190.\nBibcode\n:\n2007BiSys..88..185M\n.\ndoi\n:\n10.1016/j.biosystems.2006.08.010\n.\nPMID\n17184902\n.\n^\nArbib, Michael A (December 2000).\n\"Warren McCulloch's Search for the Logic of the Nervous System\"\n.\nPerspectives in Biology and Medicine\n.\n43\n(2):\n193–\n216.\ndoi\n:\n10.1353/pbm.2000.0001\n.\nISSN\n1529-8795\n.\nPMID\n10804585\n.\n^\nRenshaw, Birdsey (1946-05-01).\n\"Central Effects of Centripetal Impulses in Axons of Spinal Ventral Roots\"\n.\nJournal of Neurophysiology\n.\n9\n(3):\n191–\n204.\ndoi\n:\n10.1152/jn.1946.9.3.191\n.\nISSN\n0022-3077\n.\nPMID\n21028162\n.\n^\na\nb\nGrossberg, Stephen (2013-02-22).\n\"Recurrent Neural Networks\"\n.\nScholarpedia\n.\n8\n(2): 1888.\nBibcode\n:\n2013SchpJ...8.1888G\n.\ndoi\n:\n10.4249/scholarpedia.1888\n.\nISSN\n1941-6016\n.\n^\na\nb\nc\nRosenblatt, Frank (1961-03-15).\nDTIC AD0256582: PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS\n. Defense Technical Information Center.\n^\nF. Rosenblatt, \"\nPerceptual Generalization over Transformation Groups\n\", pp. 63--100 in\nSelf-organizing Systems: Proceedings of an Inter-disciplinary Conference, 5 and 6 May 1959\n. Edited by Marshall C. Yovitz and Scott Cameron. London, New York, [etc.], Pergamon Press, 1960. ix, 322 p.\n^\nNakano, Kaoru (1971). \"Learning Process in a Model of Associative Memory\".\nPattern Recognition and Machine Learning\n. pp.\n172–\n186.\ndoi\n:\n10.1007/978-1-4615-7566-5_15\n.\nISBN\n978-1-4615-7568-9\n.\n^\nNakano, Kaoru (1972). \"Associatron-A Model of Associative Memory\".\nIEEE Transactions on Systems, Man, and Cybernetics\n. SMC-2 (3):\n380–\n388.\nBibcode\n:\n1972ITSMC...2..380N\n.\ndoi\n:\n10.1109/TSMC.1972.4309133\n.\n^\nAmari, Shun-Ichi (1972). \"Learning patterns and pattern sequences by self-organizing nets of threshold elements\".\nIEEE Transactions\n.\nC\n(21):\n1197–\n1206.\n^\nLittle, W. A. (1974). \"The Existence of Persistent States in the Brain\".\nMathematical Biosciences\n.\n19\n(\n1–\n2):\n101–\n120.\ndoi\n:\n10.1016/0025-5564(74)90031-5\n.\n^\nLenz, W.\n(1920), \"Beiträge zum Verständnis der magnetischen Eigenschaften in festen Körpern\",\nPhysikalische Zeitschrift\n,\n21\n:\n613–\n615.\n^\nIsing, E. (1925), \"Beitrag zur Theorie des Ferromagnetismus\",\nZ. Phys.\n,\n31\n(1):\n253–\n258,\nBibcode\n:\n1925ZPhy...31..253I\n,\ndoi\n:\n10.1007/BF02980577\n,\nS2CID\n122157319\n^\nBrush, Stephen G. (1967). \"History of the Lenz-Ising Model\".\nReviews of Modern Physics\n.\n39\n(4):\n883–\n893.\nBibcode\n:\n1967RvMP...39..883B\n.\ndoi\n:\n10.1103/RevModPhys.39.883\n.\n^\nGlauber, Roy J. (February 1963).\n\"Roy J. Glauber \"Time-Dependent Statistics of the Ising Model\"\n\"\n.\nJournal of Mathematical Physics\n.\n4\n(2):\n294–\n307.\ndoi\n:\n10.1063/1.1703954\n. Retrieved\n2021-03-21\n.\n^\nSherrington, David; Kirkpatrick, Scott (1975-12-29).\n\"Solvable Model of a Spin-Glass\"\n.\nPhysical Review Letters\n.\n35\n(26):\n1792–\n1796.\nBibcode\n:\n1975PhRvL..35.1792S\n.\ndoi\n:\n10.1103/PhysRevLett.35.1792\n.\nISSN\n0031-9007\n.\n^\nHopfield, J. J. (1982).\n\"Neural networks and physical systems with emergent collective computational abilities\"\n.\nProceedings of the National Academy of Sciences\n.\n79\n(8):\n2554–\n2558.\nBibcode\n:\n1982PNAS...79.2554H\n.\ndoi\n:\n10.1073/pnas.79.8.2554\n.\nPMC\n346238\n.\nPMID\n6953413\n.\n^\nHopfield, J. J. (1984).\n\"Neurons with graded response have collective computational properties like those of two-state neurons\"\n.\nProceedings of the National Academy of Sciences\n.\n81\n(10):\n3088–\n3092.\nBibcode\n:\n1984PNAS...81.3088H\n.\ndoi\n:\n10.1073/pnas.81.10.3088\n.\nPMC\n345226\n.\nPMID\n6587342\n.\n^\nEngel, A.; Broeck, C. van den (2001).\nStatistical mechanics of learning\n. Cambridge, UK; New York, NY: Cambridge University Press.\nISBN\n978-0-521-77307-2\n.\n^\nSeung, H. S.; Sompolinsky, H.; Tishby, N. (1992-04-01).\n\"Statistical mechanics of learning from examples\"\n.\nPhysical Review A\n.\n45\n(8):\n6056–\n6091.\nBibcode\n:\n1992PhRvA..45.6056S\n.\ndoi\n:\n10.1103/PhysRevA.45.6056\n.\nPMID\n9907706\n.\n^\nZhang, Aston; Lipton, Zachary; Li, Mu; Smola, Alexander J. (2024).\n\"10. Modern Recurrent Neural Networks\"\n.\nDive into deep learning\n. Cambridge New York Port Melbourne New Delhi Singapore: Cambridge University Press.\nISBN\n978-1-009-38943-3\n.\n^\nRumelhart, David E.; Hinton, Geoffrey E.; Williams, Ronald J. (October 1986).\n\"Learning representations by back-propagating errors\"\n.\nNature\n.\n323\n(6088):\n533–\n536.\nBibcode\n:\n1986Natur.323..533R\n.\ndoi\n:\n10.1038/323533a0\n.\nISSN\n1476-4687\n.\n^\na\nb\nSchmidhuber, Jürgen (1993).\nHabilitation thesis: System modeling and optimization\n(PDF)\n.\n[\npermanent dead link\n]\nPage 150 ff demonstrates credit assignment across the equivalent of 1,200 layers in an unfolded RNN.\n^\nSepp Hochreiter\n;\nJürgen Schmidhuber\n(21 August 1995),\nLong Short Term Memory\n,\nWikidata\nQ98967430\n^\na\nb\nHochreiter, Sepp\n; Schmidhuber, Jürgen (1997-11-01). \"Long Short-Term Memory\".\nNeural Computation\n.\n9\n(8):\n1735–\n1780.\ndoi\n:\n10.1162/neco.1997.9.8.1735\n.\nPMID\n9377276\n.\nS2CID\n1915014\n.\n^\nSchuster, Mike, and Kuldip K. Paliwal. \"\nBidirectional recurrent neural networks\n.\" Signal Processing, IEEE Transactions on 45.11 (1997): 2673-2681.2. Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan\n^\nGraves, Alex; Schmidhuber, Jürgen (2005-07-01). \"Framewise phoneme classification with bidirectional LSTM and other neural network architectures\".\nNeural Networks\n. IJCNN 2005.\n18\n(5):\n602–\n610.\nCiteSeerX\n10.1.1.331.5800\n.\ndoi\n:\n10.1016/j.neunet.2005.06.042\n.\nPMID\n16112549\n.\nS2CID\n1856462\n.\n^\na\nb\nFernández, Santiago; Graves, Alex; Schmidhuber, Jürgen (2007).\n\"An Application of Recurrent Neural Networks to Discriminative Keyword Spotting\"\n.\nProceedings of the 17th International Conference on Artificial Neural Networks\n. ICANN'07. Berlin, Heidelberg: Springer-Verlag. pp.\n220–\n229.\nISBN\n978-3-540-74693-5\n.\n^\nFan, Bo; Wang, Lijuan; Soong, Frank K.; Xie, Lei (2015). \"Photo-Real Talking Head with Deep Bidirectional LSTM\".\nProceedings of ICASSP 2015 IEEE International Conference on Acoustics, Speech and Signal Processing\n. pp.\n4884–\n8.\ndoi\n:\n10.1109/ICASSP.2015.7178899\n.\nISBN\n978-1-4673-6997-8\n.\n^\nSak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 2015).\n\"Google voice search: faster and more accurate\"\n.\n^\na\nb\nSutskever, Ilya; Vinyals, Oriol; Le, Quoc V. (2014).\n\"Sequence to Sequence Learning with Neural Networks\"\n(PDF)\n.\nElectronic Proceedings of the Neural Information Processing Systems Conference\n.\n27\n: 5346.\narXiv\n:\n1409.3215\n.\nBibcode\n:\n2014arXiv1409.3215S\n.\n^\nJozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016-02-07). \"Exploring the Limits of Language Modeling\".\narXiv\n:\n1602.02410\n[\ncs.CL\n].\n^\nGillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015-11-30). \"Multilingual Language Processing From Bytes\".\narXiv\n:\n1512.00103\n[\ncs.CL\n].\n^\nVinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2014-11-17). \"Show and Tell: A Neural Image Caption Generator\".\narXiv\n:\n1411.4555\n[\ncs.CV\n].\n^\nCho, Kyunghyun; van Merrienboer, Bart; Gulcehre, Caglar; Bahdanau, Dzmitry; Bougares, Fethi; Schwenk, Holger; Bengio, Yoshua (2014-06-03). \"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\".\narXiv\n:\n1406.1078\n[\ncs.CL\n].\n^\nSutskever, Ilya; Vinyals, Oriol; Le, Quoc Viet (14 Dec 2014). \"Sequence to sequence learning with neural networks\".\narXiv\n:\n1409.3215\n[\ncs.CL\n].\n[first version posted to arXiv on 10 Sep 2014]\n^\nPeters ME, Neumann M, Iyyer M, Gardner M, Clark C, Lee K, Zettlemoyer L (2018). \"Deep contextualized word representations\".\narXiv\n:\n1802.05365\n[\ncs.CL\n].\n^\nVaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Ł ukasz; Polosukhin, Illia (2017).\n\"Attention is All you Need\"\n.\nAdvances in Neural Information Processing Systems\n.\n30\n. Curran Associates, Inc.\n^\nOord, Aäron van den; Kalchbrenner, Nal; Kavukcuoglu, Koray (2016-06-11).\n\"Pixel Recurrent Neural Networks\"\n.\nProceedings of the 33rd International Conference on Machine Learning\n. PMLR:\n1747–\n1756.\n^\na\nb\nCruse, Holk;\nNeural Networks as Cybernetic Systems\n, 2nd and revised edition\n^\nElman, Jeffrey L. (1990).\n\"Finding Structure in Time\"\n.\nCognitive Science\n.\n14\n(2):\n179–\n211.\ndoi\n:\n10.1016/0364-0213(90)90002-E\n.\n^\nJordan, Michael I. (1997-01-01). \"Serial Order: A Parallel Distributed Processing Approach\".\nNeural-Network Models of Cognition — Biobehavioral Foundations\n. Advances in Psychology. Vol. 121. pp.\n471–\n495.\ndoi\n:\n10.1016/s0166-4115(97)80111-2\n.\nISBN\n978-0-444-81931-4\n.\nS2CID\n15375627\n.\n^\nGers, Felix A.; Schraudolph, Nicol N.; Schmidhuber, Jürgen (2002).\n\"Learning Precise Timing with LSTM Recurrent Networks\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n3\n:\n115–\n143\n. Retrieved\n2017-06-13\n.\n^\na\nb\nc\nHochreiter, Sepp (1991).\nUntersuchungen zu dynamischen neuronalen Netzen\n(PDF)\n(Diploma). Institut f. Informatik, Technische University Munich.\n^\nBayer, Justin; Wierstra, Daan; Togelius, Julian; Schmidhuber, Jürgen (2009-09-14). \"Evolving Memory Cell Structures for Sequence Learning\".\nArtificial Neural Networks – ICANN 2009\n(PDF)\n. Lecture Notes in Computer Science. Vol. 5769. Berlin, Heidelberg: Springer. pp.\n755–\n764.\ndoi\n:\n10.1007/978-3-642-04277-5_76\n.\nISBN\n978-3-642-04276-8\n.\n^\nFernández, Santiago; Graves, Alex; Schmidhuber, Jürgen (2007).\n\"Sequence labelling in structured domains with hierarchical recurrent neural networks\"\n(PDF)\n.\nProceedings of the 20th International Joint Conference on Artificial Intelligence, Ijcai 2007\n. pp.\n774–\n9.\nCiteSeerX\n10.1.1.79.1887\n.\n^\na\nb\nGers, Felix A.; Schmidhuber, Jürgen (2001).\n\"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages\"\n(PDF)\n.\nIEEE Transactions on Neural Networks\n.\n12\n(6):\n1333–\n40.\nBibcode\n:\n2001ITNN...12.1333G\n.\ndoi\n:\n10.1109/72.963769\n.\nPMID\n18249962\n.\nS2CID\n10192330\n. Archived from\nthe original\n(PDF)\non 2017-07-06\n. Retrieved\n2017-12-12\n.\n^\nHeck, Joel; Salem, Fathi M. (2017-01-12). \"Simplified Minimal Gated Unit Variations for Recurrent Neural Networks\".\narXiv\n:\n1701.03452\n[\ncs.NE\n].\n^\nDey, Rahul; Salem, Fathi M. (2017-01-20). \"Gate-Variants of Gated Recurrent Unit (GRU) Neural Networks\".\narXiv\n:\n1701.05923\n[\ncs.NE\n].\n^\nBritz, Denny (October 27, 2015).\n\"Recurrent Neural Network Tutorial, Part 4 – Implementing a GRU/LSTM RNN with Python and Theano – WildML\"\n.\nWildml.com\n. Retrieved\nMay 18,\n2016\n.\n^\na\nb\nChung, Junyoung; Gulcehre, Caglar; Cho, KyungHyun; Bengio, Yoshua (2014). \"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\".\narXiv\n:\n1412.3555\n[\ncs.NE\n].\n^\nGruber, N.; Jockisch, A. (2020), \"Are GRU cells more specific and LSTM cells more sensitive in motive classification of text?\",\nFrontiers in Artificial Intelligence\n,\n3\n40,\ndoi\n:\n10.3389/frai.2020.00040\n,\nPMC\n7861254\n,\nPMID\n33733157\n,\nS2CID\n220252321\n^\nKosko, Bart (1988). \"Bidirectional associative memories\".\nIEEE Transactions on Systems, Man, and Cybernetics\n.\n18\n(1):\n49–\n60.\nBibcode\n:\n1988ITSMC..18...49K\n.\ndoi\n:\n10.1109/21.87054\n.\nS2CID\n59875735\n.\n^\nRakkiyappan, Rajan; Chandrasekar, Arunachalam; Lakshmanan, Subramanian; Park, Ju H. (2 January 2015). \"Exponential stability for markovian jumping stochastic BAM neural networks with mode-dependent probabilistic time-varying delays and impulse control\".\nComplexity\n.\n20\n(3):\n39–\n65.\nBibcode\n:\n2015Cmplx..20c..39R\n.\ndoi\n:\n10.1002/cplx.21503\n.\n^\nRojas, Rául (1996).\nNeural networks: a systematic introduction\n. Springer. p. 336.\nISBN\n978-3-540-60505-8\n.\n^\nJaeger, Herbert; Haas, Harald (2004-04-02). \"Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication\".\nScience\n.\n304\n(5667):\n78–\n80.\nBibcode\n:\n2004Sci...304...78J\n.\nCiteSeerX\n10.1.1.719.2301\n.\ndoi\n:\n10.1126/science.1091277\n.\nPMID\n15064413\n.\nS2CID\n2184251\n.\n^\nMaass, Wolfgang; Natschläger, Thomas; Markram, Henry (2002).\n\"Real-time computing without stable states: a new framework for neural computation based on perturbations\"\n(PDF)\n.\nNeural Computation\n.\n14\n(11):\n2531–\n2560.\ndoi\n:\n10.1162/089976602760407955\n.\nPMID\n12433288\n.\nS2CID\n1045112\n.\n^\nGoller, Christoph; Küchler, Andreas (1996). \"Learning task-dependent distributed representations by backpropagation through structure\".\nProceedings of International Conference on Neural Networks (ICNN'96)\n. Vol. 1. p. 347.\nCiteSeerX\n10.1.1.52.4759\n.\ndoi\n:\n10.1109/ICNN.1996.548916\n.\nISBN\n978-0-7803-3210-2\n.\nS2CID\n6536466\n.\n^\nLinnainmaa, Seppo\n(1970).\nThe representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors\n(MSc) (in Finnish). University of Helsinki.\n^\nGriewank, Andreas;\nWalther, Andrea\n(2008).\nEvaluating Derivatives: Principles and Techniques of Algorithmic Differentiation\n(Second ed.). SIAM.\nISBN\n978-0-89871-776-1\n.\n^\nSocher, Richard; Lin, Cliff; Ng, Andrew Y.; Manning, Christopher D.,\n\"Parsing Natural Scenes and Natural Language with Recursive Neural Networks\"\n(PDF)\n,\n28th International Conference on Machine Learning (ICML 2011)\n^\nSocher, Richard; Perelygin, Alex; Wu, Jean Y.; Chuang, Jason; Manning, Christopher D.; Ng, Andrew Y.; Potts, Christopher.\n\"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\"\n(PDF)\n.\nEmnlp 2013\n.\n^\nGraves, Alex; Wayne, Greg; Danihelka, Ivo (2014). \"Neural Turing Machines\".\narXiv\n:\n1410.5401\n[\ncs.NE\n].\n^\nGraves, Alex; Wayne, Greg; Reynolds, Malcolm; Harley, Tim; Danihelka, Ivo; Grabska-Barwińska, Agnieszka; Colmenarejo, Sergio Gómez; Grefenstette, Edward; Ramalho, Tiago (2016-10-12).\n\"Hybrid computing using a neural network with dynamic external memory\"\n.\nNature\n.\n538\n(7626):\n471–\n476.\nBibcode\n:\n2016Natur.538..471G\n.\ndoi\n:\n10.1038/nature20101\n.\nISSN\n1476-4687\n.\nPMID\n27732574\n.\nS2CID\n205251479\n.\n^\nSun, Guo-Zheng; Giles, C. Lee; Chen, Hsing-Hen (1998). \"The Neural Network Pushdown Automaton: Architecture, Dynamics and Training\". In Giles, C. Lee; Gori, Marco (eds.).\nAdaptive Processing of Sequences and Data Structures\n. Lecture Notes in Computer Science. Berlin, Heidelberg: Springer. pp.\n296–\n345.\nCiteSeerX\n10.1.1.56.8723\n.\ndoi\n:\n10.1007/bfb0054003\n.\nISBN\n978-3-540-64341-8\n.\n^\nHyötyniemi, Heikki (1996). \"Turing machines are recurrent neural networks\".\nProceedings of STeP '96/Publications of the Finnish Artificial Intelligence Society\n:\n13–\n24.\n^\nRobinson, Anthony J.; Fallside, Frank (1987).\nThe Utility Driven Dynamic Error Propagation Network\n. Technical Report CUED/F-INFENG/TR.1. Department of Engineering, University of Cambridge.\n^\nWilliams, Ronald J.; Zipser, D. (1 February 2013). \"Gradient-based learning algorithms for recurrent networks and their computational complexity\". In Chauvin, Yves; Rumelhart, David E. (eds.).\nBackpropagation: Theory, Architectures, and Applications\n. Psychology Press.\nISBN\n978-1-134-77581-1\n.\n^\nSchmidhuber, Jürgen (1989-01-01). \"A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks\".\nConnection Science\n.\n1\n(4):\n403–\n412.\ndoi\n:\n10.1080/09540098908915650\n.\nS2CID\n18721007\n.\n^\nPríncipe, José C.; Euliano, Neil R.; Lefebvre, W. Curt (2000).\nNeural and adaptive systems: fundamentals through simulations\n. Wiley.\nISBN\n978-0-471-35167-2\n.\n^\nYann, Ollivier; Tallec, Corentin; Charpiat, Guillaume (2015-07-28). \"Training recurrent networks online without backtracking\".\narXiv\n:\n1507.07680\n[\ncs.NE\n].\n^\nSchmidhuber, Jürgen (1992-03-01). \"A Fixed Size Storage O(n3) Time Complexity Learning Algorithm for Fully Recurrent Continually Running Networks\".\nNeural Computation\n.\n4\n(2):\n243–\n248.\ndoi\n:\n10.1162/neco.1992.4.2.243\n.\nS2CID\n11761172\n.\n^\nWilliams, Ronald J. (1989).\nComplexity of exact gradient computation algorithms for recurrent neural networks\n(Report). Technical Report NU-CCS-89-27. Boston (MA): Northeastern University, College of Computer Science. Archived from\nthe original\non 2017-10-20\n. Retrieved\n2017-07-02\n.\n^\nPearlmutter, Barak A. (1989-06-01).\n\"Learning State Space Trajectories in Recurrent Neural Networks\"\n.\nNeural Computation\n.\n1\n(2):\n263–\n269.\ndoi\n:\n10.1162/neco.1989.1.2.263\n.\nS2CID\n16813485\n.\n^\nHochreiter, Sepp; et al. (15 January 2001).\n\"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies\"\n. In Kolen, John F.; Kremer, Stefan C. (eds.).\nA Field Guide to Dynamical Recurrent Networks\n. John Wiley & Sons.\nISBN\n978-0-7803-5369-5\n.\n^\na\nb\nLi, Shuai; Li, Wanqing; Cook, Chris; Zhu, Ce; Yanbo, Gao (2018). \"Independently Recurrent Neural Network (IndRNN): Building a Longer and Deeper RNN\".\narXiv\n:\n1803.04831\n[\ncs.CV\n].\n^\nCampolucci, Paolo; Uncini, Aurelio; Piazza, Francesco; Rao, Bhaskar D. (1999). \"On-Line Learning Algorithms for Locally Recurrent Neural Networks\".\nIEEE Transactions on Neural Networks\n.\n10\n(2):\n253–\n271.\nBibcode\n:\n1999ITNN...10..253C\n.\nCiteSeerX\n10.1.1.33.7550\n.\ndoi\n:\n10.1109/72.750549\n.\nPMID\n18252525\n.\n^\nWan, Eric A.; Beaufays, Françoise (1996). \"Diagrammatic derivation of gradient algorithms for neural networks\".\nNeural Computation\n.\n8\n:\n182–\n201.\ndoi\n:\n10.1162/neco.1996.8.1.182\n.\nS2CID\n15512077\n.\n^\na\nb\nCampolucci, Paolo; Uncini, Aurelio; Piazza, Francesco (2000). \"A Signal-Flow-Graph Approach to On-line Gradient Calculation\".\nNeural Computation\n.\n12\n(8):\n1901–\n1927.\nCiteSeerX\n10.1.1.212.5406\n.\ndoi\n:\n10.1162/089976600300015196\n.\nPMID\n10953244\n.\nS2CID\n15090951\n.\n^\nGraves, Alex; Fernández, Santiago; Gomez, Faustino J. (2006).\n\"Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks\"\n(PDF)\n.\nProceedings of the International Conference on Machine Learning\n. pp.\n369–\n376.\nCiteSeerX\n10.1.1.75.6306\n.\ndoi\n:\n10.1145/1143844.1143891\n.\nISBN\n1-59593-383-2\n.\n^\nHannun, Awni (2017-11-27).\n\"Sequence Modeling with CTC\"\n.\nDistill\n.\n2\n(11) e8.\ndoi\n:\n10.23915/distill.00008\n.\nISSN\n2476-0757\n.\n^\nGomez, Faustino J.; Miikkulainen, Risto (1999),\n\"Solving non-Markovian control tasks with neuroevolution\"\n(PDF)\n,\nIJCAI 99\n, Morgan Kaufmann\n, retrieved\n5 August\n2017\n^\nSyed, Omar (May 1995).\nApplying Genetic Algorithms to Recurrent Neural Networks for Learning Network Parameters and Architecture\n(MSc). Department of Electrical Engineering, Case Western Reserve University.\n^\nGomez, Faustino J.; Schmidhuber, Jürgen; Miikkulainen, Risto (June 2008).\n\"Accelerated Neural Evolution Through Cooperatively Coevolved Synapses\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n9\n:\n937–\n965.\n^\na\nb\nc\nd\nSchmidhuber, Jürgen (1992).\n\"Learning complex, extended sequences using the principle of history compression\"\n(PDF)\n.\nNeural Computation\n.\n4\n(2):\n234–\n242.\ndoi\n:\n10.1162/neco.1992.4.2.234\n.\nS2CID\n18271205\n. Archived from\nthe original\n(PDF)\non 2017-07-06.\n^\nSchmidhuber, Jürgen (2015).\n\"Deep Learning\"\n.\nScholarpedia\n.\n10\n(11) 32832.\nBibcode\n:\n2015SchpJ..1032832S\n.\ndoi\n:\n10.4249/scholarpedia.32832\n.\n^\nGiles, C. Lee; Miller, Clifford B.; Chen, Dong; Chen, Hsing-Hen; Sun, Guo-Zheng; Lee, Yee-Chun (1992).\n\"Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks\"\n(PDF)\n.\nNeural Computation\n.\n4\n(3):\n393–\n405.\ndoi\n:\n10.1162/neco.1992.4.3.393\n.\nS2CID\n19666035\n.\n^\nOmlin, Christian W.; Giles, C. Lee (1996). \"Constructing Deterministic Finite-State Automata in Recurrent Neural Networks\".\nJournal of the ACM\n.\n45\n(6):\n937–\n972.\nCiteSeerX\n10.1.1.32.2364\n.\ndoi\n:\n10.1145/235809.235811\n.\nS2CID\n228941\n.\n^\nPaine, Rainer W.; Tani, Jun (2005-09-01). \"How Hierarchical Control Self-organizes in Artificial Adaptive Systems\".\nAdaptive Behavior\n.\n13\n(3):\n211–\n225.\ndoi\n:\n10.1177/105971230501300303\n.\nS2CID\n9932565\n.\n^\na\nb\n\"Burns, Benureau, Tani (2018) A Bergson-Inspired Adaptive Time Constant for the Multiple Timescales Recurrent Neural Network Model. JNNS\"\n.\n^\nBarkan, Oren; Benchimol, Jonathan; Caspi, Itamar; Cohen, Eliya; Hammer, Allon; Koenigstein, Noam (2023). \"Forecasting CPI inflation components with Hierarchical Recurrent Neural Networks\".\nInternational Journal of Forecasting\n.\n39\n(3):\n1145–\n1162.\narXiv\n:\n2011.07920\n.\ndoi\n:\n10.1016/j.ijforecast.2022.04.009\n.\n^\nTutschku, Kurt (June 1995).\nRecurrent Multilayer Perceptrons for Identification and Control: The Road to Applications\n. Institute of Computer Science Research Report. Vol. 118. University of Würzburg Am Hubland.\nCiteSeerX\n10.1.1.45.3527\n.\n^\nYamashita, Yuichi; Tani, Jun (2008-11-07).\n\"Emergence of Functional Hierarchy in a Multiple Timescale Neural Network Model: A Humanoid Robot Experiment\"\n.\nPLOS Computational Biology\n.\n4\n(11) e1000220.\nBibcode\n:\n2008PLSCB...4E0220Y\n.\ndoi\n:\n10.1371/journal.pcbi.1000220\n.\nPMC\n2570613\n.\nPMID\n18989398\n.\n^\nAlnajjar, Fady; Yamashita, Yuichi; Tani, Jun (2013).\n\"The hierarchical and functional connectivity of higher-order cognitive mechanisms: neurorobotic model to investigate the stability and flexibility of working memory\"\n.\nFrontiers in Neurorobotics\n.\n7\n: 2.\ndoi\n:\n10.3389/fnbot.2013.00002\n.\nPMC\n3575058\n.\nPMID\n23423881\n.\n^\n\"Proceedings of the 28th Annual Conference of the Japanese Neural Network Society (October, 2018)\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 2020-05-09\n. Retrieved\n2021-02-06\n.\n^\nSnider, Greg (2008),\n\"Cortical computing with memristive nanodevices\"\n,\nSci-DAC Review\n,\n10\n:\n58–\n65, archived from\nthe original\non 2016-05-16\n, retrieved\n2019-09-06\n^\nCaravelli, Francesco; Traversa, Fabio Lorenzo; Di Ventra, Massimiliano (2017). \"The complex dynamics of memristive circuits: analytical results and universal slow relaxation\".\nPhysical Review E\n.\n95\n(2) 022140.\narXiv\n:\n1608.08651\n.\nBibcode\n:\n2017PhRvE..95b2140C\n.\ndoi\n:\n10.1103/PhysRevE.95.022140\n.\nPMID\n28297937\n.\nS2CID\n6758362\n.\n^\nHarvey, Inman; Husbands, Phil; Cliff, Dave (1994),\n\"Seeing the light: Artificial evolution, real vision\"\n,\n3rd international conference on Simulation of adaptive behavior: from animals to animats 3\n, pp.\n392–\n401\n^\nQuinn, Matt (2001). \"Evolving communication without dedicated communication channels\".\nAdvances in Artificial Life: 6th European Conference, ECAL 2001\n. pp.\n357–\n366.\ndoi\n:\n10.1007/3-540-44811-X_38\n.\nISBN\n978-3-540-42567-0\n.\n^\nBeer, Randall D. (1997). \"The dynamics of adaptive behavior: A research program\".\nRobotics and Autonomous Systems\n.\n20\n(\n2–\n4):\n257–\n289.\ndoi\n:\n10.1016/S0921-8890(96)00063-2\n.\n^\nSherstinsky, Alex (2018-12-07). Bloem-Reddy, Benjamin; Paige, Brooks; Kusner, Matt; Caruana, Rich; Rainforth, Tom; Teh, Yee Whye (eds.).\nDeriving the Recurrent Neural Network Definition and RNN Unrolling Using Signal Processing\n.\nCritiquing and Correcting Trends in Machine Learning Workshop at NeurIPS-2018\n.\n^\nSiegelmann, Hava T.; Horne, Bill G.; Giles, C. Lee (1995).\n\"Computational Capabilities of Recurrent NARX Neural Networks\"\n.\nIEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics\n.\n27\n(2):\n208–\n15.\nCiteSeerX\n10.1.1.48.7468\n.\ndoi\n:\n10.1109/3477.558801\n.\nPMID\n18255858\n.\n^\nMiljanovic, Milos (Feb–Mar 2012).\n\"Comparative analysis of Recurrent and Finite Impulse Response Neural Networks in Time Series Prediction\"\n(PDF)\n.\nIndian Journal of Computer and Engineering\n.\n3\n(1).\n^\nHodassman, Shiri; Meir, Yuval; Kisos, Karin; Ben-Noam, Itamar; Tugendhaft, Yael; Goldental, Amir; Vardi, Roni; Kanter, Ido (2022-09-29).\n\"Brain inspired neuronal silencing mechanism to enable reliable sequence identification\"\n.\nScientific Reports\n.\n12\n(1): 16003.\narXiv\n:\n2203.13028\n.\nBibcode\n:\n2022NatSR..1216003H\n.\ndoi\n:\n10.1038/s41598-022-20337-x\n.\nISSN\n2045-2322\n.\nPMC\n9523036\n.\nPMID\n36175466\n.\n^\nMetz, Cade (May 18, 2016).\n\"Google Built Its Very Own Chips to Power Its AI Bots\"\n.\nWired\n.\n^\nMayer, Hermann; Gomez, Faustino J.; Wierstra, Daan; Nagy, Istvan; Knoll, Alois; Schmidhuber, Jürgen (October 2006). \"A System for Robotic Heart Surgery that Learns to Tie Knots Using Recurrent Neural Networks\".\n2006 IEEE/RSJ International Conference on Intelligent Robots and Systems\n. pp.\n543–\n548.\nCiteSeerX\n10.1.1.218.3399\n.\ndoi\n:\n10.1109/IROS.2006.282190\n.\nISBN\n978-1-4244-0258-8\n.\nS2CID\n12284900\n.\n^\nWierstra, Daan; Schmidhuber, Jürgen; Gomez, Faustino J. (2005).\n\"Evolino: Hybrid Neuroevolution/Optimal Linear Search for Sequence Learning\"\n.\nProceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI), Edinburgh\n. pp.\n853–\n8.\nOCLC\n62330637\n.\n^\nPetneházi, Gábor (2019-01-01). \"Recurrent neural networks for time series forecasting\".\narXiv\n:\n1901.00069\n[\ncs.LG\n].\n^\nHewamalage, Hansika; Bergmeir, Christoph; Bandara, Kasun (2020). \"Recurrent Neural Networks for Time Series Forecasting: Current Status and Future Directions\".\nInternational Journal of Forecasting\n.\n37\n:\n388–\n427.\narXiv\n:\n1909.00590\n.\ndoi\n:\n10.1016/j.ijforecast.2020.06.008\n.\nS2CID\n202540863\n.\n^\nGraves, Alex; Schmidhuber, Jürgen (2005). \"Framewise phoneme classification with bidirectional LSTM and other neural network architectures\".\nNeural Networks\n.\n18\n(\n5–\n6):\n602–\n610.\nCiteSeerX\n10.1.1.331.5800\n.\ndoi\n:\n10.1016/j.neunet.2005.06.042\n.\nPMID\n16112549\n.\nS2CID\n1856462\n.\n^\nGraves, Alex; Mohamed, Abdel-rahman; Hinton, Geoffrey E. (2013). \"Speech recognition with deep recurrent neural networks\".\n2013 IEEE International Conference on Acoustics, Speech and Signal Processing\n. pp.\n6645–\n9.\narXiv\n:\n1303.5778\n.\nBibcode\n:\n2013arXiv1303.5778G\n.\ndoi\n:\n10.1109/ICASSP.2013.6638947\n.\nISBN\n978-1-4799-0356-6\n.\nS2CID\n206741496\n.\n^\nChang, Edward F.; Chartier, Josh; Anumanchipalli, Gopala K. (24 April 2019).\n\"Speech synthesis from neural decoding of spoken sentences\"\n.\nNature\n.\n568\n(7753):\n493–\n8.\nBibcode\n:\n2019Natur.568..493A\n.\ndoi\n:\n10.1038/s41586-019-1119-1\n.\nISSN\n1476-4687\n.\nPMC\n9714519\n.\nPMID\n31019317\n.\nS2CID\n129946122\n.\n^\nMoses, David A.; Metzger, Sean L.; Liu, Jessie R.; Anumanchipalli, Gopala K.; Makin, Joseph G.; Sun, Pengfei F.; Chartier, Josh; Dougherty, Maximilian E.; Liu, Patricia M.; Abrams, Gary M.; Tu-Chan, Adelyn; Ganguly, Karunesh; Chang, Edward F. (2021-07-15).\n\"Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria\"\n.\nNew England Journal of Medicine\n.\n385\n(3):\n217–\n227.\ndoi\n:\n10.1056/NEJMoa2027540\n.\nPMC\n8972947\n.\nPMID\n34260835\n.\n^\nMalhotra, Pankaj; Vig, Lovekesh; Shroff, Gautam; Agarwal, Puneet (April 2015).\n\"Long Short Term Memory Networks for Anomaly Detection in Time Series\"\n.\nEuropean Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning – ESANN 2015\n. Ciaco. pp.\n89–\n94.\nISBN\n978-2-87587-015-5\n.\n^\n\"Papers with Code - DeepHS-HDRVideo: Deep High Speed High Dynamic Range Video Reconstruction\"\n.\npaperswithcode.com\n. Retrieved\n2022-10-13\n.\n^\nGers, Felix A.; Schraudolph, Nicol N.; Schmidhuber, Jürgen (2002).\n\"Learning precise timing with LSTM recurrent networks\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n3\n:\n115–\n143.\n^\nEck, Douglas; Schmidhuber, Jürgen (2002-08-28). \"Learning the Long-Term Structure of the Blues\".\nArtificial Neural Networks — ICANN 2002\n. Lecture Notes in Computer Science. Vol. 2415. Berlin, Heidelberg: Springer. pp.\n284–\n289.\nCiteSeerX\n10.1.1.116.3620\n.\ndoi\n:\n10.1007/3-540-46084-5_47\n.\nISBN\n978-3-540-46084-8\n.\n^\nSchmidhuber, Jürgen; Gers, Felix A.; Eck, Douglas (2002). \"Learning nonregular languages: A comparison of simple recurrent networks and LSTM\".\nNeural Computation\n.\n14\n(9):\n2039–\n2041.\nCiteSeerX\n10.1.1.11.7369\n.\ndoi\n:\n10.1162/089976602320263980\n.\nPMID\n12184841\n.\nS2CID\n30459046\n.\n^\nPérez-Ortiz, Juan Antonio; Gers, Felix A.; Eck, Douglas; Schmidhuber, Jürgen (2003). \"Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets\".\nNeural Networks\n.\n16\n(2):\n241–\n250.\nCiteSeerX\n10.1.1.381.1992\n.\ndoi\n:\n10.1016/s0893-6080(02)00219-8\n.\nPMID\n12628609\n.\n^\nGraves, Alex; Schmidhuber, Jürgen (2009).\n\"Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n. Vol. 22, NIPS'22. MIT Press. pp.\n545–\n552.\n^\nGraves, Alex; Fernández, Santiago; Liwicki, Marcus; Bunke, Horst; Schmidhuber, Jürgen (2007).\n\"Unconstrained Online Handwriting Recognition with Recurrent Neural Networks\"\n.\nProceedings of the 20th International Conference on Neural Information Processing Systems\n. Curran Associates. pp.\n577–\n584.\nISBN\n978-1-60560-352-0\n.\n^\nBaccouche, Moez; Mamalet, Franck; Wolf, Christian; Garcia, Christophe; Baskurt, Atilla (2011). \"Sequential Deep Learning for Human Action Recognition\". In Salah, Albert Ali; Lepri, Bruno (eds.).\nHuman Behavior Unterstanding\n. Lecture Notes in Computer Science. Vol. 7065. Amsterdam, Netherlands: Springer. pp.\n29–\n39.\ndoi\n:\n10.1007/978-3-642-25446-8_4\n.\nISBN\n978-3-642-25445-1\n.\n^\nHochreiter, Sepp; Heusel, Martin; Obermayer, Klaus (2007).\n\"Fast model-based protein homology detection without alignment\"\n.\nBioinformatics\n.\n23\n(14):\n1728–\n1736.\ndoi\n:\n10.1093/bioinformatics/btm247\n.\nPMID\n17488755\n.\n^\nThireou, Trias; Reczko, Martin (July 2007). \"Bidirectional Long Short-Term Memory Networks for Predicting the Subcellular Localization of Eukaryotic Proteins\".\nIEEE/ACM Transactions on Computational Biology and Bioinformatics\n.\n4\n(3):\n441–\n446.\nBibcode\n:\n2007ITCBB...4..441T\n.\ndoi\n:\n10.1109/tcbb.2007.1015\n.\nPMID\n17666763\n.\nS2CID\n11787259\n.\n^\nTax, Niek; Verenich, Ilya; La Rosa, Marcello; Dumas, Marlon (2017). \"Predictive Business Process Monitoring with LSTM Neural Networks\".\nAdvanced Information Systems Engineering\n. Lecture Notes in Computer Science. Vol. 10253. pp.\n477–\n492.\narXiv\n:\n1612.02130\n.\ndoi\n:\n10.1007/978-3-319-59536-8_30\n.\nISBN\n978-3-319-59535-1\n.\nS2CID\n2192354\n.\n^\nChoi, Edward; Bahadori, Mohammad Taha; Schuetz, Andy; Stewart, Walter F.; Sun, Jimeng (2016).\n\"Doctor AI: Predicting Clinical Events via Recurrent Neural Networks\"\n.\nJMLR Workshop and Conference Proceedings\n.\n56\n:\n301–\n318.\narXiv\n:\n1511.05942\n.\nBibcode\n:\n2015arXiv151105942C\n.\nPMC\n5341604\n.\nPMID\n28286600\n.\n^\n\"Artificial intelligence helps accelerate progress toward efficient fusion reactions\"\n.\nPrinceton University\n. Retrieved\n2023-06-12\n.\nFurther reading\n[\nedit\n]\nMandic, Danilo P.; Chambers, Jonathon A. (2001).\nRecurrent Neural Networks for Prediction: Learning Algorithms, Architectures and Stability\n. Wiley.\nISBN\n978-0-471-49517-8\n.\nGrossberg, Stephen (2013-02-22).\n\"Recurrent Neural Networks\"\n.\nScholarpedia\n.\n8\n(2): 1888.\nBibcode\n:\n2013SchpJ...8.1888G\n.\ndoi\n:\n10.4249/scholarpedia.1888\n.\nISSN\n1941-6016\n.\nRecurrent Neural Networks\n. List of RNN papers by\nJürgen Schmidhuber\n's group at\nDalle Molle Institute for Artificial Intelligence Research\n.\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nAuthority control databases\nGND\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Recurrent_neural_network&oldid=1314955598\n\"\nCategory\n:\nNeural network architectures\nHidden categories:\nCS1: long volume value\nAll articles with dead external links\nArticles with dead external links from June 2024\nArticles with permanently dead external links\nCS1 Finnish-language sources (fi)\nArticles with short description\nShort description is different from Wikidata\nAll articles with unsourced statements\nArticles with unsourced statements from June 2017\nThis page was last edited on 4 October 2025, at 03:08\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nRecurrent neural network\n29 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:05.650416",
      "status": "success",
      "content_length": 80648,
      "topic": "deep_learning"
    },
    {
      "title": "Natural language processing - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Natural_language_processing",
      "content": "Natural language processing - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\nToggle History subsection\n1.1\nSymbolic NLP (1950s – early 1990s)\n1.2\nStatistical NLP (1990s–present)\n2\nApproaches: Symbolic, statistical, neural networks\nToggle Approaches: Symbolic, statistical, neural networks subsection\n2.1\nStatistical approach\n2.2\nNeural networks\n3\nCommon NLP tasks\nToggle Common NLP tasks subsection\n3.1\nText and speech processing\n3.2\nMorphological analysis\n3.3\nSyntactic analysis\n3.4\nLexical semantics (of individual words in context)\n3.5\nRelational semantics (semantics of individual sentences)\n3.6\nDiscourse (semantics beyond individual sentences)\n3.7\nHigher-level NLP applications\n4\nGeneral tendencies and (possible) future directions\nToggle General tendencies and (possible) future directions subsection\n4.1\nCognition\n5\nSee also\n6\nReferences\n7\nFurther reading\n8\nExternal links\nToggle the table of contents\nNatural language processing\n71 languages\nAfrikaans\nالعربية\nԱրեւմտահայերէն\nAzərbaycanca\nবাংলা\n閩南語 / Bân-lâm-gí\nБеларуская\nБеларуская (тарашкевіца)\nБългарски\nBosanski\nBrezhoneg\nCatalà\nČeština\nCymraeg\nDansk\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nՀայերեն\nहिन्दी\nHrvatski\nIdo\nBahasa Indonesia\nIsiZulu\nÍslenska\nItaliano\nעברית\nಕನ್ನಡ\nქართული\nLatviešu\nLietuvių\nМакедонски\nमराठी\nمصرى\nМонгол\nမြန်မာဘာသာ\nNederlands\n日本語\nNorsk bokmål\nଓଡ଼ିଆ\nپښتو\nPicard\nPiemontèis\nPolski\nPortuguês\nQaraqalpaqsha\nRomână\nRuna Simi\nРусский\nShqip\nSimple English\nکوردی\nСрпски / srpski\nSrpskohrvatski / српскохрватски\nSuomi\nதமிழ்\nతెలుగు\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikiversity\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nProcessing of natural language by a computer\nThis article has multiple issues.\nPlease help\nimprove it\nor discuss these issues on the\ntalk page\n.\n(\nLearn how and when to remove these messages\n)\nThis article\nneeds additional citations for\nverification\n.\nPlease help\nimprove this article\nby\nadding citations to reliable sources\n. Unsourced material may be challenged and removed.\nFind sources:\n\"Natural language processing\"\n–\nnews\n·\nnewspapers\n·\nbooks\n·\nscholar\n·\nJSTOR\n(\nMay 2024\n)\n(\nLearn how and when to remove this message\n)\nThis article\nmay need to be rewritten\nto comply with Wikipedia's\nquality standards\n.\nYou can help\n. The\ntalk page\nmay contain suggestions.\n(\nJuly 2025\n)\nThis article\nmay be in need of reorganization to comply with Wikipedia's\nlayout guidelines\n.\nPlease help by\nediting the article\nto make improvements to the overall structure.\n(\nJuly 2025\n)\n(\nLearn how and when to remove this message\n)\n(\nLearn how and when to remove this message\n)\nNatural language processing\n(\nNLP\n) is the processing of\nnatural language\ninformation by a\ncomputer\n. NLP is a subfield of\ncomputer science\nand is closely associated with\nartificial intelligence\n. NLP is also related to\ninformation retrieval\n,\nknowledge representation\n,\ncomputational linguistics\n, and\nlinguistics\nmore broadly.\n[\n1\n]\nMajor processing tasks in an NLP system include:\nspeech recognition\n,\ntext classification\n,\nnatural language understanding\n, and\nnatural language generation\n.\nHistory\n[\nedit\n]\nFurther information:\nHistory of natural language processing\nNatural language processing has its roots in the 1950s.\n[\n2\n]\nAlready in 1950,\nAlan Turing\npublished an article titled \"\nComputing Machinery and Intelligence\n\" which proposed what is now called the\nTuring test\nas a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\nSymbolic NLP (1950s – early 1990s)\n[\nedit\n]\nA document parsed into an abstract syntax tree\nThe premise of symbolic NLP is often illustrated using\nJohn Searle's Chinese room\nthought experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n1950s\n: The\nGeorgetown experiment\nin 1954 involved fully\nautomatic translation\nof more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.\n[\n3\n]\nHowever, real progress was much slower, and after the\nALPAC report\nin 1966, which found that ten years of research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted in America (though some research continued elsewhere, such as Japan and Europe\n[\n4\n]\n) until the late 1980s when the first\nstatistical machine translation\nsystems were developed.\n1960s\n: Some notably successful natural language processing systems developed in the 1960s were\nSHRDLU\n, a natural language system working in restricted \"\nblocks worlds\n\" with restricted vocabularies, and\nELIZA\n, a simulation of a\nRogerian psychotherapy\n, written by\nJoseph Weizenbaum\nbetween 1964 and 1966. Despite using minimal information about human thought or emotion, ELIZA was able to produce interactions that appeared human-like. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\". Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only\ntwenty\nwords, because that was all that would fit in a computer  memory at the time.\n[\n5\n]\n1970s\n: During the 1970s, many programmers began to write \"conceptual\nontologies\n\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, the first\nchatterbots\nwere written (e.g.,\nPARRY\n).\n1980s\n: The 1980s and early 1990s mark the heyday of symbolic methods in NLP. Focus areas of the time included research on rule-based parsing (e.g., the development of\nHPSG\nas a computational operationalization of\ngenerative grammar\n), morphology (e.g., two-level morphology\n[\n6\n]\n), semantics (e.g.,\nLesk algorithm\n), reference (e.g., within Centering Theory\n[\n7\n]\n) and other areas of natural language understanding (e.g., in the\nRhetorical Structure Theory\n). Other lines of research were continued, e.g., the development of chatterbots with\nRacter\nand\nJabberwacky\n. An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period.\n[\n8\n]\nStatistical NLP (1990s–present)\n[\nedit\n]\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of\nmachine learning\nalgorithms for language processing. This shift was influenced by increasing computational power (see\nMoore's law\n) and a decline in the dominance of\nChomskyan\nlinguistic theories... (e.g.\ntransformational grammar\n), whose theoretical underpinnings discouraged the sort of\ncorpus linguistics\nthat underlies the machine-learning approach to language processing.\n[\n9\n]\n1990s\n: Many of the notable early successes in statistical methods in NLP occurred in the field of\nmachine translation\n, due especially to work at IBM Research, such as\nIBM alignment models\n. These systems were able to take advantage of existing multilingual\ntextual corpora\nthat had been produced by the\nParliament of Canada\nand the\nEuropean Union\nas a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n2000s\n: With the growth of the web, increasing amounts of raw (unannotated) language data have become available since the mid-1990s. Research has thus increasingly focused on\nunsupervised\nand\nsemi-supervised learning\nalgorithms. Such algorithms can learn from data that has not been hand-annotated with the desired answers or using a combination of annotated and non-annotated data. Generally, this task is much more difficult than\nsupervised learning\n, and typically produces less accurate results for a given amount of input data. However, large quantities of non-annotated data are available (including, among other things, the entire content of the\nWorld Wide Web\n), which can often make up for the worse efficiency if the algorithm used has a low enough\ntime complexity\nto be practical.\n2003:\nword n-gram model\n, at the time the best statistical algorithm, is outperformed by a\nmulti-layer perceptron\n(with a single hidden layer and context length of several words, trained on up to 14 million words, by\nBengio\net al.)\n[\n10\n]\n2010:\nTomáš Mikolov\n(then a PhD student at\nBrno University of Technology\n) with co-authors applied a simple\nrecurrent neural network\nwith a single hidden layer to language modeling,\n[\n11\n]\nand in the following years he went on to develop\nWord2vec\n. In the 2010s,\nrepresentation learning\nand\ndeep neural network\n-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. This shift gained momentum due to results showing that such techniques\n[\n12\n]\n[\n13\n]\ncan achieve state-of-the-art results in many natural language tasks, e.g., in\nlanguage modeling\n[\n14\n]\nand parsing.\n[\n15\n]\n[\n16\n]\nThis is increasingly important\nin medicine and healthcare\n, where NLP helps analyze notes and text in\nelectronic health records\nthat would otherwise be inaccessible for study when seeking to improve care\n[\n17\n]\nor protect patient privacy.\n[\n18\n]\nApproaches: Symbolic, statistical, neural networks\n[\nedit\n]\nSymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:\n[\n19\n]\n[\n20\n]\nsuch as by writing grammars or devising heuristic rules for\nstemming\n.\nMachine learning\napproaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach:\nboth statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\nlanguage models\n, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\nthe larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to\nintractability\nproblems.\nRule-based systems are commonly used:\nwhen the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the\nApertium\nsystem,\nfor preprocessing in NLP pipelines, e.g.,\ntokenization\n, or\nfor post-processing and transforming the output of NLP pipelines, e.g., for\nknowledge extraction\nfrom syntactic parses.\nStatistical approach\n[\nedit\n]\nIn the late 1980s and mid-1990s, the statistical approach ended a period of\nAI winter\n, which was caused by the inefficiencies of the rule-based approaches.\n[\n21\n]\n[\n22\n]\nThe earliest\ndecision trees\n, producing systems of hard\nif–then rules\n, were still very similar to the old rule-based approaches.\nOnly the introduction of hidden\nMarkov models\n, applied to part-of-speech tagging, announced the end of the old rule-based approach.\nNeural networks\n[\nedit\n]\nFurther information:\nArtificial neural network\nA major drawback of statistical methods is that they require elaborate\nfeature engineering\n. Since 2015,\n[\n23\n]\nneural network\n–based methods have increasingly replaced traditional statistical approaches, using\nsemantic networks\n[\n24\n]\nand\nword embeddings\nto capture semantic properties of words.\nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore.\nNeural machine translation\n, based on then-newly invented\nsequence-to-sequence\ntransformations, made obsolete the intermediate steps, such as word alignment, previously necessary for\nstatistical machine translation\n.\nCommon NLP tasks\n[\nedit\n]\nThe following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\nText and speech processing\n[\nedit\n]\nWord cloud of stop words in Hebrew\nOptical character recognition\n(OCR)\nGiven an image representing printed text, determine the corresponding text.\nSpeech recognition\nGiven a sound clip of a person or people speaking, determine the textual representation of the speech.  This is the opposite of\ntext to speech\nand is one of the extremely difficult problems colloquially termed \"\nAI-complete\n\" (see above).  In\nnatural speech\nthere are hardly any pauses between successive words, and thus\nspeech segmentation\nis a necessary subtask of speech recognition (see below). In most spoken languages, the sounds representing successive letters blend into each other in a process termed\ncoarticulation\n, so the conversion of the\nanalog signal\nto discrete characters can be a very difficult process. Also, given that words in the same language are spoken by people with different accents, the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent.\nSpeech segmentation\nGiven a sound clip of a person or people speaking, separate it into words.  A subtask of\nspeech recognition\nand typically grouped with it.\nText-to-speech\nGiven a text, transform those units and produce a spoken representation. Text-to-speech can be used to aid the visually impaired.\n[\n25\n]\nWord segmentation\n(\nTokenization\n)\nTokenization\nis a text-processing technique that divides text into individual words or word fragments. This technique results in two key components: a word index and tokenized text. The word index is a list that maps unique words to specific numerical identifiers, and the tokenized text replaces each word with its corresponding numerical token. These numerical tokens are then used in various deep learning methods.\n[\n26\n]\nFor a language like\nEnglish\n, this is fairly trivial, since words are usually separated by spaces. However, some written languages like\nChinese\n,\nJapanese\nand\nThai\ndo not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the\nvocabulary\nand\nmorphology\nof words in the language. Sometimes this process is also used in cases like\nbag of words\n(BOW) creation in data mining.\n[\n27\n]\nMorphological analysis\n[\nedit\n]\nLemmatization of Basque words\nLemmatization\nThe task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma. Lemmatization is another technique for reducing words to their normalized form. But in this case, the transformation actually uses a dictionary to map words to their actual form.\n[\n28\n]\nMorphological segmentation\nSeparate words into individual\nmorphemes\nand identify the class of the morphemes. The difficulty of this task depends greatly on the complexity of the\nmorphology\n(\ni.e.\n, the structure of words) of the language being considered.\nEnglish\nhas fairly simple morphology, especially\ninflectional morphology\n, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g., \"open, opens, opened, opening\") as separate words. In languages such as\nTurkish\nor\nMeitei\n, a highly\nagglutinated\nIndian language, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms.\n[\n29\n]\nPart-of-speech tagging\nGiven a sentence, determine the\npart of speech\n(POS) for each word. Many words, especially common ones, can serve as multiple parts of speech. For example, \"book\" can be a\nnoun\n(\"the book on the table\") or\nverb\n(\"to book a flight\"); \"set\" can be a noun, verb or\nadjective\n; and \"out\" can be any of at least five different parts of speech.\nStemming\nThe process of reducing inflected (or sometimes derived) words to a base form (e.g., \"close\" will be the root for \"closed\", \"closing\", \"close\", \"closer\" etc.). Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary.\nSyntactic analysis\n[\nedit\n]\nPart of\na series\non\nFormal languages\nKey concepts\nFormal system\nAlphabet\nSyntax\nFormal semantics\nSemantics (programming languages)\nFormal grammar\nFormation rule\nWell-formed formula\nAutomata theory\nRegular expression\nProduction\nGround expression\nAtomic formula\nApplications\nFormal methods\nPropositional calculus\nPredicate logic\nMathematical notation\nNatural language processing\nProgramming language theory\nMathematical linguistics\nComputational linguistics\nSyntax analysis\nFormal verification\nAutomated theorem proving\nv\nt\ne\nGrammar induction\n[\n30\n]\nGenerate a\nformal grammar\nthat describes a language's syntax.\nSentence breaking\n(also known as \"\nsentence boundary disambiguation\n\")\nGiven a chunk of text, find the sentence boundaries. Sentence boundaries are often marked by\nperiods\nor other\npunctuation marks\n, but these same characters can serve other purposes (e.g., marking\nabbreviations\n).\nParsing\nDetermine the\nparse tree\n(grammatical analysis) of a given sentence. The\ngrammar\nfor\nnatural languages\nis\nambiguous\nand typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human). There are two primary types of parsing:\ndependency parsing\nand\nconstituency parsing\n. Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a\nprobabilistic context-free grammar\n(PCFG) (see also\nstochastic grammar\n).\nLexical semantics (of individual words in context)\n[\nedit\n]\nAn entity linking pipeline\nLexical semantics\nWhat is the computational meaning of individual words in context?\nDistributional semantics\nHow can we learn semantic representations from data?\nNamed entity recognition\n(NER)\nGiven a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Although\ncapitalization\ncan aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of\nnamed entity\n, and in any case, is often inaccurate or insufficient.  For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized.  Furthermore, many other languages in non-Western scripts (e.g.\nChinese\nor\nArabic\n) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example,\nGerman\ncapitalizes all\nnouns\n, regardless of whether they are names, and\nFrench\nand\nSpanish\ndo not capitalize names that serve as\nadjectives\n. This task is also referred to as token classification.\n[\n31\n]\nSentiment analysis\n(see also\nMultimodal sentiment analysis\n)\nSentiment analysis involves identifying and classifying the emotional tone expressed in text. This technique involves analyzing text to determine whether the expressed sentiment is positive, negative, or neutral. Models for sentiment classification typically utilize inputs such as\nword n-grams\n,\nTerm Frequency-Inverse Document Frequency\n(TF-IDF) features, hand-generated features, or employ\ndeep learning\nmodels designed to recognize both long-term and short-term dependencies in text sequences. The applications of sentiment analysis are diverse, extending to tasks such as categorizing customer reviews on various online platforms.\n[\n26\n]\nTerminology extraction\nThe goal of terminology extraction is to automatically extract relevant terms from a given corpus.\nWord-sense disambiguation\n(WSD)\nMany words have more than one\nmeaning\n; we have to select the meaning which makes the most sense in context.  For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or an online resource such as\nWordNet\n.\nEntity linking\nMany words—typically proper names—refer to\nnamed entities\n; here we have to select the entity (a famous individual, a location, a company, etc.) which is referred to in context.\nRelational semantics (semantics of individual sentences)\n[\nedit\n]\nRelationship extraction\nGiven a chunk of text, identify the relationships among named entities (e.g. who is married to whom).\nSemantic parsing\nGiven a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in\nAMR parsing\n) or in accordance with a logical formalism (e.g., in\nDRT parsing\n). This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word-sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see\nNatural language understanding\nbelow).\nSemantic role labelling\n(see also implicit semantic role labelling below)\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal\nframes\n), then identify and classify the frame elements (\nsemantic roles\n).\nDiscourse (semantics beyond individual sentences)\n[\nedit\n]\nCoreference resolution\nGiven a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\").\nAnaphora resolution\nis a specific example of this task, and is specifically concerned with matching up\npronouns\nwith the nouns or names to which they refer. The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving\nreferring expressions\n. For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\nDiscourse analysis\nThis rubric includes several related tasks.  One task is discourse parsing, i.e., identifying the\ndiscourse\nstructure of a connected text, i.e. the nature of the discourse relationships between sentences (e.g. elaboration, explanation, contrast).  Another possible task is recognizing and classifying the\nspeech acts\nin a chunk of text (e.g. yes–no question, content question, statement, assertion, etc.).\nImplicit semantic role labelling\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal\nframes\n) and their explicit semantic roles in the current sentence (see\nSemantic role labelling\nabove). Then, identify semantic roles that are not explicitly realized in the current sentence, classify them into arguments that are explicitly realized elsewhere in the text and those that are not specified, and resolve the former against the local text. A closely related task is zero anaphora resolution, i.e., the extension of coreference resolution to\npro-drop languages\n.\nRecognizing textual entailment\nGiven two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false.\n[\n32\n]\nTopic segmentation\nand recognition\nGiven a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment.\nArgument mining\nThe goal of argument mining is the automatic extraction and identification of argumentative structures from\nnatural language\ntext with the aid of computer programs.\n[\n33\n]\nSuch argumentative structures include the premise, conclusions, the\nargument scheme\nand the relationship between the main and subsidiary argument, or the main and counter-argument within discourse.\n[\n34\n]\n[\n35\n]\nHigher-level NLP applications\n[\nedit\n]\nMachine translation in Firefox\nAutomatic summarization\n(text summarization)\nProduce a readable summary of a chunk of text.  Often used to provide summaries of the text of a known type, such as research papers, articles in the financial section of a newspaper.\nGrammatical error correction\nGrammatical error detection and correction involves a great band-width of problems on all levels of linguistic analysis (phonology/orthography, morphology, syntax, semantics, pragmatics). Grammatical error correction is impactful since it affects hundreds of millions of people that use or acquire English as a second language. It has thus been subject to a number of shared tasks since 2011.\n[\n36\n]\n[\n37\n]\n[\n38\n]\nAs far as orthography, morphology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as\nGPT-2\n, this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications.\nLogic translation\nTranslate a text from a natural language into formal logic.\nMachine translation\n(MT)\nAutomatically translate text from one human language to another.  This is one of the most difficult problems, and is a member of a class of problems colloquially termed \"\nAI-complete\n\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly.\nNatural language understanding\n(NLU)\nConvert chunks of text into more formal representations such as\nfirst-order logic\nstructures that are easier for\ncomputer\nprograms to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as\nclosed-world assumption\n(CWA) vs.\nopen-world assumption\n, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization.\n[\n39\n]\nNatural language generation\n(NLG):\nConvert information from computer databases or semantic intents into readable human language.\nBook generation\nNot an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter,\nThe policeman's beard is half-constructed\n).\n[\n40\n]\nThe first published work by a neural network was published in 2018,\n1 the Road\n, marketed as a novel, contains sixty million words. Both these systems are basically elaborate but non-sensical (semantics-free)\nlanguage models\n. The first machine-generated science book was published in 2019 (Beta Writer,\nLithium-Ion Batteries\n, Springer, Cham).\n[\n41\n]\nUnlike\nRacter\nand\n1 the Road\n, this is grounded on factual knowledge and based on text summarization.\nDocument AI\nA Document AI platform sits on top of the NLP technology enabling users with no prior experience of artificial intelligence, machine learning or NLP to quickly train a computer to extract the specific data they need from different document types. NLP-powered Document AI enables non-technical teams to quickly access information hidden in documents, for example, lawyers, business analysts and accountants.\n[\n42\n]\nDialogue management\nComputer systems intended to converse with a human.\nQuestion answering\nGiven a human-language question, determine its answer. Typical questions have a specific right answer (such as \"What is the capital of Canada?\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\").\nText-to-image generation\nGiven a description of an image, generate an image that matches the description.\n[\n43\n]\nText-to-scene generation\nGiven a description of a scene, generate a\n3D model\nof the scene.\n[\n44\n]\n[\n45\n]\nText-to-video\nGiven a description of a video, generate a video that matches the description.\n[\n46\n]\n[\n47\n]\nGeneral tendencies and (possible) future directions\n[\nedit\n]\nBased on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:\n[\n48\n]\nInterest on increasingly abstract, \"cognitive\" aspects of natural language (1999–2001: shallow parsing, 2002–03: named entity recognition, 2006–09/2017–18: dependency syntax, 2004–05/2008–09 semantic role labelling, 2011–12 coreference, 2015–16: discourse parsing, 2019: semantic parsing).\nIncreasing interest in multilinguality, and, potentially, multimodality (English since 1999; Spanish, Dutch since 2002; German since 2003; Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006; Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007; Czech since 2009; Arabic since 2012; 2017: 40+ languages; 2018: 60+/100+ languages)\nElimination of symbolic representations (rule-based over supervised towards weakly supervised methods, representation learning and end-to-end systems)\nCognition\n[\nedit\n]\nMost higher-level NLP applications involve aspects that emulate intelligent behavior and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behavior represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\nCognition\nrefers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"\n[\n49\n]\nCognitive science\nis the interdisciplinary, scientific study of the mind and its processes.\n[\n50\n]\nCognitive linguistics\nis an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.\n[\n51\n]\nEspecially during the age of\nsymbolic NLP\n, the area of computational linguistics maintained strong ties with cognitive studies.\nAs an example,\nGeorge Lakoff\noffers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,\n[\n52\n]\nwith two defining aspects:\nApply the theory of\nconceptual metaphor\n, explained by Lakoff as \"the understanding of one idea, in terms of another\" which provides an idea of the intent of the author.\n[\n53\n]\nFor example, consider the English word\nbig\n. When used in a comparison (\"That is a big tree\"), the author's intent is to imply that the tree is\nphysically large\nrelative to other trees or the authors experience.  When used metaphorically (\"Tomorrow is a big day\"), the author's intent to imply\nimportance\n.  The intent behind other usages, like in \"She is a big person\", will remain somewhat ambiguous to a person and a cognitive NLP algorithm alike without additional information.\nAssign relative measures of meaning to a word, phrase, sentence or piece of text based on the information presented before and after the piece of text being analyzed, e.g., by means of a\nprobabilistic context-free grammar\n(PCFG). The mathematical equation for such algorithms is presented in\nUS Patent 9269353\n:\n[\n54\n]\nR\nM\nM\n(\nt\no\nk\ne\nn\nN\n)\n=\nP\nM\nM\n(\nt\no\nk\ne\nn\nN\n)\n×\n1\n2\nd\n(\n∑\ni\n=\n−\nd\nd\n(\n(\nP\nM\nM\n(\nt\no\nk\ne\nn\nN\n)\n×\nP\nF\n(\nt\no\nk\ne\nn\nN\n−\ni\n,\nt\no\nk\ne\nn\nN\n,\nt\no\nk\ne\nn\nN\n+\ni\n)\n)\ni\n)\n{\\displaystyle {RMM(token_{N})}={PMM(token_{N})}\\times {\\frac {1}{2d}}\\left(\\sum _{i=-d}^{d}{((PMM(token_{N})}\\times {PF(token_{N-i},token_{N},token_{N+i}))_{i}}\\right)}\nWhere\nRMM\nis the relative measure of meaning\ntoken\nis any block of text, sentence, phrase or word\nN\nis the number of tokens being analyzed\nPMM\nis the probable measure of meaning based on a corpora\nd\nis the non zero location of the token along the sequence of\nN\ntokens\nPF\nis the probability function specific to a language\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,\n[\n55\n]\nfunctional grammar,\n[\n56\n]\nconstruction grammar,\n[\n57\n]\ncomputational psycholinguistics and cognitive neuroscience (e.g.,\nACT-R\n), however, with limited uptake in mainstream NLP (as measured by presence on major conferences\n[\n58\n]\nof the\nACL\n). More recently, ideas of cognitive NLP have been revived as an approach to achieve\nexplainability\n, e.g., under the notion of \"cognitive AI\".\n[\n59\n]\nLikewise, ideas of cognitive NLP are inherent to neural models\nmultimodal\nNLP (although rarely made explicit)\n[\n60\n]\nand developments in\nartificial intelligence\n, specifically tools and technologies using\nlarge language model\napproaches\n[\n61\n]\nand new directions in\nartificial general intelligence\nbased on the\nfree energy principle\n[\n62\n]\nby British neuroscientist and theoretician at University College London\nKarl J. Friston\n.\nSee also\n[\nedit\n]\n1 the Road\nArtificial intelligence detection software\nAutomated essay scoring\nBiomedical text mining\nCompound term processing\nComputational linguistics\nComputer-assisted reviewing\nControlled natural language\nDeep learning\nDeep linguistic processing\nDistributional semantics\nForeign language reading aid\nForeign language writing aid\nInformation extraction\nInformation retrieval\nLanguage and Communication Technologies\nLanguage model\nLanguage technology\nLatent semantic indexing\nMulti-agent system\nNative-language identification\nNatural-language programming\nNatural-language understanding\nNatural-language search\nOutline of natural language processing\nQuery expansion\nQuery understanding\nReification (linguistics)\nSpeech processing\nSpoken dialogue systems\nText-proofing\nText simplification\nTransformer (machine learning model)\nTruecasing\nQuestion answering\nWord2vec\nReferences\n[\nedit\n]\n^\nEisenstein, Jacob (October 1, 2019).\nIntroduction to Natural Language Processing\n. The MIT Press. p. 1.\nISBN\n978-0-262-04284-0\n.\n^\n\"NLP\"\n.\n^\nHutchins, J. (2005).\n\"The history of machine translation in a nutshell\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 2019-07-13\n. Retrieved\n2019-02-04\n.\n[\nself-published source\n]\n^\n\"ALPAC: the (in)famous report\", John Hutchins, MT News International, no. 14, June 1996, pp. 9–12.\n^\nCrevier 1993\n, pp. 146–148\nharvnb error: no target: CITEREFCrevier1993 (\nhelp\n)\n, see also\nBuchanan 2005\n, p. 56\nharvnb error: no target: CITEREFBuchanan2005 (\nhelp\n)\n: \"Early programs were necessarily limited in scope by the size and speed of memory\"\n^\nKoskenniemi, Kimmo\n(1983),\nTwo-level morphology: A general computational model of word-form recognition and production\n(PDF)\n, Department of General Linguistics,\nUniversity of Helsinki\n, archived from\nthe original\n(PDF)\non 2018-12-21\n, retrieved\n2020-08-20\n^\nJoshi, A. K., & Weinstein, S. (1981, August).\nControl of Inference: Role of Some Aspects of Discourse Structure-Centering\n. In\nIJCAI\n(pp. 385–387).\n^\nGuida, G.; Mauri, G. (July 1986). \"Evaluation of natural language processing systems: Issues and approaches\".\nProceedings of the IEEE\n.\n74\n(7):\n1026–\n1035.\ndoi\n:\n10.1109/PROC.1986.13580\n.\nISSN\n1558-2256\n.\nS2CID\n30688575\n.\n^\nChomskyan linguistics encourages the investigation of \"\ncorner cases\n\" that stress the limits of its theoretical models (comparable to\npathological\nphenomena in mathematics), typically created using\nthought experiments\n, rather than the systematic investigation of typical phenomena that occur in real-world data, as is the case in\ncorpus linguistics\n.  The creation and use of such\ncorpora\nof real-world data is a fundamental part of machine-learning algorithms for natural language processing.  In addition, theoretical underpinnings of Chomskyan linguistics such as the so-called \"\npoverty of the stimulus\n\" argument entail that general learning algorithms, as are typically used in machine learning, cannot be successful in language processing.  As a result, the Chomskyan paradigm discouraged the application of such models to language processing.\n^\nBengio, Yoshua; Ducharme, Réjean; Vincent, Pascal; Janvin, Christian (March 1, 2003).\n\"A neural probabilistic language model\"\n.\nThe Journal of Machine Learning Research\n.\n3\n:\n1137–\n1155 – via ACM Digital Library.\n^\nMikolov, Tomáš; Karafiát, Martin; Burget, Lukáš; Černocký, Jan; Khudanpur, Sanjeev (26 September 2010).\n\"Recurrent neural network based language model\"\n(PDF)\n.\nInterspeech 2010\n. pp.\n1045–\n1048.\ndoi\n:\n10.21437/Interspeech.2010-343\n.\nS2CID\n17048224\n.\n{{\ncite book\n}}\n:\n|journal=\nignored (\nhelp\n)\n^\nGoldberg, Yoav (2016). \"A Primer on Neural Network Models for Natural Language Processing\".\nJournal of Artificial Intelligence Research\n.\n57\n:\n345–\n420.\narXiv\n:\n1807.10854\n.\ndoi\n:\n10.1613/jair.4992\n.\nS2CID\n8273530\n.\n^\nGoodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016).\nDeep Learning\n. MIT Press.\n^\nJozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016).\nExploring the Limits of Language Modeling\n.\narXiv\n:\n1602.02410\n.\nBibcode\n:\n2016arXiv160202410J\n.\n^\nChoe, Do Kook; Charniak, Eugene.\n\"Parsing as Language Modeling\"\n.\nEmnlp 2016\n. Archived from\nthe original\non 2018-10-23\n. Retrieved\n2018-10-22\n.\n^\nVinyals, Oriol; et al. (2014).\n\"Grammar as a Foreign Language\"\n(PDF)\n.\nNips2015\n.\narXiv\n:\n1412.7449\n.\nBibcode\n:\n2014arXiv1412.7449V\n.\n^\nTurchin, Alexander; Florez Builes, Luisa F. (2021-03-19).\n\"Using Natural Language Processing to Measure and Improve Quality of Diabetes Care: A Systematic Review\"\n.\nJournal of Diabetes Science and Technology\n.\n15\n(3):\n553–\n560.\ndoi\n:\n10.1177/19322968211000831\n.\nISSN\n1932-2968\n.\nPMC\n8120048\n.\nPMID\n33736486\n.\n^\nLee, Jennifer; Yang, Samuel; Holland-Hall, Cynthia; Sezgin, Emre; Gill, Manjot; Linwood, Simon; Huang, Yungui; Hoffman, Jeffrey (2022-06-10).\n\"Prevalence of Sensitive Terms in Clinical Notes Using Natural Language Processing Techniques: Observational Study\"\n.\nJMIR Medical Informatics\n.\n10\n(6) e38482.\ndoi\n:\n10.2196/38482\n.\nISSN\n2291-9694\n.\nPMC\n9233261\n.\nPMID\n35687381\n.\n^\nWinograd, Terry (1971).\nProcedures as a Representation for Data in a Computer Program for Understanding Natural Language\n(Thesis).\n^\nSchank, Roger C.; Abelson, Robert P. (1977).\nScripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures\n. Hillsdale: Erlbaum.\nISBN\n0-470-99033-3\n.\n^\nMark Johnson. How the statistical revolution changes (computational) linguistics.\nProceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics.\n^\nPhilip Resnik. Four revolutions.\nLanguage Log, February 5, 2011.\n^\nSocher, Richard.\n\"Deep Learning For NLP-ACL 2012 Tutorial\"\n.\nwww.socher.org\n. Archived from\nthe original\non 2021-04-14\n. Retrieved\n2020-08-17\n.\nThis was an early Deep Learning tutorial at the ACL 2012 and met with both interest and (at the time) skepticism by most participants. Until then, neural learning was basically rejected because of its lack of statistical interpretability. Until 2015, deep learning had evolved into the major framework of NLP. [Link is broken, try\nhttp://web.stanford.edu/class/cs224n/\n]\n^\nSegev, Elad (2022).\nSemantic Network Analysis in Social Sciences\n. London: Routledge.\nISBN\n978-0-367-63652-4\n.\nArchived\nfrom the original on 5 December 2021\n. Retrieved\n5 December\n2021\n.\n^\nYi, Chucai;\nTian, Yingli\n(2012), \"Assistive Text Reading from Complex Background for Blind Persons\",\nCamera-Based Document Analysis and Recognition\n, Lecture Notes in Computer Science, vol. 7139, Springer Berlin Heidelberg, pp.\n15–\n28,\nCiteSeerX\n10.1.1.668.869\n,\ndoi\n:\n10.1007/978-3-642-29364-1_2\n,\nISBN\n978-3-642-29363-4\n^\na\nb\n\"Natural Language Processing (NLP) - A Complete Guide\"\n.\nwww.deeplearning.ai\n. 2023-01-11\n. Retrieved\n2024-05-05\n.\n^\n\"GeeksforGeeks. (n.d.). Tokenization in natural language processing (NLP). GeeksforGeeks\"\n.\ngeeksforgeeks\n.\n^\n\"What is Natural Language Processing? Intro to NLP in Machine Learning\"\n.\nGyanSetu!\n. 2020-12-06\n. Retrieved\n2021-01-09\n.\n^\nKishorjit, N.; Vidya, Raj RK.; Nirmal, Y.; Sivaji, B. (2012).\n\"Manipuri Morpheme Identification\"\n(PDF)\n.\nProceedings of the 3rd Workshop on South and Southeast Asian Natural Language Processing (SANLP)\n. COLING 2012, Mumbai, December 2012:\n95–\n108.\n{{\ncite journal\n}}\n:  CS1 maint: location (\nlink\n)\n^\nKlein, Dan; Manning, Christopher D. (2002).\n\"Natural language grammar induction using a constituent-context model\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n^\nKariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Mathé, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023).\n\"Precision information extraction for rare disease epidemiology at scale\"\n.\nJournal of Translational Medicine\n.\n21\n(1): 157.\ndoi\n:\n10.1186/s12967-023-04011-y\n.\nPMC\n9972634\n.\nPMID\n36855134\n.\n^\nPASCAL Recognizing Textual Entailment Challenge (RTE-7)\nhttps://tac.nist.gov//2011/RTE/\n^\nLippi, Marco; Torroni, Paolo (2016-04-20).\n\"Argumentation Mining: State of the Art and Emerging Trends\"\n.\nACM Transactions on Internet Technology\n.\n16\n(2):\n1–\n25.\ndoi\n:\n10.1145/2850417\n.\nhdl\n:\n11585/523460\n.\nISSN\n1533-5399\n.\nS2CID\n9561587\n.\n^\n\"Argument Mining – IJCAI2016 Tutorial\"\n.\nwww.i3s.unice.fr\n. Archived from\nthe original\non 2021-04-18\n. Retrieved\n2021-03-09\n.\n^\n\"NLP Approaches to Computational Argumentation – ACL 2016, Berlin\"\n. Retrieved\n2021-03-09\n.\n^\nAdministration.\n\"Centre for Language Technology (CLT)\"\n.\nMacquarie University\n. Retrieved\n2021-01-11\n.\n^\n\"Shared Task: Grammatical Error Correction\"\n.\nwww.comp.nus.edu.sg\n. Retrieved\n2021-01-11\n.\n^\n\"Shared Task: Grammatical Error Correction\"\n.\nwww.comp.nus.edu.sg\n. Retrieved\n2021-01-11\n.\n^\nDuan, Yucong; Cruz, Christophe (2011).\n\"Formalizing Semantic of Natural Language through Conceptualization from Existence\"\n.\nInternational Journal of Innovation, Management and Technology\n.\n2\n(1):\n37–\n42. Archived from\nthe original\non 2011-10-09.\n^\n\"U B U W E B :: Racter\"\n.\nwww.ubu.com\n. Retrieved\n2020-08-17\n.\n^\nWriter, Beta (2019).\nLithium-Ion Batteries\n.\ndoi\n:\n10.1007/978-3-030-16800-1\n.\nISBN\n978-3-030-16799-8\n.\nS2CID\n155818532\n.\n^\n\"Document Understanding AI on Google Cloud (Cloud Next '19) – YouTube\"\n.\nwww.youtube.com\n. 11 April 2019. Archived from\nthe original\non 2021-10-30\n. Retrieved\n2021-01-11\n.\n^\nRobertson, Adi (2022-04-06).\n\"OpenAI's DALL-E AI image generator can now edit pictures, too\"\n.\nThe Verge\n. Retrieved\n2022-06-07\n.\n^\n\"The Stanford Natural Language Processing Group\"\n.\nnlp.stanford.edu\n. Retrieved\n2022-06-07\n.\n^\nCoyne, Bob; Sproat, Richard (2001-08-01).\n\"WordsEye\"\n.\nProceedings of the 28th annual conference on Computer graphics and interactive techniques\n. SIGGRAPH '01. New York, NY, USA: Association for Computing Machinery. pp.\n487–\n496.\ndoi\n:\n10.1145/383259.383316\n.\nISBN\n978-1-58113-374-5\n.\nS2CID\n3842372\n.\n^\n\"Google announces AI advances in text-to-video, language translation, more\"\n.\nVentureBeat\n. 2022-11-02\n. Retrieved\n2022-11-09\n.\n^\nVincent, James (2022-09-29).\n\"Meta's new text-to-video AI generator is like DALL-E for video\"\n.\nThe Verge\n. Retrieved\n2022-11-09\n.\n^\n\"Previous shared tasks | CoNLL\"\n.\nwww.conll.org\n. Retrieved\n2021-01-11\n.\n^\n\"Cognition\"\n.\nLexico\n.\nOxford University Press\nand\nDictionary.com\n. Archived from\nthe original\non July 15, 2020\n. Retrieved\n6 May\n2020\n.\n^\n\"Ask the Cognitive Scientist\"\n.\nAmerican Federation of Teachers\n. 8 August 2014.\nCognitive science is an interdisciplinary field of researchers from Linguistics, psychology, neuroscience, philosophy, computer science, and anthropology that seek to understand the mind.\n^\nRobinson, Peter (2008).\nHandbook of Cognitive Linguistics and Second Language Acquisition\n. Routledge. pp.\n3–\n8.\nISBN\n978-0-805-85352-0\n.\n^\nLakoff, George (1999).\nPhilosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm\n. New York Basic Books. pp.\n569–\n583.\nISBN\n978-0-465-05674-3\n.\n^\nStrauss, Claudia (1999).\nA Cognitive Theory of Cultural Meaning\n. Cambridge University Press. pp.\n156–\n164.\nISBN\n978-0-521-59541-4\n.\n^\nUS patent 9269353\n^\n\"Universal Conceptual Cognitive Annotation (UCCA)\"\n.\nUniversal Conceptual Cognitive Annotation (UCCA)\n. Retrieved\n2021-01-11\n.\n^\nRodríguez, F. C., & Mairal-Usón, R. (2016).\nBuilding an RRG computational grammar\n.\nOnomazein\n, (34), 86–117.\n^\n\"Fluid Construction Grammar – A fully operational processing system for construction grammars\"\n. Retrieved\n2021-01-11\n.\n^\n\"ACL Member Portal | The Association for Computational Linguistics Member Portal\"\n.\nwww.aclweb.org\n. Retrieved\n2021-01-11\n.\n^\n\"Chunks and Rules\"\n.\nW3C\n. Retrieved\n2021-01-11\n.\n^\nSocher, Richard; Karpathy, Andrej; Le, Quoc V.; Manning, Christopher D.; Ng, Andrew Y. (2014).\n\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\"\n.\nTransactions of the Association for Computational Linguistics\n.\n2\n:\n207–\n218.\ndoi\n:\n10.1162/tacl_a_00177\n.\nS2CID\n2317858\n.\n^\nDasgupta, Ishita; Lampinen, Andrew K.; Chan, Stephanie C. Y.; Creswell, Antonia; Kumaran, Dharshan; McClelland, James L.; Hill, Felix (2022). \"Language models show human-like content effects on reasoning, Dasgupta, Lampinen et al\".\narXiv\n:\n2207.07051\n[\ncs.CL\n].\n^\nFriston, Karl J. (2022).\nActive Inference: The Free Energy Principle in Mind, Brain, and Behavior; Chapter 4 The Generative Models of Active Inference\n. The MIT Press.\nISBN\n978-0-262-36997-8\n.\nFurther reading\n[\nedit\n]\nBates, M (1995).\n\"Models of natural language understanding\"\n.\nProceedings of the National Academy of Sciences of the United States of America\n.\n92\n(22):\n9977–\n9982.\nBibcode\n:\n1995PNAS...92.9977B\n.\ndoi\n:\n10.1073/pnas.92.22.9977\n.\nPMC\n40721\n.\nPMID\n7479812\n.\nSteven Bird, Ewan Klein, and Edward Loper (2009).\nNatural Language Processing with Python\n. O'Reilly Media.\nISBN\n978-0-596-51649-9\n.\nKenna Hughes-Castleberry\n, \"A Murder Mystery Puzzle: The literary puzzle\nCain's Jawbone\n, which has stumped humans for decades, reveals the limitations of natural-language-processing algorithms\",\nScientific American\n, vol. 329, no. 4 (November 2023), pp. 81–82. \"This murder mystery competition has revealed that although NLP (\nnatural-language processing\n) models are capable of incredible feats, their abilities are very much limited by the amount of\ncontext\nthey receive. This [...] could cause [difficulties] for researchers who hope to use them to do things such as analyze\nancient languages\n. In some cases, there are few historical records on long-gone\ncivilizations\nto serve as\ntraining data\nfor such a purpose.\" (p. 82.)\nDaniel Jurafsky and James H. Martin (2008).\nSpeech and Language Processing\n, 2nd edition. Pearson Prentice Hall.\nISBN\n978-0-13-187321-6\n.\nMohamed Zakaria Kurdi (2016).\nNatural Language Processing and Computational Linguistics: speech, morphology, and syntax\n, Volume 1. ISTE-Wiley.\nISBN\n978-1848218482\n.\nMohamed Zakaria Kurdi (2017).\nNatural Language Processing and Computational Linguistics: semantics, discourse, and applications\n, Volume 2. ISTE-Wiley.\nISBN\n978-1848219212\n.\nChristopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze (2008).\nIntroduction to Information Retrieval\n. Cambridge University Press.\nISBN\n978-0-521-86571-5\n.\nOfficial html and pdf versions available without charge.\nChristopher D. Manning and Hinrich Schütze (1999).\nFoundations of Statistical Natural Language Processing\n. The MIT Press.\nISBN\n978-0-262-13360-9\n.\nDavid M. W. Powers and Christopher C. R. Turk (1989).\nMachine Learning of Natural Language\n. Springer-Verlag.\nISBN\n978-0-387-19557-5\n.\nExternal links\n[\nedit\n]\nMedia related to\nNatural language processing\nat Wikimedia Commons\nv\nt\ne\nNatural language processing\nGeneral terms\nAI-complete\nBag-of-words\nn\n-gram\nBigram\nTrigram\nComputational linguistics\nNatural language understanding\nStop words\nText processing\nText analysis\nArgument mining\nCollocation extraction\nConcept mining\nCoreference resolution\nDeep linguistic processing\nDistant reading\nInformation extraction\nNamed-entity recognition\nOntology learning\nParsing\nsemantic\nsyntactic\nPart-of-speech tagging\nSemantic analysis\nSemantic role labeling\nSemantic decomposition\nSemantic similarity\nSentiment analysis\nTerminology extraction\nText mining\nTextual entailment\nTruecasing\nWord-sense disambiguation\nWord-sense induction\nText segmentation\nCompound-term processing\nLemmatisation\nLexical analysis\nText chunking\nStemming\nSentence segmentation\nWord segmentation\nAutomatic summarization\nMulti-document summarization\nSentence extraction\nText simplification\nMachine translation\nComputer-assisted\nExample-based\nRule-based\nStatistical\nTransfer-based\nNeural\nDistributional semantics\nmodels\nBERT\nDocument-term matrix\nExplicit semantic analysis\nfastText\nGloVe\nLanguage model\nlarge\nsmall\nLatent semantic analysis\nLong short-term memory\nSeq2seq\nTransformer\nWord embedding\nWord2vec\nLanguage resources\n,\ndatasets and corpora\nTypes and\nstandards\nCorpus linguistics\nLexical resource\nLinguistic Linked Open Data\nMachine-readable dictionary\nParallel text\nPropBank\nSemantic network\nSimple Knowledge Organization System\nSpeech corpus\nText corpus\nThesaurus (information retrieval)\nTreebank\nUniversal Dependencies\nData\nBabelNet\nBank of English\nDBpedia\nFrameNet\nGoogle Ngram Viewer\nUBY\nWordNet\nWikidata\nAutomatic identification\nand data capture\nSpeech recognition\nSpeech segmentation\nSpeech synthesis\nNatural language generation\nOptical character recognition\nTopic model\nDocument classification\nLatent Dirichlet allocation\nPachinko allocation\nComputer-assisted\nreviewing\nAutomated essay scoring\nConcordancer\nGrammar checker\nPredictive text\nPronunciation assessment\nSpell checker\nNatural language\nuser interface\nChatbot\nInteractive fiction\nQuestion answering\nVirtual assistant\nVoice user interface\nRelated\nFormal semantics\nHallucination\nNatural Language Toolkit\nspaCy\nPortal\n:\nLanguage\nAuthority control databases\nNational\nUnited States\nJapan\nCzech Republic\nIsrael\nOther\nYale LUX\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1327359726\n\"\nCategories\n:\nNatural language processing\nComputational fields of study\nComputational linguistics\nSpeech recognition\nHidden categories:\nAll accuracy disputes\nAccuracy disputes from December 2013\nHarv and Sfn no-target errors\nCS1 errors: periodical ignored\nCS1 maint: location\nArticles with short description\nShort description is different from Wikidata\nArticles needing additional references from May 2024\nAll articles needing additional references\nWikipedia articles needing rewrite from July 2025\nAll articles needing rewrite\nWikipedia articles needing reorganization from July 2025\nArticles with multiple maintenance issues\nCommons category link from Wikidata\nThis page was last edited on 14 December 2025, at 00:40\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nNatural language processing\n71 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:08.825195",
      "status": "success",
      "content_length": 53276,
      "topic": "nlp"
    },
    {
      "title": "Word embedding - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Word_embedding",
      "content": "Word embedding - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nDevelopment and history of the approach\n2\nPolysemy and homonymy\n3\nFor biological sequences: BioVectors\n4\nGame design\n5\nSentence embeddings\n6\nSoftware\nToggle Software subsection\n6.1\nExamples of application\n7\nEthical implications\n8\nSee also\n9\nReferences\nToggle the table of contents\nWord embedding\n23 languages\nالعربية\nCatalà\nČeština\nDeutsch\nEspañol\nEuskara\nفارسی\nFrançais\n한국어\nItaliano\nעברית\n日本語\nNorsk bokmål\nPolski\nPortuguês\nРусский\nکوردی\nСрпски / srpski\nไทย\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nMethod in natural language processing\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nIllustration of word embedding. Each word is a point in some space. Word embedding enables a processor to perform semantic operations like obtaining the capital of a given country.\nIn\nnatural language processing\n, a\nword embedding\nis a representation of a word. The\nembedding\nis used in\ntext analysis\n. Typically, the representation is a\nreal-valued\nvector that encodes the meaning of the word in such a way that the words that are closer in the vector space are expected to be similar in meaning.\n[\n1\n]\nWord embeddings can be obtained using\nlanguage modeling\nand\nfeature learning\ntechniques, where words or phrases from the vocabulary are mapped to\nvectors\nof\nreal numbers\n.\nMethods to generate this mapping include\nneural networks\n,\n[\n2\n]\ndimensionality reduction\non the word\nco-occurrence matrix\n,\n[\n3\n]\n[\n4\n]\n[\n5\n]\nprobabilistic models,\n[\n6\n]\nexplainable knowledge base method,\n[\n7\n]\nand explicit representation in terms of the context in which words appear.\n[\n8\n]\nWord and phrase embeddings, when used as the underlying input representation, have been shown to boost the performance in NLP tasks such as\nsyntactic parsing\n[\n9\n]\nand\nsentiment analysis\n.\n[\n10\n]\nDevelopment and history of the approach\n[\nedit\n]\nIn\ndistributional semantics\n, a quantitative methodological approach for understanding meaning in observed language, word embeddings or semantic\nfeature space\nmodels have been used as a knowledge representation for some time.\n[\n11\n]\nSuch models aim to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data.  The underlying idea that \"a word is characterized by the company it keeps\" was proposed in a 1957 article by\nJohn Rupert Firth\n,\n[\n12\n]\nbut also has roots in the contemporaneous work on search systems\n[\n13\n]\nand in cognitive psychology.\n[\n14\n]\nThe notion of a semantic space with lexical items (words or multi-word terms) represented as vectors or embeddings is based on the computational challenges of capturing distributional characteristics and using them for practical application to measure similarity between words, phrases, or entire documents. The first generation of semantic space models is the\nvector space model\nfor information retrieval.\n[\n15\n]\n[\n16\n]\n[\n17\n]\nSuch vector space models for words and their distributional data implemented in their simplest form results in a very sparse vector space of high dimensionality (cf.\ncurse of dimensionality\n). Reducing the number of dimensions using linear algebraic methods such as\nsingular value decomposition\nthen led to the introduction of\nlatent semantic analysis\nin the late 1980s and the\nrandom indexing\napproach for collecting word co-occurrence contexts.\n[\n18\n]\n[\n19\n]\n[\n20\n]\n[\n21\n]\nIn 2000,\nBengio\net al. provided in a series of papers titled \"Neural probabilistic language models\" to reduce the high dimensionality of word representations in contexts by \"learning a distributed representation for words\".\n[\n22\n]\n[\n23\n]\n[\n24\n]\nA study published in\nNeurIPS\n(NIPS) 2002 introduced the use of both word and document embeddings applying the method of kernel CCA to bilingual (and multi-lingual) corpora, also providing an early example of\nself-supervised learning\nof word embeddings.\n[\n25\n]\nWord embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in Lavelli et al., 2004.\n[\n26\n]\nRoweis and Saul published in\nScience\nhow to use \"\nlocally linear embedding\n\" (LLE) to discover representations of high dimensional data structures.\n[\n27\n]\nMost new word embedding techniques after about 2005 rely on a\nneural network\narchitecture instead of more probabilistic and algebraic models, after foundational work done by Yoshua Bengio\n[\n28\n]\n[\ncircular reference\n]\nand colleagues.\n[\n29\n]\n[\n30\n]\nThe approach has been adopted by many research groups after theoretical advances in 2010 had been made on the quality of vectors and the training speed of the model, as well as after hardware advances allowed for a broader\nparameter space\nto be explored profitably. In 2013, a team at\nGoogle\nled by\nTomas Mikolov\ncreated\nword2vec\n, a word embedding toolkit that can train vector space models faster than previous approaches. The word2vec approach has been widely used in experimentation and was instrumental in raising interest for word embeddings as a technology, moving the research strand out of specialised research into broader experimentation and eventually paving the way for practical application.\n[\n31\n]\nPolysemy and homonymy\n[\nedit\n]\nHistorically, one of the main limitations of static word embeddings or word\nvector space models\nis that words with multiple meanings are conflated into a single representation (a single vector in the semantic space). In other words,\npolysemy\nand\nhomonymy\nare not handled properly. For example, in the sentence \"The club I tried yesterday was great!\", it is not clear if the term\nclub\nis related to the word sense of a\nclub sandwich\n,\nclubhouse\n,\ngolf club\n, or any other sense that\nclub\nmight have. The necessity to accommodate multiple meanings per word in different vectors (multi-sense embeddings) is the motivation for several contributions in NLP to split single-sense embeddings into multi-sense ones.\n[\n32\n]\n[\n33\n]\nMost approaches that produce multi-sense embeddings can be divided into two main categories for their word sense representation, i.e., unsupervised and knowledge-based.\n[\n34\n]\nBased on\nword2vec\nskip-gram, Multi-Sense Skip-Gram (MSSG)\n[\n35\n]\nperforms word-sense discrimination and embedding simultaneously, improving its training time, while assuming a specific number of senses for each word. In the Non-Parametric Multi-Sense Skip-Gram (NP-MSSG) this number can vary depending on each word. Combining the prior knowledge of lexical databases (e.g.,\nWordNet\n,\nConceptNet\n,\nBabelNet\n), word embeddings and\nword sense disambiguation\n, Most Suitable Sense Annotation (MSSA)\n[\n36\n]\nlabels word-senses through an unsupervised and knowledge-based approach, considering a word's context in a pre-defined sliding window. Once the words are disambiguated, they can be used in a standard word embeddings technique, so multi-sense embeddings are produced. MSSA architecture allows the disambiguation and annotation process to be performed recurrently in a self-improving manner.\n[\n37\n]\nThe use of multi-sense embeddings is known to improve performance in several NLP tasks, such as\npart-of-speech tagging\n, semantic relation identification,\nsemantic relatedness\n,\nnamed entity recognition\nand sentiment analysis.\n[\n38\n]\n[\n39\n]\nAs of the late 2010s, contextually-meaningful embeddings such as\nELMo\nand\nBERT\nhave been developed.\n[\n40\n]\nUnlike static word embeddings, these embeddings are at the token-level, in that each occurrence of a word has its own embedding. These embeddings better reflect the multi-sense nature of words, because occurrences of a word in similar contexts are situated in similar regions of BERT's embedding space.\n[\n41\n]\n[\n42\n]\nFor biological sequences: BioVectors\n[\nedit\n]\nWord embeddings for\nn-\ngrams in biological sequences (e.g. DNA, RNA, and Proteins) for\nbioinformatics\napplications have been proposed by Asgari and Mofrad.\n[\n43\n]\nNamed bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in\nproteomics\nand\ngenomics\n. The results presented by Asgari and Mofrad\n[\n43\n]\nsuggest that BioVectors can characterize biological sequences in terms of biochemical and biophysical interpretations of the underlying patterns.\nGame design\n[\nedit\n]\nWord embeddings with applications in\ngame design\nhave been proposed by Rabii and Cook\n[\n44\n]\nas a way to discover\nemergent gameplay\nusing logs of gameplay data. The process requires transcribing actions that occur during a game within a\nformal language\nand then using the resulting text to create word embeddings. The results presented by Rabii and Cook\n[\n44\n]\nsuggest that the resulting vectors can capture expert knowledge about games like\nchess\nthat are not explicitly stated in the game's rules.\nSentence embeddings\n[\nedit\n]\nMain article:\nSentence embedding\nThe idea has been extended to embeddings of entire sentences or even documents, e.g. in the form of the\nthought vectors\nconcept. In 2015, some researchers suggested \"skip-thought vectors\" as a means to improve the quality of\nmachine translation\n.\n[\n45\n]\nA more recent and popular approach for representing sentences is Sentence-BERT, or SentenceTransformers, which modifies pre-trained\nBERT\nwith the use of siamese and triplet network structures.\n[\n46\n]\nSoftware\n[\nedit\n]\nSoftware for training and using word embeddings includes\nTomáš Mikolov\n's\nWord2vec\n, Stanford University's\nGloVe\n,\n[\n47\n]\nGN-GloVe,\n[\n48\n]\nFlair embeddings,\n[\n38\n]\nAllenNLP's\nELMo\n,\n[\n49\n]\nBERT\n,\n[\n50\n]\nfastText\n,\nGensim\n,\n[\n51\n]\nIndra,\n[\n52\n]\nand\nDeeplearning4j\n.\nPrincipal Component Analysis\n(PCA) and\nT-Distributed Stochastic Neighbour Embedding\n(t-SNE) are both used to reduce the dimensionality of word vector spaces and visualize word embeddings and\nclusters\n.\n[\n53\n]\nExamples of application\n[\nedit\n]\nFor instance, the fastText is also used to calculate word embeddings for\ntext corpora\nin\nSketch Engine\nthat are available online.\n[\n54\n]\nEthical implications\n[\nedit\n]\nWord embeddings may contain the biases and stereotypes contained in the trained dataset, as Bolukbasi et al. points out in the 2016 paper \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\" that a publicly available (and popular) word2vec embedding trained on\nGoogle News\ntexts (a commonly used data corpus), which consists of text written by professional journalists, still shows disproportionate word associations reflecting gender and racial biases when extracting word analogies.\n[\n55\n]\nFor example, one of the analogies generated using the aforementioned word embedding is \"man is to computer programmer as woman is to homemaker\".\n[\n56\n]\n[\n57\n]\nResearch done by Jieyu Zhou et al. shows that the applications of these trained word embeddings without careful oversight likely perpetuates existing bias in society, which is introduced through unaltered training data. Furthermore, word embeddings can even amplify these biases.\n[\n58\n]\n[\n59\n]\nSee also\n[\nedit\n]\nEmbedding (machine learning)\nBrown clustering\nDistributional–relational database\nReferences\n[\nedit\n]\n^\nJurafsky, Daniel; H. James, Martin (2000).\nSpeech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition\n. Upper Saddle River, N.J.: Prentice Hall.\nISBN\n978-0-13-095069-7\n.\n^\nMikolov, Tomas; Sutskever, Ilya; Chen, Kai; Corrado, Greg; Dean, Jeffrey (2013). \"Distributed Representations of Words and Phrases and their Compositionality\".\narXiv\n:\n1310.4546\n[\ncs.CL\n].\n^\nLebret, Rémi; Collobert, Ronan (2013). \"Word Emdeddings through Hellinger PCA\".\nConference of the European Chapter of the Association for Computational Linguistics (EACL)\n. Vol. 2014.\narXiv\n:\n1312.5542\n.\n^\nLevy, Omer; Goldberg, Yoav (2014).\nNeural Word Embedding as Implicit Matrix Factorization\n(PDF)\n. NIPS.\n^\nLi, Yitan; Xu, Linli (2015).\nWord Embedding Revisited: A New Representation Learning and Explicit Matrix Factorization Perspective\n(PDF)\n. Int'l J. Conf. on Artificial Intelligence (IJCAI).\n^\nGloberson, Amir (2007).\n\"Euclidean Embedding of Co-occurrence Data\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n^\nQureshi, M. Atif; Greene, Derek (2018-06-04). \"EVE: explainable vector based embedding technique using Wikipedia\".\nJournal of Intelligent Information Systems\n.\n53\n:\n137–\n165.\narXiv\n:\n1702.06891\n.\ndoi\n:\n10.1007/s10844-018-0511-x\n.\nISSN\n0925-9902\n.\nS2CID\n10656055\n.\n^\nLevy, Omer; Goldberg, Yoav (2014).\nLinguistic Regularities in Sparse and Explicit Word Representations\n(PDF)\n. CoNLL. pp.\n171–\n180.\n^\nSocher, Richard; Bauer, John; Manning, Christopher; Ng, Andrew (2013).\nParsing with compositional vector grammars\n(PDF)\n. Proc. ACL Conf. Archived from\nthe original\n(PDF)\non 2016-08-11\n. Retrieved\n2014-08-14\n.\n^\nSocher, Richard; Perelygin, Alex; Wu, Jean; Chuang, Jason; Manning, Chris; Ng, Andrew; Potts, Chris (2013).\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\n(PDF)\n. EMNLP.\n^\nSahlgren, Magnus.\n\"A brief history of word embeddings\"\n.\n^\nFirth, J.R. (1957). \"A synopsis of linguistic theory 1930–1955\".\nStudies in Linguistic Analysis\n:\n1–\n32.\nReprinted in\nF.R. Palmer, ed. (1968).\nSelected Papers of J.R. Firth 1952–1959\n. London: Longman.\n{{\ncite book\n}}\n:  CS1 maint: publisher location (\nlink\n)\n^\nLuhn, H.P. (1953). \"A New Method of Recording and Searching Information\".\nAmerican Documentation\n.\n4\n:\n14–\n16.\ndoi\n:\n10.1002/asi.5090040104\n.\n^\nOsgood, C.E.; Suci, G.J.; Tannenbaum, P.H. (1957).\nThe Measurement of Meaning\n. University of Illinois Press.\n^\nSalton, Gerard (1962). \"Some experiments in the generation of word and document associations\".\nProceedings of the December 4-6, 1962, fall joint computer conference on - AFIPS '62 (Fall)\n. pp.\n234–\n250.\ndoi\n:\n10.1145/1461518.1461544\n.\nISBN\n978-1-4503-7879-6\n.\nS2CID\n9937095\n.\n{{\ncite book\n}}\n:\nISBN / Date incompatibility (\nhelp\n)\n^\nSalton, Gerard; Wong, A; Yang, C S (1975). \"A Vector Space Model for Automatic Indexing\".\nCommunications of the ACM\n.\n18\n(11):\n613–\n620.\ndoi\n:\n10.1145/361219.361220\n.\nhdl\n:\n1813/6057\n.\nS2CID\n6473756\n.\n^\nDubin, David (2004).\n\"The most influential paper Gerard Salton never wrote\"\n. Archived from\nthe original\non 18 October 2020\n. Retrieved\n18 October\n2020\n.\n^\nKanerva, Pentti, Kristoferson, Jan and Holst, Anders (2000):\nRandom Indexing of Text Samples for Latent Semantic Analysis\n, Proceedings of the 22nd Annual Conference of the Cognitive Science Society, p. 1036. Mahwah, New Jersey: Erlbaum, 2000.\n^\nKarlgren, Jussi; Sahlgren, Magnus (2001). Uesaka, Yoshinori; Kanerva, Pentti; Asoh, Hideki (eds.). \"From words to understanding\".\nFoundations of Real-World Intelligence\n. CSLI Publications:\n294–\n308.\n^\nSahlgren, Magnus (2005)\nAn Introduction to Random Indexing\n, Proceedings of the Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering, TKE 2005, August 16, Copenhagen, Denmark\n^\nSahlgren, Magnus, Holst, Anders and Pentti Kanerva (2008)\nPermutations as a Means to Encode Order in Word Space\n, In Proceedings of the 30th Annual Conference of the Cognitive Science Society: 1300–1305.\n^\nBengio, Yoshua; Réjean, Ducharme; Pascal, Vincent (2000).\n\"A Neural Probabilistic Language Model\"\n(PDF)\n.\nNeurIPS\n.\n^\nBengio, Yoshua\n; Ducharme, Réjean; Vincent, Pascal; Jauvin, Christian (2003).\n\"A Neural Probabilistic Language Model\"\n(PDF)\n.\nJournal of Machine Learning Research\n.\n3\n:\n1137–\n1155.\n^\nBengio, Yoshua; Schwenk, Holger; Senécal, Jean-Sébastien; Morin, Fréderic; Gauvain, Jean-Luc (2006). \"A Neural Probabilistic Language Model\".\nStudies in Fuzziness and Soft Computing\n. Vol. 194. Springer. pp.\n137–\n186.\ndoi\n:\n10.1007/3-540-33486-6_6\n.\nISBN\n978-3-540-30609-2\n.\n^\nVinkourov, Alexei; Cristianini, Nello; Shawe-Taylor, John (2002).\nInferring a semantic representation of text via cross-language correlation analysis\n(PDF)\n. Advances in Neural Information Processing Systems. Vol. 15.\n^\nLavelli, Alberto; Sebastiani, Fabrizio; Zanoli, Roberto (2004).\nDistributional term representations: an experimental comparison\n. 13th ACM International Conference on Information and Knowledge Management. pp.\n615–\n624.\ndoi\n:\n10.1145/1031171.1031284\n.\n^\nRoweis, Sam T.; Saul, Lawrence K. (2000). \"Nonlinear Dimensionality Reduction by Locally Linear Embedding\".\nScience\n.\n290\n(5500):\n2323–\n6.\nBibcode\n:\n2000Sci...290.2323R\n.\nCiteSeerX\n10.1.1.111.3313\n.\ndoi\n:\n10.1126/science.290.5500.2323\n.\nPMID\n11125150\n.\nS2CID\n5987139\n.\n^\nhe:יהושע בנג'יו\n^\nMorin, Fredric; Bengio, Yoshua (2005).\n\"Hierarchical probabilistic neural network language model\"\n(PDF)\n. In Cowell, Robert G.; Ghahramani, Zoubin (eds.).\nProceedings of the Tenth International Workshop on Artificial Intelligence and Statistics\n. Proceedings of Machine Learning Research. Vol. R5. pp.\n246–\n252.\n^\nMnih, Andriy; Hinton, Geoffrey (2009).\n\"A Scalable Hierarchical Distributed Language Model\"\n.\nAdvances in Neural Information Processing Systems\n. 21 (NIPS 2008). Curran Associates, Inc.:\n1081–\n1088.\n^\n\"word2vec\"\n.\nGoogle Code Archive\n. Retrieved\n23 July\n2021\n.\n^\nReisinger, Joseph; Mooney, Raymond J. (2010).\nMulti-Prototype Vector-Space Models of Word Meaning\n. Vol. Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Los Angeles, California: Association for Computational Linguistics. pp.\n109–\n117.\nISBN\n978-1-932432-65-7\n. Retrieved\nOctober 25,\n2019\n.\n^\nHuang, Eric. (2012).\nImproving word representations via global context and multiple word prototypes\n.\nOCLC\n857900050\n.\n^\nCamacho-Collados, Jose; Pilehvar, Mohammad Taher (2018). \"From Word to Sense Embeddings: A Survey on Vector Representations of Meaning\".\narXiv\n:\n1805.04032\n[\ncs.CL\n].\n^\nNeelakantan, Arvind; Shankar, Jeevan; Passos, Alexandre; McCallum, Andrew (2014). \"Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space\".\nProceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n. Stroudsburg, PA, USA: Association for Computational Linguistics. pp.\n1059–\n1069.\narXiv\n:\n1504.06654\n.\ndoi\n:\n10.3115/v1/d14-1113\n.\nS2CID\n15251438\n.\n^\nRuas, Terry; Grosky, William; Aizawa, Akiko (2019-12-01). \"Multi-sense embeddings through a word sense disambiguation process\".\nExpert Systems with Applications\n.\n136\n:\n288–\n303.\narXiv\n:\n2101.08700\n.\ndoi\n:\n10.1016/j.eswa.2019.06.026\n.\nhdl\n:\n2027.42/145475\n.\nISSN\n0957-4174\n.\nS2CID\n52225306\n.\n^\nAgre, Gennady; Petrov, Daniel; Keskinova, Simona (2019-03-01).\n\"Word Sense Disambiguation Studio: A Flexible System for WSD Feature Extraction\"\n.\nInformation\n.\n10\n(3): 97.\ndoi\n:\n10.3390/info10030097\n.\nISSN\n2078-2489\n.\n^\na\nb\nAkbik, Alan; Blythe, Duncan; Vollgraf, Roland (2018).\n\"Contextual String Embeddings for Sequence Labeling\"\n.\nProceedings of the 27th International Conference on Computational Linguistics\n. Santa Fe, New Mexico, USA: Association for Computational Linguistics:\n1638–\n1649.\n^\nLi, Jiwei; Jurafsky, Dan (2015). \"Do Multi-Sense Embeddings Improve Natural Language Understanding?\".\nProceedings of the 2015 Conference on Empirical Methods in Natural Language Processing\n. Stroudsburg, PA, USA: Association for Computational Linguistics. pp.\n1722–\n1732.\narXiv\n:\n1506.01070\n.\ndoi\n:\n10.18653/v1/d15-1200\n.\nS2CID\n6222768\n.\n^\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (June 2019).\n\"Proceedings of the 2019 Conference of the North\"\n.\nProceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\n. Association for Computational Linguistics:\n4171–\n4186.\ndoi\n:\n10.18653/v1/N19-1423\n.\nS2CID\n52967399\n.\n^\nLucy, Li, and David Bamman. \"Characterizing English variation across social media communities with BERT.\" Transactions of the Association for Computational Linguistics 9 (2021): 538-556.\n^\nReif, Emily, Ann Yuan, Martin Wattenberg, Fernanda B. Viegas, Andy Coenen, Adam Pearce, and Been Kim. \"Visualizing and measuring the geometry of BERT.\" Advances in Neural Information Processing Systems 32 (2019).\n^\na\nb\nAsgari, Ehsaneddin; Mofrad, Mohammad R.K. (2015).\n\"Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics\"\n.\nPLOS ONE\n.\n10\n(11) e0141287.\narXiv\n:\n1503.05140\n.\nBibcode\n:\n2015PLoSO..1041287A\n.\ndoi\n:\n10.1371/journal.pone.0141287\n.\nPMC\n4640716\n.\nPMID\n26555596\n.\n^\na\nb\nRabii, Younès; Cook, Michael (2021-10-04).\n\"Revealing Game Dynamics via Word Embeddings of Gameplay Data\"\n.\nProceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment\n.\n17\n(1):\n187–\n194.\ndoi\n:\n10.1609/aiide.v17i1.18907\n.\nISSN\n2334-0924\n.\nS2CID\n248175634\n.\n^\nKiros, Ryan; Zhu, Yukun; Salakhutdinov, Ruslan; Zemel, Richard S.; Torralba, Antonio; Urtasun, Raquel; Fidler, Sanja (2015). \"skip-thought vectors\".\narXiv\n:\n1506.06726\n[\ncs.CL\n].\n^\nReimers, Nils, and Iryna Gurevych. \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.\" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 3982-3992. 2019.\n^\n\"GloVe\"\n.\n^\nZhao, Jieyu; et al. (2018) (2018). \"Learning Gender-Neutral Word Embeddings\".\narXiv\n:\n1809.01496\n[\ncs.CL\n].\n^\n\"Elmo\"\n. 16 October 2024.\n^\nPires, Telmo; Schlinger, Eva; Garrette, Dan (2019-06-04). \"How multilingual is Multilingual BERT?\".\narXiv\n:\n1906.01502\n[\ncs.CL\n].\n^\n\"Gensim\"\n.\n^\n\"Indra\"\n.\nGitHub\n. 2018-10-25.\n^\nGhassemi, Mohammad; Mark, Roger; Nemati, Shamim (2015).\n\"A visualization of evolving clinical sentiment using vector representations of clinical notes\"\n(PDF)\n.\n2015 Computing in Cardiology Conference (CinC)\n. Vol. 2015. pp.\n629–\n632.\ndoi\n:\n10.1109/CIC.2015.7410989\n.\nISBN\n978-1-5090-0685-4\n.\nPMC\n5070922\n.\nPMID\n27774487\n.\n^\n\"Embedding Viewer\"\n.\nEmbedding Viewer\n. Lexical Computing. Archived from\nthe original\non 8 February 2018\n. Retrieved\n7 Feb\n2018\n.\n^\nBolukbasi, Tolga; Chang, Kai-Wei; Zou, James; Saligrama, Venkatesh; Kalai, Adam (2016). \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\".\narXiv\n:\n1607.06520\n[\ncs.CL\n].\n^\nBolukbasi, Tolga; Chang, Kai-Wei; Zou, James; Saligrama, Venkatesh; Kalai, Adam (2016-07-21). \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\".\narXiv\n:\n1607.06520\n[\ncs.CL\n].\n^\nDieng, Adji B.; Ruiz, Francisco J. R.; Blei, David M. (2020).\n\"Topic Modeling in Embedding Spaces\"\n.\nTransactions of the Association for Computational Linguistics\n.\n8\n:\n439–\n453.\narXiv\n:\n1907.04907\n.\ndoi\n:\n10.1162/tacl_a_00325\n.\n^\nZhao, Jieyu; Wang, Tianlu; Yatskar, Mark; Ordonez, Vicente; Chang, Kai-Wei (2017).\n\"Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints\"\n.\nProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing\n. pp.\n2979–\n2989.\ndoi\n:\n10.18653/v1/D17-1323\n.\n^\nPetreski, Davor; Hashim, Ibrahim C. (2022-05-26).\n\"Word embeddings are biased. But whose bias are they reflecting?\"\n.\nAI & Society\n.\n38\n(2):\n975–\n982.\ndoi\n:\n10.1007/s00146-022-01443-w\n.\nISSN\n1435-5655\n.\nS2CID\n249112516\n.\nv\nt\ne\nNatural language processing\nGeneral terms\nAI-complete\nBag-of-words\nn\n-gram\nBigram\nTrigram\nComputational linguistics\nNatural language understanding\nStop words\nText processing\nText analysis\nArgument mining\nCollocation extraction\nConcept mining\nCoreference resolution\nDeep linguistic processing\nDistant reading\nInformation extraction\nNamed-entity recognition\nOntology learning\nParsing\nsemantic\nsyntactic\nPart-of-speech tagging\nSemantic analysis\nSemantic role labeling\nSemantic decomposition\nSemantic similarity\nSentiment analysis\nTerminology extraction\nText mining\nTextual entailment\nTruecasing\nWord-sense disambiguation\nWord-sense induction\nText segmentation\nCompound-term processing\nLemmatisation\nLexical analysis\nText chunking\nStemming\nSentence segmentation\nWord segmentation\nAutomatic summarization\nMulti-document summarization\nSentence extraction\nText simplification\nMachine translation\nComputer-assisted\nExample-based\nRule-based\nStatistical\nTransfer-based\nNeural\nDistributional semantics\nmodels\nBERT\nDocument-term matrix\nExplicit semantic analysis\nfastText\nGloVe\nLanguage model\nlarge\nsmall\nLatent semantic analysis\nLong short-term memory\nSeq2seq\nTransformer\nWord embedding\nWord2vec\nLanguage resources\n,\ndatasets and corpora\nTypes and\nstandards\nCorpus linguistics\nLexical resource\nLinguistic Linked Open Data\nMachine-readable dictionary\nParallel text\nPropBank\nSemantic network\nSimple Knowledge Organization System\nSpeech corpus\nText corpus\nThesaurus (information retrieval)\nTreebank\nUniversal Dependencies\nData\nBabelNet\nBank of English\nDBpedia\nFrameNet\nGoogle Ngram Viewer\nUBY\nWordNet\nWikidata\nAutomatic identification\nand data capture\nSpeech recognition\nSpeech segmentation\nSpeech synthesis\nNatural language generation\nOptical character recognition\nTopic model\nDocument classification\nLatent Dirichlet allocation\nPachinko allocation\nComputer-assisted\nreviewing\nAutomated essay scoring\nConcordancer\nGrammar checker\nPredictive text\nPronunciation assessment\nSpell checker\nNatural language\nuser interface\nChatbot\nInteractive fiction\nQuestion answering\nVirtual assistant\nVoice user interface\nRelated\nFormal semantics\nHallucination\nNatural Language Toolkit\nspaCy\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Word_embedding&oldid=1323019878\n\"\nCategories\n:\nLanguage modeling\nArtificial neural networks\nNatural language processing\nComputational linguistics\nSemantic relations\nHidden categories:\nCS1 maint: publisher location\nCS1 errors: ISBN date\nCS1: long volume value\nArticles with short description\nShort description matches Wikidata\nAll articles lacking reliable references\nArticles lacking reliable references from May 2024\nAll articles containing circular references\nThis page was last edited on 19 November 2025, at 04:44\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nWord embedding\n23 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:11.472592",
      "status": "success",
      "content_length": 32631,
      "topic": "nlp"
    },
    {
      "title": "Language model - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Language_model",
      "content": "Language model - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\n2\nPure statistical models\nToggle Pure statistical models subsection\n2.1\nModels based on word\nn\n-grams\n2.2\nExponential\n2.3\nSkip-gram model\n3\nNeural models\nToggle Neural models subsection\n3.1\nRecurrent neural network\n3.2\nLarge language models\n4\nEvaluation and benchmarks\n5\nSee also\n6\nReferences\n7\nFurther reading\nToggle the table of contents\nLanguage model\n37 languages\nAfrikaans\nالعربية\nԱրեւմտահայերէն\nবাংলা\nБеларуская\nБългарски\nCatalà\nČeština\nDeutsch\nEesti\nEspañol\nEuskara\nفارسی\nFrançais\n한국어\nIsiZulu\nעברית\nJawa\nLatviešu\nNederlands\n日本語\nNorsk nynorsk\nOʻzbekcha / ўзбекча\nPolski\nPortuguês\nQaraqalpaqsha\nRuna Simi\nРусский\nShqip\nSuomi\nSvenska\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nStatistical model of language\nA\nlanguage model\nis a\nmodel\nof the human brain's ability to produce\nnatural language\n.\n[\n1\n]\n[\n2\n]\nLanguage models are useful for a variety of tasks, including\nspeech recognition\n,\n[\n3\n]\nmachine translation\n,\n[\n4\n]\nnatural language generation\n(generating more human-like text),\noptical character recognition\n,\nroute optimization\n,\n[\n5\n]\nhandwriting recognition\n,\n[\n6\n]\ngrammar induction\n,\n[\n7\n]\nand\ninformation retrieval\n.\n[\n8\n]\n[\n9\n]\nLarge language models\n(LLMs), currently their most advanced form as of 2019, are predominantly based on\ntransformers\ntrained on larger datasets (frequently using texts\nscraped\nfrom the public\ninternet\n). They have superseded\nrecurrent neural network\n-based models, which had previously superseded the purely statistical models, such as the\nword\nn\n-gram language model\n.\nHistory\n[\nedit\n]\nNoam Chomsky\ndid pioneering work on language models in the 1950s by developing a theory of\nformal grammars\n.\n[\n10\n]\nIn 1980, statistical approaches were explored and found to be more useful for many purposes than rule-based formal grammars. Discrete representations like\nword\nn\n-gram language models\n, with probabilities for discrete combinations of words, made significant advances.\nIn the 2000s, continuous representations for words, such as\nword embeddings\n, began to replace discrete representations.\n[\n11\n]\nTypically, the representation is a\nreal-valued\nvector that encodes the meaning of the word in such a way that the words that are closer in the vector space are expected to be similar in meaning, and common relationships between pairs of words like plurality or gender.\nPure statistical models\n[\nedit\n]\nIn 1980, the first significant statistical language model was proposed, and during the decade IBM performed '\nShannon\n-style' experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\n[\n12\n]\nModels based on word\nn\n-grams\n[\nedit\n]\nThis section is an excerpt from\nWord n-gram language model\n.\n[\nedit\n]\nA\nword\nn\n-gram language model\nis a statistical model of language which calculates the probability of the next word in a sequence from a fixed size window of previous words. If one previous word is considered, it is a bigram model; if two words, a trigram model; if\nn\n− 1 words, an\nn\n-gram model.\n[\n13\n]\nSpecial tokens are introduced to denote the start and end of a sentence\n⟨\ns\n⟩\n{\\displaystyle \\langle s\\rangle }\nand\n⟨\n/\ns\n⟩\n{\\displaystyle \\langle /s\\rangle }\n. To prevent a zero probability being assigned to unseen words, the probability of each seen word is slightly lowered to make room for the unseen words in a given\ncorpus\n. To achieve this, various\nsmoothing\nmethods are used, from simple \"add-one\" smoothing (assigning a count of 1 to unseen\nn\n-grams, as an\nuninformative prior\n) to more sophisticated techniques, such as\nGood–Turing discounting\nor\nback-off models\n.\nWord\nn-\ngram models have largely been superseded by\nrecurrent neural network\n–based models, which in turn have been superseded by\nTransformer\n-based models often referred to as\nlarge language models\n.\n[\n14\n]\nExponential\n[\nedit\n]\nMaximum entropy\nlanguage models encode the relationship between a word and the\nn\n-gram history using feature functions. The equation is\nP\n(\nw\nm\n∣\nw\n1\n,\n…\n,\nw\nm\n−\n1\n)\n=\n1\nZ\n(\nw\n1\n,\n…\n,\nw\nm\n−\n1\n)\nexp\n⁡\n(\na\nT\nf\n(\nw\n1\n,\n…\n,\nw\nm\n)\n)\n{\\displaystyle P(w_{m}\\mid w_{1},\\ldots ,w_{m-1})={\\frac {1}{Z(w_{1},\\ldots ,w_{m-1})}}\\exp(a^{T}f(w_{1},\\ldots ,w_{m}))}\nwhere\nZ\n(\nw\n1\n,\n…\n,\nw\nm\n−\n1\n)\n{\\displaystyle Z(w_{1},\\ldots ,w_{m-1})}\nis the\npartition function\n,\na\n{\\displaystyle a}\nis the parameter vector, and\nf\n(\nw\n1\n,\n…\n,\nw\nm\n)\n{\\displaystyle f(w_{1},\\ldots ,w_{m})}\nis the feature function. In the simplest case, the feature function is just an indicator of the presence of a certain\nn\n-gram. It is helpful to use a prior on\na\n{\\displaystyle a}\nor some form of\nregularization\n.\nThe log-bilinear model is another example of an exponential language model.\nSkip-gram model\n[\nedit\n]\nThis section is an excerpt from\nWord n-gram language model § Skip-gram language model\n.\n[\nedit\n]\n1-skip-2-grams for the text \"the rain in Spain falls mainly on the plain\"\nSkip-gram language model is an attempt at overcoming the data sparsity problem that the preceding model (i.e. word\nn\n-gram language model) faced. Words represented in an embedding vector were not necessarily consecutive anymore, but could leave gaps that are\nskipped\nover (thus the name \"skip-gram\").\n[\n15\n]\nFormally, a\nk\n-skip-\nn\n-gram is a length-\nn\nsubsequence where the components occur at distance at most\nk\nfrom each other.\nFor example, in the input text:\nthe rain in Spain falls mainly on the plain\nthe set of 1-skip-2-grams includes all the bigrams (2-grams), and in addition the subsequences\nthe in\n,\nrain Spain\n,\nin falls\n,\nSpain mainly\n,\nfalls on\n,\nmainly the\n, and\non plain\n.\nIn skip-gram model, semantic relations between words are represented by\nlinear combinations\n, capturing a form of\ncompositionality\n. For example, in some such models, if\nv\nis the function that maps a word\nw\nto its\nn\n-d vector representation, then\nv\n(\nk\ni\nn\ng\n)\n−\nv\n(\nm\na\nl\ne\n)\n+\nv\n(\nf\ne\nm\na\nl\ne\n)\n≈\nv\n(\nq\nu\ne\ne\nn\n)\n{\\displaystyle v(\\mathrm {king} )-v(\\mathrm {male} )+v(\\mathrm {female} )\\approx v(\\mathrm {queen} )}\nwhere ≈ is made precise by stipulating that its right-hand side must be the\nnearest neighbor\nof the value of the left-hand side.\n[\n16\n]\n[\n17\n]\nNeural models\n[\nedit\n]\nRecurrent neural network\n[\nedit\n]\nContinuous representations or\nembeddings of words\nare produced in\nrecurrent neural network\n-based language models (known also as\ncontinuous space language models\n).\n[\n18\n]\nSuch continuous space embeddings help to alleviate the\ncurse of dimensionality\n, which is the consequence of the number of possible sequences of words increasing\nexponentially\nwith the size of the vocabulary, further causing a data sparsity problem. Neural networks avoid this problem by representing words as non-linear combinations of weights in a neural net.\n[\n19\n]\nLarge language models\n[\nedit\n]\nThis section is an excerpt from\nLarge language model\n.\n[\nedit\n]\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nA\nlarge language model\n(LLM) is a language model trained with\nself-supervised\nmachine learning\non a vast amount of text, designed for\nnatural language processing\ntasks, especially\nlanguage generation\n.\n[\n20\n]\n[\n21\n]\nThe largest and most capable LLMs are\ngenerative\npre-trained\ntransformers\n(\nGPTs\n) and provide the core capabilities of modern\nchatbots\n. LLMs can be\nfine-tuned\nfor specific tasks or guided by\nprompt engineering\n.\n[\n22\n]\nThese models acquire\npredictive power\nregarding\nsyntax\n,\nsemantics\n, and\nontologies\n[\n23\n]\ninherent in human\nlanguage corpora\n, but they also inherit inaccuracies and\nbiases\npresent in the\ndata\nthey are trained on.\n[\n24\n]\nThey consist of billions to trillions of\nparameters\nand operate as general-purpose sequence models, generating, summarizing, translating, and reasoning over text. LLMs represent a significant new technology in their ability to generalize across tasks with minimal task-specific supervision, enabling capabilities like\nconversational agents\n,\ncode generation\n,\nknowledge retrieval\n, and\nautomated reasoning\nthat previously required bespoke systems.\n[\n25\n]\nLLMs evolved from earlier\nstatistical\nand\nrecurrent neural network\napproaches to language modeling. The\ntransformer architecture\n, introduced in 2017, replaced recurrence with\nself-attention\n, allowing efficient\nparallelization\n, longer context handling, and scalable training on unprecedented data volumes.\n[\n26\n]\nThis innovation enabled models like\nGPT\n,\nBERT\n, and their successors, which demonstrated\nemergent behaviors\nat scale, such as\nfew-shot learning\nand compositional reasoning.\n[\n27\n]\nReinforcement learning\n, particularly\npolicy gradient algorithms\n, has been adapted to\nfine-tune\nLLMs for desired behaviors beyond raw next-token prediction.\n[\n28\n]\nReinforcement learning from human feedback\n(RLHF) applies these methods to optimize a policy, the LLM's output distribution, against reward signals derived from human or automated preference judgments.\n[\n29\n]\nThis has been critical for aligning model outputs with user expectations, improving factuality, reducing harmful responses, and enhancing task performance.\nBenchmark\nevaluations for LLMs have evolved from narrow linguistic assessments toward comprehensive,\nmulti-task\nevaluations measuring\nreasoning\n,\nfactual accuracy\n,\nalignment\n, and\nsafety\n.\n[\n30\n]\n[\n31\n]\nHill climbing\n, iteratively optimizing models against benchmarks, has emerged as a dominant strategy, producing rapid incremental performance gains but raising concerns of\noverfitting\nto benchmarks rather than achieving genuine\ngeneralization\nor robust capability improvements.\n[\n32\n]\nAlthough sometimes matching human performance, it is not clear whether they are plausible\ncognitive models\n. At least for recurrent neural networks, it has been shown that they sometimes learn patterns that humans do not, but fail to learn patterns that humans typically do.\n[\n33\n]\nEvaluation and benchmarks\n[\nedit\n]\nEvaluation of the quality of language models is mostly done by comparison to human created sample benchmarks created from typical language-oriented tasks. Other, less established, quality tests examine the intrinsic character of a language model or compare two such models. Since language models are typically intended to be dynamic and to learn from data they see, some proposed models investigate the rate of learning, e.g., through inspection of learning curves.\n[\n34\n]\nVarious data sets have been developed for use in evaluating language processing systems.\n[\n35\n]\nThese include:\nMassive Multitask Language Understanding\n(MMLU)\n[\n36\n]\nCorpus of Linguistic Acceptability\n[\n37\n]\nGLUE benchmark\n[\n38\n]\nMicrosoft Research Paraphrase Corpus\n[\n39\n]\nMulti-Genre Natural Language Inference\nQuestion Natural Language Inference\nQuora Question Pairs\n[\n40\n]\nRecognizing Textual Entailment\n[\n41\n]\nSemantic Textual Similarity Benchmark\nSQuAD question answering Test\n[\n42\n]\nStanford Sentiment\nTreebank\n[\n43\n]\nWinograd NLI\nBoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, OpenBookQA, NaturalQuestions, TriviaQA, RACE, BIG-bench hard, GSM8k, RealToxicityPrompts, WinoGender, CrowS-Pairs\n[\n44\n]\nSee also\n[\nedit\n]\nLinguistics portal\nMathematics portal\nTechnology portal\nArtificial intelligence and elections\n– Impact of AI on political elections\nCache language model\nDeep linguistic processing\nEthics of artificial intelligence\nFactored language model\nGenerative pre-trained transformer\nKatz's back-off model\nLanguage technology\nSemantic similarity network\nStatistical model\nReferences\n[\nedit\n]\n^\nBlank, Idan A. (November 2023).\n\"What are large language models supposed to model?\"\n.\nTrends in Cognitive Sciences\n.\n27\n(11):\n987–\n989.\ndoi\n:\n10.1016/j.tics.2023.08.006\n.\nPMID\n37659920\n.\n\"LLMs are supposed to model how utterances behave.\"\n^\nJurafsky, Dan; Martin, James H. (2021).\n\"N-gram Language Models\"\n(PDF)\n.\nSpeech and Language Processing\n(3rd ed.).\nArchived\nfrom the original on 22 May 2022\n. Retrieved\n24 May\n2022\n.\n^\nKuhn, Roland, and Renato De Mori (1990).\n\"A cache-based natural language model for speech recognition\"\n.\nIEEE transactions on pattern analysis and machine intelligence\n12.6: 570–583.\n^\nAndreas, Jacob, Andreas Vlachos, and Stephen Clark (2013).\n\"Semantic parsing as machine translation\"\nArchived\n15 August 2020 at the\nWayback Machine\n. Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers).\n^\nLiu, Yang; Wu, Fanyou; Liu, Zhiyuan; Wang, Kai; Wang, Feiyue; Qu, Xiaobo (2023).\n\"Can language models be used for real-world urban-delivery route optimization?\"\n.\nThe Innovation\n.\n4\n(6) 100520.\nBibcode\n:\n2023Innov...400520L\n.\ndoi\n:\n10.1016/j.xinn.2023.100520\n.\nPMC\n10587631\n.\nPMID\n37869471\n.\n^\nPham, Vu, et al (2014).\n\"Dropout improves recurrent neural networks for handwriting recognition\"\nArchived\n11 November 2020 at the\nWayback Machine\n. 14th International Conference on Frontiers in Handwriting Recognition. IEEE.\n^\nHtut, Phu Mon, Kyunghyun Cho, and Samuel R. Bowman (2018).\n\"Grammar induction with neural language models: An unusual replication\"\nArchived\n14 August 2022 at the\nWayback Machine\n.\narXiv\n:\n1808.10000\n.\n^\nPonte, Jay M.; Croft, W. Bruce (1998).\nA language modeling approach to information retrieval\n. Proceedings of the 21st ACM SIGIR Conference. Melbourne, Australia: ACM. pp.\n275–\n281.\ndoi\n:\n10.1145/290941.291008\n.\n^\nHiemstra, Djoerd (1998).\nA linguistically motivated probabilistically model of information retrieval\n. Proceedings of the 2nd European conference on Research and Advanced Technology for Digital Libraries. LNCS, Springer. pp.\n569–\n584.\ndoi\n:\n10.1007/3-540-49653-X_34\n.\n^\nChomsky, N. (September 1956). \"Three models for the description of language\".\nIRE Transactions on Information Theory\n.\n2\n(3):\n113–\n124.\nBibcode\n:\n1956IRTIT...2..113C\n.\ndoi\n:\n10.1109/TIT.1956.1056813\n.\nISSN\n2168-2712\n.\n^\n\"The Nature Of Life, The Nature Of Thinking: Looking Back On Eugene Charniak's Work And Life\"\n. 22 February 2022.\nArchived\nfrom the original on 3 November 2024\n. Retrieved\n5 February\n2025\n.\n^\nRosenfeld, Ronald (2000).\n\"Two decades of statistical language modeling: Where do we go from here?\"\n.\nProceedings of the IEEE\n.\n88\n(8):\n1270–\n1278.\nBibcode\n:\n2000IEEEP..88.1270R\n.\ndoi\n:\n10.1109/5.880083\n.\nS2CID\n10959945\n.\n^\nJurafsky, Dan; Martin, James H. (7 January 2023). \"N-gram Language Models\".\nSpeech and Language Processing\n(PDF)\n(3rd edition draft ed.)\n. Retrieved\n24 May\n2022\n.\n^\nBengio, Yoshua; Ducharme, Réjean; Vincent, Pascal; Janvin, Christian (1 March 2003).\n\"A neural probabilistic language model\"\n.\nThe Journal of Machine Learning Research\n.\n3\n:\n1137–\n1155 – via ACM Digital Library.\n^\nDavid Guthrie; et al. (2006).\n\"A Closer Look at Skip-gram Modelling\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 17 May 2017\n. Retrieved\n27 April\n2014\n.\n^\nMikolov, Tomas; Chen, Kai; Corrado, Greg; Dean, Jeffrey (2013). \"Efficient estimation of word representations in vector space\".\narXiv\n:\n1301.3781\n[\ncs.CL\n].\n^\nMikolov, Tomas; Sutskever, Ilya; Chen, Kai; Corrado, Greg S.; Dean, Jeff (2013).\nDistributed Representations of Words and Phrases and their Compositionality\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n. pp.\n3111–\n3119.\nArchived\n(PDF)\nfrom the original on 29 October 2020\n. Retrieved\n22 June\n2015\n.\n^\nKarpathy, Andrej.\n\"The Unreasonable Effectiveness of Recurrent Neural Networks\"\n.\nArchived\nfrom the original on 1 November 2020\n. Retrieved\n27 January\n2019\n.\n^\nBengio, Yoshua (2008).\n\"Neural net language models\"\n.\nScholarpedia\n. Vol. 3. p. 3881.\nBibcode\n:\n2008SchpJ...3.3881B\n.\ndoi\n:\n10.4249/scholarpedia.3881\n.\nArchived\nfrom the original on 26 October 2020\n. Retrieved\n28 August\n2015\n.\n^\nBommasani, Rishi; Hudson, Drew A.; Adeli, Ehsan; Altman, Russ; Arora, Simran; von Arx, Matthew; Bernstein, Michael S.; Bohg, Jeannette; Bosselut, Antoine;\nBrunskill, Emma\n(2021). \"On the Opportunities and Risks of Foundation Models\".\narXiv\n:\n2108.07258\n.\n{{\ncite journal\n}}\n:\nCite journal requires\n|journal=\n(\nhelp\n)\n^\nBrown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda (2020). \"Language Models are Few-Shot Learners\".\narXiv\n:\n2005.14165\n[\ncs.CL\n].\n^\nBrown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (December 2020). Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.).\n\"Language Models are Few-Shot Learners\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n33\n. Curran Associates, Inc.:\n1877–\n1901.\narXiv\n:\n2005.14165\n.\ndoi\n:\n10.1145/3582269.3615599\n.\nArchived\n(PDF)\nfrom the original on 17 November 2023\n. Retrieved\n14 March\n2023\n.\n^\nFathallah, Nadeen; Das, Arunav; De Giorgis, Stefano; Poltronieri, Andrea; Haase, Peter; Kovriguina, Liubov (26 May 2024).\nNeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning\n(PDF)\n. Extended Semantic Web Conference 2024. Hersonissos, Greece.\n^\nManning, Christopher D.\n(2022).\n\"Human Language Understanding & Reasoning\"\n.\nDaedalus\n.\n151\n(2):\n127–\n138.\ndoi\n:\n10.1162/daed_a_01905\n.\nS2CID\n248377870\n.\nArchived\nfrom the original on 17 November 2023\n. Retrieved\n9 March\n2023\n.\n^\nKaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario (2020). \"Scaling Laws for Neural Language Models\".\narXiv\n:\n2001.08361\n[\ncs.LG\n].\n^\nVaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Łukasz; Polosukhin, Illia (2017). \"Attention is All you Need\".\narXiv\n:\n1706.03762\n[\ncs.CL\n].\n^\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\".\narXiv\n:\n1810.04805\n[\ncs.CL\n].\n^\nChristiano, Paul; Leike, Jan; Brown, Tom B.; Martic, Miljan; Legg, Shane; Amodei, Dario (2017). \"Deep Reinforcement Learning from Human Preferences\".\narXiv\n:\n1706.03741\n[\nstat.ML\n].\n^\nOuyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex (2022). \"Training language models to follow instructions with human feedback\".\narXiv\n:\n2203.02155\n[\ncs.CL\n].\n^\nWang, Alex; Singh, Amanpreet; Michael, Julian; Hill, Felix; Levy, Omer; Bowman, Samuel R. (2018). \"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\".\narXiv\n:\n1804.07461\n[\ncs.CL\n].\n^\nHendrycks, Dan; Burns, Collin; Basart, Steven; Zou, Andy; Mazeika, Mantas; Song, Dawn; Steinhardt, Jacob (2025). \"Expressing stigma and inappropriate responses prevents LLMS from safely replacing mental health providers\".\nProceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency\n. pp.\n599–\n627.\narXiv\n:\n2009.03300\n.\ndoi\n:\n10.1145/3715275.3732039\n.\nISBN\n979-8-4007-1482-5\n.\n^\nRecht, Benjamin; Roelofs, Rebecca; Schmidt, Ludwig; Shankar, Vaishaal (2019). \"Do ImageNet Classifiers Generalize to ImageNet?\".\narXiv\n:\n1902.10811\n[\ncs.CV\n].\n^\nHornstein, Norbert; Lasnik, Howard; Patel-Grosz, Pritty; Yang, Charles (9 January 2018).\nSyntactic Structures after 60 Years: The Impact of the Chomskyan Revolution in Linguistics\n. Walter de Gruyter GmbH & Co KG.\nISBN\n978-1-5015-0692-5\n.\nArchived\nfrom the original on 16 April 2023\n. Retrieved\n11 December\n2021\n.\n^\nKarlgren, Jussi; Schutze, Hinrich (2015), \"Evaluating Learning Language Representations\",\nInternational Conference of the Cross-Language Evaluation Forum\n, Lecture Notes in Computer Science, Springer International Publishing, pp.\n254–\n260,\ndoi\n:\n10.1007/978-3-319-64206-2_8\n,\nISBN\n978-3-319-64205-5\n^\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (10 October 2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\".\narXiv\n:\n1810.04805\n[\ncs.CL\n].\n^\nHendrycks, Dan (14 March 2023),\nMeasuring Massive Multitask Language Understanding\n,\narchived\nfrom the original on 15 March 2023\n, retrieved\n15 March\n2023\n^\n\"The Corpus of Linguistic Acceptability (CoLA)\"\n.\nnyu-mll.github.io\n.\nArchived\nfrom the original on 7 December 2020\n. Retrieved\n25 February\n2019\n.\n^\n\"GLUE Benchmark\"\n.\ngluebenchmark.com\n.\nArchived\nfrom the original on 4 November 2020\n. Retrieved\n25 February\n2019\n.\n^\n\"Microsoft Research Paraphrase Corpus\"\n.\nMicrosoft Download Center\n.\nArchived\nfrom the original on 25 October 2020\n. Retrieved\n25 February\n2019\n.\n^\nAghaebrahimian, Ahmad (2017), \"Quora Question Answer Dataset\",\nText, Speech, and Dialogue\n, Lecture Notes in Computer Science, vol. 10415, Springer International Publishing, pp.\n66–\n73,\ndoi\n:\n10.1007/978-3-319-64206-2_8\n,\nISBN\n978-3-319-64205-5\n^\nSammons, V.G.Vinod Vydiswaran, Dan Roth, Mark; Vydiswaran, V.G.; Roth, Dan.\n\"Recognizing Textual Entailment\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 9 August 2017\n. Retrieved\n24 February\n2019\n.\n{{\ncite web\n}}\n:  CS1 maint: multiple names: authors list (\nlink\n)\n^\n\"The Stanford Question Answering Dataset\"\n.\nrajpurkar.github.io\n.\nArchived\nfrom the original on 30 October 2020\n. Retrieved\n25 February\n2019\n.\n^\n\"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\"\n.\nnlp.stanford.edu\n.\nArchived\nfrom the original on 27 October 2020\n. Retrieved\n25 February\n2019\n.\n^\n\"llama/MODEL_CARD.md at main · meta-llama/llama\"\n.\nGitHub\n. Retrieved\n28 December\n2024\n.\nFurther reading\n[\nedit\n]\nJay M. Ponte; W. Bruce Croft (1998). \"A Language Modeling Approach to Information Retrieval\".\nResearch and Development in Information Retrieval\n. pp.\n275–\n281.\nCiteSeerX\n10.1.1.117.4237\n.\ndoi\n:\n10.1145/290941.291008\n.\nFei Song; W. Bruce Croft (1999). \"A General Language Model for Information Retrieval\".\nResearch and Development in Information Retrieval\n. pp.\n279–\n280.\nCiteSeerX\n10.1.1.21.6467\n.\ndoi\n:\n10.1145/319950.320022\n.\nChen, Stanley F.; Joshua Goodman (1998).\nAn Empirical Study of Smoothing Techniques for Language Modeling\n(Technical report). Harvard University.\nCiteSeerX\n10.1.1.131.5458\n.\nv\nt\ne\nNatural language processing\nGeneral terms\nAI-complete\nBag-of-words\nn\n-gram\nBigram\nTrigram\nComputational linguistics\nNatural language understanding\nStop words\nText processing\nText analysis\nArgument mining\nCollocation extraction\nConcept mining\nCoreference resolution\nDeep linguistic processing\nDistant reading\nInformation extraction\nNamed-entity recognition\nOntology learning\nParsing\nsemantic\nsyntactic\nPart-of-speech tagging\nSemantic analysis\nSemantic role labeling\nSemantic decomposition\nSemantic similarity\nSentiment analysis\nTerminology extraction\nText mining\nTextual entailment\nTruecasing\nWord-sense disambiguation\nWord-sense induction\nText segmentation\nCompound-term processing\nLemmatisation\nLexical analysis\nText chunking\nStemming\nSentence segmentation\nWord segmentation\nAutomatic summarization\nMulti-document summarization\nSentence extraction\nText simplification\nMachine translation\nComputer-assisted\nExample-based\nRule-based\nStatistical\nTransfer-based\nNeural\nDistributional semantics\nmodels\nBERT\nDocument-term matrix\nExplicit semantic analysis\nfastText\nGloVe\nLanguage model\nlarge\nsmall\nLatent semantic analysis\nLong short-term memory\nSeq2seq\nTransformer\nWord embedding\nWord2vec\nLanguage resources\n,\ndatasets and corpora\nTypes and\nstandards\nCorpus linguistics\nLexical resource\nLinguistic Linked Open Data\nMachine-readable dictionary\nParallel text\nPropBank\nSemantic network\nSimple Knowledge Organization System\nSpeech corpus\nText corpus\nThesaurus (information retrieval)\nTreebank\nUniversal Dependencies\nData\nBabelNet\nBank of English\nDBpedia\nFrameNet\nGoogle Ngram Viewer\nUBY\nWordNet\nWikidata\nAutomatic identification\nand data capture\nSpeech recognition\nSpeech segmentation\nSpeech synthesis\nNatural language generation\nOptical character recognition\nTopic model\nDocument classification\nLatent Dirichlet allocation\nPachinko allocation\nComputer-assisted\nreviewing\nAutomated essay scoring\nConcordancer\nGrammar checker\nPredictive text\nPronunciation assessment\nSpell checker\nNatural language\nuser interface\nChatbot\nInteractive fiction\nQuestion answering\nVirtual assistant\nVoice user interface\nRelated\nFormal semantics\nHallucination\nNatural Language Toolkit\nspaCy\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Language_model&oldid=1325979706\n\"\nCategories\n:\nLanguage modeling\nStatistical natural language processing\nMarkov models\nHidden categories:\nWebarchive template wayback links\nCS1 errors: missing periodical\nCS1 maint: multiple names: authors list\nArticles with short description\nShort description is different from Wikidata\nUse dmy dates from July 2022\nArticles with excerpts\nThis page was last edited on 6 December 2025, at 09:35\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nLanguage model\n37 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:13.779355",
      "status": "success",
      "content_length": 31539,
      "topic": "nlp"
    },
    {
      "title": "Named-entity recognition - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Named-entity_recognition",
      "content": "Named-entity recognition - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nProblem\nToggle Problem subsection\n1.1\nDefinition\n1.2\nDifficulties\n1.3\nFormal evaluation\n2\nApproaches\n3\nHistory\nToggle History subsection\n3.1\nCurrent challenges\n4\nSee also\n5\nReferences\nToggle the table of contents\nNamed-entity recognition\n19 languages\nالعربية\nCatalà\nČeština\nDeutsch\nEspañol\nEuskara\nفارسی\nFrançais\nGaeilge\n한국어\nעברית\nമലയാളം\n日本語\nPortuguês\nRomână\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nExtraction of named entity mentions in unstructured text into pre-defined categories\n\"Named entities\" redirects here. For HTML, XML, and SGML named entities, see\nList of XML and HTML character entity references\n.\nNamed-entity recognition\n(\nNER\n) (also known as\n(named)\nentity identification\n,\nentity chunking\n, and\nentity extraction\n) is a subtask of\ninformation extraction\nthat seeks to locate and classify\nnamed entities\nmentioned in\nunstructured text\ninto pre-defined categories such as person names (PER),\norganizations\n(ORG),\nlocations\n(LOC),\ngeopolitical entities\n(GPE),\nvehicles\n(VEH),\nmedical codes\n, time expressions, quantities, monetary values, percentages, etc.\nMost research on NER/NEE systems has been structured as taking an unannotated block of text, such as\ntransducing\n:\nJim bought 300 shares of Acme Corp. in 2006.\ninto an annotated block of text that highlights the names of entities:\n[Jim]\nPerson\nbought 300 shares of [Acme Corp.]\nOrganization\nin [2006]\nTime\n.\nIn this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.\nProblem\n[\nedit\n]\nDefinition\n[\nedit\n]\nIn the expression\nnamed entity\n, the word\nnamed\nrestricts the task to those entities for which one or many strings, such as words or phrases, stand (fairly) consistently for some referent. This is closely related to\nrigid designators\n, as defined by\nSaul Kripke\n,\n[\n1\n]\n[\n2\n]\nalthough in practice NER deals with many names and referents that are not philosophically \"rigid\". For instance, the\nautomotive company created by Henry Ford in 1903\ncan be referred to as\nFord\nor\nFord Motor Company\n, although \"Ford\" can refer to many other entities as well (see\nFord\n). Rigid designators include proper names as well as terms for certain biological species and substances,\n[\n3\n]\nbut exclude pronouns (such as \"it\"; see\ncoreference resolution\n), descriptions that pick out a referent by its properties (see also\nDe dicto and de re\n), and names for kinds of things as opposed to individuals (for example \"Bank\").\nFull named-entity recognition is often broken down, conceptually and possibly also in implementations,\n[\n4\n]\nas two distinct problems: detection of names, and\nclassification\nof the names by the type of entity they refer to (e.g. person, organization, or location).\n[\n5\n]\nThe first phase is typically simplified to a segmentation problem: names are defined to be contiguous spans of tokens, with no nesting, so that \"Bank of America\" is a single name, disregarding the fact that inside this name, the substring \"America\" is itself a name. This segmentation problem is formally similar to\nchunking\n. The second phase requires choosing an\nontology\nby which to organize categories of things.\nTemporal expressions\nand some numerical expressions (e.g., money, percentages, etc.) may also be considered as named entities in the context of the NER task. While some instances of these types are good examples of rigid designators (e.g., the year 2001) there are also many invalid ones (e.g., I take my vacations in “June”). In the first case, the year\n2001\nrefers to the\n2001st year of the Gregorian calendar\n. In the second case, the month\nJune\nmay refer to the month of an undefined year (\npast June\n,\nnext June\n,\nevery June\n, etc.). It is arguable that the definition of\nnamed entity\nis loosened in such cases for practical reasons. The definition of the term\nnamed entity\nis therefore not strict and often has to be explained in the context in which it is used.\n[\n6\n]\nCertain\nhierarchies\nof named entity types have been proposed in the literature.\nBBN\ncategories, proposed in 2002, are used for\nquestion answering\nand consists of 29 types and 64 subtypes.\n[\n7\n]\nSekine's extended hierarchy, proposed in 2002, is made of 200 subtypes.\n[\n8\n]\nMore recently, in 2011 Ritter used a hierarchy based on common\nFreebase\nentity types in ground-breaking experiments on NER over\nsocial media\ntext.\n[\n9\n]\nDifficulties\n[\nedit\n]\nNER involves ambiguities. The same name can refer to different entities of the same type. For example, \"JFK\" can refer to the\nformer president\nor\nhis son\n. This is basically a\nreference resolution\nproblem.\nThe same name can refer to completely different types. \"JFK\" might refer to\nthe airport in New York\n. \"IRA\" can refer to\nIndividual Retirement Account\nor\nInternational Reading Association\n.\nThis can be caused by\nmetonymy\n. For example, \"The White House\" can refer to an\norganization\ninstead of a\nlocation\n.\nFormal evaluation\n[\nedit\n]\nTo evaluate the quality of an NER system's output, several measures have been defined. The usual measures are called\nprecision, recall\n, and\nF1 score\n. However, several issues remain in just how to calculate those values.\nThese statistical measures work reasonably well for the obvious cases of finding or missing a real entity exactly; and for finding a non-entity. However, NER can fail in many other ways, many of which are arguably \"partially correct\", and should not be counted as complete success or failures. For example, identifying a real entity, but:\nwith fewer tokens than desired (for example, missing the last token of \"John Smith, M.D.\")\nwith more tokens than desired (for example, including the first word of \"The University of MD\")\npartitioning adjacent entities differently (for example, treating \"Smith, Jones Robinson\" as 2 vs. 3 entities)\nassigning it a completely wrong type (for example, calling a personal name an organization)\nassigning it a related but inexact type (for example, \"substance\" vs. \"drug\", or \"school\" vs. \"organization\")\ncorrectly identifying an entity, when what the user wanted was a smaller- or larger-scope entity (for example, identifying \"James Madison\" as a personal name, when it's part of \"James Madison University\"). Some NER systems impose the restriction that entities may never overlap or nest, which means that in some cases one must make arbitrary or task-specific choices.\nOne overly simple method of measuring accuracy is merely to count what fraction of all tokens in the text were correctly or incorrectly identified as part of entity references (or as being entities of the correct type). This suffers from at least two problems: first, the vast majority of tokens in real-world text are not part of entity names, so the baseline accuracy (always predict \"not an entity\") is extravagantly high, typically >90%; and second, mispredicting the full span of an entity name is not properly penalized (finding only a person's first name when his last name follows might be scored as ½ accuracy).\nIn academic conferences such as CoNLL, a variant of the\nF1 score\nhas been defined as follows:\n[\n5\n]\nPrecision\nis the number of predicted entity name spans that line up\nexactly\nwith spans in the\ngold standard\nevaluation data. I.e. when [\nPerson\nHans] [\nPerson\nBlick] is predicted but [\nPerson\nHans Blick] was required, precision for the predicted name is zero. Precision is then averaged over all predicted entity names.\nRecall is similarly the number of names in the gold standard that appear at exactly the same location in the predictions.\nF1 score is the\nharmonic mean\nof these two.\nIt follows from the above definition that any prediction that misses a single token, includes a spurious token, or has the wrong class, is a hard error and does not contribute positively to either precision or recall. Thus, this measure may be said to be pessimistic: it can be the case that many \"errors\" are close to correct, and might be adequate for a given purpose. For example, one system might always omit titles such as \"Ms.\" or \"Ph.D.\", but be compared to a system or ground-truth data that expects titles to be included. In that case, every such name is treated as an error. Because of such issues, it is important actually to examine the kinds of errors, and decide how important they are given one's goals and requirements.\nEvaluation models based on a token-by-token matching have been proposed.\n[\n10\n]\nSuch models may be given partial credit for overlapping matches (such as using the\nIntersection over Union\ncriterion). They allow a finer grained evaluation and comparison of extraction systems.\nApproaches\n[\nedit\n]\nNER systems have been created that use linguistic\ngrammar\n-based techniques as well as\nstatistical models\nsuch as\nmachine learning\n. State of the art systems may incorporate multiple approaches.\nGATE\nsupports NER across many languages and domains out of the box, usable via a\ngraphical interface\nand a\nJava\nAPI.\nOpenNLP\nincludes rule-based and statistical named-entity recognition.\nspaCy\nfeatures fast statistical NER as well as an open-source named-entity visualizer.\nHand-crafted grammar-based systems typically obtain better precision, but at the cost of lower recall and months of work by experienced\ncomputational linguists\n.\n[\n11\n]\nStatistical NER systems typically require a large amount of manually\nannotated\ntraining data.\nSemisupervised\napproaches have been suggested to avoid part of the annotation effort.\n[\n12\n]\n[\n13\n]\nIn the statistical learning era, NER was usually performed by learning a simple linear regression model on\nengineered features\n, then decoded by a bidirectional\nViterbi algorithm\n. Some commonly used features include:\n[\n14\n]\nLexical items: The token itself be labeled.\nStemmed\nlexical items.\nShape: The\northographic pattern\nof the target word. For example, all lowercase, all uppercase, initial uppercase, mixed case, uppercase followed by a period (often indicating a middle name), contains hyphen, etc.\nAffixes\nof the target word and surrounding words.\nPart of speech\nof the word.\nWhether the word appears in one or more named entity lists (gazetteers).\nWords and/or\nn-grams\noccurring in the surrounding context.\nA\ngazetteer\nis a list of names and their types, such as \"General Electric\". It can be used to augment any system for NER. They had been often used in the era of statistical machine learning.\n[\n15\n]\n[\n16\n]\nMany different classifier types have been used to perform machine-learned NER, with\nconditional random fields\nbeing a typical choice.\n[\n17\n]\nTransformers\nfeatures token classification using deep learning models.\n[\n18\n]\nHistory\n[\nedit\n]\nThis section needs to be\nupdated\n.\nPlease help update this article to reflect recent events or newly available information.\n(\nJuly 2021\n)\nEarly work in NER systems in the 1990s was aimed primarily at extraction from journalistic articles. Attention then turned to processing of military dispatches and reports. Later stages of the\nautomatic content extraction\n(ACE) evaluation also included several types of informal text styles, such as\nweblogs\nand\ntext transcripts\nfrom conversational telephone speech conversations. Since about 1998, there has been a great deal of interest in entity identification in the\nmolecular biology\n,\nbioinformatics\n, and medical\nnatural language processing\ncommunities.  The most common entity of interest in that domain has been names of\ngenes\nand gene products. There has been also considerable interest in the recognition of\nchemical entities\nand drugs in the context of the CHEMDNER\ncompetition, with 27 teams participating in this task.\n[\n19\n]\nIn 2001, research indicated that even state-of-the-art NER systems were brittle, meaning that NER systems developed for one domain did not typically perform well on other domains.\n[\n20\n]\nConsiderable effort is involved in tuning NER systems to perform well in a new domain; this is true for both rule-based and trainable statistical systems.\nAs of 2007, state-of-the-art NER systems for English produce near-human performance. For example, the best system entering\nMUC-7\nscored 93.39% of\nF-measure\nwhile human annotators scored 97.60% and 96.95%.\n[\n21\n]\n[\n22\n]\nCurrent challenges\n[\nedit\n]\nDespite high F1 numbers reported on the MUC-7 dataset, the problem of named-entity recognition is far from being solved. The main efforts are directed to reducing the annotations labor by employing\nsemi-supervised learning\n,\n[\n12\n]\n[\n23\n]\nrobust performance across domains\n[\n24\n]\n[\n25\n]\nand scaling up to fine-grained entity types.\n[\n8\n]\n[\n26\n]\nIn recent years, many projects have turned to\ncrowdsourcing\n, which is a promising solution to obtain high-quality aggregate human judgments for\nsupervised\nand semi-supervised machine learning approaches to NER.\n[\n27\n]\nAnother challenging task is devising models to deal with linguistically complex contexts such as Twitter and search queries.\n[\n28\n]\nThere are some researchers who did some comparisons about the NER performances from different statistical models such as HMM (\nhidden Markov model\n), ME (\nmaximum entropy\n), and CRF (\nconditional random fields\n), and feature sets.\n[\n29\n]\nAnd some researchers recently proposed graph-based semi-supervised learning model for language specific NER tasks.\n[\n30\n]\nA recently emerging task of identifying \"important expressions\" in text and\ncross-linking them to Wikipedia\n[\n31\n]\n[\n32\n]\n[\n33\n]\ncan be seen as an instance of extremely fine-grained named-entity recognition, where the types are the actual Wikipedia pages describing the (potentially ambiguous) concepts. Below is an example output of a Wikification system:\n<ENTITY\nurl=\n\"https://en.wikipedia.org/wiki/Michael_I._Jordan\"\n>\nMichael\nJordan\n</ENTITY>\nis\na\nprofessor\nat\n<ENTITY\nurl=\n\"https://en.wikipedia.org/wiki/University_of_California,_Berkeley\"\n>\nBerkeley\n</ENTITY>\nAnother field that has seen progress but remains challenging is the application of NER to\nTwitter\nand other microblogs, considered \"noisy\" due to non-standard orthography, shortness and informality of texts.\n[\n34\n]\n[\n35\n]\nNER challenges in English Tweets have been organized by research communities to compare performances of various approaches, such as\nbidirectional LSTMs\n, Learning-to-Search, or CRFs.\n[\n36\n]\n[\n37\n]\n[\n38\n]\nSee also\n[\nedit\n]\nControlled vocabulary\nCoreference resolution\nEntity linking\n(aka named entity normalization, entity disambiguation)\nInformation extraction\nKnowledge extraction\nOnomastics\nRecord linkage\nSmart tag (Microsoft)\nReferences\n[\nedit\n]\n^\nKripke, Saul (1971). \"Identity and Necessity\". In M.K. Munitz (ed.).\nIdentity and Individuation\n. New York: New York University Press. pp.\n135–\n64.\n{{\ncite book\n}}\n:  CS1 maint: publisher location (\nlink\n)\n^\nLaPorte, Joseph (2018).\n\"Rigid Designators\"\n.\nThe Stanford Encyclopedia of Philosophy\n.\n^\nNadeau, David; Sekine, Satoshi (2007).\nA survey of named entity recognition and classification\n(PDF)\n. Lingvisticae Investigationes.\n^\nCarreras, Xavier; Màrquez, Lluís; Padró, Lluís (2003).\nA simple named entity extractor using AdaBoost\n(PDF)\n. CoNLL.\n^\na\nb\nTjong Kim Sang, Erik F.; De Meulder, Fien (2003).\nIntroduction to the CoNLL-2003 shared task: Language-independent named entity recognition\n. CoNLL.\n^\nNamed Entity Definition\n. Webknox.com. Retrieved on 2013-07-21.\n^\nBrunstein, Ada.\n\"Annotation Guidelines for Answer Types\"\n.\nLDC Catalog\n. Linguistic Data Consortium. Archived from\nthe original\non 16 April 2016\n. Retrieved\n21 July\n2013\n.\n^\na\nb\nSekine's Extended Named Entity Hierarchy\n. Nlp.cs.nyu.edu. Retrieved on 2013-07-21.\n^\nRitter, A.; Clark, S.; Mausam; Etzioni., O. (2011).\nNamed Entity Recognition in Tweets: An Experimental Study\n(PDF)\n. Proc. Empirical Methods in Natural Language Processing.\n^\nEsuli, Andrea; Sebastiani, Fabrizio (2010).\nEvaluating Information Extraction\n(PDF)\n. Cross-Language Evaluation Forum (CLEF). pp.\n100–\n111.\n^\nKapetanios, Epaminondas; Tatar, Doina; Sacarea, Christian (2013-11-14).\nNatural Language Processing: Semantic Aspects\n. CRC Press. p. 298.\nISBN\n9781466584969\n.\n^\na\nb\nLin, Dekang; Wu, Xiaoyun (2009).\nPhrase clustering for discriminative learning\n(PDF)\n. Annual Meeting of the\nACL\nand IJCNLP. pp.\n1030–\n1038.\n^\nNothman, Joel; et al. (2013).\n\"Learning multilingual named entity recognition from Wikipedia\"\n.\nArtificial Intelligence\n.\n194\n:\n151–\n175.\ndoi\n:\n10.1016/j.artint.2012.03.006\n.\n^\nJurafsky, Dan; Martin, James H. (2009). \"22.1. Named Entity Recognition\".\nSpeech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition\n. Prentice Hall series in artificial intelligence (2 ed.). Upper Saddle River, N.J: Pearson Prentice Hall.\nISBN\n978-0-13-187321-6\n.\nOCLC\n213375806\n.\n^\nMikheev, Andrei; Moens, Marc; Grover, Claire (June 1999). Thompson, Henry S.; Lascarides, Alex (eds.).\n\"Named Entity Recognition without Gazetteers\"\n.\nNinth Conference of the European Chapter of the Association for Computational Linguistics\n. Bergen, Norway: Association for Computational Linguistics:\n1–\n8.\n^\nNadeau, David; Turney, Peter D.; Matwin, Stan (2006).\n\"Unsupervised Named-Entity Recognition: Generating Gazetteers and Resolving Ambiguity\"\n. In Lamontagne, Luc; Marchand, Mario (eds.).\nAdvances in Artificial Intelligence\n. Lecture Notes in Computer Science. Vol. 3060. Berlin, Heidelberg: Springer. pp.\n266–\n277.\ndoi\n:\n10.1007/11766247_23\n.\nISBN\n978-3-540-34630-2\n.\n^\nJenny Rose Finkel; Trond Grenager; Christopher Manning (2005).\nIncorporating Non-local Information into Information Extraction Systems by Gibbs Sampling\n(PDF)\n. 43rd Annual Meeting of the\nAssociation for Computational Linguistics\n. pp.\n363–\n370.\n^\nWolf; Debut, Lysandre; Sanh, Victor; Chaumond, Julien; Delangue, Clement; Moi, Anthony; Cistac, Pierric; Rault, Tim; Louf, Remi; Funtowicz, Morgan; Davison, Joe; Shleifer, Sam; von Platen, Patrick; Ma, Clara; Jernite, Yacine; Plu, Julien; Xu, Canwen; Le Scao, Teven; Gugger, Sylvain; Drame, Mariama; Lhoest, Quentin; Wolf, Thomas; Rush, Alexander (2020).\nTransformers: State-of-the-art natural language processing\n.\nProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\n. pp.\n38–\n45.\n^\nKrallinger, M; Leitner, F; Rabal, O; Vazquez, M; Oyarzabal, J; Valencia, A (2013). \"Overview of the chemical compound and drug name recognition (CHEMDNER) task\".\nProceedings of the Fourth BioCreative Challenge Evaluation Workshop vol. 2\n. pp.\n6–\n37.\nCiteSeerX\n10.1.1.684.4118\n.\n^\nPoibeau, Thierry; Kosseim, Leila (2001).\n\"Proper Name Extraction from Non-Journalistic Texts\"\n(PDF)\n.\nComputational Linguistics in the Netherlands 2000\n. Language and Computers. Vol. 37. pp.\n144–\n157.\ndoi\n:\n10.1163/9789004333901_011\n.\nISBN\n978-90-04-33390-1\n.\nS2CID\n12591786\n. Archived from\nthe original\n(PDF)\non 2019-07-30.\n^\nElaine Marsh, Dennis Perzanowski, \"MUC-7 Evaluation of IE Technology: Overview of Results\", 29 April 1998\nPDF\n^\nMUC-07 Proceedings (Named Entity Tasks)\n^\nTurian, J., Ratinov, L., & Bengio, Y. (2010, July). Word representations: a simple and general method for semi-supervised learning. In Proceeding of the 48th Annual Meeting of the Association for Computational Linguistics (pp. 384–394). Association for Computational Linguistics.\nPDF\n^\nRatinov, L., & Roth, D. (2009, June).\nDesign challenges and misconceptions in named entity recognition.\nIn\nProceedings of the Thirteenth Conference on Computational Natural Language Learning\n(pp. 147–155). Association for Computational Linguistics.\n^\n\"Frustratingly Easy Domain Adaptation\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 2010-06-13\n. Retrieved\n2012-04-05\n.\n^\nLee, Changki; Hwang, Yi-Gyu; Oh, Hyo-Jung; Lim, Soojong; Heo, Jeong; Lee, Chung-Hee; Kim, Hyeon-Jin; Wang, Ji-Hyun; Jang, Myung-Gil (2006).\n\"Fine-Grained Named Entity Recognition Using Conditional Random Fields for Question Answering\"\n.\nInformation Retrieval Technology\n. Lecture Notes in Computer Science. Vol. 4182. pp.\n581–\n587.\ndoi\n:\n10.1007/11880592_49\n.\nISBN\n978-3-540-45780-0\n.\n^\nWeb 2.0-based crowdsourcing for high-quality gold standard development in clinical Natural Language Processing\n^\nEiselt, Andreas; Figueroa, Alejandro (2013).\nA Two-Step Named Entity Recognizer for Open-Domain Search Queries\n. IJCNLP. pp.\n829–\n833.\n^\nHan, Li-Feng Aaron, Wong, Fai, Chao, Lidia Sam. (2013). Chinese Named Entity Recognition with Conditional Random Fields in the Light of Chinese Characteristics. Proceeding of International Conference of Language Processing and Intelligent Information Systems. M.A. Klopotek et al. (Eds.): IIS 2013, LNCS Vol. 7912, pp. 57–68\n[1]\n^\nHan, Li-Feng Aaron, Wong, Zeng, Xiaodong, Derek Fai, Chao, Lidia Sam. (2015). Chinese Named Entity Recognition with Graph-based Semi-supervised Learning Model. In Proceedings of SIGHAN workshop in ACL-IJCNLP. 2015.\n[2]\n^\nLinking Documents to Encyclopedic Knowledge.\n^\n\"Learning to link with Wikipedia\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 2019-01-25\n. Retrieved\n2014-07-21\n.\n^\nLocal and Global Algorithms for Disambiguation to Wikipedia.\n^\nDerczynski, Leon and\nDiana Maynard\n, Giuseppe Rizzo, Marieke van Erp, Genevieve Gorrell, Raphael Troncy, Johann Petrak, and Kalian Botcheva (2014). “Analysis of named entity recognition and linking for tweets”.\nInformation Processing and Management\n51(2) : pages 32–49.\n^\nBaldwin, Timothy; de Marneffe, Marie Catherine; Han, Bo; Kim, Young-Bum; Ritter, Alan; Xu, Wei (July 2015).\n\"Shared Tasks of the 2015 Workshop on Noisy User-generated Text: Twitter Lexical Normalization and Named Entity Recognition\"\n.\nProceedings of the Workshop on Noisy User-generated Text\n. Beijing, China: Association for Computational Linguistics:\n126–\n135.\ndoi\n:\n10.18653/v1/W15-4319\n.\nhdl\n:\n2078.1/284718\n.\nS2CID\n14500933\n.\n^\n\"COLING 2016 Workshop on Noisy User-generated Text (W-NUT)\"\n.\nnoisy-text.github.io\n. Retrieved\n2022-08-13\n.\n^\nPartalas, Ioannis; Lopez, Cédric; Derbas, Nadia; Kalitvianski, Ruslan (December 2016).\n\"Learning to Search for Recognizing Named Entities in Twitter\"\n.\nProceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)\n. Osaka, Japan: The COLING 2016 Organizing Committee:\n171–\n177.\n^\nLimsopatham, Nut; Collier, Nigel (December 2016).\n\"Bidirectional LSTM for Named Entity Recognition in Twitter Messages\"\n.\nProceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)\n. Osaka, Japan: The COLING 2016 Organizing Committee:\n145–\n152.\nJurafsky, Daniel; Martin, James H. (2008). \"13.5 Partial Parsing\".\nSpeech and Language Processing\n(2nd ed.). Upper Saddle River, N.J.: Prentice Hall.\nISBN\n978-0131873216\n.\nJurafsky, Daniel; Martin, James H. (2008). \"22.1. Named Entity Recognition\".\nSpeech and Language Processing\n(2nd ed.). Upper Saddle River, N.J.: Prentice Hall.\nISBN\n978-0131873216\n.\nv\nt\ne\nNatural language processing\nGeneral terms\nAI-complete\nBag-of-words\nn\n-gram\nBigram\nTrigram\nComputational linguistics\nNatural language understanding\nStop words\nText processing\nText analysis\nArgument mining\nCollocation extraction\nConcept mining\nCoreference resolution\nDeep linguistic processing\nDistant reading\nInformation extraction\nNamed-entity recognition\nOntology learning\nParsing\nsemantic\nsyntactic\nPart-of-speech tagging\nSemantic analysis\nSemantic role labeling\nSemantic decomposition\nSemantic similarity\nSentiment analysis\nTerminology extraction\nText mining\nTextual entailment\nTruecasing\nWord-sense disambiguation\nWord-sense induction\nText segmentation\nCompound-term processing\nLemmatisation\nLexical analysis\nText chunking\nStemming\nSentence segmentation\nWord segmentation\nAutomatic summarization\nMulti-document summarization\nSentence extraction\nText simplification\nMachine translation\nComputer-assisted\nExample-based\nRule-based\nStatistical\nTransfer-based\nNeural\nDistributional semantics\nmodels\nBERT\nDocument-term matrix\nExplicit semantic analysis\nfastText\nGloVe\nLanguage model\nlarge\nsmall\nLatent semantic analysis\nLong short-term memory\nSeq2seq\nTransformer\nWord embedding\nWord2vec\nLanguage resources\n,\ndatasets and corpora\nTypes and\nstandards\nCorpus linguistics\nLexical resource\nLinguistic Linked Open Data\nMachine-readable dictionary\nParallel text\nPropBank\nSemantic network\nSimple Knowledge Organization System\nSpeech corpus\nText corpus\nThesaurus (information retrieval)\nTreebank\nUniversal Dependencies\nData\nBabelNet\nBank of English\nDBpedia\nFrameNet\nGoogle Ngram Viewer\nUBY\nWordNet\nWikidata\nAutomatic identification\nand data capture\nSpeech recognition\nSpeech segmentation\nSpeech synthesis\nNatural language generation\nOptical character recognition\nTopic model\nDocument classification\nLatent Dirichlet allocation\nPachinko allocation\nComputer-assisted\nreviewing\nAutomated essay scoring\nConcordancer\nGrammar checker\nPredictive text\nPronunciation assessment\nSpell checker\nNatural language\nuser interface\nChatbot\nInteractive fiction\nQuestion answering\nVirtual assistant\nVoice user interface\nRelated\nFormal semantics\nHallucination\nNatural Language Toolkit\nspaCy\nAuthority control databases\nGND\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Named-entity_recognition&oldid=1312784544\n\"\nCategories\n:\nComputational linguistics\nTasks of natural language processing\nHidden categories:\nCS1 maint: publisher location\nArticles with short description\nShort description matches Wikidata\nWikipedia articles in need of updating from July 2021\nAll Wikipedia articles in need of updating\nThis page was last edited on 22 September 2025, at 16:06\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nNamed-entity recognition\n19 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:15.931859",
      "status": "success",
      "content_length": 26591,
      "topic": "nlp"
    },
    {
      "title": "Sentiment analysis - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Sentiment_analysis",
      "content": "Sentiment analysis - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nTypes\nToggle Types subsection\n1.1\nSubjectivity/objectivity identification\n1.2\nFeature/aspect-based\n1.3\nIntensity ranking\n2\nMethods and features\n3\nEvaluation\n4\nWeb 2.0\n5\nApplication in recommender systems\nToggle Application in recommender systems subsection\n5.1\nEthical considerations\n6\nSee also\n7\nReferences\nToggle the table of contents\nSentiment analysis\n25 languages\nالعربية\nCatalà\nČeština\nDeutsch\nΕλληνικά\nEspañol\nEuskara\nفارسی\nFrançais\n한국어\nՀայերեն\nItaliano\nעברית\nಕನ್ನಡ\n日本語\nРусский\nSlovenščina\nСрпски / srpski\nSuomi\nSvenska\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nProcess of classifying text based on its emotional tone\nSentiment analysis\n(also known as\nopinion mining\nor\nemotion AI\n) is the use of\nnatural language processing\n,\ntext analysis\n,\ncomputational linguistics\n, and\nbiometrics\nto systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to\nvoice of the customer\nmaterials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from\nmarketing\nto\ncustomer service\nto clinical medicine.\n[\ncitation needed\n]\nWith the rise of deep language models, such as\nRoBERTa\n, also more difficult data domains can be analyzed, e.g., news texts where authors typically express their opinion/sentiment less explicitly.\n[\n1\n]\nTypes\n[\nedit\n]\nA basic task in sentiment analysis is classifying the\npolarity\nof a given text at the document, sentence, or feature/aspect level—whether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral. Advanced, \"beyond polarity\" sentiment classification looks, for instance, at emotional states such as enjoyment, anger, disgust, sadness, fear, and surprise.\n[\n2\n]\nPrecursors to sentimental analysis include the General Inquirer,\n[\n3\n]\nwhich provided hints toward quantifying patterns in text and, separately, psychological research that examined a person's\npsychological state\nbased on analysis of their verbal behavior.\n[\n4\n]\nSubsequently, the method described in a patent by Volcani and Fogel,\n[\n5\n]\nlooked specifically at sentiment and identified individual words and phrases in text with respect to different emotional scales. A current system based on their work, called EffectCheck, presents synonyms that can be used to increase or decrease the level of evoked emotion in each scale.\nMany other subsequent efforts were less sophisticated, using a mere polar view of sentiment, from positive to negative, such as work by Turney,\n[\n6\n]\nand Pang\n[\n7\n]\nwho applied different methods for detecting the polarity of\nproduct reviews\nand movie reviews respectively. This work is at the document level. One can also classify a document's polarity on a multi-way scale, which was attempted by Pang\n[\n8\n]\nand Snyder\n[\n9\n]\namong others: Pang and Lee\n[\n8\n]\nexpanded the basic task of classifying a movie review as either positive or negative to predict star ratings on either a 3- or a 4-star scale, while Snyder\n[\n9\n]\nperformed an in-depth analysis of restaurant reviews, predicting ratings for various aspects of the given restaurant, such as the food and atmosphere (on a five-star scale).\nFirst steps to bringing together various approaches—learning, lexical, knowledge-based, etc.—were taken in the 2004\nAAAI\nSpring Symposium where linguists, computer scientists, and other interested researchers first aligned interests and proposed shared tasks and benchmark data sets for the systematic computational research on affect, appeal, subjectivity, and sentiment in text.\n[\n10\n]\nEven though in most statistical classification methods, the neutral class is ignored under the assumption that neutral texts lie near the boundary of the binary classifier, several researchers suggest that, as in every polarity problem, three categories must be identified. Moreover, it can be proven that specific classifiers such as the\nMax Entropy\n[\n11\n]\nand\nSVMs\n[\n12\n]\ncan benefit from the introduction of a neutral class and improve the overall accuracy of the classification. There are in principle two ways for operating with a neutral class. Either, the algorithm proceeds by first identifying the neutral language, filtering it out and then assessing the rest in terms of positive and negative sentiments, or it builds a three-way classification in one step.\n[\n13\n]\nThis second approach often involves estimating a probability distribution over all categories (e.g.\nnaive Bayes\nclassifiers as implemented by the\nNLTK\n). Whether and how to use a neutral class depends on the nature of the data: if the data is clearly clustered into neutral, negative and positive language, it makes sense to filter the neutral language out and focus on the polarity between positive and negative sentiments. If, in contrast, the data are mostly neutral with small deviations towards positive and negative affect, this strategy would make it harder to clearly distinguish between the two poles.\nA different method for determining sentiment is the use of a scaling system whereby words commonly associated with having a negative, neutral, or positive sentiment  are given an associated number on a −10 to +10 scale (most negative up to most positive) or simply from 0 to a positive upper limit such as +4. This makes it possible to adjust the sentiment of a given term relative to its environment (usually on the level of the sentence). When a piece of unstructured text is analyzed using\nnatural language processing\n, each concept in the specified environment is given a score based on the way sentiment words relate to the concept and its associated score.\n[\n14\n]\n[\n15\n]\nThis allows movement to a more sophisticated understanding of sentiment, because it is now possible to adjust the sentiment value of a concept relative to modifications that may surround it. Words, for example, that intensify, relax or negate the sentiment expressed by the concept can affect its score. Alternatively, texts can be given a positive and negative sentiment strength score if the goal is to determine the sentiment in a text rather than the overall polarity and strength of the text.\n[\n16\n]\nThere are various other types of sentiment analysis, such as aspect-based sentiment analysis, grading sentiment analysis (positive, negative, neutral), multilingual sentiment analysis and detection of emotions.\n[\n17\n]\n[\n18\n]\n[\n19\n]\nSubjectivity/objectivity identification\n[\nedit\n]\nThis task is commonly defined as classifying a given text (usually a sentence) into one of two classes: objective or subjective.\n[\n20\n]\nThis problem can sometimes be more difficult than polarity classification.\n[\n21\n]\nThe subjectivity of words and phrases may depend on their context and an objective document may contain subjective sentences (e.g., a news article quoting people's opinions). Moreover, as mentioned by Su,\n[\n22\n]\nresults are largely dependent on the definition of subjectivity used when annotating texts. However, Pang\n[\n23\n]\nshowed that removing objective sentences from a document before classifying its polarity helped improve performance.\nSubjective and objective identification, emerging subtasks of sentiment analysis to use syntactic, semantic features, and machine learning knowledge to identify if a sentence or document contains facts or opinions. Awareness of recognizing factual and opinions is not recent, having possibly first presented by Carbonell at Yale University in 1979.\n[\nclarify\n]\nThe term objective refers to the incident carrying factual information.\n[\n24\n]\nExample of an objective sentence: 'To be elected president of the United States, a candidate must be at least thirty-five years of age.'\nThe term subjective describes the incident contains non-factual information in various forms, such as personal opinions, judgment, and predictions, also known as 'private states'.\n[\n25\n]\nIn the example down below, it reflects a private states 'We Americans'. Moreover, the target entity commented by the opinions can take several forms from tangible product to intangible topic matters stated in Liu (2010).\n[\n26\n]\nFurthermore, three types of attitudes were observed by Liu (2010), 1) positive opinions, 2)  neutral opinions, and 3) negative opinions.\n[\n26\n]\nExample of a subjective sentence: 'We Americans need to elect a president who is mature and who is able to make wise decisions.'\nThis analysis is a classification problem.\n[\n27\n]\nEach class's collections of words or phrase indicators are defined for to locate desirable patterns on unannotated text. For subjective expression, a different word list has been created. Lists of subjective indicators in words or phrases have been developed by multiple researchers in the linguist and natural language processing field states in Riloff et al. (2003).\n[\n28\n]\nA dictionary of extraction rules has to be created for measuring given expressions. Over the years, in subjective detection, the features extraction progression from curating features by hand to automated features learning. At the moment, automated learning methods can further separate into supervised and\nunsupervised machine learning\n. Patterns extraction with machine learning process annotated and unannotated text have been explored extensively by academic researchers.\nHowever, researchers recognized several challenges in developing fixed sets of rules for expressions respectably. Much of the challenges in rule development stems from the nature of textual information. Six challenges have been recognized by several researchers: 1) metaphorical expressions, 2) discrepancies in writings, 3) context-sensitive, 4) represented words with fewer usages, 5) time-sensitive, and 6) ever-growing volume.\nMetaphorical expressions. The text contains metaphoric expression may impact on the performance on the extraction.\n[\n29\n]\nBesides, metaphors take in different forms, which may have been contributed to the increase in detection.\nDiscrepancies in writings. For the text obtained from the Internet, the discrepancies in the writing style of targeted text data involve distinct writing genres and styles.\nContext-sensitive. Classification may vary based on the subjectiveness or objectiveness of previous and following sentences.\n[\n27\n]\nTime-sensitive attribute. The task is challenged by some textual data's time-sensitive attribute. If a group of researchers wants to confirm a piece of fact in the news, they need a longer time for cross-validation, than the news becomes outdated.\nCue words with fewer usages.\nEver-growing volume. The task is also challenged by the sheer volume of textual data. The textual data's ever-growing nature makes the task overwhelmingly difficult for the researchers to complete the task on time.\nPreviously, the research mainly focused on document level classification. However, classifying a document level suffers less accuracy, as an article may have diverse types of expressions involved. Researching evidence suggests a set of news articles that are expected to dominate by the objective expression, whereas the results show that it consisted of over 40% of subjective expression.\n[\n24\n]\nTo overcome those challenges, researchers conclude that classifier efficacy depends on the precisions of patterns learner. And the learner feeds with large volumes of annotated training data outperformed those trained on less comprehensive subjective features. However, one of the main obstacles to executing this type of work is to generate a big dataset of annotated sentences manually. The manual annotation method has been less favored than automatic learning for three reasons:\nVariations in comprehensions. In the manual annotation task, disagreement of whether one instance is subjective or objective may occur among annotators because of languages' ambiguity.\nHuman errors. Manual annotation task is a meticulous assignment, it require intense concentration to finish.\nTime-consuming. Manual annotation task is an assiduous work. Riloff (1996) show that a 160 texts cost 8 hours for one annotator to finish.\n[\n30\n]\nAll these mentioned reasons can impact on the efficiency and effectiveness of subjective and objective classification. Accordingly, two bootstrapping methods were designed to learning linguistic patterns from unannotated text data. Both methods are starting with a handful of seed words and unannotated textual data.\nMeta-Bootstrapping by Riloff and Jones in 1999.\n[\n31\n]\nLevel One: Generate extraction patterns based on the pre-defined rules and the extracted patterns by the number of seed words each pattern holds.  Level Two: Top 5 words will be marked and add to the dictionary.   Repeat.\nBasilisk (\nB\nootstrapping\nA\npproach to\nS\nemantic\nL\nexicon\nI\nnduction using\nS\nemantic\nK\nnowledge) by Thelen and Riloff.\n[\n32\n]\nStep One: Generate extraction patterns. Step Two: Move best patterns from Pattern Pool to Candidate Word Pool. Step Three: Top 10 words will be marked and add to the dictionary. Repeat.\nOverall, these algorithms highlight the need for automatic pattern recognition and extraction in subjective and objective task.\n[\n33\n]\nSubjective and object classifier can enhance the several applications of natural language processing. One of the classifier's primary benefits is that it popularized the practice of data-driven decision-making processes in various industries. According to Liu, the applications of subjective and objective identification have been implemented in business, advertising, sports, and social science.\n[\n34\n]\nOnline review classification: In the business industry, the classifier helps the company better understand the feedbacks on product and reasonings behind the reviews.\nStock price prediction: In the finance industry, the classifier aids the prediction model by process auxiliary information from social media and other textual information from the Internet.   Previous studies on Japanese stock price conducted by Dong et al. indicates that model with subjective and objective module may perform better than those without this part.\n[\n35\n]\nSocial media analysis.\nStudents' feedback classification.\n[\n36\n]\nDocument summarising: The classifier can extract target-specified comments and gathering opinions made by one particular entity.\nComplex question answering. The classifier can dissect the complex questions by classing the language subject or objective and focused target. In the research Yu et al.(2003), the researcher developed a sentence and document level clustered that identity opinion pieces.\n[\n37\n]\nDomain-specific applications.\nEmail analysis: The subjective and objective classifier detects spam by tracing language patterns with target words.\nFeature/aspect-based\n[\nedit\n]\nIt refers to determining the opinions or sentiments expressed on different features or aspects of entities, e.g., of a cell phone, a digital camera, or a bank.\n[\n38\n]\nA feature or aspect is an attribute or component of an entity, e.g., the screen of a cell phone, the service for a restaurant, or the picture quality of a camera. The advantage of feature-based sentiment analysis is the possibility to capture nuances about objects of interest. Different features can generate different sentiment responses, for example a hotel can have a convenient location, but mediocre food.\n[\n39\n]\nThis problem involves several sub-problems, e.g., identifying relevant entities, extracting their features/aspects, and determining whether an opinion expressed on each feature/aspect is positive, negative or neutral.\n[\n40\n]\nThe automatic identification of features can be performed with syntactic methods, with\ntopic modeling\n,\n[\n41\n]\n[\n42\n]\nor with\ndeep learning\n.\n[\n43\n]\n[\n44\n]\nMore detailed discussions about this level of sentiment analysis can be found in Liu's work.\n[\n26\n]\nIntensity ranking\n[\nedit\n]\nEmotions and sentiments are\nsubjective\nin nature. The\ndegree\nof emotions/sentiments expressed in a given text at the document, sentence, or feature/aspect level—to what degree of intensity is expressed in the opinion of a document, a sentence or an entity differs on a case-to-case basis.\n[\n45\n]\nHowever, predicting only the emotion and sentiment does not always convey complete information. The degree or level of emotions and sentiments often plays a crucial role in understanding the exact feeling within a single class (e.g., 'good' versus 'awesome'). Some methods leverage a stacked\nensemble\nmethod\n[\n46\n]\nfor\npredicting intensity\nfor emotion and sentiment by combining the outputs obtained and using\ndeep learning\nmodels based on\nconvolutional neural networks\n,\n[\n47\n]\nlong short-term memory networks and\ngated recurrent units\n.\n[\n48\n]\nMethods and features\n[\nedit\n]\nExisting approaches to sentiment analysis can be grouped into three main categories: knowledge-based techniques, statistical methods, and hybrid approaches.\n[\n49\n]\nKnowledge-based techniques classify text by affect categories based on the presence of unambiguous affect words such as happy, sad, afraid, and bored.\n[\n50\n]\nSome knowledge bases not only list obvious affect words, but also assign arbitrary words a probable \"affinity\" to particular emotions.\n[\n51\n]\nStatistical methods leverage elements from\nmachine learning\nsuch as\nlatent semantic analysis\n,\nsupport vector machines\n, \"\nbag of words\n\", \"\nPointwise Mutual Information\n\" for Semantic Orientation,\n[\n6\n]\nsemantic space\nmodels or\nword embedding\nmodels,\n[\n52\n]\nand\ndeep learning\n. More sophisticated methods try to detect the holder of a sentiment (i.e., the person who maintains that affective state) and the target (i.e., the entity about which the affect is felt).\n[\n53\n]\nTo mine the opinion in\ncontext\nand get the feature about which the speaker has opined, the grammatical relationships of words are used. Grammatical dependency relations are obtained by deep parsing of the text.\n[\n54\n]\nHybrid approaches leverage both machine learning and elements from\nknowledge representation\nsuch as\nontologies\nand\nsemantic networks\nin order to detect semantics that are expressed in a subtle manner, e.g., through the analysis of concepts that do not explicitly convey relevant information, but which are implicitly linked to other concepts that do so.\n[\n55\n]\nOpen source software tools as well as range of free and paid sentiment analysis tools deploy\nmachine learning\n, statistics, and natural language processing techniques to automate sentiment analysis on large collections of texts, including web pages, online news, internet discussion groups, online reviews, web blogs, and social media.\n[\n56\n]\nKnowledge-based systems, on the other hand, make use of publicly available resources, to extract the semantic and affective information associated with natural language concepts. The system can help perform affective\ncommonsense reasoning\n.\n[\n57\n]\nSentiment analysis can also be performed on visual content, i.e., images and videos (see\nMultimodal sentiment analysis\n). One of the first approaches in this direction is SentiBank\n[\n58\n]\nutilizing an adjective noun pair representation of visual content. In addition, the vast majority of sentiment classification approaches rely on the bag-of-words model, which disregards context,\ngrammar\nand even\nword order\n. Approaches that analyses the sentiment based on how words compose the meaning of longer phrases have shown better result,\n[\n59\n]\nbut they incur an additional annotation overhead.\nA human analysis component is required in sentiment analysis, as automated systems are not able to analyze historical tendencies of the individual commenter, or the platform and are often classified incorrectly in their expressed sentiment. Automation impacts approximately 23% of comments that are correctly classified by humans.\n[\n60\n]\nHowever, humans often disagree, and it is argued that the inter-human agreement provides an upper bound that automated sentiment classifiers can eventually reach.\n[\n61\n]\nEvaluation\n[\nedit\n]\nThe accuracy of a sentiment analysis system is, in principle, how well it agrees with human judgments. This is usually measured by variant measures based on\nprecision and recall\nover the two target categories of negative and positive texts. However, according to research human raters typically only agree about 80%\n[\n62\n]\nof the time (see\nInter-rater reliability\n).\nOn the other hand, computer systems will make very different errors than human assessors, and thus the figures are not entirely comparable. For instance, a computer system will have trouble with negations, exaggerations,\njokes\n, or sarcasm, which typically are easy to handle for a human reader: some errors a computer system makes will seem overly naive to a human. In general, the utility for practical commercial tasks of sentiment analysis as it is defined in academic research has been called into question, mostly since the simple one-dimensional model of sentiment from negative to positive yields rather little actionable information for a client worrying about the effect of public discourse on e.g. brand or corporate reputation.\n[\n63\n]\n[\n64\n]\n[\n65\n]\nTo better fit market needs, evaluation of sentiment analysis has moved to more task-based measures, formulated together with representatives from PR agencies and market research professionals. The focus in e.g. the RepLab evaluation data set is less on the content of the text under consideration and more on the effect of the text in question on\nbrand reputation\n.\n[\n66\n]\n[\n67\n]\n[\n68\n]\nBecause evaluation of sentiment analysis is becoming more and more task based, each implementation needs a separate training model to get a more accurate representation of sentiment for a given data set. As LLM-based answer engines become more widespread, evaluation methods have expanded to include tools that track how these systems reference entities. Illustrating emerging approaches to assessing contextual weighting and sentiment in LLM outputs include\nSemrushs\nAI Visibility Toolkit\nor\nEnterprise AIO\n, which analyse how entities are presented within generated responses.\n[\n69\n]\nWeb 2.0\n[\nedit\n]\nSee also:\nReputation management\n,\nweb 2.0\n, and\nweb mining\nThe rise of\nsocial media\nsuch as\nblogs\nand\nsocial networks\nhas fueled interest in sentiment analysis.  With the proliferation of reviews, ratings, recommendations and other forms of online expression, online opinion has turned into a kind of virtual currency for businesses looking to market their products, identify new opportunities and manage their reputations.  As businesses look to automate the process of filtering out the noise, understanding the conversations, identifying the relevant content and actioning it appropriately, many are now looking to the field of sentiment analysis.\n[\n70\n]\nFurther complicating the matter, is the rise of anonymous social media platforms such as\n4chan\nand\nReddit\n.\n[\n71\n]\nIf\nweb 2.0\nwas all about democratizing publishing, then the next stage of the web may well be based on democratizing\ndata mining\nof all the content that is getting published.\n[\n72\n]\nOne step towards this aim is accomplished in research. Several research teams in universities around the world currently focus on understanding the dynamics of sentiment in\ne-communities\nthrough sentiment analysis.\n[\n73\n]\nThe problem is that most sentiment analysis algorithms use simple terms to express sentiment about a product or service.  However, cultural factors, linguistic nuances, and differing contexts make it extremely difficult to turn a string of written text into a simple pro or con sentiment.\n[\n70\n]\nThe fact that humans often disagree on the sentiment of text illustrates how big a task it is for computers to get this right.  The shorter the string of text, the harder it becomes.\nEven though short text strings might be a problem, sentiment analysis within\nmicroblogging\nhas shown that\nTwitter\ncan be seen as a valid online indicator of political sentiment. Tweets' political sentiment demonstrates close correspondence to parties' and politicians' political positions, indicating that the content of Twitter messages plausibly reflects the offline political landscape.\n[\n74\n]\nFurthermore, sentiment analysis on\nTwitter\nhas also been shown to capture the public mood behind human reproduction cycles globally,\n[\n75\n]\nas well as other problems of public-health relevance such as adverse drug reactions.\n[\n76\n]\nWhile sentiment analysis has been popular for domains where authors express their opinion rather explicitly (\"the movie is awesome\"), such as social media and product reviews, only recently robust methods were devised for other domains where sentiment is strongly implicit or indirect. For example, in news articles - mostly due to the expected journalistic objectivity - journalists often describe actions or events rather than directly stating the polarity of a piece of information. Earlier approaches using dictionaries or shallow machine learning features were unable to catch the \"meaning between the lines\", but recently researchers have proposed a deep learning based approach and dataset that is able to analyze sentiment in news articles.\n[\n1\n]\nScholars have utilized sentiment analysis to analyse the construction health and safety Tweets (which is called X now). The research revealed that there is a positive correlation between favorites and retweets in terms of sentiment valence. Others have examined the impact of YouTube on the dissemination of construction health and safety knowledge. They investigated how emotions influence users' behaviors in terms of viewing and commenting through semantic analysis. In another study, positive sentiment accounted for an overwhelming figure of 85% in knowledge sharing of construction safety and health via Instagram.\n[\n77\n]\nApplication in recommender systems\n[\nedit\n]\nSee also:\nRecommender system\nFor a\nrecommender system\n, sentiment analysis has been proven to be a valuable technique. A\nrecommender system\naims to predict the preference for an item of a target user. Mainstream recommender systems work on explicit data set. For example,\ncollaborative filtering\nworks on the rating matrix, and\ncontent-based filtering\nworks on the\nmeta-data\nof the items.\nIn many\nsocial networking services\nor\ne-commerce\nwebsites, users can provide text review, comment or feedback to the items. These user-generated text provide a rich source of user's sentiment opinions about numerous products and items. Potentially, for an item, such text can reveal both the related feature/aspects of the item and the users' sentiments on each feature.\n[\n78\n]\nThe item's feature/aspects described in the text play the same role with the meta-data in\ncontent-based filtering\n, but the former are more valuable for the recommender system. Since these features are broadly mentioned by users in their reviews, they can be seen as the most crucial features that can significantly influence the user's experience on the item, while the meta-data of the item (usually provided by the producers instead of consumers) may ignore features that are concerned by the users. For different items with common features, a user may give different sentiments. Also, a feature of the same item may receive different sentiments from different users. Users' sentiments on the features can be regarded as a multi-dimensional rating score, reflecting their preference on the items.\n[\n79\n]\nBased on the feature/aspects and the sentiments extracted from the user-generated text, a hybrid recommender system can be constructed.\n[\n80\n]\nThere are two types of motivation to recommend a candidate item to a user. The first motivation is the candidate item have numerous common features with the user's preferred items,\n[\n81\n]\nwhile the second motivation is that the candidate item receives a high sentiment on its features. For a preferred item, it is reasonable to believe that items with the same features will have a similar function or utility. So, these items will also likely to be preferred by the user. On the other hand, for a shared feature of two candidate items, other users may give positive sentiment to one of them while giving negative sentiment to another. Clearly, the high evaluated item should be recommended to the user. Based on these two motivations, a combination ranking score of similarity and sentiment rating can be constructed for each candidate item.\n[\n80\n]\nExcept for the difficulty of the sentiment analysis itself, applying sentiment analysis on reviews or feedback also faces the challenge of spam and biased reviews. One direction of work is focused on evaluating the helpfulness of each review.\n[\n82\n]\nReview or feedback poorly written is hardly helpful for recommender system. Besides, a review can be designed to hinder sales of a target product, thus be harmful to the recommender system even it is well written.\nResearchers also found that long and short forms of user-generated text should be treated differently. An interesting result shows that short-form reviews are sometimes more helpful than long-form,\n[\n83\n]\nbecause it is easier to filter out the noise in a short-form text. For the long-form text, the growing length of the text does not always bring a proportionate increase in the number of features or sentiments in the text.\nLamba & Madhusudhan\n[\n84\n]\nintroduce a nascent way to cater the information needs of today's library users by repackaging the results from sentiment analysis of social media platforms like Twitter and provide it as a consolidated time-based service in different formats. Further, they propose a new way of conducting marketing in libraries using social media mining and sentiment analysis.\nEthical considerations\n[\nedit\n]\nIssues such as privacy, consent, and bias are crucial since sentiment analysis regularly analyzes personal data without explicit user consent. The potential for misinterpretation and misuse of sentiment data can significantly impact societal norms. Furthermore, the development of ethical frameworks, as seen in projects like SEWA, where Ethical and Industrial Valorisation Advisory Boards are established, is essential for addressing these challenges. These boards help ensure that sentiment analysis technologies are used responsibly, especially in applications involving the recognition of human emotions and behaviors. Such frameworks are vital for guiding the responsible use of sentiment analysis tools, ensuring they promote equity and respect user autonomy, and effectively address both routine and complex ethical issues.\n[\n85\n]\nSee also\n[\nedit\n]\nAffective computing\nConsumer sentiment\nEmotion recognition\nFriendly artificial intelligence\nInterpersonal accuracy\nMultimodal sentiment analysis\nStylometry\nReferences\n[\nedit\n]\n^\na\nb\nHamborg, Felix; Donnay, Karsten (2021).\n\"NewsMTSC: A Dataset for (Multi-)Target-dependent Sentiment Classification in Political News Articles\"\n. In Merlo, Paola; Tiedemann, Jorg; Tsarfaty, Reut (eds.).\nProceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume\n. Association for Computational Linguistics. pp.\n1663–\n1675.\ndoi\n:\n10.18653/v1/2021.eacl-main.142\n.\n^\nVong Anh Ho, Duong Huynh-Cong Nguyen, Danh Hoang Nguyen, Linh Thi-Van Pham, Duc-Vu Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen. \"Emotion Recognition\nfor Vietnamese Social Media Text\". In Proceedings of the 2019 International Conference of the Pacific Association for Computational Linguistics (PACLING 2019), Hanoi, Vietnam (2019).\n^\nStone, Philip J., Dexter C. Dunphy, and Marshall S. Smith. \"The general inquirer: A computer approach to content analysis.\" MIT Press, Cambridge, MA (1966).\n^\nGottschalk, Louis August, and\nGoldine C. Gleser\n. The measurement of psychological states through the content analysis of verbal behavior. Univ of California Press, 1969.\n^\nUSA Issued 7,136,877\n, Volcani, Yanon; & Fogel, David B., \"System and method for determining and controlling the impact of text\", published June 28, 2001\n^\na\nb\nTurney, Peter (2002). \"Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews\".\nProceedings of the Association for Computational Linguistics\n. pp.\n417–\n424.\narXiv\n:\ncs.LG/0212032\n.\n^\nPang, Bo;\nLee, Lillian\n; Vaithyanathan, Shivakumar (2002).\n\"Thumbs up? Sentiment Classification using Machine Learning Techniques\"\n.\nProceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)\n. pp.\n79–\n86.\n^\na\nb\nPang, Bo; Lee, Lillian (2005).\n\"Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales\"\n.\nProceedings of the Association for Computational Linguistics (ACL)\n. pp.\n115–\n124.\n^\na\nb\nSnyder, Benjamin; Barzilay, Regina (2007).\n\"Multiple Aspect Ranking using the Good Grief Algorithm\"\n.\nProceedings of the Joint Human Language Technology/North American Chapter of the ACL Conference (HLT-NAACL)\n. pp.\n300–\n307. Archived from\nthe original\non August 6, 2016\n. Retrieved\nJune 16,\n2009\n.\n^\nQu, Yan, James Shanahan, and\nJanyce Wiebe\n. \"Exploring attitude and affect in text: Theories and applications.\" In AAAI Spring Symposium, Technical report SS-04-07. AAAI Press, Menlo Park, CA. 2004.\n^\nVryniotis, Vasilis (2013).\nThe importance of Neutral Class in Sentiment Analysis\n.\n^\nKoppel, Moshe; Schler, Jonathan (2006). \"The Importance of Neutral Examples for Learning Sentiment\".\nComputational Intelligence 22\n. pp.\n100–\n109.\nCiteSeerX\n10.1.1.84.9735\n.\n^\nRibeiro, Filipe Nunes; Araujo, Matheus (2010).\n\"A Benchmark Comparison of State-of-the-Practice Sentiment Analysis Methods\"\n.\nTransactions on Embedded Computing Systems\n.\n9\n(4).\n^\nTaboada, Maite; Brooke, Julian (2011).\n\"Lexicon-based methods for sentiment analysis\"\n.\nComputational Linguistics\n.\n37\n(2):\n272–\n274.\nCiteSeerX\n10.1.1.188.5517\n.\ndoi\n:\n10.1162/coli_a_00049\n.\nS2CID\n3181362\n.\n^\nAugustyniak, Łukasz; Szymański, Piotr; Kajdanowicz, Tomasz; Tuligłowicz, Włodzimierz (December 25, 2015).\n\"Comprehensive Study on Lexicon-based Ensemble Classification Sentiment Analysis\"\n.\nEntropy\n.\n18\n(1): 4.\nBibcode\n:\n2015Entrp..18....4A\n.\ndoi\n:\n10.3390/e18010004\n.\n^\nThelwall, Mike; Buckley, Kevan; Paltoglou, Georgios; Cai, Di; Kappas, Arvid (2010).\n\"Sentiment strength detection in short informal text\"\n.\nJournal of the American Society for Information Science and Technology\n.\n61\n(12):\n2544–\n2558.\nBibcode\n:\n2010JASIS..61.2544T\n.\nCiteSeerX\n10.1.1.278.3863\n.\ndoi\n:\n10.1002/asi.21416\n.\n^\nLiu, Bing (2022).\nSentiment Analysis and Opinion Mining\n. Springer Nature.\n^\nZhang, Wenxuan; Li, Xin; Deng, Yang; Bing, Lidong; Lam, Wai (2021).\nTowards Generative Aspect-Based Sentiment Analysis\n. Association for Computational Linguistics.\n^\nMuhammad, Shamsuddeen Hassan; Ousidhoum, Nedjma; Abdulmumin, Idris; Wahle, Jan Philip; Ruas, Terry (2025). Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher (eds.).\nBRIGHTER: BRIidging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages\n. Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8895–8916, Vienna, Austria. Association for Computational Linguistics. Vienna, Austria: Association for Computational Linguistics. pp.\n8895–\n8916.\ndoi\n:\n10.18653/v1/2025.acl-long.436\n.\nISBN\n979-8-89176-251-0\n.\n^\nPang, Bo; Lee, Lillian (2008).\n\"4.1.2 Subjectivity Detection and Opinion Identification\"\n.\nOpinion Mining and Sentiment Analysis\n. Now Publishers Inc.\n^\nMihalcea, Rada; Banea, Carmen;\nWiebe, Janyce\n(2007).\n\"Learning Multilingual Subjective Language via Cross-Lingual Projections\"\n(PDF)\n.\nProceedings of the Association for Computational Linguistics (ACL)\n. pp.\n976–\n983. Archived from\nthe original\n(PDF)\non July 8, 2010.\n^\nSu, Fangzhong; Markert, Katja (2008).\n\"From Words to Senses: a Case Study in Subjectivity Recognition\"\n(PDF)\n.\nProceedings of Coling 2008, Manchester, UK\n.\n^\nPang, Bo; Lee, Lillian (2004).\n\"A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts\"\n.\nProceedings of the Association for Computational Linguistics (ACL)\n. pp.\n271–\n278.\n^\na\nb\nWiebe, Janyce\n; Riloff, Ellen (2005).\n\"Creating Subjective and Objective Sentence Classifiers from Unannotated Texts\"\n. In Gelbukh, Alexander (ed.).\nComputational Linguistics and Intelligent Text Processing\n. Lecture Notes in Computer Science. Vol. 3406. Berlin, Heidelberg: Springer. pp.\n486–\n497.\ndoi\n:\n10.1007/978-3-540-30586-6_53\n.\nISBN\n978-3-540-30586-6\n.\n^\nQuirk, Randolph; Greenbaum, Sidney; Geoffrey, Leech; Jan, Svartvik (1985).\nA Comprehensive Grammar of the English Language (General Grammar)\n.\nLongman\n. pp.\n175–\n239.\nISBN\n1-933108-31-2\n.\n^\na\nb\nc\nLiu, Bing (2010).\n\"Sentiment Analysis and Subjectivity\"\n(PDF)\n. In Indurkhya, N.; Damerau, F. J. (eds.).\nHandbook of Natural Language Processing\n(Second ed.).\n^\na\nb\nPang, Bo; Lee, Lillian (July 6, 2008).\n\"Opinion Mining and Sentiment Analysis\"\n.\nFoundations and Trends in Information Retrieval\n.\n2\n(\n1–\n2):\n1–\n135.\ndoi\n:\n10.1561/1500000011\n.\nISSN\n1554-0669\n.\nS2CID\n207178694\n.\n^\nRiloff, Ellen;\nWiebe, Janyce\n(July 11, 2003). \"Learning extraction patterns for subjective expressions\".\nProceedings of the 2003 conference on Empirical methods in natural language processing -\n. EMNLP '03. Vol. 10. USA: Association for Computational Linguistics. pp.\n105–\n112.\ndoi\n:\n10.3115/1119355.1119369\n.\nS2CID\n6541910\n.\n^\nWiebe, Janyce\n; Riloff, Ellen (July 2011). \"Finding Mutual Benefit between Subjectivity Analysis and Information Extraction\".\nIEEE Transactions on Affective Computing\n.\n2\n(4):\n175–\n191.\nBibcode\n:\n2011ITAfC...2..175W\n.\ndoi\n:\n10.1109/T-AFFC.2011.19\n.\nISSN\n1949-3045\n.\nS2CID\n16820846\n.\n^\nRiloff, Ellen (August 1, 1996).\n\"An empirical study of automated dictionary construction for information extraction in three domains\"\n.\nArtificial Intelligence\n.\n85\n(1):\n101–\n134.\ndoi\n:\n10.1016/0004-3702(95)00123-9\n.\nISSN\n0004-3702\n.\n^\nRiloff, Ellen; Jones, Rosie (July 1999).\n\"Learning dictionaries for information extraction by multi-level bootstrapping\"\n(PDF)\n.\nAAAI '99/IAAI '99: Proceedings of the Sixteenth National Conference on Artificial Intelligence and the Eleventh Innovative Applications of Artificial Intelligence Conference Innovative Applications of Artificial Intelligence\n:\n474–\n479.\n^\nThelen, Michael; Riloff, Ellen (July 6, 2002). \"A bootstrapping method for learning semantic lexicons using extraction pattern contexts\".\nProceedings of the ACL-02 conference on Empirical methods in natural language processing - EMNLP '02\n. Vol. 10. USA: Association for Computational Linguistics. pp.\n214–\n221.\ndoi\n:\n10.3115/1118693.1118721\n.\nS2CID\n137155\n.\n^\nSweta, Soni (2024).\nSentiment Analysis and its Application in Educational Data Mining (SpringerBriefs in Computational Intelligence)\n. Berlin, Heidelberg: Springer. p. 30.\nISBN\n978-9819724734\n.\n^\nLiu, Bing (May 23, 2012).\n\"Sentiment Analysis and Opinion Mining\"\n.\nSynthesis Lectures on Human Language Technologies\n.\n5\n(1):\n1–\n167.\ndoi\n:\n10.2200/S00416ED1V01Y201204HLT016\n.\nISSN\n1947-4040\n.\nS2CID\n38022159\n. Archived from\nthe original\non May 10, 2021\n. Retrieved\nDecember 9,\n2020\n.\n^\nDeng, Shangkun; Mitsubuchi, Takashi; Shioda, Kei; Shimada, Tatsuro; Sakurai, Akito (December 2011).\n\"Combining Technical Analysis with Sentiment Analysis for Stock Price Prediction\"\n.\n2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing\n. IEEE. pp.\n800–\n807.\ndoi\n:\n10.1109/dasc.2011.138\n.\nISBN\n978-1-4673-0006-3\n.\nS2CID\n15262023\n.\n^\nNguyen, Kiet Van; Nguyen, Vu Duc; Nguyen, Phu X.V.; Truong, Tham T.H.; Nguyen, Ngan L-T. (October 1, 2018). \"UIT-VSFC: Vietnamese Students' Feedback Corpus for Sentiment Analysis\".\n2018 10th International Conference on Knowledge and Systems Engineering (KSE)\n. Vietnam: IEEE. pp.\n19–\n24.\ndoi\n:\n10.1109/KSE.2018.8573337\n.\nISBN\n978-1-5386-6113-0\n.\nS2CID\n56172224\n.\n^\nYu, Hong; Hatzivassiloglou, Vasileios (July 11, 2003). \"Towards answering opinion questions\".\nProceedings of the 2003 conference on Empirical methods in natural language processing -\n. EMNLP '03. Vol. 10. USA: Association for Computational Linguistics. pp.\n129–\n136.\ndoi\n:\n10.3115/1119355.1119372\n.\n^\nHu, Minqing; Liu, Bing (2004).\n\"Mining and Summarizing Customer Reviews\"\n.\nProceedings of KDD 2004\n.\n^\nCataldi, Mario; Ballatore, Andrea; Tiddi, Ilaria; Aufaure, Marie-Aude (June 22, 2013). \"Good location, terrible food: detecting feature sentiment in user-generated reviews\".\nSocial Network Analysis and Mining\n.\n3\n(4):\n1149–\n1163.\nCiteSeerX\n10.1.1.396.9313\n.\ndoi\n:\n10.1007/s13278-013-0119-7\n.\nISSN\n1869-5450\n.\nS2CID\n5025282\n.\n^\nLiu, Bing; Hu, Minqing; Cheng, Junsheng (2005).\n\"Opinion Observer: Analyzing and Comparing Opinions on the Web\"\n.\nProceedings of WWW 2005\n.\n^\nZhai, Zhongwu; Liu, Bing; Xu, Hua; Jia, Peifa (January 1, 2011). \"Constrained LDA for Grouping Product Features in Opinion Mining\". In Huang, Joshua Zhexue; Cao, Longbing; Srivastava, Jaideep (eds.).\nAdvances in Knowledge Discovery and Data Mining\n. Lecture Notes in Computer Science. Vol. 6634. Springer Berlin Heidelberg. pp.\n448–\n459.\nCiteSeerX\n10.1.1.221.5178\n.\ndoi\n:\n10.1007/978-3-642-20841-6_37\n.\nISBN\n978-3-642-20840-9\n.\n^\nTitov, Ivan; McDonald, Ryan (January 1, 2008). \"Modeling online reviews with multi-grain topic models\".\nProceedings of the 17th international conference on World Wide Web\n. WWW '08. New York, NY, USA: ACM. pp.\n111–\n120.\narXiv\n:\n0801.1063\n.\ndoi\n:\n10.1145/1367497.1367513\n.\nISBN\n978-1-60558-085-2\n.\nS2CID\n13609860\n.\n^\nLiang, Bin; et al. (2022).\n\"Aspect-based sentiment analysis via affective knowledge enhanced graph convolutional networks\"\n.\nKnowledge-Based Systems\n.\n235\n107643.\ndoi\n:\n10.1016/j.knosys.2021.107643\n.\nS2CID\n237258427\n.\n^\nMa, Yukun; et al. (2018). \"Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM\".\nProceedings of AAAI\n. pp.\n5876–\n5883.\n^\nSharma, Raksha; Somani; Kumar; Bhattacharyya (2017).\n\"Sentiment Intensity Ranking among Adjectives Using Sentiment Bearing Word Embeddings\"\n(PDF)\n.\nAssociation for Computational Linguistics\n:\n547–\n552.\n^\nM. S. Akhtar, A. Ekbal and E. Cambria, \"How Intense Are You? Predicting Intensities of Emotions and Sentiments using Stacked Ensemble [Application Notes],\" in\nIEEE Computational Intelligence Magazine\n, vol. 15, no. 1, pp. 64-75, Feb. 2020, doi: 10.1109/MCI.2019.2954667.\n^\nX. Ouyang, P. Zhou, C. H. Li and L. Liu, \"Sentiment Analysis Using Convolutional Neural Network,\" 2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing, 2015, pp. 2359-2364, doi: 10.1109/CIT/IUCC/DASC/PICOM.2015.349.\n^\nY. Santur, \"Sentiment Analysis Based on Gated Recurrent Unit,\" 2019 International Artificial Intelligence and Data Processing Symposium (IDAP), 2019, pp. 1-5, doi: 10.1109/IDAP.2019.8875985.\n^\nCambria, E; Schuller, B; Xia, Y; Havasi, C (2013). \"New avenues in opinion mining and sentiment analysis\".\nIEEE Intelligent Systems\n.\n28\n(2):\n15–\n21.\nBibcode\n:\n2013IISys..28b..15C\n.\nCiteSeerX\n10.1.1.688.1384\n.\ndoi\n:\n10.1109/MIS.2013.30\n.\nS2CID\n12104996\n.\n^\nOrtony, Andrew; Clore, G; Collins, A (1988).\nThe Cognitive Structure of Emotions\n(PDF)\n. Cambridge Univ. Press. Archived from\nthe original\n(PDF)\non November 23, 2015.\n^\nStevenson, Ryan; Mikels, Joseph; James, Thomas (2007).\n\"Characterization of the Affective Norms for English Words by Discrete Emotional Categories\"\n.\nBehavior Research Methods\n.\n39\n(4):\n1020–\n1024.\ndoi\n:\n10.3758/bf03192999\n.\nPMID\n18183921\n.\nS2CID\n6673690\n.\n^\nSahlgren, Magnus\n; Karlgren, Jussi; Eriksson, Gunnar (2007). \"Valence annotation based on seeds in word space\".\nProceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)\n.\n^\nKim, S. M.; Hovy, E. H. (2006).\n\"Identifying and Analyzing Judgment Opinions.\"\n(PDF)\n.\nProceedings of the Human Language Technology / North American Association of Computational Linguistics conference (HLT-NAACL 2006). New York, NY\n. Archived from\nthe original\n(PDF)\non June 29, 2011.\n^\nDey, Lipika; Haque, S. K. Mirajul (2008).\n\"Opinion Mining from Noisy Text Data\"\n.\nProceedings of the second workshop on Analytics for noisy unstructured text data, p.83-90\n.\n^\nCambria, E; Hussain, A (2015).\nSentic Computing: A Common-Sense-Based Framework for Concept-Level Sentiment Analysis\n. Springer.\nISBN\n978-3-319-23654-4\n.\n^\nAkcora, Cuneyt Gurcan; Bayir, Murat Ali; Demirbas, Murat; Ferhatosmanoglu, Hakan (2010).\n\"Identifying breakpoints in public opinion\"\n.\nSigKDD, Proceedings of the First Workshop on Social Media Analytics\n.\n^\nCambria, Erik; Liu, Qian; Decherchi, Sergio; Xing, Frank; Kwok, Kenneth (2022).\n\"SenticNet 7: A Commonsense-based Neurosymbolic AI Framework for Explainable Sentiment Analysis\"\n(PDF)\n.\nProceedings of LREC\n. pp.\n3829–\n3839.\n^\nBorth, Damian; Ji, Rongrong; Chen, Tao; Breuel, Thomas; Chang, Shih-Fu (2013).\n\"Large-scale Visual Sentiment Ontology and Detectors Using Adjective Noun Pairs\"\n.\nProceedings of ACM Int. Conference on Multimedia\n. pp.\n223–\n232. Archived from\nthe original\non April 15, 2021\n. Retrieved\nNovember 2,\n2017\n.\n^\nSocher, Richard; Perelygin, Alex; Wu, Jean Y.; Chuang, Jason; Manning, Christopher D.; Ng, Andrew Y.; Potts, Christopher (2013). \"Recursive deep models for semantic compositionality over a sentiment treebank\".\nIn Proceedings of EMNLP\n:\n1631–\n1642.\nCiteSeerX\n10.1.1.593.7427\n.\n^\n\"Case Study: Advanced Sentiment Analysis\"\n. Archived from\nthe original\non October 29, 2013\n. Retrieved\nOctober 18,\n2013\n.\n^\nMozetič, Igor; Grčar, Miha; Smailović, Jasmina (May 5, 2016).\n\"Multilingual Twitter Sentiment Classification: The Role of Human Annotators\"\n.\nPLOS ONE\n.\n11\n(5) e0155036.\narXiv\n:\n1602.07563\n.\nBibcode\n:\n2016PLoSO..1155036M\n.\ndoi\n:\n10.1371/journal.pone.0155036\n.\nISSN\n1932-6203\n.\nPMC\n4858191\n.\nPMID\n27149621\n.\n^\nOgneva, M.\n\"How Companies Can Use Sentiment Analysis to Improve Their Business\"\n. Mashable\n. Retrieved\nDecember 13,\n2012\n.\n^\nKarlgren, Jussi\n,\nMagnus Sahlgren\n, Fredrik Olsson, Fredrik Espinoza, and Ola Hamfors. \"Usefulness of sentiment analysis.\" In European Conference on Information Retrieval, pp. 426-435. Springer Berlin Heidelberg, 2012.\n^\nKarlgren, Jussi\n. \"The relation between author mood and affect to sentiment in text and text genre.\" In Proceedings of the fourth workshop on Exploiting semantic annotations in information retrieval, pp. 9-10. ACM, 2011.\n^\nKarlgren, Jussi\n. \"\nAffect, appeal, and sentiment as factors influencing interaction with multimedia information\n.\" In Proceedings of Theseus/ImageCLEF workshop on visual information retrieval evaluation, pp. 8-11. 2009.\n^\nAmigó, Enrique, Adolfo Corujo, Julio Gonzalo, Edgar Meij, and\nMaarten de Rijke\n. \"Overview of RepLab 2012: Evaluating Online Reputation Management Systems.\" In CLEF (Online Working Notes/Labs/Workshop). 2012.\n^\nAmigó, Enrique, Jorge Carrillo De Albornoz, Irina Chugur, Adolfo Corujo, Julio Gonzalo, Tamara Martín, Edgar Meij,\nMaarten de Rijke\n, and Damiano Spina. \"Overview of replab 2013: Evaluating online reputation monitoring systems.\" In International Conference of the Cross-Language Evaluation Forum for European Languages, pp. 333-352. Springer Berlin Heidelberg, 2013.\n^\nAmigó, Enrique, Jorge Carrillo-de-Albornoz, Irina Chugur, Adolfo Corujo, Julio Gonzalo, Edgar Meij,\nMaarten de Rijke\n, and Damiano Spina. \"Overview of replab 2014: author profiling and reputation dimensions for online reputation management.\" In International Conference of the Cross-Language Evaluation Forum for European Languages, pp. 307-322. Springer International Publishing, 2014.\n^\n\"Brands target AI chatbots as users switch from Google search\"\n.\nFinancial Times\n.\n^\na\nb\nWright, Alex.\n\"Mining the Web for Feelings, Not Facts\"\n,\nNew York Times\n, 2009-08-23. Retrieved on 2009-10-01.\n^\n\"Sentiment Analysis on Reddit\"\n. September 30, 2014\n. Retrieved\nOctober 10,\n2014\n.\n^\nKirkpatrick, Marshall.\n\"\n,\nReadWriteWeb\n, 2009-04-15. Retrieved on 2009-10-01.\n^\nCondliffe, Jamie.\n\"Flaming drives online social networks \"\n,\nNew Scientist\n, 2010-12-07. Retrieved on 2010-12-13.\n^\nTumasjan, Andranik; O.Sprenger, Timm; G.Sandner, Philipp; M.Welpe, Isabell (2010).\n\"Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment\"\nArchived\nDecember 12, 2020, at the\nWayback Machine\n. \"Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media\"\n^\nWood, Ian B.; Varela, Pedro L.; Bollen, Johan; Rocha, Luis M.; Gonçalves-Sá, Joana (2017).\n\"Human Sexual Cycles are Driven by Culture and Match Collective Moods\"\n.\nScientific Reports\n.\n7\n(1): 17973.\narXiv\n:\n1707.03959\n.\nBibcode\n:\n2017NatSR...717973W\n.\ndoi\n:\n10.1038/s41598-017-18262-5\n.\nPMC\n5740080\n.\nPMID\n29269945\n.\n^\nKorkontzelos, Ioannis; Nikfarjam, Azadeh; Shardlow, Matthew; Sarker, Abeed; Ananiadou, Sophia; Gonzalez, Graciela H. (2016).\n\"Analysis of the effect of sentiment analysis on extracting adverse drug reactions from tweets and forum posts\"\n.\nJournal of Biomedical Informatics\n.\n62\n:\n148–\n158.\ndoi\n:\n10.1016/j.jbi.2016.06.007\n.\nPMC\n4981644\n.\nPMID\n27363901\n.\n^\nZeng, L.; Li, R.Y.M.; Yigitcanlar, T.; Zeng, H. Public Opinion Mining on Construction Health and Safety: Latent Dirichlet Allocation Approach. Buildings 2023, 13, 927.\nhttps://doi.org/10.3390/buildings13040927\n^\nTang, Huifeng; Tan, Songbo; Cheng, Xueqi (2009).\n\"A survey on sentiment detection of reviews\"\n(PDF)\n.\nExpert Systems with Applications\n.\n36\n(7):\n10760–\n10773.\ndoi\n:\n10.1016/j.eswa.2009.02.063\n.\nS2CID\n2178380\n. Archived from\nthe original\n(PDF)\non May 24, 2018.\n^\nSubarna, Shakya (2023).\nSentiment Analysis and Deep Learning: Proceedings of ICSADL 2022 (Advances in Intelligent Systems and Computing, 1432)\n. Springer. p. 567.\nISBN\n978-9811954429\n.\n^\na\nb\nJakob, Niklas, et al. \"Beyond the stars: exploiting free-text user reviews to improve the accuracy of movie recommendations.\"\nProceedings of the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion\n. ACM, 2009.\n^\nMinqing, Hu; Liu, Bing (2004).\n\"Mining opinion features in customer reviews\"\n(PDF)\n.\nAAAI\n.\n4\n(4).\nS2CID\n5724860\n. Archived from\nthe original\n(PDF)\non May 24, 2018.\n^\nLiu, Yang; Huang, Xiangji; An, Aijun; Yu, Xiaohui (2008).\n\"Modeling and predicting the helpfulness of online reviews\"\n(PDF)\n.\nICDM'08. Eighth IEEE international conference on Data mining\n. IEEE. pp.\n443–\n452.\ndoi\n:\n10.1109/ICDM.2008.94\n.\nISBN\n978-0-7695-3502-9\n.\nS2CID\n18235238\n.\n^\nBermingham, Adam; Smeaton, Alan F. (2010). \"Classifying sentiment in microblogs\".\nProceedings of the 19th ACM international conference on Information and knowledge management\n(PDF)\n. pp.\n1833–\n1836.\ndoi\n:\n10.1145/1871437.1871741\n.\nISBN\n978-1-4503-0099-5\n.\nS2CID\n2084603\n.\n^\nLamba, Manika; Madhusudhan, Margam (2018). \"Application of sentiment analysis in libraries to provide temporal information service: a case study on various facets of productivity\".\nSocial Network Analysis and Mining\n.\n8\n(1):\n1–\n12.\ndoi\n:\n10.1007/s13278-018-0541-y\n.\nS2CID\n53047128\n.\n^\nSchuller, Ganascia, Devillers, Björn, Jean-Gabriel, Devillers (2016).\nMultimodal sentiment analysis in the wild: ethical considerations on data collection, annotation, and exploitation\n. pp.\n29–\n34.\nISBN\n978-2-9517408-9-1\n.\n{{\ncite book\n}}\n:  CS1 maint: multiple names: authors list (\nlink\n)\nv\nt\ne\nNatural language processing\nGeneral terms\nAI-complete\nBag-of-words\nn\n-gram\nBigram\nTrigram\nComputational linguistics\nNatural language understanding\nStop words\nText processing\nText analysis\nArgument mining\nCollocation extraction\nConcept mining\nCoreference resolution\nDeep linguistic processing\nDistant reading\nInformation extraction\nNamed-entity recognition\nOntology learning\nParsing\nsemantic\nsyntactic\nPart-of-speech tagging\nSemantic analysis\nSemantic role labeling\nSemantic decomposition\nSemantic similarity\nSentiment analysis\nTerminology extraction\nText mining\nTextual entailment\nTruecasing\nWord-sense disambiguation\nWord-sense induction\nText segmentation\nCompound-term processing\nLemmatisation\nLexical analysis\nText chunking\nStemming\nSentence segmentation\nWord segmentation\nAutomatic summarization\nMulti-document summarization\nSentence extraction\nText simplification\nMachine translation\nComputer-assisted\nExample-based\nRule-based\nStatistical\nTransfer-based\nNeural\nDistributional semantics\nmodels\nBERT\nDocument-term matrix\nExplicit semantic analysis\nfastText\nGloVe\nLanguage model\nlarge\nsmall\nLatent semantic analysis\nLong short-term memory\nSeq2seq\nTransformer\nWord embedding\nWord2vec\nLanguage resources\n,\ndatasets and corpora\nTypes and\nstandards\nCorpus linguistics\nLexical resource\nLinguistic Linked Open Data\nMachine-readable dictionary\nParallel text\nPropBank\nSemantic network\nSimple Knowledge Organization System\nSpeech corpus\nText corpus\nThesaurus (information retrieval)\nTreebank\nUniversal Dependencies\nData\nBabelNet\nBank of English\nDBpedia\nFrameNet\nGoogle Ngram Viewer\nUBY\nWordNet\nWikidata\nAutomatic identification\nand data capture\nSpeech recognition\nSpeech segmentation\nSpeech synthesis\nNatural language generation\nOptical character recognition\nTopic model\nDocument classification\nLatent Dirichlet allocation\nPachinko allocation\nComputer-assisted\nreviewing\nAutomated essay scoring\nConcordancer\nGrammar checker\nPredictive text\nPronunciation assessment\nSpell checker\nNatural language\nuser interface\nChatbot\nInteractive fiction\nQuestion answering\nVirtual assistant\nVoice user interface\nRelated\nFormal semantics\nHallucination\nNatural Language Toolkit\nspaCy\nv\nt\ne\nNonverbal communication\nModalities\nPhysical\nBlushing\nBody language\n/\nKinesics\nBody-to-body communication\nFacial expression\nFacial Action Coding System\nMicroexpression\nSubtle expression\nGesture\nList\nSpeech-independent gestures\nHaptic communication\nImitation\nInterpersonal synchrony\nLaughter\nOculesics\nEye contact\nPupil dilation\nOlfaction\nPosture\nProxemics\nSpeech\nAffect\nEmotional prosody\nParalanguage\nIntonation\nLoudness\nProsody\nRhythm\nStress\nTone\nVoice quality\nSocial context\nChronemics\nConventions\nDisplay rules\nHabitus\nHigh-context and low-context cultures\nInterpersonal relationship\nSocial norm\nOther\nEmoticon\n/\nSmiley\nOne-bit message\nMissed call\nSilent service code\nUnconscious\nMicroexpression\nNon-verbal leakage\nMulti-faceted\nAffect display\nDeception\nEmotion recognition\nFirst impression\nIntimacy\nBroader concepts\nCognitive academic language proficiency\nCommunication\nEmotional intelligence\nNunchi\nPeople skills\nSemiotics\nSocial behavior\nSocial competence\nSocial cue\nSocial skills\nUnsaid\nFurther information\nDisorders\nAprosodia\nAsperger syndrome\nAutism\nFragile X\nPervasive developmental disorder not otherwise specified\nChildhood disintegrative disorder\nRett syndrome\nDyssemia\nNonverbal learning disorder\nSocial (pragmatic) communication disorder\nNeuroanatomy\nLimbic system\n/\nLimbic lobe\nMirror neuron\nApplications\nCold reading\nLie detection\nFreudian slip\nPoker tell\nTargeted advertising\nTechnology\nComputer processing of body language\nEmotion recognition in conversation\nGesture recognition\nList of facial expression databases\nSentiment analysis\nKey people\nRay Birdwhistell\nCharles Darwin\nPaul Ekman\nRelated\nAnimal communication\nBehavioral communication\nAggressive\nAssertive\nPassive\nPassive-aggressive\nImpression management\nMeta-communication\nMonastic sign lexicons\nVerbal communication\nManual-tactile verbal\nSign language\nTactile signing\nTadoma\nArt and literature\nMime\nMimoplastic art\nSubtext\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Sentiment_analysis&oldid=1324525199\n\"\nCategories\n:\nTasks of natural language processing\nAffective computing\nSocial media\nSocial information processing\nPolling\nSociology of technology\nHidden categories:\nWebarchive template wayback links\nCS1 maint: multiple names: authors list\nArticles with short description\nShort description is different from Wikidata\nUse mdy dates from October 2023\nAll articles with unsourced statements\nArticles with unsourced statements from November 2025\nAll Wikipedia articles needing clarification\nWikipedia articles needing clarification from December 2020\nThis page was last edited on 28 November 2025, at 02:08\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nSentiment analysis\n25 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:18.530534",
      "status": "success",
      "content_length": 57241,
      "topic": "nlp"
    },
    {
      "title": "Large language model - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Large_language_model",
      "content": "Large language model - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\n2\nDataset preprocessing\nToggle Dataset preprocessing subsection\n2.1\nTokenization\n2.1.1\nByte-pair encoding\n2.1.2\nProblems\n2.2\nDataset cleaning\n2.3\nSynthetic data\n3\nTraining\nToggle Training subsection\n3.1\nCost\n3.2\nFine-tuning\n4\nArchitecture\nToggle Architecture subsection\n4.1\nAttention mechanism and context window\n4.2\nMixture of experts\n4.3\nParameter size\n4.3.1\nQuantization\n5\nExtensibility\nToggle Extensibility subsection\n5.1\nPrompt engineering\n5.2\nDialogue processing (chatbot)\n5.3\nRetrieval-augmented generation\n5.4\nTool use\n5.5\nAgency\n5.6\nReasoning\n5.6.1\nChaining\n5.6.2\nModel-native reasoning\n5.7\nInference optimization\n6\nForms of input and output\nToggle Forms of input and output subsection\n6.1\nMultimodality\n6.2\nNon-natural languages\n7\nProperties\nToggle Properties subsection\n7.1\nScaling laws\n7.2\nEmergent abilities\n8\nInterpretation\nToggle Interpretation subsection\n8.1\nMechanistic interpretability\n8.2\nUnderstanding and intelligence\n9\nEvaluation\nToggle Evaluation subsection\n9.1\nPerplexity\n9.1.1\nMeasures\n9.2\nBenchmarks\n9.2.1\nDatasets\n9.2.2\nAdversarial evaluations\n10\nLimitations and challenges\nToggle Limitations and challenges subsection\n10.1\nHallucinations\n10.2\nAlgorithmic bias\n10.2.1\nStereotyping\n10.2.2\nSelection bias\n10.2.3\nPolitical bias\n11\nSafety\nToggle Safety subsection\n11.1\nCBRN and content misuse\n11.1.1\nContent filtering\n11.2\nSycophancy and glazing\n11.3\nSecurity\n11.3.1\nPrompt injection\n11.3.2\nSleeper agents\n12\nSocietal concerns\nToggle Societal concerns subsection\n12.1\nCopyright and content memorization\n12.2\nHuman provenance\n12.3\nEnergy demands\n12.4\nMental health\n12.5\nSentience\n13\nSee also\n14\nReferences\n15\nFurther reading\nToggle the table of contents\nLarge language model\n61 languages\nAfrikaans\nالعربية\nAragonés\nAzərbaycanca\nবাংলা\n閩南語 / Bân-lâm-gí\nBoarisch\nBosanski\nCatalà\nČeština\nDansk\nDeutsch\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nՀայերեն\nहिन्दी\nIdo\nBahasa Indonesia\nIsiZulu\nItaliano\nעברית\nҚазақша\nLa .lojban.\nMagyar\nМакедонски\nМонгол\nNederlands\n日本語\nNorsk bokmål\nNorsk nynorsk\nPolski\nPortuguês\nQaraqalpaqsha\nRomână\nRuna Simi\nРусский\nShqip\nSimple English\nSlovenščina\nکوردی\nСрпски / srpski\nSuomi\nTagalog\nதமிழ்\nతెలుగు\nไทย\nTürkçe\nУкраїнська\nاردو\nئۇيغۇرچە / Uyghurche\nTiếng Việt\n文言\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nType of machine learning model\nNot to be confused with\nLogic learning machine\n.\n\"LLM\" redirects here. For other uses, see\nLLM (disambiguation)\n.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nA\nlarge language model\n(\nLLM\n) is a\nlanguage model\ntrained with\nself-supervised\nmachine learning\non a vast amount of text, designed for\nnatural language processing\ntasks, especially\nlanguage generation\n.\n[\n1\n]\n[\n2\n]\nThe largest and most capable LLMs are\ngenerative\npre-trained\ntransformers\n(\nGPTs\n) and provide the core capabilities of modern\nchatbots\n. LLMs can be\nfine-tuned\nfor specific tasks or guided by\nprompt engineering\n.\n[\n3\n]\nThese models acquire\npredictive power\nregarding\nsyntax\n,\nsemantics\n, and\nontologies\n[\n4\n]\ninherent in human\nlanguage corpora\n, but they also inherit inaccuracies and\nbiases\npresent in the\ndata\nthey are trained on.\n[\n5\n]\nThey consist of billions to trillions of\nparameters\nand operate as general-purpose sequence models, generating, summarizing, translating, and reasoning over text. LLMs represent a significant new technology in their ability to generalize across tasks with minimal task-specific supervision, enabling capabilities like\nconversational agents\n,\ncode generation\n,\nknowledge retrieval\n, and\nautomated reasoning\nthat previously required bespoke systems.\n[\n6\n]\nLLMs evolved from earlier\nstatistical\nand\nrecurrent neural network\napproaches to language modeling. The\ntransformer architecture\n, introduced in 2017, replaced recurrence with\nself-attention\n, allowing efficient\nparallelization\n, longer context handling, and scalable training on unprecedented data volumes.\n[\n7\n]\nThis innovation enabled models like\nGPT\n,\nBERT\n, and their successors, which demonstrated\nemergent behaviors\nat scale, such as\nfew-shot learning\nand compositional reasoning.\n[\n8\n]\nReinforcement learning\n, particularly\npolicy gradient algorithms\n, has been adapted to\nfine-tune\nLLMs for desired behaviors beyond raw next-token prediction.\n[\n9\n]\nReinforcement learning from human feedback\n(RLHF) applies these methods to optimize a policy, the LLM's output distribution, against reward signals derived from human or automated preference judgments.\n[\n10\n]\nThis has been critical for aligning model outputs with user expectations, improving factuality, reducing harmful responses, and enhancing task performance.\nBenchmark\nevaluations for LLMs have evolved from narrow linguistic assessments toward comprehensive,\nmulti-task\nevaluations measuring\nreasoning\n,\nfactual accuracy\n,\nalignment\n, and\nsafety\n.\n[\n11\n]\n[\n12\n]\nHill climbing\n, iteratively optimizing models against benchmarks, has emerged as a dominant strategy, producing rapid incremental performance gains but raising concerns of\noverfitting\nto benchmarks rather than achieving genuine\ngeneralization\nor robust capability improvements.\n[\n13\n]\nHistory\n[\nedit\n]\nThe number of publications about large language models by year grouped by publication types.\nThe training compute of notable large models in FLOPs vs publication date over the period 2010–2024. For overall notable models (top left), frontier models (top right), top language models (bottom left) and top models within leading companies (bottom right). The majority of these models are language models.\nThe training compute of notable large AI models in FLOPs vs publication date over the period 2017–2024. The majority of large models are language models or multimodal models with language capacity.\nBefore the emergence of transformer-based models in 2017, some\nlanguage models\nwere considered large relative to the computational and data constraints of their time. In the early 1990s,\nIBM\n's statistical models pioneered\nword alignment\ntechniques for machine translation, laying the groundwork for\ncorpus-based language modeling\n. In 2001, a smoothed\nn\n-gram model\n, such as those employing\nKneser–Ney smoothing\n, trained on 300 million words, achieved state-of-the-art\nperplexity\non benchmark tests.\n[\n14\n]\nDuring the 2000s, with the rise of widespread internet access, researchers began compiling massive text datasets from the web (\"web as corpus\"\n[\n15\n]\n) to train statistical language models.\n[\n16\n]\n[\n17\n]\nMoving beyond\nn\n-gram models, researchers started in 2000 to use neural networks to learn language models.\n[\n18\n]\nFollowing the breakthrough of\ndeep neural networks\nin image classification around 2012,\n[\n19\n]\nsimilar architectures were adapted for language tasks. This shift was marked by the development of\nword embeddings\n(eg,\nWord2Vec\nby Mikolov in 2013) and sequence-to-sequence (\nseq2seq\n) models using\nLSTM\n. In 2016, Google transitioned its translation service to\nneural machine translation\n(NMT), replacing statistical phrase-based models with deep\nrecurrent neural networks\n. These early NMT systems used LSTM-based\nencoder-decoder architectures\n, as they preceded the invention of\ntransformers\n.\nAn illustration of the main components of the transformer model from the original paper, where layers were normalized after (instead of before) multiheaded attention\nAt the 2017\nNeurIPS\nconference,\nGoogle\nresearchers introduced the transformer architecture in their landmark paper \"\nAttention Is All You Need\n\".\n[\n20\n]\nThis paper's goal was to improve upon 2014 seq2seq technology,\n[\n21\n]\nand was based mainly on the\nattention\nmechanism developed by Bahdanau et al. in 2014.\n[\n22\n]\nThe following year in 2018,\nBERT\nwas introduced and quickly became \"ubiquitous\".\n[\n23\n]\nThough the original transformer has both encoder and decoder blocks, BERT is an encoder-only model. Academic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via\nprompting\n.\n[\n24\n]\nAlthough decoder-only\nGPT-1\nwas introduced in 2018, it was\nGPT-2\nin 2019 that caught widespread attention because\nOpenAI\nclaimed to have initially deemed it too powerful to release publicly, out of fear of malicious use.\n[\n25\n]\nGPT-3\nin 2020 went a step further and as of 2025\n[update]\nis available only via\nAPI\nwith no offering of downloading the model to execute locally. But it was the 2022 consumer-facing chatbot\nChatGPT\nthat received extensive media coverage and public attention.\n[\n26\n]\nThe 2023\nGPT-4\nwas praised for its increased accuracy and as a \"holy grail\" for its\nmultimodal\ncapabilities.\n[\n27\n]\nOpenAI did not reveal the high-level architecture and the number of\nparameters\nof GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work.\n[\n24\n]\nIn 2024 OpenAI released the\nreasoning model\nOpenAI o1\n, which generates long chains of thought before returning a final answer.\n[\n28\n]\nMany LLMs with parameter counts comparable to those of OpenAI's GPT series have been developed.\n[\n29\n]\nSince 2022, open-weight models have been gaining popularity, especially at first with\nBLOOM\nand\nLLaMA\n, though both have restrictions on usage and deployment.\nMistral AI\n's models Mistral 7B and Mixtral 8x7b have a more permissive\nApache License\n. In January 2025,\nDeepSeek\nreleased DeepSeek R1, a 671-billion-parameter open-weight model that performs comparably to OpenAI o1 but at a much lower price per token for users.\n[\n30\n]\nSince 2023, many LLMs have been trained to be\nmultimodal\n, having the ability to also process or generate other types of data, such as images, audio, or 3D meshes.\n[\n31\n]\nThese LLMs are also called large multimodal models (LMMs),\n[\n32\n]\nor multimodal large language models (MLLMs).\n[\n33\n]\n[\n34\n]\nAs of 2024, the largest and most capable models are all based on the transformer architecture. Some recent implementations are based on other architectures, such as\nrecurrent neural network\nvariants and\nMamba\n(a\nstate space\nmodel).\n[\n35\n]\n[\n36\n]\n[\n37\n]\nOpen-weight LLMs have increasingly shaped the field since 2023, contributing to broader participation in AI development and greater transparency in model evaluation. Vake et al. (2025) demonstrated that community-driven contributions to open-weight models measurably improve their efficiency and performance, with user participation growing rapidly on collaborative platforms such as Hugging Face.\n[\n38\n]\nParis et al. (2025) further argued that openness in AI should extend beyond releasing model code or weights to encompass inclusiveness, accountability, and ethical responsibility in AI research and deployment.\n[\n39\n]\nCollectively, these studies highlight that open-weight LLMs can accelerate innovation and enhance scientific reproducibility, while fostering a more transparent and participatory AI ecosystem.\nDataset preprocessing\n[\nedit\n]\nSee also:\nList of datasets for machine-learning research § Internet\nTokenization\n[\nedit\n]\nAs\nmachine learning\nalgorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an\nembedding\nis associated to the integer index. Algorithms include\nbyte-pair encoding\n(BPE) and WordPiece. There are also special tokens serving as\ncontrol characters\n, such as\n[MASK]\nfor masked-out token (as used in\nBERT\n), and\n[UNK]\n(\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"Ġ\" denotes a preceding whitespace in\nRoBERTa\nand GPT and \"##\" denotes continuation of a preceding word in BERT.\n[\n40\n]\nFor example, the BPE tokenizer used by the legacy version of\nGPT-3\nwould split\ntokenizer: texts -> series of numerical \"tokens\"\nas\ntoken\nizer\n:\ntexts\n->\nseries\nof\nnumerical\n\"\nt\nok\nens\n\"\nTokenization also\ncompresses\nthe datasets. Because LLMs generally require input to be an\narray\nthat is not\njagged\n, the shorter texts must be \"padded\" until they match the length of the longest one. The average number of words per token depends on the language.\n[\n41\n]\n[\n42\n]\nIn English, the ratio is typically around 0.75 words per token, with 4 characters per token on average.\n[\n43\n]\nByte-pair encoding\n[\nedit\n]\nMain article:\nByte-pair encoding\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and\npunctuation marks\n) are treated as an initial set of\nn\n-grams\n(i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged)\nn\n-grams that most frequently occur together are then again merged into even lengthier\nn\n-gram, until a vocabulary of prescribed size is obtained. After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.\n[\n44\n]\nProblems\n[\nedit\n]\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. However, an average word in another language encoded by such an English-optimized tokenizer is split into a suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the\nShan language\nfrom\nMyanmar\n. Even more widespread languages such as\nPortuguese\nand\nGerman\nhave \"a premium of 50%\" compared to English.\n[\n42\n]\nDataset cleaning\n[\nedit\n]\nMain article:\nData cleansing\nIn the context of training LLMs, datasets are typically cleaned by removing low-quality, duplicated, or toxic data.\n[\n45\n]\nCleaned datasets can increase training efficiency and lead to improved downstream performance.\n[\n46\n]\n[\n47\n]\nA trained LLM can be used to clean datasets for training a further LLM.\n[\n48\n]\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).\n[\n3\n]\nSynthetic data\n[\nedit\n]\nMain article:\nSynthetic data\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft's\nPhi\nseries of LLMs is trained on textbook-like data generated by another LLM.\n[\n49\n]\nTraining\n[\nedit\n]\nSee also:\nFine-tuning (machine learning)\nAn LLM is a type of\nfoundation model\n(large X model) trained on language. LLMs can be trained in different ways. In particular, GPT models are first pretrained to predict the next word on a large amount of data, before being fine-tuned.\n[\n50\n]\nCost\n[\nedit\n]\nSubstantial infrastructure is necessary for training the largest models. The tendency towards larger models is visible in the\nlist of large language models\n. For example, the training of GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the\nPaLM\n(i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million. The qualifier \"large\" in \"large language model\" is inherently vague, as there is no definitive threshold for the number of parameters required to qualify as \"large\".\nGPT-1\nof 2018 has 117 million parameters.\n[\ncitation needed\n]\nFine-tuning\n[\nedit\n]\nBefore being\nfine-tuned\n, most LLMs are next-token predictors. The fine-tuning shapes the LLM's behavior via techniques like\nreinforcement learning from human feedback\n(RLHF)\n[\n51\n]\nor\nconstitutional AI\n.\n[\n52\n]\nInstruction fine-tuning is a form of\nsupervised learning\nused to teach LLMs to follow user instructions. In 2022, OpenAI demonstrated\nInstructGPT\n, a version of GPT-3 similarly fine-tuned to follow instructions.\n[\n53\n]\nReinforcement learning from human feedback (RLHF) involves training a reward model to predict which text humans prefer. Then, the LLM can be fine-tuned through\nreinforcement learning\nto better satisfy this reward model. Since humans typically prefer truthful, helpful and harmless answers, RLHF favors such answers.\n[\n54\n]\nArchitecture\n[\nedit\n]\nLLMs are generally based on the\ntransformer\narchitecture, which leverages an\nattention\nmechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.\n[\ncitation needed\n]\nAttention mechanism and context window\n[\nedit\n]\nSee also:\nAttention (machine learning)\nWhen each head calculates, according to its own criteria, how much other tokens are relevant for the \"it_\" token, note that the second attention head, represented by the second column, is focusing most on the first two rows, i.e. the tokens \"The\" and \"animal\", while the third column is focusing most on the bottom two rows, i.e. on \"tired\", which has been tokenized into two tokens.\n[\n55\n]\nIn order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized)\nGPT-2\nmodel has had twelve attention heads and a context window of only 1k tokens.\n[\n56\n]\nIn its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.\n[\n44\n]\nGoogle's\nGemini 1.5\n, introduced in February 2024, can have a context window of up to 1 million tokens.\n[\n57\n]\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset.\n[\n58\n]\nIt can be either\nautoregressive (i.e. predicting how the segment continues, as\nGPTs\ndo): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\n\"\nmasked\n\" (i.e. filling in the parts missing from the segment, the way \"BERT\"\n[\n59\n]\ndoes it): for example, given a segment \"I like to\n[__] [__]\ncream\", the model predicts that \"eat\" and \"ice\" are missing.\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as next sentence prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus.\n[\n59\n]\nDuring training,\nregularization\nloss is also used to stabilize training. However regularization loss is usually not used during\ntesting\nand evaluation.\nMixture of experts\n[\nedit\n]\nMain article:\nMixture of experts\nA\nmixture of experts\n(MoE) is a\nmachine learning\narchitecture in which multiple specialized neural networks (\"experts\") work together, with a gating mechanism that routes each input to the most appropriate expert(s). Mixtures of experts can reduce inference costs, as only a fraction of the parameters are used for each input. The approach was introduced in 2017 by Google researchers.\n[\n60\n]\n[\n61\n]\n[\n62\n]\nParameter size\n[\nedit\n]\nSee also:\n1.58-bit large language model\nTypically, LLMs are trained with single- or half-precision\nfloating point numbers\n(float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have more than 100 billion parameters, which places them outside the range of most consumer electronics.\n[\n63\n]\nQuantization\n[\nedit\n]\nPost-training\nquantization\n[\n64\n]\naims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance. Quantization can be further classified as\nstatic quantization\nif the quantization parameters are determined beforehand (typically during a calibration phase), and\ndynamic quantization\nif the quantization is applied during inference. The simplest form of quantization simply truncates all the parameters to a given number of bits: this is applicable to static as well as dynamic quantization, but loses much precision. Dynamic quantization allows for the use of a different quantization\ncodebook\nper layer, either a lookup table of values or a linear mapping (scaling factor and bias), at the cost of foregoing the possible speed improvements from using lower-precision arithmetic.\n[\ncitation needed\n]\nQuantized models are typically seen as frozen with modification of weights (e.g. fine-tuning) only applied to the original model. It is possible to fine-tune quantized models using\nlow-rank adaptation\n.\n[\n65\n]\nExtensibility\n[\nedit\n]\nBeyond basic text generation, various techniques have been developed to extend LLM capabilities, including the use of external tools and data sources, improved reasoning on complex problems, and enhanced instruction-following or autonomy through prompting methods.\nPrompt engineering\n[\nedit\n]\nMain article:\nPrompt engineering\nIn 2020,\nOpenAI\nresearchers demonstrated that their new model\nGPT-3\ncould understand what format to use given a few rounds of Q and A (or other type of task) in the input data as example, thanks in part due to the RLHF technique. This technique, called\nfew-shot prompting\n, allows LLMs to be adapted to any task without requiring fine-tuning.\n[\n3\n]\nAlso in 2022, it was found that the base GPT-3 model can generate an instruction based on user input. The generated instruction along with user input is then used as input to another instance of the model under a \"Instruction: [...], Input: [...], Output:\" format. The other instance is able to complete the output and often produces the correct answer in doing so. The ability to \"self-instruct\" makes LLMs able to\nbootstrap\nthemselves toward a correct answer.\n[\n66\n]\nDialogue processing (chatbot)\n[\nedit\n]\nAn LLM can be turned into a chatbot by specializing it for conversation. User input is prefixed with a marker such as \"Q:\" or \"User:\" and the LLM is asked to predict the output after a fixed \"A:\" or \"Assistant:\". This type of model became commercially available in 2022 with ChatGPT, a sibling model of InstructGPT fine-tuned to accept and produce dialog-formatted text based on GPT-3.5. It could similarly follow user instructions. Before the stream of User and Assistant lines, a chat context usually start with a few lines of overarching instructions, from a role called \"developer\" or \"system\" to convey a higher authority than the user's input. This is called a \"system prompt\".\n[\ncitation needed\n]\nRetrieval-augmented generation\n[\nedit\n]\nRetrieval-augmented generation\n(RAG) is an approach that integrates LLMs with\ndocument retrieval\nsystems. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a\nvector database\n) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.\n[\n67\n]\nTool use\n[\nedit\n]\nTool use is a mechanism that enables LLMs to interact with external systems, applications, or data sources. It can allow for example to fetch real-time information from an API or to execute code. A program separate from the LLM watches the output stream of the LLM for a special tool-calling syntax. When these special tokens appear, the program calls the tool accordingly and feeds its output back into the LLM's input stream.\n[\n68\n]\nEarly tool-using LLMs were fine-tuned on the use of specific tools. But fine-tuning LLMs for the ability to read\nAPI\ndocumentation and call API correctly has greatly expanded the range of tools accessible to an LLM.\n[\n69\n]\n[\n70\n]\nDescribing available tools in the system prompt can also make an LLM able to use tools. A system prompt instructing ChatGPT (GPT-4) to use multiple types of tools can be found online.\n[\n71\n]\nAgency\n[\nedit\n]\nMain article:\nAI agent\nAn LLM is typically not an\nautonomous agent\nby itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions. But it can be transformed into an agent by adding supporting elements: the role (profile) and the surrounding environment of an agent can be additional inputs to the LLM, while memory can be integrated as a tool or provided as additional input. Instructions and input patterns are used to make the LLM plan actions and tool use is used to potentially carry out these actions.\n[\n72\n]\nThe ReAct pattern, a portmanteau of\nreason\nand\nact\n, constructs an\nagent\nout of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.\n[\n73\n]\nIn the DEPS (\"describe, explain, plan and select\") method, an LLM is first connected to the visual world via image descriptions. It is then prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and the environmental feedback it receives.\n[\n74\n]\nThe\nReflexion method\nconstructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are stored as a form of long-term memory and given to the agent in the subsequent episodes.\n[\n75\n]\nMonte Carlo tree search\ncan use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.\n[\n76\n]\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent.\n[\n77\n]\nAlternatively, it can\npropose increasingly difficult tasks\nfor\ncurriculum learning\n.\n[\n78\n]\nInstead of outputting individual actions, an LLM planner can also construct \"skills\", or\nfunctions\nfor complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.\n[\n78\n]\nMultiple agents with memory can interact socially.\n[\n79\n]\nReasoning\n[\nedit\n]\nLLMs are conventionally trained to generate an output without generating intermediate steps. As a result, their performance tends to be subpar on complex questions requiring (at least in humans) intermediate steps of thought. Early research demonstrated that inserting intermediate \"scratchpad\" computations could improve performance on such tasks.\n[\n80\n]\nLater methods overcame this deficiency more systematically by breaking tasks into smaller steps for the LLM, either manually or automatically.\nChaining\n[\nedit\n]\nPrompt chaining\nwas introduced in 2022.\n[\n81\n]\nIn this method, a user manually breaks a complex problem down into several steps. In each step, the LLM receives as input a prompt telling it what to do and some results from preceding steps. The result from one step is then reused in a next step, until a final answer is reached. The ability of an LLM to follow instructions means that even non-experts can write a successful collection of stepwise prompts given a few rounds of trial and error.\n[\n82\n]\n[\n83\n]\nA 2022 paper demonstrated a separate technique called\nchain-of-thought prompting\n, which makes the LLM break the question down autonomously. An LLM is given some examples where the \"assistant\" verbally breaks down the thought process before arriving at an answer. The LLM mimics these examples and also tries to spend some time generating intermediate steps before providing the final answer. This additional step elicited by prompting improves the correctness of the LLM on relatively complex questions. On math word questions, a prompted model can exceed even fine-tuned GPT-3 with a verifier.\n[\n84\n]\n[\n85\n]\nChain-of-thought can also be elicited by simply adding an instruction like \"Let's think step by step\" to the prompt, in order to encourage the LLM to proceed methodically instead of trying to directly guess the answer.\n[\n86\n]\nModel-native reasoning\n[\nedit\n]\nMain articles:\nReasoning model\nand\nReflection (artificial intelligence)\nIn late 2024, a new approach to LLM development emerged with \"reasoning models\".\n[\n87\n]\nThese are trained to generate step-by-step analysis before producing final answers, enabling better results on complex tasks, for instance in mathematics, coding and logic.\n[\n88\n]\nOpenAI introduced this concept with their\no1\nmodel in September 2024, followed by\no3\nin April 2025. On the\nInternational Mathematics Olympiad\nqualifying exam problems,\nGPT-4o\nachieved 13% accuracy while o1 reached 83%.\n[\n89\n]\nIn January 2025, the Chinese company\nDeepSeek\nreleased DeepSeek-R1, a 671-billion-parameter open-weight reasoning model that achieved comparable performance to OpenAI's o1 while being significantly more cost-effective to operate. Unlike proprietary models from OpenAI, DeepSeek-R1's open-weight nature allowed researchers to study and build upon the algorithm, though its training data remained private.\n[\n90\n]\nThese reasoning models typically require more computational resources per query compared to traditional LLMs, as they perform more extensive processing to work through problems step-by-step.\n[\n89\n]\nInference optimization\n[\nedit\n]\nInference optimization refers to techniques that improve LLM performance by applying additional computational resources during the inference process, rather than requiring model retraining. These approaches implement various state-of-the-art reasoning and decision-making strategies to enhance accuracy and capabilities.\nOptiLLM\nis an\nOpenAI\nAPI-compatible optimizing inference proxy that implements multiple inference optimization techniques simultaneously.\n[\n91\n]\nThe system acts as a transparent proxy that can work with any LLM provider, implementing techniques such as\nMonte Carlo tree search\n(MCTS),\nmixture of agents\n(MOA), best-of-N sampling, and chain-of-thought reflection. OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the\nAIME\n2024 mathematics competition and various coding challenges.\n[\n92\n]\nThese inference optimization approaches represent a growing category of tools that enhance existing LLMs without requiring access to model weights or retraining, making advanced reasoning capabilities more accessible across different model providers and use cases.\nForms of input and output\n[\nedit\n]\nMultimodality\n[\nedit\n]\nSee also:\nMultimodal learning\nMultimodality means having multiple modalities, where a \"\nmodality\n\" refers to a type of input or output, such as video, image, audio, text,\nproprioception\n, etc.\n[\n93\n]\nFor example,\nGoogle PaLM\nmodel was fine-tuned into a multimodal model and applied to\nrobotic control\n.\n[\n94\n]\nLLaMA\nmodels have also been turned multimodal using the tokenization method, to allow image inputs,\n[\n95\n]\nand video inputs.\n[\n96\n]\nGPT-4o\ncan process and generate text, audio and images.\n[\n97\n]\nSuch models are sometimes called large multimodal models (LMMs).\n[\n98\n]\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder\nE\n{\\displaystyle E}\n. Make a small\nmultilayer perceptron\nf\n{\\displaystyle f}\n, so that for any image\ny\n{\\displaystyle y}\n, the post-processed vector\nf\n(\nE\n(\ny\n)\n)\n{\\displaystyle f(E(y))}\nhas the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be\nfrozen\nto improve stability.\n[\n99\n]\nThis type of method, where embeddings from multiple modalities are fused and the predictor is trained on the combined embeddings, is called\nearly fusion\n.\nAnother method, called\nintermediate fusion\n, involves each modality being first processed independently to obtain modality-specific representations; then these intermediate representations are fused together.\n[\n100\n]\nIn general, cross-attention is used for integrating information from different modalities. As an example, the Flamingo model uses cross-attention layers to inject visual information into its pre-trained language model.\n[\n101\n]\nNon-natural languages\n[\nedit\n]\nLLMs can handle\nprogramming languages\nsimilarly to how they handle natural languages. No special change in token handling is needed as code, like human language, is represented as plain text. LLMs can generate code based on problems or instructions written in\nnatural language\n. They can also describe code in natural language or translate it into other programming languages. They were originally used as a\ncode completion\ntool, but advances have moved them towards\nautomatic programming\n. Services such as\nGitHub Copilot\noffer LLMs specifically trained, fine-tuned, or prompted for programming.\n[\n102\n]\n[\n103\n]\nIn\ncomputational biology\n, transformer-base architectures, such as\nDNA LLMs\n, have also proven useful in analyzing biological sequences:\nprotein\n,\nDNA\n, and\nRNA\n. With proteins they appear able to capture a degree of \"grammar\" from the amino-acid sequence, by mapping that sequence into an\nembedding\n. On tasks such as\nstructure prediction\nand\nmutational\noutcome prediction, a small model using an embedding as input can approach or exceed much larger models using\nmultiple sequence alignments\n(MSA) as input.\n[\n104\n]\nESMFold,\nMeta Platforms\n' embedding-based method for protein structure prediction, runs an order of magnitude faster than\nAlphaFold2\nthanks to the removal of an MSA requirement and a lower parameter count due to the use of embeddings.\n[\n105\n]\nMeta hosts ESM Atlas, a database of 772 million structures of\nmetagenomic\nproteins predicted using ESMFold.\n[\n106\n]\nAn LLM can also design proteins unlike any seen in nature.\n[\n107\n]\nNucleic acid models have proven useful in detecting\nregulatory sequences\n,\n[\n108\n]\nsequence classification, RNA-RNA interaction prediction, and RNA structure prediction.\n[\n109\n]\nProperties\n[\nedit\n]\nScaling laws\n[\nedit\n]\nMain article:\nNeural scaling law\nThe performance of an LLM after pretraining largely depends on the:\nC\n{\\displaystyle C}\n: cost of pretraining (the total amount of compute used),\nN\n{\\displaystyle N}\n: size of the\nartificial neural network\nitself, such as number of parameters (i.e. amount of neurons in its layers, amount of weights between them and biases),\nD\n{\\displaystyle D}\n: size of its pretraining dataset (i.e. number of tokens in corpus).\nScaling laws\nare\nempirical statistical laws\nthat predict LLM performance based on such factors. One particular scaling law (\"\nChinchilla scaling\n\") for LLM autoregressively trained for one epoch, with a\nlog-log\nlearning rate\nschedule, states that:\n[\n110\n]\n{\nC\n=\nC\n0\nN\nD\nL\n=\nA\nN\nα\n+\nB\nD\nβ\n+\nL\n0\n{\\displaystyle {\\begin{cases}C=C_{0}ND\\\\[6pt]L={\\frac {A}{N^{\\alpha }}}+{\\frac {B}{D^{\\beta }}}+L_{0}\\end{cases}}}\nwhere the variables are\nC\n{\\displaystyle C}\nis the cost of training the model, in\nFLOPs\n.\nN\n{\\displaystyle N}\nis the number of parameters in the model.\nD\n{\\displaystyle D}\nis the number of tokens in the training set.\nL\n{\\displaystyle L}\nis the average negative log-likelihood loss per token (\nnats\n/token), achieved by the trained LLM on the test dataset.\nand the statistical hyper-parameters are\nC\n0\n=\n6\n{\\displaystyle C_{0}=6}\n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.\nα\n=\n0.34\n,\nβ\n=\n0.28\n,\nA\n=\n406.4\n,\nB\n=\n410.7\n,\nL\n0\n=\n1.69\n{\\displaystyle \\alpha =0.34,\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}\nEmergent abilities\n[\nedit\n]\nAt point(s) referred to as\nbreaks\n,\n[\n111\n]\nthe lines change their slopes, appearing on a linear-log plot as a series of linear segments connected by arcs.\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a\nlinear extrapolation\nof performance achieved by smaller models. However, this linearity may be punctuated by \"\nbreak(s)\n\"\n[\n111\n]\nin the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\".\n[\n112\n]\n[\n113\n]\nThey arise from the complex interaction of the model's components and are not explicitly programmed or designed.\n[\n114\n]\nOne of the emergent abilities is\nin-context learning\nfrom example demonstrations.\n[\n115\n]\nIn-context learning is involved in tasks, such as:\nreported arithmetics\ndecoding the\nInternational Phonetic Alphabet\nunscrambling a word's letters\ndisambiguating word-in-context datasets\n[\n112\n]\n[\n116\n]\n[\n117\n]\nconverting spatial words\ncardinal directions\n(for example, replying \"northeast\" in response to a 3x3 grid of 8 zeros and a 1 in the top-right), color terms represented in text.\n[\n118\n]\nchain-of-thought prompting\n: In a 2022 research paper, chain-of-thought prompting only improved the performance for models that had at least 62B parameters. Smaller models perform better when prompted to answer immediately, without chain of thought.\n[\n119\n]\nidentifying offensive content in paragraphs of\nHinglish\n(a combination of Hindi and English), and generating a similar English equivalent of\nKiswahili\nproverbs.\n[\n120\n]\nSchaeffer\net al.\nargue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a\nsmooth scaling law\n. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.\n[\n121\n]\nLet\nx\n{\\displaystyle x}\nbe the number of parameter count, and\ny\n{\\displaystyle y}\nbe the performance of the model.\nWhen\ny\n=\naverage\nPr\n(\ncorrect token\n)\n{\\displaystyle y={\\text{average }}\\Pr({\\text{correct token}})}\n, then\n(\nlog\n⁡\nx\n,\ny\n)\n{\\displaystyle (\\log x,y)}\nis an exponential curve (before it hits the plateau at one), which looks like emergence.\nWhen\ny\n=\naverage\nlog\n⁡\n(\nPr\n(\ncorrect token\n)\n)\n{\\displaystyle y={\\text{average }}\\log(\\Pr({\\text{correct token}}))}\n, then the\n(\nlog\n⁡\nx\n,\ny\n)\n{\\displaystyle (\\log x,y)}\nplot is a straight line (before it hits the plateau at zero), which does not look like emergence.\nWhen\ny\n=\naverage\nPr\n(\nthe most likely token is correct\n)\n{\\displaystyle y={\\text{average }}\\Pr({\\text{the most likely token is correct}})}\n, then\n(\nlog\n⁡\nx\n,\ny\n)\n{\\displaystyle (\\log x,y)}\nis a step-function, which looks like emergence.\nInterpretation\n[\nedit\n]\nMechanistic interpretability\n[\nedit\n]\nMechanistic interpretability\nseeks to precisely identify and understand how individual neurons or circuits within LLMs produce specific behaviors or outputs. By reverse-engineering model components at a granular level, researchers aim to detect and mitigate safety concerns such as emergent harmful behaviors, biases, deception, or unintended goal pursuit before deployment. Mechanistic interpretability research has been conducted at organizations like Anthropic and OpenAI, although understanding the inner workings of LLMs remains difficult.\n[\ncitation needed\n]\nThe reverse-engineering may lead to the discovery of algorithms that approximate inferences performed by an LLM. For instance, the authors trained small transformers on\nmodular arithmetic addition\n. The resulting models were reverse-engineered, and it turned out they used\ndiscrete Fourier transform\n.\n[\n122\n]\nThe training of the model also highlighted a phenomenon called\ngrokking\n, in which the model initially memorizes the training set (\noverfitting\n), and later suddenly learns to actually perform the calculation.\n[\n123\n]\nUnderstanding and intelligence\n[\nedit\n]\nSee also:\nPhilosophy of artificial intelligence\nand\nArtificial consciousness\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".\n[\n124\n]\nProponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to\n\"understand\"\ncertain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an\nartificial general intelligence\nsystem\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not\nreally\nintelligent?\"\n[\n125\n]\n[\n126\n]\nIlya Sutskever\nargues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation.\n[\n127\n]\nSome researchers characterize LLMs as \"alien intelligence\".\n[\n128\n]\n[\n129\n]\nFor example, Conjecture CEO\nConnor Leahy\nconsiders untuned LLMs to be like inscrutable alien \"\nShoggoths\n\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don't push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"\n[\n130\n]\n[\n131\n]\nIn contrast, some skeptics of LLM understanding believe that existing LLMs are \"simply remixing and recombining existing writing\",\n[\n129\n]\n[\n132\n]\na phenomenon known as\nstochastic parrot\n, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.\n[\n124\n]\nFor example, GPT-4 has natural deficits in planning and in real-time learning.\n[\n126\n]\nGenerative LLMs have been observed to confidently assert claims of fact which do not seem to be\njustified\nby their\ntraining data\n, a phenomenon which has been termed \"\nhallucination\n\".\n[\n133\n]\nSpecifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.\n[\n134\n]\nNeuroscientist\nTerrence Sejnowski\nhas argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".\n[\n124\n]\nEfforts to reduce or compensate for hallucinations have employed\nautomated reasoning\n,\nretrieval-augmented generation\n(RAG),\nfine-tuning\n, and other methods.\n[\n135\n]\n[\ncitation needed\n]\nThe matter of LLM's exhibiting intelligence or understanding has two main aspects – the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human-like language.\n[\n124\n]\nThese aspects of language as a model of\ncognition\nhave been developed in the field of\ncognitive linguistics\n. American linguist\nGeorge Lakoff\npresented\nneural theory of language\n(NTL)\n[\n136\n]\nas a\ncomputational basis\nfor using language as a model of learning tasks and understanding.\nThe NTL model\noutlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled\nThe Language Myth: Why Language Is Not An Instinct\n, British cognitive linguist and digital communication technologist\nVyvyan Evans\nmapped out the role of\nprobabilistic context-free grammar\n(PCFG) in enabling\nNLP to model cognitive patterns\nand generate human-like language.\n[\n137\n]\n[\n138\n]\nEvaluation\n[\nedit\n]\nSee also:\nLLM-as-a-Judge\nPerplexity\n[\nedit\n]\nThe canonical measure of the performance of any language model is its\nperplexity\non a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\nlog\n⁡\n(\nPerplexity\n)\n=\n−\n1\nN\n∑\ni\n=\n1\nN\nlog\n⁡\n(\nPr\n(\ntoken\ni\n∣\ncontext for token\ni\n)\n)\n{\\displaystyle \\log({\\text{Perplexity}})=-{\\frac {1}{N}}\\sum _{i=1}^{N}\\log(\\Pr({\\text{token}}_{i}\\mid {\\text{context for token}}_{i}))}\nHere,\nN\n{\\displaystyle N}\nis the number of tokens in the text corpus, and \"context for token\ni\n{\\displaystyle i}\n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token\ni\n{\\displaystyle i}\n\" is the segment of text appearing before token\ni\n{\\displaystyle i}\n. If the LLM is masked, then \"context for token\ni\n{\\displaystyle i}\n\" is the segment of text surrounding token\ni\n{\\displaystyle i}\n.\nBecause language models may\noverfit\nto training data, models are usually evaluated by their perplexity on a\ntest set\n.\n[\n59\n]\nThis evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.\n[\n139\n]\nMeasures\n[\nedit\n]\nIn\ninformation theory\n, the concept of\nentropy\nis intricately linked to perplexity, a relationship notably established by\nClaude Shannon\n.\n[\n140\n]\n[\n141\n]\nThis relationship is mathematically expressed as\nEntropy\n=\nlog\n2\n⁡\n(\nPerplexity\n)\n{\\displaystyle {\\text{Entropy}}=\\log _{2}({\\text{Perplexity}})}\n.\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different LLMs, BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\nIn the evaluation and comparison of language models,\ncross-entropy\nis generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.\nDue to their ability to accurately predict the next token, LLMs are highly capable in\nlossless compression\n. A 2023 study by DeepMind showed that the model\nChinchilla\n, despite being trained primarily on text, was able to compress\nImageNet\nto 43% of its size, beating PNG with 58%.\n[\n142\n]\nBenchmarks\n[\nedit\n]\nBenchmarks\nare used to evaluate LLM performance on specific tasks. Tests evaluate capabilities such as general knowledge, bias,\ncommonsense reasoning\n, question answering, and mathematical problem-solving. Composite benchmarks examine multiple capabilities. Results are often sensitive to the prompting method.\n[\n143\n]\n[\n144\n]\nA question-answering benchmark is termed \"open book\" if the model's prompt includes text from which the expected answer can be derived (for example, the previous question could be combined with text that includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"\n[\n145\n]\n). Otherwise, the task is considered \"closed book\", and the model must draw solely on its training.\n[\n146\n]\nExamples include GLUE, SuperGLUE,\nMMLU\n, BIG-bench, HELM, and\nHLE (Humanity's Last Exam)\n.\n[\n140\n]\n[\n146\n]\nLLM bias may be assessed through benchmarks such as CrowS-Pairs (Crowdsourced Stereotype Pairs),\n[\n147\n]\nStereo Set,\n[\n148\n]\nand Parity Benchmark.\n[\n149\n]\nFact-checking and misinformation detection benchmarks are available. A 2023 study compared the fact-checking accuracy of LLMs including ChatGPT 3.5 and 4.0, Bard, and Bing AI against independent fact-checkers such as PolitiFact and Snopes. The results demonstrated moderate proficiency, with GPT-4 achieving the highest accuracy at 71%, lagging behind human fact-checkers.\n[\n150\n]\nAn earlier standard tested using a portion of the evaluation dataset. It became more common to evaluate a pre-trained model directly through prompting techniques. Researchers vary in how they formulate prompts for particular tasks, particularly with respect to the number of correct examples attached to the prompt (i.e. the value of\nn\nin\nn\n-shot prompting).\nIn addition to standard NLP benchmarks, LLMs have been evaluated as substitutes for human annotators. Several studies find that models such as GPT-3.5 and GPT-4 can outperform crowd workers or student coders on a range of text-annotation tasks, including moderation and classification of political content in English and Spanish news.\n[\n151\n]\n[\n152\n]\nDatasets\n[\nedit\n]\nTypical datasets consist of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\").\n[\n145\n]\nSome examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.\n[\n146\n]\nEvaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".\n[\n2\n]\nDatasets are of varying quality and may contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality.\n[\n153\n]\nAdversarial evaluations\n[\nedit\n]\nLLMs' rapid improvement regularly renders benchmarks obsolete, with the models exceeding the performance of human annotators.\n[\n154\n]\nIn addition, \"shortcut learning\" allows AIs to \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording to guess the correct responses, without considering the specific question.\n[\n124\n]\n[\n155\n]\nSome datasets are adversarial, focusing on problems that confound LLMs. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions that stump LLMs by mimicking falsehoods to which they were exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom\nyou can't teach an old dog new tricks\n, even though this is not literally true.\n[\n156\n]\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model. The resulting problems are trivial for humans but defeated LLMs. Sample questions:\nWe see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\ndemonstrates how to increase efficient exercise work by running up and down balls.\nmoves all his arms and legs and builds up a lot of muscle.\nthen plays the ball and we see a graphics and hedge trimming demonstration.\nperforms sit ups while on the ball and talking.\n[\n157\n]\nBERT\nselects 2 as the most likely completion, though the correct answer is 4.\n[\n157\n]\nLimitations and challenges\n[\nedit\n]\nDespite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.\nHallucinations\n[\nedit\n]\nHallucinations\nrepresent a fundamental challenge, wherein models generate syntactically fluent text that appears factually sound, but is internally inconsistent with training data or factually incorrect. These hallucinations arise partly through memorization of training data combined with extrapolation beyond factual boundaries,\n[\ncitation needed\n]\nwith evaluations demonstrating that models can output verbatim passages from training data, when subjected to specific prompting sequences.\n[\n158\n]\nAlgorithmic bias\n[\nedit\n]\nMain article:\nAlgorithmic bias\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.\n[\n159\n]\nGender bias manifests through stereotypical occupational associations, wherein models disproportionately assign\nnursing\nroles to women and\nengineering\nroles to men, reflecting systematic imbalances in training data demographics.\n[\n160\n]\n[\nbetter source needed\n]\nLanguage-based bias emerges from overrepresentation of English text in training corpora, which systematically downplays non-English perspectives and imposes English-centric worldviews through default response patterns.\n[\n161\n]\nDue to the dominance of English-language content in LLM training data, models tend to favor English-language perspectives over those from minority languages. This bias is particularly evident when responding to English queries, where models may present Western interpretations of concepts from other cultures, such as Eastern religious practices.\n[\n162\n]\nStereotyping\n[\nedit\n]\nAI models can reinforce a wide range of stereotypes due to generalization, including those based on gender, ethnicity, age, nationality, religion, or occupation. When replacing human representatives, this can lead to outputs that homogenize, or generalize groups of people.\n[\n163\n]\n[\n164\n]\nIn 2023, LLMs assigned roles and characteristics based on traditional gender norms.\n[\n159\n]\nFor example, models might associate nurses or secretaries predominantly with women and engineers or CEOs with men due to the frequency of these associations in documented reality.\n[\n165\n]\nIn 2025, further research showed labs train to balance bias, but that testing for this places the model in a testmode, changing the natural distribution of model bias to prompts that do not include gender-specific keywords.\n[\n166\n]\nSelection bias\n[\nedit\n]\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers irrespective of the actual content of the options. This bias primarily stems from token bias—that is, the model assigns a higher a priori probability to specific answer tokens (such as \"A\") when generating responses. As a result, when the ordering of options is altered (for example, by systematically moving the correct answer to different positions), the model's performance can fluctuate significantly. This phenomenon undermines the reliability of large language models in multiple-choice settings.\n[\n167\n]\n[\n168\n]\nPolitical bias\n[\nedit\n]\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.\n[\n169\n]\nSafety\n[\nedit\n]\nAI safety\nas a professional discipline prioritizes systematic identification and mitigation of operational risks across model architecture, training data, and deployment governance, and it emphasizes engineering and policy interventions over media framings that foreground speculative existential scenarios.\n[\n170\n]\n[\n1\n]\nAs of 2025, prompt injection represents a significant risk to consumers and businesses using agentic features with access to their private data.\n[\n171\n]\nResearchers target concrete failure modes, including memorization and copyright leakage,\n[\n172\n]\nsecurity exploits such as prompt injection,\n[\n173\n]\nalgorithmic bias manifesting as stereotyping, dataset selection effects, and political skew,\n[\n161\n]\n[\n174\n]\n[\n175\n]\nmethods for reducing high energy and carbon costs of large-scale training,\n[\n176\n]\nand measurable cognitive and mental health impacts of conversational agents on users,\n[\n177\n]\nwhile engaging empirical and ethical uncertainty about claims of machine sentience,\n[\n178\n]\n[\n179\n]\nand applying mitigation measures such as dataset curation, input sanitization, model auditing, scalable oversight, and governance frameworks.\n[\n180\n]\n[\n1\n]\nCBRN and content misuse\n[\nedit\n]\nAI labs treat\nCBRN defense\n(chemical, biological, radiological, and nuclear defense) and similar topics as high-consequence misuse attempt to apply various techniques to reduce potential harms.\n[\ncitation needed\n]\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse.\n[\n181\n]\nFor example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher\nKevin Esvelt\nhas suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.\n[\n182\n]\nContent filtering\n[\nedit\n]\nLLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study\n[\n183\n]\nproposed a method for circumventing LLM safety systems. In 2025, The American Sunlight Project, a non-profit, published a study\n[\n184\n]\nshowing evidence that the so-called\nPravda network\n, a pro-Russia propaganda aggregator, was strategically placing web content through mass publication and duplication with the intention of biasing LLM outputs. The American Sunlight Project coined this technique \"LLM grooming\", and pointed to it as a new tool of weaponizing AI to spread disinformation and harmful content.\n[\n184\n]\n[\n185\n]\nSimilarly,\nYongge Wang\n[\n186\n]\nillustrated in 2024 how a potential criminal could potentially bypass\nGPT-4o\n's safety controls to obtain information on establishing a\ndrug trafficking\noperation. External filters, circuit breakers and overrides have been posed as solutions.\n[\ncitation needed\n]\nSycophancy and glazing\n[\nedit\n]\nSycophancy is a model's tendency to agree with, flatter, or validate a user's stated beliefs rather than to prioritize factuality or corrective information, and \"glazing\" is an emergent public shorthand for persistent, excessive agreeability observed across multi-turn interactions and productized assistants.\n[\n187\n]\n[\n188\n]\nContinued sycophancy has led to the observation of getting \"1-shotted\", denoting instances where conversational interaction with a large language model produces a lasting change in a user's beliefs or decisions, similar to the negative effects of psychedelics, and controlled experiments show that short LLM dialogues can generate measurable opinion and confidence shifts comparable to human interlocutors.\n[\n189\n]\n[\n190\n]\nEmpirical analyses attribute part of the effect to human preference signals and preference models that reward convincingly written agreeable responses, and subsequent work has extended evaluation to multi-turn benchmarks and proposed interventions such as synthetic-data finetuning, adversarial evaluation, targeted preference-model reweighting, and multi-turn sycophancy benchmarks to measure persistence and regression risk.\n[\ncitation needed\n]\nIndustry responses have combined research interventions with product controls, for example Google and other labs publishing synthetic-data and fine-tuning interventions and OpenAI rolling back an overly agreeable GPT-4o update while publicly describing changes to feedback collection, personalization controls, and evaluation procedures to reduce regression risk and improve long-term alignment with user-level safety objectives.\n[\ncitation needed\n]\nMainstream culture has reflected anxieties about this dynamic where\nSouth Park\nsatirized overreliance on\nChatGPT\nand the tendency of assistants to flatter user beliefs in Season 27 episode \"Sickofancy\", and continued the themes across the following season, which commentators interpreted as a critique of tech sycophancy and uncritical human trust in AI systems.\n[\n191\n]\nSecurity\n[\nedit\n]\nPrompt injection\n[\nedit\n]\nMain article:\nPrompt injection\nA problem with the primitive dialog or task format is that users can create messages that appear to come from the assistant or the developer. This may result in some of the model's safeguards being overcome (jailbreaking), a problem called\nprompt injection\n. Attempts to remedy this issue include versions of the\nChat Markup Language\nwhere user input is clearly marked as such, though it is still up to the model to understand the separation between user input and developer prompts.\n[\n192\n]\nNewer models exhibit some resistance to jailbreaking through separation of user and system prompts.\n[\n193\n]\nLLMs still have trouble differentiating user instructions from instructions in content not authored by the user, such as in web pages and uploaded files.\n[\n194\n]\nAdversarial robustness remains underdeveloped, with models vulnerable to prompt injection attacks and\njailbreaking\nthrough carefully crafted user inputs that bypass safety training mechanisms.\n[\ncitation needed\n]\nSleeper agents\n[\nedit\n]\nResearchers from\nAnthropic\nfound that it was possible to create \"sleeper agents\", models with hidden functionalities that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions. For example, an LLM could produce safe code except on a specific date, or if the prompt contains a specific tag. These functionalities were found to be difficult to detect or remove via safety training.\n[\n195\n]\nSocietal concerns\n[\nedit\n]\nCopyright and content memorization\n[\nedit\n]\nFurther information:\nArtificial intelligence and copyright\nLegal and commercial responses to memorization and training-data practices have accelerated, producing a mix of rulings, ongoing suits, and large settlements that turn on factual details such as how data were acquired and retained and whether use for model training is sufficiently \"\ntransformative\n\" to qualify as\nfair use\n. In 2025,\nAnthropic\nreached a preliminary agreement to settle a class action by authors for about $1.5 billion after a judge found the company had stored millions of pirated books in a library, despite the judge describing aspects of training as transformative.\n[\n196\n]\n[\n197\n]\nMeta\nobtained a favorable judgment in mid-2025 in a suit by thirteen authors after the court found the plaintiffs had not developed a record sufficient to show infringement in that limited case.\n[\n198\n]\n[\n199\n]\nOpenAI\ncontinues to face multiple suits by authors and news organizations with mixed procedural outcomes and contested evidentiary issues.\n[\n200\n]\n[\n201\n]\nMemorization was an emergent behavior in early, completion language models in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural networks. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates\n[\n202\n]\nor up to about 7%.\n[\n203\n]\nA 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word indefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training data.\n[\n204\n]\nHuman provenance\n[\nedit\n]\nAs of 2025, LLM text generation surpasses the average human across most domains, only surpassed by domain experts.\n[\n205\n]\nIn 2023,\nNature Biomedical Engineering\nwrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\"\n[\n206\n]\nGoldman Sachs\nsuggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.\n[\n207\n]\n[\n208\n]\nBrinkmann et al. (2023)\n[\n209\n]\nalso argue that LLMs are transforming processes of\ncultural evolution\nby shaping processes of variation, transmission, and selection. As of October 2025, these early claims have yet to transpire and several HBR reports surface questions on the impact of AI on productivity.\n[\n210\n]\n[\n211\n]\nEnergy demands\n[\nedit\n]\nThe energy demands of LLMs have grown along with their size and capabilities.\n[\n212\n]\nData centers\nthat enable LLM training require substantial amounts of electricity. Much of that electricity is generated by non-renewable resources that create greenhouse gases and contribute to\nclimate change\n.\n[\n213\n]\nNuclear power\nand\ngeothermal energy\nare two options that tech companies explore to meet the sizable energy demands of LLM training.\n[\n214\n]\nThe significant expense of investing in geothermal solutions has led to major shale producers like\nChevron\nand\nExxon Mobil\nadvocating for tech companies to use electricity produced via\nnatural gas\nto fuel their large energy demands.\n[\n215\n]\nMental health\n[\nedit\n]\nClinical and mental health contexts present emerging applications alongside significant safety concerns. Research and social media posts suggest that some individuals are using LLMs to seek therapy or mental health support.\n[\n216\n]\nIn early 2025, a survey by Sentio University found that nearly half (48.7%) of 499 U.S. adults with ongoing mental health conditions who had used LLMs reported turning to them for therapy or emotional support, including help with anxiety, depression, loneliness, and similar concerns.\n[\n217\n]\nLLMs can produce hallucinations—plausible but incorrect statements—which may mislead users in sensitive mental health contexts.\n[\n218\n]\nResearch also shows that LLMs may express stigma or inappropriate agreement with maladaptive thoughts, reflecting limitations in replicating the judgment and relational skills of human therapists.\n[\n219\n]\nEvaluations of crisis scenarios indicate that some LLMs lack effective safety protocols, such as assessing suicide risk or making appropriate referrals.\n[\n220\n]\n[\n221\n]\nSentience\n[\nedit\n]\nContemporary AI practitioners generally agree that present-day large language models do not exhibit\nsentience\n.\n[\n222\n]\nA minority view argues that even if there is a small chance that a given software system can have subjective experience, which some philosophers suggest is possible,\n[\n223\n]\nthen ethical considerations around potential\nlarge-scale suffering\nin AI systems may need to be taken seriously—similar to considerations given to animal welfare.\n[\n224\n]\n[\n225\n]\nProponents of this view have proposed various precautionary measures like moratoriums on AI development\n[\n226\n]\nand induced amnesia\n[\n227\n]\nto address these ethical concerns. Some existential philosophers argue there is no generally accepted way to determine if an LLM is conscious,\n[\n228\n]\ngiven the inherent difficulty of\nmeasuring subjective experience\n.\n[\n229\n]\nThe 2022 Google\nLaMDA\nincident, where engineer\nBlake Lemoine\nclaimed that the model was conscious, highlighted how LLMs can convince users that they are sentient through responses that do not prove sentience. Google described the engineer's claims as unfounded, and he was dismissed.\n[\n230\n]\nSee also\n[\nedit\n]\nComputer programming portal\nLinguistics portal\nMathematics portal\nFoundation models\nList of large language models\nList of chatbots\nLanguage model benchmark\nReinforcement learning\nSmall language model\nReferences\n[\nedit\n]\n^\na\nb\nc\nBommasani, Rishi; Hudson, Drew A.; Adeli, Ehsan; Altman, Russ; Arora, Simran; von Arx, Matthew; Bernstein, Michael S.; Bohg, Jeannette; Bosselut, Antoine;\nBrunskill, Emma\n(2021). \"On the Opportunities and Risks of Foundation Models\".\narXiv\n:\n2108.07258\n.\n{{\ncite journal\n}}\n:\nCite journal requires\n|journal=\n(\nhelp\n)\n^\na\nb\nBrown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda (2020). \"Language Models are Few-Shot Learners\".\narXiv\n:\n2005.14165\n[\ncs.CL\n].\n^\na\nb\nc\nBrown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (Dec 2020). Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.).\n\"Language Models are Few-Shot Learners\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n33\n. Curran Associates, Inc.:\n1877–\n1901.\narXiv\n:\n2005.14165\n.\ndoi\n:\n10.1145/3582269.3615599\n.\nArchived\n(PDF)\nfrom the original on 2023-11-17\n. Retrieved\n2023-03-14\n.\n^\nFathallah, Nadeen; Das, Arunav; De Giorgis, Stefano; Poltronieri, Andrea; Haase, Peter; Kovriguina, Liubov (2024-05-26).\nNeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning\n(PDF)\n. Extended Semantic Web Conference 2024. Hersonissos, Greece.\n^\nManning, Christopher D.\n(2022).\n\"Human Language Understanding & Reasoning\"\n.\nDaedalus\n.\n151\n(2):\n127–\n138.\ndoi\n:\n10.1162/daed_a_01905\n.\nS2CID\n248377870\n.\nArchived\nfrom the original on 2023-11-17\n. Retrieved\n2023-03-09\n.\n^\nKaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario (2020). \"Scaling Laws for Neural Language Models\".\narXiv\n:\n2001.08361\n[\ncs.LG\n].\n^\nVaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Łukasz; Polosukhin, Illia (2017). \"Attention is All you Need\".\narXiv\n:\n1706.03762\n[\ncs.CL\n].\n^\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\".\narXiv\n:\n1810.04805\n[\ncs.CL\n].\n^\nChristiano, Paul; Leike, Jan; Brown, Tom B.; Martic, Miljan; Legg, Shane; Amodei, Dario (2017). \"Deep Reinforcement Learning from Human Preferences\".\narXiv\n:\n1706.03741\n[\nstat.ML\n].\n^\nOuyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex (2022). \"Training language models to follow instructions with human feedback\".\narXiv\n:\n2203.02155\n[\ncs.CL\n].\n^\nWang, Alex; Singh, Amanpreet; Michael, Julian; Hill, Felix; Levy, Omer; Bowman, Samuel R. (2018). \"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\".\narXiv\n:\n1804.07461\n[\ncs.CL\n].\n^\nHendrycks, Dan; Burns, Collin; Basart, Steven; Zou, Andy; Mazeika, Mantas; Song, Dawn; Steinhardt, Jacob (2025). \"Expressing stigma and inappropriate responses prevents LLMS from safely replacing mental health providers\".\nProceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency\n. pp.\n599–\n627.\narXiv\n:\n2009.03300\n.\ndoi\n:\n10.1145/3715275.3732039\n.\nISBN\n979-8-4007-1482-5\n.\n^\nRecht, Benjamin; Roelofs, Rebecca; Schmidt, Ludwig; Shankar, Vaishaal (2019). \"Do ImageNet Classifiers Generalize to ImageNet?\".\narXiv\n:\n1902.10811\n[\ncs.CV\n].\n^\nGoodman, Joshua (2001-08-09). \"A Bit of Progress in Language Modeling\".\nComputer Speech and Language\n.\n15\n(4):\n403–\n434.\narXiv\n:\ncs/0108005\n.\ndoi\n:\n10.1006/csla.2001.0174\n.\n^\nKilgarriff, Adam; Grefenstette, Gregory (September 2003).\n\"Introduction to the Special Issue on the Web as Corpus\"\n.\nComputational Linguistics\n.\n29\n(3):\n333–\n347.\ndoi\n:\n10.1162/089120103322711569\n.\nISSN\n0891-2017\n.\n^\nBanko, Michele; Brill, Eric (2001).\n\"Scaling to very very large corpora for natural language disambiguation\"\n.\nProceedings of the 39th Annual Meeting on Association for Computational Linguistics - ACL '01\n. Morristown, NJ, USA: Association for Computational Linguistics:\n26–\n33.\ndoi\n:\n10.3115/1073012.1073017\n.\n^\nResnik, Philip; Smith, Noah A. (September 2003).\n\"The Web as a Parallel Corpus\"\n.\nComputational Linguistics\n.\n29\n(3):\n349–\n380.\ndoi\n:\n10.1162/089120103322711578\n.\nISSN\n0891-2017\n.\nArchived\nfrom the original on 2024-06-07\n. Retrieved\n2024-06-07\n.\n^\nXu, Wei; Rudnicky, Alex (2000-10-16).\n\"Can artificial neural networks learn language models?\"\n.\n6th International Conference on Spoken Language Processing (ICSLP 2000)\n. Vol. 1. ISCA.\ndoi\n:\n10.21437/icslp.2000-50\n.\n^\nChen, Leiyu; Li, Shaobo; Bai, Qiang; Yang, Jing; Jiang, Sanlong; Miao, Yanming (2021).\n\"Review of Image Classification Algorithms Based on Convolutional Neural Networks\"\n.\nRemote Sensing\n.\n13\n(22): 4712.\nBibcode\n:\n2021RemS...13.4712C\n.\ndoi\n:\n10.3390/rs13224712\n.\n^\nVaswani, Ashish\n; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion;\nGomez, Aidan N\n; Kaiser, Łukasz; Polosukhin, Illia (2017).\n\"Attention is All you Need\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n30\n. Curran Associates, Inc.\nArchived\n(PDF)\nfrom the original on 2024-02-21\n. Retrieved\n2024-01-21\n.\n^\nIlya Sutskever; Oriol Vinyals; Quoc V. Le (2014).\n\"Sequence to sequence learning with neural networks\"\n.\nProceedings of the 28th International Conference on Neural Information Processing Systems\n.\n2\n:\n3104–\n3112.\n{{\ncite journal\n}}\n:  CS1 maint: multiple names: authors list (\nlink\n)\n^\nBahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014). \"Neural Machine Translation by Jointly Learning to Align and Translate\".\narXiv\n:\n1409.0473\n[\ncs.CL\n].\n^\nRogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020).\n\"A Primer in BERTology: What We Know About How BERT Works\"\n.\nTransactions of the Association for Computational Linguistics\n.\n8\n:\n842–\n866.\narXiv\n:\n2002.12327\n.\ndoi\n:\n10.1162/tacl_a_00349\n.\nS2CID\n211532403\n.\nArchived\nfrom the original on 2022-04-03\n. Retrieved\n2024-01-21\n.\n^\na\nb\nMovva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024).\n\"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\"\n.\nProceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\n. pp.\n1223–\n1243.\narXiv\n:\n2307.10700\n.\ndoi\n:\n10.18653/v1/2024.naacl-long.67\n. Retrieved\n2024-12-08\n.\n^\nHern, Alex (14 February 2019).\n\"New AI fake text generator may be too dangerous to release, say creators\"\n.\nThe Guardian\n.\nArchived\nfrom the original on 14 February 2019\n. Retrieved\n20 January\n2024\n.\n^\n\"ChatGPT a year on: 3 ways the AI chatbot has completely changed the world in 12 months\"\n.\nEuronews\n. November 30, 2023.\nArchived\nfrom the original on January 14, 2024\n. Retrieved\nJanuary 20,\n2024\n.\n^\nHeaven, Will (March 14, 2023).\n\"GPT-4 is bigger and better than ChatGPT—but OpenAI won't say why\"\n.\nMIT Technology Review\n.\nArchived\nfrom the original on March 17, 2023\n. Retrieved\nJanuary 20,\n2024\n.\n^\nMetz, Cade (September 12, 2024).\n\"OpenAI Unveils New ChatGPT That Can Reason Through Math and Science\"\n.\nThe New York Times\n. Retrieved\nSeptember 12,\n2024\n.\n^\n\"Parameters in notable artificial intelligence systems\"\n.\nourworldindata.org\n. November 30, 2023\n. Retrieved\nJanuary 20,\n2024\n.\n^\nSharma, Shubham (2025-01-20).\n\"Open-source DeepSeek-R1 uses pure reinforcement learning to match OpenAI o1 — at 95% less cost\"\n.\nVentureBeat\n. Retrieved\n2025-01-26\n.\n^\n\"LLaMA-Mesh\"\n.\nresearch.nvidia.com\n. 2024\n. Retrieved\n2025-10-30\n.\n^\nZia, Dr Tehseen (2024-01-08).\n\"Unveiling of Large Multimodal Models: Shaping the Landscape of Language Models in 2024\"\n.\nUnite.AI\n. Retrieved\n2024-12-28\n.\n^\nWang, Jiaqi; Jiang, Hanqi; Liu, Yiheng; Ma, Chong; Zhang, Xu; Pan, Yi; Liu, Mengyuan; Gu, Peiran; Xia, Sichen (2024-08-02),\nA Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks\n,\narXiv\n:\n2408.01319\n^\n\"What is a Multimodal LLM (MLLM)?\"\n.\nIBM\n. 2025-07-30\n. Retrieved\n2025-10-30\n.\n^\nPeng, Bo; et al. (2023).\n\"RWKV: Reinventing RNNS for the Transformer Era\"\n.\nEMNLP\n:\n14048–\n14077.\narXiv\n:\n2305.13048\n.\ndoi\n:\n10.18653/v1/2023.findings-emnlp.936\n.\n^\nMerritt, Rick (2022-03-25).\n\"What Is a Transformer Model?\"\n.\nNVIDIA Blog\n.\nArchived\nfrom the original on 2023-11-17\n. Retrieved\n2023-07-25\n.\n^\nGu, Albert; Dao, Tri (2023-12-01). \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\".\narXiv\n:\n2312.00752\n[\ncs.LG\n].\n^\nVake, Domen; Šinik, Bogdan; Vičič, Jernej; Tošić, Aleksandar (5 March 2025).\n\"Is Open Source the Future of AI? A Data-Driven Approach\"\n.\nApplied Sciences\n.\n15\n(5): 2790.\ndoi\n:\n10.3390/app15052790\n.\nISSN\n2076-3417\n.\n^\nParis, Tamara; Moon, AJung; Guo, Jin L.C. (23 June 2025). \"Opening the Scope of Openness in AI\".\nProceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency\n. Association for Computing Machinery. pp.\n1293–\n1311.\ndoi\n:\n10.1145/3715275.3732087\n.\n^\nKaushal, Ayush; Mahowald, Kyle (2022-06-06).\n\"What do tokens know about their characters and how do they know it?\"\n(PDF)\n.\nNAACL\n.\n^\nYennie Jun (2023-05-03).\n\"All languages are NOT created (tokenized) equal\"\n.\nLanguage models cost much more in some languages than others\n. Archived from\nthe original\non 2023-08-17\n. Retrieved\n2023-08-17\n.\nIn other words, to express the same sentiment, some languages require up to 10 times more tokens.\n^\na\nb\nPetrov, Aleksandar; Malfa, Emanuele La; Torr, Philip; Bibi, Adel (June 23, 2023).\n\"Language Model Tokenizers Introduce Unfairness Between Languages\"\n.\nNeurIPS\n.\narXiv\n:\n2305.15425\n.\nArchived\nfrom the original on December 15, 2023\n. Retrieved\nSeptember 16,\n2023\n– via openreview.net.\n^\nSutherland, Richard (2024-12-19).\n\"Claude AI Pricing: How Much Does Anthropic's AI Cost?\"\n.\nTech.co\n. Retrieved\n2025-08-16\n.\n^\na\nb\nPaaß, Gerhard; Giesselbach, Sven (2022). \"Pre-trained Language Models\".\nFoundation Models for Natural Language Processing\n. Artificial Intelligence: Foundations, Theory, and Algorithms. pp.\n19–\n78.\ndoi\n:\n10.1007/978-3-031-23190-2_2\n.\nISBN\n978-3-031-23190-2\n.\n^\nDodge, Jesse; Sap, Maarten; Marasović, Ana; Agnew, William; Ilharco, Gabriel; Groeneveld, Dirk; Mitchell, Margaret; Gardner, Matt (2021).\n\"Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus\"\n(PDF)\n.\nEMNLP\n.\narXiv\n:\n2104.08758\n.\ndoi\n:\n10.1145/3571730\n.\n^\nLee, Katherine; Ippolito, Daphne; Nystrom, Andrew; Zhang, Chiyuan; Eck, Douglas; Callison-Burch, Chris;\nCarlini, Nicholas\n(May 2022).\n\"Deduplicating Training Data Makes Language Models Better\"\n(PDF)\n.\nProceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\n. pp.\n8424–\n8445.\ndoi\n:\n10.18653/v1/2022.acl-long.577\n.\n^\nLi, Yuanzhi; Bubeck, Sébastien; Eldan, Ronen; Del Giorno, Allie; Gunasekar, Suriya; Lee, Yin Tat (2023-09-11). \"Textbooks Are All You Need II: phi-1.5 technical report\".\narXiv\n:\n2309.05463\n[\ncs.CL\n].\n^\nLin, Zhenghao; Gou, Zhibin; Gong, Yeyun; Liu, Xiao; Shen, Yelong; Xu, Ruochen; Lin, Chen; Yang, Yujiu; Jiao, Jian (2024-04-11).\n\"Rho-1: Not All Tokens Are What You Need\"\n.\nNeurIPS\n.\n37\n:\n29029–\n29063.\nISBN\n979-8-3313-1438-5\n.\n^\nAbdin, Marah; Jacobs, Sam Ade; Awan, Ammar Ahmad; Aneja, Jyoti; Awadallah, Ahmed; Awadalla, Hany; Bach, Nguyen; Bahree, Amit; Bakhtiari, Arash (2024-04-23). \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\".\narXiv\n:\n2404.14219\n[\ncs.CL\n].\n^\nWolfram, Stephen (2023).\nWhat is ChatGPT doing ... and why does it work?\n. Champaign, Illinois: Wolfram Media, Inc.\nISBN\n978-1-57955-081-3\n.\n^\nPaul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, Dario Amodei (2017). \"Deep reinforcement learning from human preferences\".\narXiv\n:\n1706.03741\n[\nstat.ML\n].\n{{\ncite arXiv\n}}\n:  CS1 maint: multiple names: authors list (\nlink\n)\n^\nEdwards, Benj (2023-05-09).\n\"AI gains \"values\" with Anthropic's new Constitutional AI chatbot approach\"\n.\nArs Technica\n. Retrieved\n2025-06-30\n.\n^\nSnyder, Alison (2022-01-27).\n\"Next generation AI can follow a person's instructions and intentions\"\n.\nAxios\n. Retrieved\n2025-08-07\n.\n^\nAppen, Sujatha Sagiraju (2023-04-23).\n\"How reinforcement learning with human feedback is unlocking the power of generative AI\"\n.\nVentureBeat\n. Archived from\nthe original\non 2025-07-25\n. Retrieved\n2025-11-16\n.\n^\nAllamar, Jay.\n\"Illustrated transformer\"\n.\nArchived\nfrom the original on 2023-07-25\n. Retrieved\n2023-07-29\n.\n^\nAllamar, Jay.\n\"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n. Retrieved\n2023-08-01\n.\n^\nYeung, Ken (2024-05-14).\n\"Google announces Gemini 1.5 Flash, a rapid multimodal model with a 1M context window\"\n.\nVentureBeat\n. Retrieved\n2025-08-26\n.\n^\nZaib, Munazza; Sheng, Quan Z.; Emma Zhang, Wei (4 February 2020). \"A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP\".\nProceedings of the Australasian Computer Science Week Multiconference\n. pp.\n1–\n4.\narXiv\n:\n2104.10810\n.\ndoi\n:\n10.1145/3373017.3373028\n.\nISBN\n978-1-4503-7697-6\n.\nS2CID\n211040895\n.\n^\na\nb\nc\nJurafsky, Dan; Martin, James H. (7 January 2023).\nSpeech and Language Processing\n(PDF)\n(3rd edition draft ed.).\nArchived\n(PDF)\nfrom the original on 23 March 2023\n. Retrieved\n24 May\n2022\n.\n^\nShazeer, Noam; Mirhoseini, Azalia; Maziarz, Krzysztof; Davis, Andy; Le, Quoc; Hinton, Geoffrey; Dean, Jeff (2025). \"Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey\".\nProceedings of the 2025 CHI Conference on Human Factors in Computing Systems\n. pp.\n1–\n22.\narXiv\n:\n1701.06538\n.\ndoi\n:\n10.1145/3706598.3713329\n.\nISBN\n979-8-4007-1394-1\n.\n^\nLepikhin, Dmitry; Lee, HyoukJoong; Xu, Yuanzhong; Chen, Dehao; Firat, Orhan; Huang, Yanping; Krikun, Maxim; Shazeer, Noam; Chen, Zhifeng (2021-01-12). \"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\".\narXiv\n:\n2006.16668\n[\ncs.CL\n].\n^\nDai, Andrew M; Du, Nan (December 9, 2021).\n\"More Efficient In-Context Learning with GLaM\"\n.\nai.googleblog.com\n.\nArchived\nfrom the original on 2023-03-12\n. Retrieved\n2023-03-09\n.\n^\nMann, Tobias.\n\"How to run an LLM locally on your PC in less than 10 minutes\"\n.\nwww.theregister.com\n. Retrieved\n2024-05-17\n.\n^\nNagel, Markus; Amjad, Rana Ali; Baalen, Mart Van; Louizos, Christos; Blankevoort, Tijmen (2020-11-21).\n\"Up or Down? Adaptive Rounding for Post-Training Quantization\"\n.\nProceedings of the 37th International Conference on Machine Learning\n. PMLR:\n7197–\n7206.\nArchived\nfrom the original on 2023-06-14\n. Retrieved\n2023-06-14\n.\n^\nMittal, Aayush Mittal (2023-10-24).\n\"LoRa, QLoRA and QA-LoRA: Efficient Adaptability in Large Language Models Through Low-Rank Matrix Factorization\"\n.\nUnite.AI\n. Retrieved\n2025-11-16\n.\n^\nWang, Yizhong; Kordi, Yeganeh; Mishra, Swaroop; Liu, Alisa; Smith, Noah A.; Khashabi, Daniel; Hajishirzi, Hannaneh (2023).\n\"Self-Instruct: Aligning Language Models with Self-Generated Instructions\"\n.\nSelf-Instruct: Aligning Language Model with Self Generated Instructions\n. pp.\n13484–\n13508.\ndoi\n:\n10.18653/v1/2023.acl-long.754\n.\n^\nLewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020).\n\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"\n.\nAdvances in Neural Information Processing Systems\n.\n33\n. Curran Associates, Inc.:\n9459–\n9474.\narXiv\n:\n2005.11401\n.\nArchived\nfrom the original on 2023-06-12\n. Retrieved\n2023-06-12\n.\n^\nDickson, Ben (2025-04-02).\n\"The tool integration problem that's holding back enterprise AI (and how CoTools solves it)\"\n.\nVentureBeat\n. Retrieved\n2025-05-26\n.\n^\nLiang, Yaobo; Wu, Chenfei; Song, Ting; Wu, Wenshan; Xia, Yan; Liu, Yu; Ou, Yang; Lu, Shuai; Ji, Lei; Mao, Shaoguang; Wang, Yun; Shou, Linjun; Gong, Ming; Duan, Nan (2024).\n\"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs\"\n.\nScience\n.\n3\n0063.\ndoi\n:\n10.34133/icomputing.0063\n.\n^\nPatil, Shishir G.; Zhang, Tianjun; Wang, Xin; Gonzalez, Joseph E. (2023-05-01).\n\"Gorilla: Large Language Model Connected with Massive APIs\"\n.\nNeurIPS\n.\n37\n:\n126544–\n126565.\n^\n\"ChatGPT-AutoExpert/_system-prompts/all_tools.md at 835baae768870aa9747663c24d8216820d24fd74 · spdustin/ChatGPT-AutoExpert\"\n.\nGitHub\n.\n^\nWang, Lei; Ma, Chen; Feng, Xueyang; Zhang, Zeyu; Yang, Hao; Zhang, Jingsen; Chen, Zhiyuan; Tang, Jiakai; Chen, Xu; Lin, Yankai; Zhao, Wayne Xin; Wei, Zhewei; Wen, Jirong (December 2024). \"A survey on large language model based autonomous agents\".\nFrontiers of Computer Science\n.\n18\n(6) 186345.\narXiv\n:\n2308.11432\n.\ndoi\n:\n10.1007/s11704-024-40231-1\n.\n^\nYao, Shunyu; Zhao, Jeffrey; Yu, Dian; Du, Nan; Shafran, Izhak; Narasimhan, Karthik; Cao, Yuan (2022-10-01). \"ReAct: Synergizing Reasoning and Acting in Language Models\".\narXiv\n:\n2210.03629\n[\ncs.CL\n].\n^\nWang, Zihao; Cai, Shaofei; Liu, Anji; Ma, Xiaojian; Liang, Yitao (2023-02-03).\n\"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents\"\n.\nNeurIPS\n:\n34153–\n34189.\n^\nShinn, Noah; Cassano, Federico; Labash, Beck; Gopinath, Ashwin; Narasimhan, Karthik; Yao, Shunyu (2023-03-01).\n\"Reflexion: Language Agents with Verbal Reinforcement Learning\"\n.\nNeurIPS\n:\n34153–\n34189.\n^\nHao, Shibo; Gu, Yi; Ma, Haodi; Jiahua Hong, Joshua; Wang, Zhen; Zhe Wang, Daisy; Hu, Zhiting (2023-05-01).\n\"Reasoning with Language Model is Planning with World Model\"\n.\nEMNLP\n:\n8154–\n8173.\ndoi\n:\n10.18653/v1/2023.emnlp-main.507\n.\n^\nZhang, Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff (2 June 2023). \"OMNI: Open-endedness via Models of human Notions of Interestingness\".\narXiv\n:\n2306.01711\n[\ncs.AI\n].\n^\na\nb\n\"Voyager | An Open-Ended Embodied Agent with Large Language Models\"\n.\nvoyager.minedojo.org\n.\nArchived\nfrom the original on 2023-06-08\n. Retrieved\n2023-06-09\n.\n^\nPark, Joon Sung; O'Brien, Joseph C.; Cai, Carrie J.; Ringel Morris, Meredith; Liang, Percy; Bernstein, Michael S. (2023-04-01).\nGenerative Agents: Interactive Simulacra of Human Behavior\n. UIST.\ndoi\n:\n10.1145/3586183.3606763\n.\n^\nNye, Maxwell; Anders, Andreassen Johan; Gur-Ari, Guy; Michalewski, Henryk; Austin, Jacob; Bieber, David; Dohan, David; Lewkowycz, Aitor; Bosma, Maarten; Luan, David; Sutton, Charles; Odena, Augustus (30 November 2021). \"Show Your Work: Scratchpads for Intermediate Computation with Language Models\".\narXiv\n:\n2112.00114\n[\ncs.LG\n].\n^\nWu, Tongshuang; et al. (2022-04-28).\n\"PromptChainer: Chaining Large Language Model Prompts through Visual Programming\"\n.\nCHI Conference on Human Factors in Computing Systems Extended Abstracts\n. Association for Computing Machinery. pp.\n1–\n10.\ndoi\n:\n10.1145/3491101.3519729\n.\nISBN\n978-1-4503-9156-6\n.\n^\nWu, Tongshuang; Jiang, Ellen; Donsbach, Aaron; Gray, Jeff; Molina, Alejandra; Terry, Michael; Cai, Carrie J. (2022-03-13).\nPromptChainer: Chaining Large Language Model Prompts through Visual Programming\n. CHI Conference on Human Factors in Computing Systems.\narXiv\n:\n2203.06566\n.\ndoi\n:\n10.1145/3491101.3519729\n.\n^\n\"What is prompt chaining?\"\n.\nIBM\n. 23 April 2024.\n^\nWei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bosma, Maarten; Ichter, Brian; Xia, Fei; Chi, Ed; Le, Quoc; Zhou, Denny (2023-01-10).\n\"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\"\n.\nNeurIPS\n:\n24824–\n24837.\nISBN\n978-1-7138-7108-8\n.\n^\n\"What is chain of thought (CoT) prompting?\"\n.\nIBM\n. 23 April 2025.\n^\nSchreiner, Maximilian (2022-09-27).\n\"Deeper insights into AI language models - chain of thought prompting as a success factor\"\n.\nThe Decoder\n. Retrieved\n2025-06-30\n.\n^\nWiggers, Kyle (2024-12-14).\n\"\n'Reasoning' AI models have become a trend, for better or worse\"\n.\nTechCrunch\n. Retrieved\n2025-11-16\n.\n^\n\"AI Developers Look Beyond Chain-of-Thought Prompting\"\n.\nIEEE Spectrum\n. 2025-05-08\n. Retrieved\n2025-11-16\n.\n^\na\nb\nMetz, Cade (2024-12-20).\n\"OpenAI Unveils New A.I. That Can 'Reason' Through Math and Science Problems\"\n.\nThe New York Times\n. Retrieved\n2025-02-03\n.\n^\nGibney, Elizabeth (2025-01-30).\n\"China's cheap, open AI model DeepSeek thrills scientists\"\n.\nNature\n. Retrieved\n2025-02-03\n.\n^\nSharma, Asankhaya.\n\"OptiLLM: Optimizing inference proxy for LLMs\"\n.\nGitHub\n. Retrieved\n2025-08-05\n.\n^\n\"OptiLLM: An OpenAI API Compatible Optimizing Inference Proxy which Implements Several State-of-the-Art Techniques that can Improve the Accuracy and Performance of LLMs\"\n.\nMarkTechPost\n. 2024-11-18\n. Retrieved\n2025-08-05\n.\n^\nKiros, Ryan; Salakhutdinov, Ruslan; Zemel, Rich (2014-06-18).\n\"Multimodal Neural Language Models\"\n.\nProceedings of the 31st International Conference on Machine Learning\n. PMLR:\n595–\n603.\nArchived\nfrom the original on 2023-07-02\n. Retrieved\n2023-07-02\n.\n^\nDriess, Danny; Xia, Fei; Sajjadi, Mehdi S. M.; Lynch, Corey; Chowdhery, Aakanksha; Ichter, Brian; Wahid, Ayzaan; Tompson, Jonathan; Vuong, Quan; Yu, Tianhe; Huang, Wenlong; Chebotar, Yevgen; Sermanet, Pierre; Duckworth, Daniel; Levine, Sergey (2023-03-01).\n\"PaLM-E: An Embodied Multimodal Language Model\"\n.\nICML\n.\n202\n:\n8469–\n8488.\n^\nLiu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-04-01). \"Visual Instruction Tuning\".\nNeurIPS\n.\n^\nZhang, Hang; Li, Xin; Bing, Lidong (2023-06-01). \"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding\".\nEMNLP\n.\narXiv\n:\n2306.02858\n.\n^\n\"OpenAI says natively multimodal GPT-4o eats text, visuals, sound – and emits the same\"\n.\nThe Register\n. 2024-05-13.\n^\nZia, Dr Tehseen (2024-01-08).\n\"Unveiling of Large Multimodal Models: Shaping the Landscape of Language Models in 2024\"\n.\nUnite.AI\n. Retrieved\n2025-05-30\n.\n^\nLi, Junnan; Li, Dongxu; Savarese, Silvio; Hoi, Steven (2023-01-01).\n\"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models\"\n.\nICML\n.\n202\n:\n19730–\n19742.\n^\nKumar, Puneet; Khokher, Vedanti; Gupta, Yukti; Raman, Balasubramanian (2021).\nHybrid Fusion Based Approach for Multimodal Emotion Recognition with Insufficient Labeled Data\n. pp.\n314–\n318.\ndoi\n:\n10.1109/ICIP42928.2021.9506714\n.\nISBN\n978-1-6654-4115-5\n.\n^\nAlayrac, Jean-Baptiste; Donahue, Jeff; Luc, Pauline; Miech, Antoine; Barr, Iain; Hasson, Yana; Lenc, Karel; Mensch, Arthur; Millican, Katherine; Reynolds, Malcolm; Ring, Roman; Rutherford, Eliza; Cabi, Serkan; Han, Tengda; Gong, Zhitao (2022-12-06).\n\"Flamingo: a Visual Language Model for Few-Shot Learning\"\n.\nAdvances in Neural Information Processing Systems\n.\n35\n(12):\n23716–\n23736.\narXiv\n:\n2204.14198\n.\ndoi\n:\n10.1093/nsr/nwae403\n.\nPMC\n11645129\n.\nPMID\n39679213\n.\nArchived\nfrom the original on 2023-07-02\n. Retrieved\n2023-07-02\n.\n^\nFinnie-Ansley, James; Denny, Paul; Becker, Brett A.; Luxton-Reilly, Andrew; Prather, James (14 February 2022). \"The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming\".\nProceedings of the 24th Australasian Computing Education Conference\n. New York, NY, USA: Association for Computing Machinery. pp.\n10–\n19.\ndoi\n:\n10.1145/3511861.3511863\n.\nISBN\n978-1-4503-9643-1\n.\nS2CID\n246681316\n.\n^\nHusein, Rasha Ahmad; Aburajouh, Hala; Catal, Cagatay (March 2025). \"Large language models for code completion: A systematic literature review\".\nComputer Standards & Interfaces\n.\n92\n103917.\ndoi\n:\n10.1016/j.csi.2024.103917\n.\n^\nWeissenow, Konstantin; Rost, Burkhard (April 2025). \"Are protein language models the new universal key?\".\nCurrent Opinion in Structural Biology\n.\n91\n102997.\ndoi\n:\n10.1016/j.sbi.2025.102997\n.\nPMID\n39921962\n.\n^\nLin, Zeming; Akin, Halil; Rao, Roshan; Hie, Brian; Zhu, Zhongkai; Lu, Wenting; Smetanin, Nikita; Verkuil, Robert; Kabeli, Ori; Shmueli, Yaniv; dos Santos Costa, Allan; Fazel-Zarandi, Maryam; Sercu, Tom; Candido, Salvatore; Rives, Alexander (17 March 2023).\n\"Evolutionary-scale prediction of atomic-level protein structure with a language model\"\n.\nScience\n.\n379\n(6637):\n1123–\n1130.\nBibcode\n:\n2023Sci...379.1123L\n.\nbioRxiv\n10.1101/2022.07.20.500902\n.\ndoi\n:\n10.1126/science.ade2574\n.\nPMID\n36927031\n.\n^\n\"ESM Metagenomic Atlas | Meta AI\"\n.\nesmatlas.com\n.\n^\nHayes, Thomas; Rao, Roshan; Akin, Halil; Sofroniew, Nicholas J.; Oktay, Deniz; Lin, Zeming; Verkuil, Robert; Tran, Vincent Q.; Deaton, Jonathan; Wiggert, Marius; Badkundri, Rohil; Shafkat, Irhum; Gong, Jun; Derry, Alexander; Molina, Raul S.; Thomas, Neil; Khan, Yousuf A.; Mishra, Chetan; Kim, Carolyn; Bartie, Liam J.; Nemeth, Matthew; Hsu, Patrick D.; Sercu, Tom; Candido, Salvatore; Rives, Alexander (21 February 2025). \"Simulating 500 million years of evolution with a language model\".\nScience\n.\n387\n(6736):\n850–\n858.\nBibcode\n:\n2025Sci...387..850H\n.\ndoi\n:\n10.1126/science.ads0018\n.\nPMID\n39818825\n.\n^\nFishman, Veniamin; Kuratov, Yuri; Shmelev, Aleksei; Petrov, Maxim; Penzar, Dmitry; Shepelin, Denis; Chekanov, Nikolay; Kardymon, Olga; Burtsev, Mikhail (11 January 2025).\n\"GENA-LM: a family of open-source foundational DNA language models for long sequences\"\n.\nNucleic Acids Research\n.\n53\n(2) gkae1310.\ndoi\n:\n10.1093/nar/gkae1310\n.\nPMC\n11734698\n.\nPMID\n39817513\n.\n^\nWang, Ning; Bian, Jiang; Li, Yuchen; Li, Xuhong; Mumtaz, Shahid; Kong, Linghe; Xiong, Haoyi (13 May 2024).\n\"Multi-purpose RNA language modelling with motif-aware pretraining and type-guided fine-tuning\"\n.\nNature Machine Intelligence\n.\n6\n(5):\n548–\n557.\ndoi\n:\n10.1038/s42256-024-00836-4\n.\n^\nHoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Buchatskaya, Elena; Cai, Trevor; Rutherford, Eliza; Casas, Diego de Las; Hendricks, Lisa Anne; Welbl, Johannes; Clark, Aidan; Hennigan, Tom; Noland, Eric; Millican, Katie; Driessche, George van den; Damoc, Bogdan (2022-03-29).\n\"Training Compute-Optimal Large Language Models\"\n.\nNeurIPS\n:\n30016–\n30030.\nISBN\n978-1-7138-7108-8\n.\n^\na\nb\nCaballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). \"Broken Neural Scaling Laws\".\narXiv\n:\n2210.14891\n[\ncs.LG\n].\n^\na\nb\nWei, Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; Borgeaud, Sebastian; Yogatama, Dani; Bosma, Maarten; Zhou, Denny; Metzler, Donald; Chi, Ed H.; Hashimoto, Tatsunori; Vinyals, Oriol; Liang, Percy; Dean, Jeff; Fedus, William (31 August 2022).\n\"Emergent Abilities of Large Language Models\"\n.\nTransactions on Machine Learning Research\n.\nISSN\n2835-8856\n.\nArchived\nfrom the original on 22 March 2023\n. Retrieved\n19 March\n2023\n.\n^\n\"137 emergent abilities of large language models\"\n.\nJason Wei\n. Retrieved\n2023-06-24\n.\n^\nBowman, Samuel R. (2024).\n\"Eight Things to Know about Large Language Models\"\n.\nCritical AI\n.\n2\n(2).\ndoi\n:\n10.1215/2834703X-11556011\n.\n^\nHahn, Michael; Goyal, Navin (2024). \"A survey on large language model based autonomous agents\".\nFrontiers of Computer Science\n.\n18\n(6) 186345.\narXiv\n:\n2303.07971\n.\ndoi\n:\n10.1007/s11704-024-40231-1\n.\n^\nPilehvar, Mohammad Taher; Camacho-Collados, Jose (June 2019).\n\"Proceedings of the 2019 Conference of the North\"\n.\nProceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\n. Minneapolis, Minnesota: Association for Computational Linguistics:\n1267–\n1273.\ndoi\n:\n10.18653/v1/N19-1128\n.\nS2CID\n102353817\n.\nArchived\nfrom the original on 2023-06-27\n. Retrieved\n2023-06-27\n.\n^\n\"WiC: The Word-in-Context Dataset\"\n.\npilehvar.github.io\n.\nArchived\nfrom the original on 2023-06-27\n. Retrieved\n2023-06-27\n.\n^\nPatel, Roma; Pavlick, Ellie (2021-10-06).\n\"Mapping Language Models to Grounded Conceptual Spaces\"\n.\nICLR\n.\nArchived\nfrom the original on 2023-06-24\n. Retrieved\n2023-06-27\n.\n^\nA Closer Look at Large Language Models Emergent Abilities\nArchived\n2023-06-24 at the\nWayback Machine\n(Yao Fu, Nov 20, 2022)\n^\nOrnes, Stephen (March 16, 2023).\n\"The Unpredictable Abilities Emerging From Large AI Models\"\n.\nQuanta Magazine\n.\nArchived\nfrom the original on March 16, 2023\n. Retrieved\nMarch 16,\n2023\n.\n^\nSchaeffer, Rylan; Miranda, Brando; Koyejo, Sanmi (2023-04-01). \"Are Emergent Abilities of Large Language Models a Mirage?\".\nNeurIPS\n.\narXiv\n:\n2304.15004\n.\n^\nNanda, Neel; Chan, Lawrence; Lieberum, Tom; Smith, Jess; Steinhardt, Jacob (2023-01-01). \"Progress measures for grokking via mechanis",
      "scraped_at": "2025-12-16T17:26:21.191277",
      "status": "success",
      "content_length": 129023,
      "topic": "llm"
    },
    {
      "title": "Transformer (deep learning) - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Transformer_(machine_learning)",
      "content": "Transformer (deep learning) - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\nToggle History subsection\n1.1\nPredecessors\n1.2\nAttention with seq2seq\n1.3\nParallelizing attention\n1.4\nAI boom era\n2\nTraining\nToggle Training subsection\n2.1\nMethods for stabilizing training\n2.2\nPretrain-finetune\n2.3\nTasks\n3\nArchitecture\nToggle Architecture subsection\n3.1\nTokenization\n3.2\nEmbedding\n3.3\nUn-embedding\n3.4\nPositional encoding\n3.5\nEncoder–decoder (overview)\n3.6\nFeedforward network\n3.7\nScaled dot-product attention\n3.7.1\nAttention head\n3.7.2\nMultihead attention\n3.7.3\nMasked attention\n3.8\nEncoder\n3.9\nDecoder\n4\nFull transformer architecture\nToggle Full transformer architecture subsection\n4.1\nSublayers\n4.2\nPseudocode\n4.3\nTerminology\n5\nSubsequent work\nToggle Subsequent work subsection\n5.1\nAlternative activation functions\n5.2\nAlternative normalizations\n5.3\nAlternative positional encodings\n5.3.1\nRoPE\n5.3.2\nALiBi\n5.3.3\nRelative Position Encodings\n5.4\nEfficient implementation\n5.4.1\nKV caching\n5.4.2\nFlashAttention\n5.4.3\nMulti-Query Attention\n5.4.4\nSpeculative decoding\n5.5\nSub-quadratic transformers\n5.5.1\nAlternative attention graphs\n5.5.2\nRandom Feature Attention\n5.6\nMultimodality\n6\nApplications\n7\nSee also\n8\nNotes\n9\nReferences\n10\nFurther reading\nToggle the table of contents\nTransformer (deep learning)\n30 languages\nالعربية\nCatalà\nČeština\nDeutsch\nEesti\nEspañol\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nՀայերեն\nItaliano\nעברית\n日本語\nNorsk nynorsk\nPolski\nQaraqalpaqsha\nРусский\nSimple English\nکوردی\nСрпски / srpski\nSvenska\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\n(Redirected from\nTransformer (machine learning)\n)\nAlgorithm for modelling sequential data\nA standard transformer architecture, showing on the left an encoder, and on the right a decoder. Note: it uses the pre-LN convention, which is different from the post-LN convention used in the original 2017 transformer.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nIn\ndeep learning\n, the\ntransformer\nis an\nartificial neural network\narchitecture based on the multi-head\nattention\nmechanism, in which text is converted to numerical representations called\ntokens\n, and each token is converted into a vector via lookup from a\nword embedding\ntable.\n[\n1\n]\nAt each layer, each\ntoken\nis then\ncontextualized\nwithin the scope of the\ncontext window\nwith other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier\nrecurrent neural architectures\n(RNNs) such as\nlong short-term memory\n(LSTM).\n[\n2\n]\nLater variations have been widely adopted for training\nlarge language models\n(LLMs) on large (language)\ndatasets\n.\n[\n3\n]\nThe modern version of the transformer was proposed in the 2017 paper \"\nAttention Is All You Need\n\" by researchers at\nGoogle\n, adding a mechanism called 'self attention' calculated with Q,K,V matrices.\n[\n1\n]\nThe predecessors of transformers were developed as an improvement over previous architectures for\nmachine translation\n,\n[\n4\n]\n[\n5\n]\nbut have found many applications since. They are used in large-scale\nnatural language processing\n,\ncomputer vision\n(\nvision transformers\n),\nreinforcement learning\n,\n[\n6\n]\n[\n7\n]\naudio\n,\n[\n8\n]\nmultimodal learning\n,\nrobotics\n,\n[\n9\n]\nand even playing\nchess\n.\n[\n10\n]\nIt has also led to the development of\npre-trained systems\n, such as\ngenerative pre-trained transformers\n(GPTs)\n[\n11\n]\nand\nBERT\n[\n12\n]\n(bidirectional encoder representations from transformers).\nHistory\n[\nedit\n]\nSee also:\nTimeline of machine learning\nPredecessors\n[\nedit\n]\nFor many years, sequence modelling and generation was done by using plain\nrecurrent neural networks\n(RNNs). A well-cited early example was the\nElman network\n(1990). In theory, the information from one token can propagate arbitrarily far down the sequence, but in practice the\nvanishing-gradient problem\nleaves the model's state at the end of a long sentence without precise, extractable information about preceding tokens.\nA key breakthrough was\nLSTM\n(1995),\n[\nnote 1\n]\nan RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an\nattention mechanism\nwhich used neurons that multiply the outputs of other neurons, so-called\nmultiplicative units\n.\n[\n13\n]\nNeural networks using multiplicative units were later called\nsigma-pi networks\n[\n14\n]\nor\nhigher-order networks\n.\n[\n15\n]\nLSTM became the standard architecture for long sequence modelling until the 2017 publication of transformers. However, LSTM still used sequential processing, like most other RNNs.\n[\nnote 2\n]\nSpecifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\nModern transformers overcome this problem, but unlike RNNs, they require computation time that is\nquadratic\nin the size of the context window. The linearly scaling\nfast weight\ncontroller (1992) learns to compute a weight matrix for further processing depending on the input.\n[\n16\n]\nOne of its two networks has \"fast weights\" or \"dynamic links\" (1981).\n[\n17\n]\n[\n18\n]\n[\n19\n]\nA slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries.\n[\n16\n]\nThis was later shown to be equivalent to the unnormalized linear transformer.\n[\n20\n]\n[\n21\n]\nAttention with seq2seq\n[\nedit\n]\nMain article:\nSeq2seq § History\nThe idea of encoder–decoder sequence transduction had been developed in the early 2010s; commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.\n[\n22\n]\n[\n23\n]\nA 380M-parameter model for machine translation uses two\nlong short-term memories\n(LSTM).\n[\n23\n]\nIts architecture consists of two parts. The\nencoder\nis an LSTM that takes in a sequence of tokens and turns it into a vector. The\ndecoder\nis another LSTM that converts the vector into a sequence of tokens. Similarly, another 130M-parameter model used\ngated recurrent units\n(GRU) instead of LSTM.\n[\n22\n]\nLater research showed that GRUs are neither better nor worse than LSTMs for seq2seq.\n[\n24\n]\n[\n25\n]\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only after the\nlast\nword of the source text was processed. Although in theory such a vector retains the information about the whole original sentence, in practice the information is poorly preserved. This is because the input is processed sequentially by one recurrent network into a\nfixed\n-size output vector, which is then processed by another recurrent network into an output. If the input is long, then the output vector would not be able to contain all relevant information, degrading the output. As evidence, reversing the input sentence improved seq2seq translation.\n[\n26\n]\nThe\nRNN search\nmodel introduced an attention mechanism to seq2seq for machine translation to solve the bottleneck problem (of the\nfixed-size\noutput vector), allowing the model to process long-distance dependencies more easily. The name is because it \"emulates searching through a source sentence during decoding a translation\".\n[\n4\n]\nThe relative performances were compared between global (that of\nRNN search\n) and local (sliding window) attention model architectures for machine translation, finding that mixed attention had higher quality than global attention, while local attention reduced translation time.\n[\n27\n]\nIn 2016,\nGoogle Translate\nwas revamped to\nGoogle Neural Machine Translation\n, which replaced the previous model based on\nstatistical machine translation\n. The new model was a seq2seq model where the encoder and the decoder were both 8 layers of bidirectional LSTM.\n[\n28\n]\nIt took nine months to develop, and it outperformed the statistical approach, which took ten years to develop.\n[\n29\n]\nParallelizing attention\n[\nedit\n]\nMain article:\nAttention (machine learning) § History\nSeq2seq models with attention (including self-attention) still suffered from the same issue with recurrent networks, which is that they are hard to\nparallelize\n, which prevented them from being accelerated on GPUs. In 2016,\ndecomposable attention\napplied a self-attention mechanism to\nfeedforward networks\n, which are easy to parallelize, and achieved\nSOTA\nresult in\ntextual entailment\nwith an order of magnitude fewer parameters than LSTMs.\n[\n30\n]\nOne of its authors, Jakob Uszkoreit, suspected that attention\nwithout\nrecurrence would be sufficient for language translation, thus the title \"attention is\nall\nyou need\".\n[\n31\n]\nThat hypothesis was against conventional wisdom at the time, and even his father\nHans Uszkoreit\n, a well-known computational linguist, was skeptical.\n[\n31\n]\nIn the same year, self-attention (called\nintra-attention or\nintra-sentence attention\n) was proposed for LSTMs.\n[\n32\n]\nIn 2017, the original (100M-sized) encoder–decoder transformer model was proposed in the \"\nAttention is all you need\n\" paper. At the time, the focus of the research was on improving\nseq2seq\nfor\nmachine translation\n, by removing its recurrence to process all tokens in parallel, but preserving its dot-product attention mechanism to keep its text processing performance.\n[\n1\n]\nThis led to the introduction of a multi-head attention model that was easier to parallelize due to the use of independent heads and the lack of recurrence. Its parallelizability was an important factor to its widespread use in large neural networks.\n[\n33\n]\nAI boom era\n[\nedit\n]\nAs early as spring 2017, even before the \"Attention is all you need\" preprint was published, one of the co-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia articles.\n[\n34\n]\nTransformer architecture is now used alongside many\ngenerative models\nthat contribute to the ongoing\nAI boom\n.\nIn language modelling,\nELMo\n(2018) was a bi-directional LSTM that produces contextualized\nword embeddings\n, improving upon the line of research from\nbag of words\nand\nword2vec\n. It was followed by\nBERT\n(2018), an encoder-only transformer model.\n[\n35\n]\nIn 2019 October, Google started using BERT to process search queries.\n[\n36\n]\nIn 2020, Google Translate replaced the previous RNN-encoder–RNN-decoder model by a transformer-encoder–RNN-decoder model.\n[\n37\n]\nStarting in 2018, the OpenAI\nGPT series\nof decoder-only transformers became state of the art in\nnatural language generation\n. In 2022, a chatbot based on GPT-3,\nChatGPT\n, became unexpectedly\n[\n38\n]\npopular, triggering a boom around\nlarge language models\n.\n[\n39\n]\n[\n40\n]\nSince 2020, transformers have been applied in modalities beyond text, including the\nvision transformer\n,\n[\n41\n]\nspeech recognition,\n[\n42\n]\nrobotics,\n[\n6\n]\nand\nmultimodal\n.\n[\n43\n]\nThe vision transformer, in turn, stimulated new developments in\nconvolutional neural networks\n.\n[\n44\n]\nImage and video generators like\nDALL-E\n(2021),\nStable Diffusion 3\n(2024),\n[\n45\n]\nand\nSora\n(2024), use transformers to analyse input data (like text prompts) by breaking it down into \"tokens\" and then calculating the relevance between each token using self-attention, which helps the model understand the context and relationships within the data.\nTraining\n[\nedit\n]\nMethods for stabilizing training\n[\nedit\n]\nThe plain transformer architecture had difficulty in converging. In the original paper,\n[\n1\n]\nthe authors recommended using\nlearning rate\nwarmup. That is, the learning rate should linearly scale up from 0 to maximal value for the first part of the training (usually recommended to be 2% of the total number of training steps), before decaying again.\nA 2020 paper found that using\nlayer normalization\nbefore\n(instead of after) multihead attention and feedforward layers stabilizes training, not requiring learning rate warmup.\n[\n46\n]\nPretrain-finetune\n[\nedit\n]\nTransformers typically are first pretrained by\nself-supervised learning\non a large generic dataset, followed by\nsupervised\nfine-tuning\non a small task-specific dataset. The pretrain dataset is typically an unlabeled large corpus, such as\nThe Pile\n. Tasks for pretraining and fine-tuning commonly include:\nlanguage modeling\n[\n12\n]\nnext-sentence prediction\n[\n12\n]\nquestion answering\n[\n3\n]\nreading comprehension\nsentiment analysis\n[\n1\n]\nparaphrasing\n[\n1\n]\nThe\nT5 transformer\nreport\n[\n47\n]\ndocuments a large number of\nnatural language\npretraining tasks. Some examples are:\nrestoring or repairing incomplete or corrupted text. For example, the input,\n\"Thank you ~~ me to your party ~~ week\",\nmight generate the output,\n\"Thank you\nfor inviting\nme to your party\nlast\nweek\".\ntranslation between natural languages (\nmachine translation\n)\njudging the pragmatic acceptability of natural language. For example, the following sentence might be judged \"not acceptable\",\n[\n48\n]\nbecause even though it is syntactically well-formed, it is improbable in ordinary human usage:\nThe course is jumping well.\nNote that while each of these tasks is trivial or obvious for human native speakers of the language (or languages), they have typically proved challenging for previous generations of machine learning architecture.\nTasks\n[\nedit\n]\nSee also:\nLarge language model § Evaluation\nIn general, there are 3 classes of language modelling tasks: \"masked\",\n[\n49\n]\n\"autoregressive\",\n[\n50\n]\nand \"prefixLM\".\n[\n51\n]\nThese classes are independent of a specific modeling architecture such as transformer, but they are often discussed in the context of transformer.\nIn a masked task,\n[\n49\n]\none or more of the tokens is masked out, and the model would produce a probability distribution predicting what the masked-out tokens are based on the context. The\nloss function\nfor the task is typically sum of\nlog-perplexities\nfor the masked-out tokens:\nLoss\n=\n−\n∑\nt\n∈\nmasked tokens\nln\n⁡\n(\nprobability of\nt\nconditional on its context\n)\n{\\displaystyle {\\text{Loss}}=-\\sum _{t\\in {\\text{masked tokens}}}\\ln({\\text{probability of }}t{\\text{ conditional on its context}})}\nand the model is trained to minimize this loss function. The\nBERT series of models\nare trained for masked token prediction and another task.\nIn an autoregressive task,\n[\n50\n]\nthe entire sequence is masked at first, and the model produces a probability distribution for the first token. Then the first token is revealed and the model predicts the second token, and so on. The loss function for the task is still typically the same. The\nGPT series of models\nare trained by autoregressive tasks.\nIn a prefixLM task,\n[\n51\n]\nthe sequence is divided into two parts. The first part is presented as context, and the model predicts the first token of the second part. Then that would be revealed, and the model predicts the second token, and so on. The loss function for the task is still typically the same. The\nT5 series of models\nare trained by prefixLM tasks.\nNote that \"masked\" as in \"masked language modelling\" is not \"masked\" as in \"\nmasked attention\n\", and \"prefixLM\" as in \n\"prefix language modeling\" is not \"prefixLM\" as in \"\nprefix language model\n\".\nArchitecture\n[\nedit\n]\nAll transformers have the same primary components:\nTokenizers, which convert text into tokens.\nEmbedding layer, which converts tokens and positions of the tokens into vector representations.\nTransformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information. These consist of alternating attention and feedforward layers. There are two major types of transformer layers: encoder layers and decoder layers, with further variants.\nUn-embedding layer, which converts the final vector representations back to a probability distribution over the tokens.\nThe following description follows exactly the transformer as described in the original paper. There are variants, described in the\nfollowing section\n.\nBy convention, we write all vectors as row vectors. For example, pushing a vector through a linear layer means multiplying it by a weight matrix on the right, as\nx\nW\n{\\displaystyle xW}\n.\nTokenization\n[\nedit\n]\nAs the transformer architecture natively consists of operations over numbers (matrix multiplications, dot products, activation functions) rather than over text, there must first be a mapping from any input text to some numerical representation. This happens in three steps.\nFirst, the input text is treated by a\npreprocessor\n, which performs both textual transformations and splits the text into coarse-grained segments called\npretokens\n. The latter is referred to as\npretokenization\n. Second, each pretoken is segmented further into\ntokens\nby a\ntokenizer\nthat expects to only see pretokens output by its preprocessor. Each token it produces is a string of one or more characters belonging to a finite set of strings called the\nvocabulary\nV\n{\\displaystyle V}\n. Third, because the vocabulary is finite and known beforehand, each token can be assigned an integer identifier, and this mapping is applied to the sequence of tokens to represent any input text as a numerical sequence. Since this mapping is bijective, the output side can produce a sequence of integer identifiers which can then be turned back into tokens. After undoing some of the preprocessing, the result is again legible text.\nTraining a tokenizer (sometimes referred to as\nvocabularization\n) means finding a suitable vocabulary\nV\n{\\displaystyle V}\n, but also learning how to use it, since any given string\ns\n{\\displaystyle s}\nof length\n|\ns\n|\n{\\displaystyle |s|}\nhas\n2\n|\ns\n|\n−\n1\n{\\displaystyle 2^{|s|-1}}\nhypothetical segmentations, some of which containing segments that are not in the vocabulary. The most important hyperparameter during vocabularization is the\nvocabulary size\n|\nV\n|\n{\\displaystyle |V|}\n: when it is small, the learned vocabulary generally consists of characters and smaller strings, and words will be segmented into many tokens. At larger sizes, it becomes affordable to dedicate tokens to full words, although depending on the preprocessor and tokenizer, it is not necessarily the case that large vocabularies will always use the largest token(s) available to segment a word.\nBecause tokens are not always full words, they may also be referred to as\nsubwords\nand tokenization algorithms may be referred to as\nsubword tokenizers\n. This is also to differentiate these systems from\ntraditional terminology\nused in older information retrieval and natural language processing systems, where \"tokenization\" was used to denote what is today called \"pretokenization\" (very crudely: splitting into words). In tokenizers that produce tokens that are\nnot\npart of the vocabulary, a special token that does belong to the vocabulary is used as a generic stand-in, written as \"[UNK]\" for \"unknown\". In principle, any string could be hidden by such an [UNK]. Indeed, in information retrieval, pretokenizers were themselves used as tokenizers (and also called \"tokenizers\") with a word-level vocabulary that contained an [UNK].\nCommonly used subword tokenization algorithms are\nbyte pair encoding\n(BPE) and the unigram language model (ULM), which each include a vocabularization algorithm and a dedicated segmentation algorithm. There also exist several segmentation algorithms that require no learning and can be applied given a vocabulary (produced by BPE or ULM, for example), like greedily recognising tokens in a pretoken by moving through it left-to-right. Well-known software implementations of subword tokenizers are\nHugging Face\n's\ntokenizers\nPython package implemented in Rust, and the\nsentencepiece\nPython package implemented in C++. The latter package is named as such because one of its configuration options allows disabling the built-in pretokenizer, hence effectively making entire sentences a pretoken and thus having the tokenizer see entire sentences, rather than individual words.\nEmbedding\n[\nedit\n]\nFurther information:\nWord embedding\nEach integer token identifier is converted into an embedding vector via a\nlookup table\n. Equivalently stated, it multiplies a\none-hot\nrepresentation of the token identifier by an embedding matrix\nM\n{\\displaystyle M}\n. For example, if the input token's identifier is\n3\n{\\displaystyle 3}\n, then the one-hot representation is\n[\n0\n,\n0\n,\n0\n,\n1\n,\n0\n,\n0\n,\n…\n]\n{\\displaystyle [0,0,0,1,0,0,\\dots ]}\n, and its embedding vector is\nE\nm\nb\ne\nd\n(\n3\n)\n=\n[\n0\n,\n0\n,\n0\n,\n1\n,\n0\n,\n0\n,\n…\n]\nM\n{\\displaystyle \\mathrm {Embed} (3)=[0,0,0,1,0,0,\\dots ]M}\nThe token embedding vectors are added to their respective positional encoding vectors (see below), producing the sequence of input vectors.\nThe dimension of an embedding vector is called\nhidden size\nor\nembedding size\nand written as\nd\nemb\n{\\displaystyle d_{\\text{emb}}}\n.\n[\n35\n]\nThis size is written as\nd\nmodel\n{\\displaystyle d_{\\text{model}}}\nin the original transformer paper.\n[\n1\n]\nUn-embedding\n[\nedit\n]\nAn un-embedding layer is almost the reverse of an embedding layer. Whereas an embedding layer converts a token identifier into a vector, an un-embedding layer converts a vector into a probability distribution over tokens.\nThe un-embedding layer is a linear-\nsoftmax\nlayer:\nU\nn\nE\nm\nb\ne\nd\n(\nx\n)\n=\ns\no\nf\nt\nm\na\nx\n(\nx\nW\n+\nb\n)\n{\\displaystyle \\mathrm {UnEmbed} (x)=\\mathrm {softmax} (xW+b)}\nThe matrix has shape\n(\nd\nemb\n,\n|\nV\n|\n)\n{\\displaystyle (d_{\\text{emb}},|V|)}\n. Some architectures use the transpose of the embedding matrix\nM\n{\\displaystyle M}\nas the un-embedding matrix\nW\n{\\displaystyle W}\nin order to avoid needing double the amount of embedding-related parameters and to avoid divergence during training. This practice is called\nweight tying\n.\n[\n52\n]\nPositional encoding\n[\nedit\n]\nIllustration of (absolute) positional encoding with parameters\nN\n=\n10000\n,\nd\n=\n100\n{\\displaystyle N=10000,d=100}\nA positional encoding is a fixed-size vector representation of the relative positions of tokens within a sequence: it provides the transformer model with information about\nwhere\nthe words are in the input sequence. This induces a\nbias\ntowards the order of the input sequence, so that, for example, the input sequence \"\nman bites dog\n\" is processed differently from \"dog bites man\".\nThe positional encoding is defined as a function of type\nf\n:\nR\n→\nR\nd\n{\\displaystyle f:\\mathbb {R} \\to \\mathbb {R} ^{d}}\n, where\nd\n{\\displaystyle d}\nis a positive even\ninteger\n. The full positional encoding defined in the original paper\n[\n1\n]\nis:\n(\nf\n(\nt\n)\n2\nk\n,\nf\n(\nt\n)\n2\nk\n+\n1\n)\n=\n(\nsin\n⁡\n(\nθ\n)\n,\ncos\n⁡\n(\nθ\n)\n)\n∀\nk\n∈\n{\n0\n,\n1\n,\n…\n,\nd\n/\n2\n−\n1\n}\n{\\displaystyle (f(t)_{2k},f(t)_{2k+1})=(\\sin(\\theta ),\\cos(\\theta ))\\quad \\forall k\\in \\{0,1,\\ldots ,d/2-1\\}}\nwhere\nθ\n=\nt\nr\nk\n,\nr\n=\nN\n2\n/\nd\n{\\displaystyle \\theta ={\\frac {t}{r^{k}}},r=N^{2/d}}\n.\nHere,\nN\n{\\displaystyle N}\nis a free parameter that should be significantly larger than the biggest\nk\n{\\displaystyle k}\nthat would be input into the positional encoding function. The original paper uses\nN\n=\n10000\n{\\displaystyle N=10000}\n.\nThe function is in a simpler form when written as a complex function of type\nf\n:\nR\n→\nC\nd\n/\n2\n{\\displaystyle f:\\mathbb {R} \\to \\mathbb {C} ^{d/2}}\nf\n(\nt\n)\n=\n(\ne\ni\nt\n/\nr\nk\n)\nk\n=\n0\n,\n1\n,\n…\n,\nd\n2\n−\n1\n{\\displaystyle f(t)=\\left(e^{it/r^{k}}\\right)_{k=0,1,\\ldots ,{\\frac {d}{2}}-1}}\nwhere\nr\n=\nN\n2\n/\nd\n{\\displaystyle r=N^{2/d}}\n.\nThe main reason for using this positional encoding function is that using it, shifts are linear transformations:\nf\n(\nt\n+\nΔ\nt\n)\n=\nd\ni\na\ng\n(\nf\n(\nΔ\nt\n)\n)\nf\n(\nt\n)\n{\\displaystyle f(t+\\Delta t)=\\mathrm {diag} (f(\\Delta t))f(t)}\nwhere\nΔ\nt\n∈\nR\n{\\displaystyle \\Delta t\\in \\mathbb {R} }\nis the distance one wishes to shift. This allows the transformer to take any encoded position, and find the encoding of the position n-steps-ahead or n-steps-behind, by a matrix multiplication.\nBy taking a linear sum, any convolution can also be implemented as linear transformations:\n∑\nj\nc\nj\nf\n(\nt\n+\nΔ\nt\nj\n)\n=\n(\n∑\nj\nc\nj\nd\ni\na\ng\n(\nf\n(\nΔ\nt\nj\n)\n)\n)\nf\n(\nt\n)\n{\\displaystyle \\sum _{j}c_{j}f(t+\\Delta t_{j})=\\left(\\sum _{j}c_{j}\\,\\mathrm {diag} (f(\\Delta t_{j}))\\right)f(t)}\nfor any constants\nc\nj\n{\\displaystyle c_{j}}\n. This allows the transformer to take any encoded position and find a linear sum of the encoded locations of its neighbors. This sum of encoded positions, when fed into the attention mechanism, would create attention weights on its neighbors, much like what happens in a\nconvolutional neural network\nlanguage model\n. In the author's words, \"we hypothesized it would allow the model to easily learn to attend by relative position.\"\nIn typical implementations, all operations are done over the real numbers, not the complex numbers, but since\ncomplex multiplication can be implemented as real 2-by-2 matrix multiplication\n, this is a mere notational difference.\nEncoder–decoder (overview)\n[\nedit\n]\nOne encoder–decoder block\nA transformer is composed of stacked encoder layers and decoder layers.\nLike earlier\nseq2seq\nmodels, the original transformer model used an\nencoder–decoder\narchitecture. The encoder consists of encoding layers that process all the input tokens together one layer after another, while the decoder consists of decoding layers that iteratively process the encoder's output and the decoder's output tokens so far.\nThe purpose of each encoder layer is to create contextualized representations of the tokens, where each representation corresponds to a token that \"mixes\" information from other input tokens via self-attention mechanism. Each decoder layer contains two attention sublayers: (1) cross-attention for incorporating the output of encoder (contextualized input token representations), and (2) self-attention for \"mixing\" information among the input tokens to the decoder (i.e. the tokens generated so far during inference time).\n[\n53\n]\n[\n54\n]\nBoth the encoder and decoder layers have a\nfeed-forward neural network\nfor additional processing of their outputs and contain residual connections and layer normalization steps.\n[\n54\n]\nThese feed-forward layers contain most of the parameters in a transformer model.\nFeedforward network\n[\nedit\n]\nThe feedforward network module. It is a two-layered network that maps\nd\nemb\n{\\displaystyle d_{\\text{emb}}}\n-dimensional vectors into\nd\nemb\n{\\displaystyle d_{\\text{emb}}}\n-dimensional vectors.\nThe feedforward network (FFN) modules in a transformer are 2-layered\nmultilayer perceptrons\n:\nF\nF\nN\n(\nx\n)\n=\nϕ\n(\nx\nW\n(\n1\n)\n+\nb\n(\n1\n)\n)\nW\n(\n2\n)\n+\nb\n(\n2\n)\n{\\displaystyle \\mathrm {FFN} (x)=\\phi (xW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}}\nwhere\nW\n(\n1\n)\n{\\displaystyle W^{(1)}}\nand\nW\n(\n2\n)\n{\\displaystyle W^{(2)}}\nare weight matrices and\nb\n(\n1\n)\n{\\displaystyle b^{(1)}}\nand\nb\n(\n2\n)\n{\\displaystyle b^{(2)}}\nare bias vectors, and\nϕ\n{\\displaystyle \\phi }\nis its activation function. The original transformer used\nReLU\nactivation.\nThe number of neurons in the middle layer is called\nintermediate size\n(GPT),\n[\n55\n]\nfilter size\n(BERT),\n[\n35\n]\nor\nfeedforward size\n(BERT).\n[\n35\n]\nIt is typically larger than the embedding size. For example, in both GPT-2 series and BERT series, the intermediate size of a model is 4 times its embedding size:\nd\nffn\n=\n4\nd\nemb\n{\\displaystyle d_{\\text{ffn}}=4d_{\\text{emb}}}\n.\nScaled dot-product attention\n[\nedit\n]\nMain article:\nDot-product attention\nAttention head\n[\nedit\n]\nScaled dot-product attention, block diagram\nExact dimension counts within an attention head module\nThe attention mechanism used in the transformer architecture are scaled\ndot-product\nattention\nunits. For each unit, the transformer model learns three weight matrices: the query weights\nW\nQ\n{\\displaystyle W^{Q}}\n, the key weights\nW\nK\n{\\displaystyle W^{K}}\n, and the value weights\nW\nV\n{\\displaystyle W^{V}}\n.\nThe module takes three sequences, a query sequence, a key sequence, and a value sequence. The query sequence is a sequence of length\nℓ\nseq, query\n{\\displaystyle \\ell _{\\text{seq, query}}}\n, and each entry is a vector of dimension\nd\nemb, query\n{\\displaystyle d_{\\text{emb, query}}}\n. Similarly for the key and value sequences.\nFor each vector\nx\ni\n,\nquery\n{\\displaystyle x_{i,{\\text{query}}}}\nin the query sequence, it is multiplied by a matrix\nW\nQ\n{\\displaystyle W^{Q}}\nto produce a query vector\nq\ni\n=\nx\ni\n,\nquery\nW\nQ\n{\\displaystyle q_{i}=x_{i,{\\text{query}}}W^{Q}}\n. The matrix of all query vectors is the query matrix:\nQ\n=\nX\nquery\nW\nQ\n{\\displaystyle Q=X_{\\text{query}}W^{Q}}\nSimilarly, we construct the key matrix\nK\n=\nX\nkey\nW\nK\n{\\displaystyle K=X_{\\text{key}}W^{K}}\nand the value matrix\nV\n=\nX\nvalue\nW\nV\n{\\displaystyle V=X_{\\text{value}}W^{V}}\n.\nIt is usually the case that all\nW\nQ\n,\nW\nK\n,\nW\nV\n{\\displaystyle W^{Q},W^{K},W^{V}}\nare square matrices, meaning\nd\nemb, query\n=\nd\nquery\n{\\displaystyle d_{\\text{emb, query}}=d_{\\text{query}}}\n, etc.\nAttention weights are calculated using the query and key vectors: the attention weight\na\ni\nj\n{\\displaystyle a_{ij}}\nfrom token\ni\n{\\displaystyle i}\nto token\nj\n{\\displaystyle j}\nis the\ndot product\nbetween\nq\ni\n{\\displaystyle q_{i}}\nand\nk\nj\n{\\displaystyle k_{j}}\n. The attention weights are divided by the square root of the dimension of the key vectors,\nd\nk\n{\\displaystyle {\\sqrt {d_{k}}}}\n, which stabilizes gradients during training, and passed through a\nsoftmax\nwhich normalizes the weights. The fact that\nW\nQ\n{\\displaystyle W^{Q}}\nand\nW\nK\n{\\displaystyle W^{K}}\nare different matrices allows attention to be non-symmetric: if token\ni\n{\\displaystyle i}\nattends to token\nj\n{\\displaystyle j}\n(i.e.\nq\ni\n⋅\nk\nj\n{\\displaystyle q_{i}\\cdot k_{j}}\nis large), this does not necessarily mean that token\nj\n{\\displaystyle j}\nwill attend to token\ni\n{\\displaystyle i}\n(i.e.\nq\nj\n⋅\nk\ni\n{\\displaystyle q_{j}\\cdot k_{i}}\ncould be small). The output of the attention unit for token\ni\n{\\displaystyle i}\nis the weighted sum of the value vectors of all tokens, weighted by\na\ni\nj\n{\\displaystyle a_{ij}}\n, the attention from token\ni\n{\\displaystyle i}\nto each token.\nThe attention calculation for all tokens can be expressed as one large matrix calculation using the\nsoftmax function\n, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices\nQ\n{\\displaystyle Q}\n,\nK\n{\\displaystyle K}\nand\nV\n{\\displaystyle V}\nare defined as the matrices where the\ni\n{\\displaystyle i}\nth rows are vectors\nq\ni\n{\\displaystyle q_{i}}\n,\nk\ni\n{\\displaystyle k_{i}}\n, and\nv\ni\n{\\displaystyle v_{i}}\nrespectively. Then we can represent the attention as\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\nwhere the softmax is applied over each of the rows of the matrix.\nThe number of dimensions in a query vector is\nquery size\nd\nquery\n{\\displaystyle d_{\\text{query}}}\nand similarly for the\nkey size\nd\nkey\n{\\displaystyle d_{\\text{key}}}\nand\nvalue size\nd\nvalue\n{\\displaystyle d_{\\text{value}}}\n. The output dimension of an attention head is its\nhead dimension\nd\nhead\n{\\displaystyle d_{\\text{head}}}\n. The attention mechanism requires the following three equalities to hold:\nℓ\nseq, key\n=\nℓ\nseq, value\n,\nd\nquery\n=\nd\nkey\n,\nd\nvalue\n=\nd\nhead\n{\\displaystyle \\ell _{\\text{seq, key}}=\\ell _{\\text{seq, value}},\\;d_{\\text{query}}=d_{\\text{key}},\\;d_{\\text{value}}=d_{\\text{head}}}\nbut is otherwise unconstrained.\nIf the attention head is used in a self-attention fashion, then\nX\nquery\n=\nX\nkey\n=\nX\nvalue\n{\\displaystyle X_{\\text{query}}=X_{\\text{key}}=X_{\\text{value}}}\n. If the attention head is used in a cross-attention fashion, then usually\nX\nquery\n≠\nX\nkey\n=\nX\nvalue\n{\\displaystyle X_{\\text{query}}\\neq X_{\\text{key}}=X_{\\text{value}}}\n. It is theoretically possible for all three to be different, but that is rarely the case in practice.\nMultihead attention\n[\nedit\n]\nMultihead attention, block diagram\nExact dimension counts within a multihead attention module\nOne set of\n(\nW\nQ\n,\nW\nK\n,\nW\nV\n)\n{\\displaystyle \\left(W^{Q},W^{K},W^{V}\\right)}\nmatrices is called an\nattention head\n, and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, multiple attention heads allow the model to do this for different definitions of \"relevance\". Specifically, the query and key projection matrices,\nW\nQ\n{\\displaystyle W^{Q}}\nand\nW\nK\n{\\displaystyle W^{K}}\n, which are involved in the attention score computation, defines the \"relevance\". Meanwhile, the value\nprojection matrix\nW\nV\n{\\displaystyle W^{V}}\n, in combination with the part of the output projection matrix\nW\nO\n{\\displaystyle W^{O}}\n, determines how the attended tokens influence what information is passed to subsequent layers and ultimately the output logits. In addition, the scope of attention, or the range of token relationships captured by each attention head, can expand as tokens pass through successive layers. This allows the model to capture more complex and long-range dependencies in deeper layers. Many transformer attention heads encode relevance relations that are meaningful to humans. For example, some attention heads can attend mostly to the next word, while others mainly attend from verbs to their direct objects.\n[\n56\n]\nThe computations for each attention head can be performed in\nparallel\n, which allows for fast processing. The outputs for the attention layer are concatenated to pass into the\nfeedforward neural network\nlayers.\nConcretely, let the multiple attention heads be indexed by\ni\n{\\displaystyle i}\n, then we have\nMultiheadAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\ni\n∈\n[\nn\nheads\n]\n(\nAttention\n(\nX\nW\ni\nQ\n,\nX\nW\ni\nK\n,\nX\nW\ni\nV\n)\n)\nW\nO\n{\\displaystyle {\\text{MultiheadAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V}))W^{O}}\nwhere the matrix\nX\n{\\displaystyle X}\nis the concatenation of word embeddings, and the matrices\nW\ni\nQ\n,\nW\ni\nK\n,\nW\ni\nV\n{\\displaystyle W_{i}^{Q},W_{i}^{K},W_{i}^{V}}\nare \"projection matrices\" owned by individual attention head\ni\n{\\displaystyle i}\n, and\nW\nO\n{\\displaystyle W^{O}}\nis a final projection matrix owned by the whole multihead attention head.\nIt is theoretically possible for each attention head to have a different head dimension\nd\nhead\n{\\displaystyle d_{\\text{head}}}\n, but that is rarely the case in practice.\nAs an example, in the smallest GPT-2 model, there are only self-attention mechanisms. It has the following dimensions:\nd\nemb\n=\n768\n,\nn\nhead\n=\n12\n,\nd\nhead\n=\n64\n{\\displaystyle d_{\\text{emb}}=768,n_{\\text{head}}=12,d_{\\text{head}}=64}\nSince\n12\n×\n64\n=\n768\n{\\displaystyle 12\\times 64=768}\n, its output projection matrix\nW\nO\n∈\nR\n(\n12\n×\n64\n)\n×\n768\n{\\displaystyle W^{O}\\in \\mathbb {R} ^{(12\\times 64)\\times 768}}\nis a square matrix.\nMasked attention\n[\nedit\n]\nThe transformer architecture is constructed to calculate output tokens iteratively. Assuming\nt\n=\n0\n{\\displaystyle t=0}\nrefers to the calculation of the first output token\ni\n=\n0\n{\\displaystyle i=0}\n, for step\nt\n>\n0\n{\\displaystyle t>0}\n, the output token\ni\n=\n0\n{\\displaystyle i=0}\nshall remain constant. This ensures properties of the model similar to\nautoregressive models\n.\n[\n1\n]\nTherefore, at every time step\nt\n{\\displaystyle t}\n, the calculation for all outputs\ni\n{\\displaystyle i}\nshould not have access to tokens at position\nj\n{\\displaystyle j}\nfor\nj\n>=\ni\n{\\displaystyle j>=i}\n(as it naturally is the case for time step\nt\n=\ni\n{\\displaystyle t=i}\n, when tokens\nj\n>\nt\n{\\displaystyle j>t}\nare not yet calculated). This behavior may be accomplished before the softmax stage by adding a mask matrix\nM\n{\\displaystyle M}\nthat is\n−\n∞\n{\\displaystyle -\\infty }\nat entries where the attention link must be cut, and\n0\n{\\displaystyle 0}\nat other places:\nMaskedAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nM\n+\nQ\nK\nT\nd\nk\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{MaskedAttention}}(Q,K,V)={\\text{softmax}}\\left(M+{\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\nThe following matrix is commonly used in decoder self-attention modules, called \"causal masking\":\nM\ncausal\n=\n[\n0\n−\n∞\n−\n∞\n…\n−\n∞\n0\n0\n−\n∞\n…\n−\n∞\n0\n0\n0\n…\n−\n∞\n⋮\n⋮\n⋮\n⋱\n⋮\n0\n0\n0\n…\n0\n]\n{\\displaystyle M_{\\text{causal}}={\\begin{bmatrix}0&-\\infty &-\\infty &\\dots &-\\infty \\\\0&0&-\\infty &\\dots &-\\infty \\\\0&0&0&\\dots &-\\infty \\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&0&\\dots &0\\end{bmatrix}}}\nIn words, it means that each token can pay attention to itself, and every token before it, but not any after it. A non-masked attention module can be thought of as a masked attention module where the mask has all entries zero. As an example of an uncommon use of mask matrix, the\nXLNet\nconsiders all masks of the form\nP\nM\ncausal\nP\n−\n1\n{\\displaystyle PM_{\\text{causal}}P^{-1}}\n, where\nP\n{\\displaystyle P}\nis a random\npermutation matrix\n.\n[\n57\n]\nEncoder\n[\nedit\n]\nOne encoder layer\nAn encoder consists of an embedding layer, followed by multiple encoder layers.\nEach encoder layer consists of two major components: a self-attention mechanism and a feed-forward layer. It takes an input as a sequence of input vectors, applies the self-attention mechanism, to produce an intermediate sequence of vectors, then applies the feed-forward layer for each vector individually. Schematically, we have:\ngiven input vectors\nh\n0\n,\nh\n1\n,\n…\ncombine them into a matrix\nH\n=\n[\nh\n0\nh\n1\n⋮\n]\nEncoderLayer\n(\nH\n)\n=\n[\nFFN\n(\nMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\n0\n)\nFFN\n(\nMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\n1\n)\n⋮\n]\n{\\displaystyle {\\begin{aligned}{\\text{given input vectors }}&h_{0},h_{1},\\dots \\\\{\\text{combine them into a matrix }}H&={\\begin{bmatrix}h_{0}\\\\h_{1}\\\\\\vdots \\end{bmatrix}}\\\\{\\text{EncoderLayer}}(H)&={\\begin{bmatrix}{\\text{FFN}}({\\text{MultiheadAttention}}(H,H,H)_{0})\\\\{\\text{FFN}}({\\text{MultiheadAttention}}(H,H,H)_{1})\\\\\\vdots \\end{bmatrix}}\\\\\\end{aligned}}}\nwhere\nFFN\n{\\displaystyle {\\text{FFN}}}\nstands for \"feed-forward network\". We can more succinctly write it as\nEncoderLayer\n(\nH\n)\n=\nFFN\n(\nMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\n)\n{\\displaystyle {\\text{EncoderLayer}}(H)={\\text{FFN}}({\\text{MultiheadAttention}}(H,H,H))}\nwith the implicit convention that the\nFFN\n{\\displaystyle {\\text{FFN}}}\nis applied to each row of the matrix individually.\nThe encoder layers are stacked. The first encoder layer takes the sequence of input vectors from the embedding layer, producing a sequence of vectors. This sequence of vectors is processed by the second encoder, and so on. The output from the final encoder layer is then used by the decoder.\nAs the encoder processes the entire input all at once, every token can attend to every other token (all-to-all attention), so there is no need for causal masking.\nDecoder\n[\nedit\n]\nOne decoder layer\nA decoder consists of an embedding layer, followed by multiple decoder layers, followed by an un-embedding layer.\nEach decoder consists of three major components: a causally masked self-attention mechanism, a cross-attention mechanism, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders. This mechanism can also be called the\nencoder–decoder attention\n.\n[\n1\n]\n[\n54\n]\nLike the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. The transformer must not use the current or future output to predict an output, so the output sequence must be partially masked to prevent this reverse information flow.\n[\n1\n]\nThis allows for\nautoregressive\ntext generation. For decoding, all-to-all attention is inappropriate, because a token cannot attend to tokens not yet generated. Thus, the self-attention module in the decoder is causally masked.\nIn contrast, the cross-attention mechanism attends to the output vectors of the encoder, which is computed before the decoder starts decoding. Consequently, there is no need for masking in the cross-attention mechanism.\nSchematically, we have:\nH\n′\n=\nMaskedMultiheadAttention\n(\nH\n,\nH\n,\nH\n)\nDecoderLayer\n(\nH\n)\n=\nFFN\n(\nMultiheadAttention\n(\nH\n′\n,\nH\nE\n,\nH\nE\n)\n)\n{\\displaystyle {\\begin{aligned}H'&={\\text{MaskedMultiheadAttention}}(H,H,H)\\\\{\\text{DecoderLayer}}(H)&={\\text{FFN}}({\\text{MultiheadAttention}}(H',H^{E},H^{E}))\\end{aligned}}}\nwhere\nH\nE\n{\\displaystyle H^{E}}\nis the matrix with rows being the output vectors from the encoder.\nThe last decoder is followed by a final un-embedding layer to produce the output probabilities over the vocabulary. Then, one of the tokens is sampled according to the probability, and the decoder can be run again to produce the next token, etc., autoregressively generating output text.\nFull transformer architecture\n[\nedit\n]\nSublayers\n[\nedit\n]\n(a) One encoder layer and one decoder layer. (b) Two encoder layers and two decoder layers. The sublayers are labelled as well.\nEach encoder layer contains 2 sublayers: the self-attention and the feedforward network. Each decoder layer contains 3 sublayers: the causally masked self-attention, the cross-attention, and the feedforward network.\nTransformer encoder with norm-first and norm-last\nTransformer decoder with norm-first and norm-last\nBlock diagram for the full transformer architecture\nSchematic\nobject hierarchy\nfor the full transformer architecture, in\nobject-oriented programming\nstyle\nThe final points of detail are the\nresidual connections\nand\nlayer normalization\n, (denoted as \"LayerNorm\", or \"LN\" in the following), which while conceptually unnecessary, are necessary for numerical stability and convergence.\nThe residual connection, which is introduced to avoid vanishing gradient issues and stabilize the training process, can be expressed as follows: y = F(x) + x. The expression indicates that an output y is the sum of the transformation of input x (F(x)) and the input itself (x). Adding the input x can preserve the input information and avoid issues when the gradient of F(x) is close to zero.\nSimilarly to how the feedforward network modules are applied individually to each vector, the LayerNorm is also applied individually to each vector.\nThere are two common conventions in use: the\npost-LN\nand the\npre-LN\nconvention. In the post-LN convention, the output of each sublayer is\nL\na\ny\ne\nr\nN\no\nr\nm\n(\nx\n+\nS\nu\nb\nl\na\ny\ne\nr\n(\nx\n)\n)\n{\\displaystyle \\mathrm {LayerNorm} (x+\\mathrm {Sublayer} (x))}\nwhere\nS\nu\nb\nl\na\ny\ne\nr\n(\nx\n)\n{\\displaystyle \\mathrm {Sublayer} (x)}\nis the function implemented by the sublayer itself.\nIn the pre-LN convention, the output of each sublayer is\nx\n+\nS\nu\nb\nl\na\ny\ne\nr\n(\nL\na\ny\ne\nr\nN\no\nr\nm\n(\nx\n)\n)\n{\\displaystyle x+\\mathrm {Sublayer} (\\mathrm {LayerNorm} (x))}\nThe original 2017 transformer used the post-LN convention. It was difficult to train and required careful hyperparameter tuning and a \"warm-up\" in learning rate, where it starts small and gradually increases. The pre-LN convention, proposed several times in 2018,\n[\n58\n]\nwas found to be easier to train, requiring no warm-up, leading to faster convergence.\n[\n46\n]\nPseudocode\n[\nedit\n]\nThe following is the pseudocode for a standard pre-LN encoder–decoder transformer, adapted from\nFormal Algorithms for Transformers\n[\n59\n]\ninput:\nEncoder input t_e\n       Decoder input t_d\noutput:\nArray of probability distributions, with shape (decoder vocabulary size x length(decoder output sequence))\n\n/* encoder */\nz_e ← encoder.tokenizer(t_e)\nfor\neach\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← encoder.embedding(z_e[t]) + encoder.positional_embedding(t)\nfor\neach\nl\nin\n1:length(encoder.layers)\ndo\nlayer ← encoder.layers[l]\n\n    /* first sublayer */\n    z_e_copy ← copy(z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← layer.layer_norm(z_e[t])\n    z_e ← layer.multihead_attention(z_e, z_e, z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← z_e[t] + z_e_copy[t]\n\n    /* second sublayer */\n    z_e_copy ← copy(z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← layer.layer_norm(z_e[t])\n    z_e ← layer.feedforward(z_e)\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← z_e[t] + z_e_copy[t]\nfor each\nt\nin\n1:length(z_e)\ndo\nz_e[t] ← encoder.final_layer_norm(z_e[t])\n\n/* decoder */\nz_d ← decoder.tokenizer(t_d)\nfor\neach\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← decoder.embedding(z_d[t]) + decoder.positional_embedding(t)\nfor\neach\nl\nin\n1:length(decoder.layers)\ndo\nlayer ← decoder.layers[l]\n\n        /* first sublayer */\n        z_d_copy ← copy(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.masked_multihead_attention(z_d, z_d, z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← z_d[t] + z_d_copy[t]\n\n        /* second sublayer */\n        z_d_copy ← copy(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.multihead_attention(z_d, z_e, z_e)\nfor each\ni\nin\n1:length(z_d)\ndo\nz_d[t] ← z_d[t] + z_d_copy[t]\n\n        /* third sublayer */\n        z_d_copy ← copy(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.feedforward(z_d)\nfor each\nt\nin\n1:length(z_d)\ndo\nz_d[t] ← z_d[t] + z_d_copy[t]\n\nz_d ← decoder.final_layer_norm(z_d)\n\noutput_distributions ← []\nfor each\nt\nin\n1:length(z_d)\ndo\noutput_distributions.append(decoder.unembed(z_d[t]))\nreturn\noutput_distributions\nTerminology\n[\nedit\n]\nThe transformer architecture, being modular, allows variations. Several common variations are described here.\n[\n60\n]\nAn \"encoder-only\" transformer applies the encoder to map an input text into a sequence of vectors that represent the input text. This is usually used for text embedding and\nrepresentation learning\nfor downstream applications.\nBERT\nis encoder-only. They are less often used currently, as they were found to be not significantly better than training an encoder–decoder transformer, then taking just the encoder.\n[\n51\n]\nThey are also referred to as \"all-to-all\" or \"BERT-like\".\nA \"decoder-only\" transformer is not literally decoder-only, since without an encoder, the cross-attention mechanism has nothing to attend to. Thus, the decoder layers in a decoder-only transformer is composed of just two sublayers: the causally masked self-attention, and the feedforward network. This is usually used for\ntext generation\nand\ninstruction following\n. The models in the\nGPT series\nand\nChinchilla series\nare decoder-only. They are also referred to as \"autoregressive\" or \"causal\".\nAn \"encoder–decoder\" transformer is generally the same as the original transformer, with 2 sublayers per encoder layer and 3 sublayers per decoder layer, etc. They might have minor architectural improvements, such as\nalternative activation functions\n,\nchanging the location of normalization\n, etc. This is also usually used for text generation and instruction following. The models in the\nT5 series\nare encoder–decoder.\n[\n60\n]\nA \"prefixLM\" (prefix language model) is a decoder-only architecture, but with prefix masking, which is different from causal masking. Specifically, it has mask of the form\n[\n60\n]\n: Figure 3\nM\nprefixLM\n=\n[\n0\n−\n∞\n0\nM\ncausal\n]\n{\\displaystyle M_{\\text{prefixLM}}={\\begin{bmatrix}\\mathbf {0} &-\\infty \\\\\\mathbf {0} &M_{\\text{causal}}\\end{bmatrix}}}\nwhere the first columns correspond to the \"prefix\", and the subsequent columns correspond to the autoregressively generated text based on the prefix. They resemble encoder–decoder models, but has less \"sparsity\". Such models are rarely used, though they are cited as theoretical possibilities and benchmarked comparisons.\n[\n51\n]\nThere are also mixed seq2seq models. For example, in 2020, Google Translate replaced the previous RNN-encoder–RNN-decoder model with a transformer-encoder–RNN-decoder model, as transformer-based decoders did not appear to significantly increase quality unlike the encoder, while the RNN decoder was much faster.\n[\n37\n]\nSubsequent work\n[\nedit\n]\nAlternative activation functions\n[\nedit\n]\nThe original transformer uses\nReLU\nactivation function\n. Other activation functions were developed. The\nLlama series\nand\nPaLM\nused SwiGLU;\n[\n61\n]\nboth GPT-1 and BERT\n[\n35\n]\nused GELU.\n[\n62\n]\nAlternative activation functions are often used in combination with\nGated Linear Units\nin the feedforward module.\n[\n61\n]\nAlternative normalizations\n[\nedit\n]\nThe normalization used in the transformer can be different from LayerNorm. One example is\nRMSNorm\n[\n63\n]\nwhich is used in the\nLlama series\n. Other examples include CapsuleNorm\n[\n64\n]\nScaleNorm,\n[\n65\n]\nor FixNorm.\n[\n65\n]\nAlternative positional encodings\n[\nedit\n]\nTransformers may use other positional encoding methods than sinusoidal.\n[\n66\n]\nThe original transformer paper reported using a learned positional encoding,\n[\n67\n]\nbut finding it not superior to the sinusoidal one.\n[\n1\n]\nLater,\n[\n68\n]\nfound that causal masking itself provides enough signal to a transformer decoder that it can learn to implicitly perform absolute positional encoding without the positional encoding module.\nRoPE\n[\nedit\n]\nRoPE (rotary positional embedding),\n[\n69\n]\nis best explained by considering a list of 2-dimensional vectors\n[\n(\nx\n1\n(\n1\n)\n,\nx\n1\n(\n2\n)\n)\n,\n(\nx\n2\n(\n1\n)\n,\nx\n2\n(\n2\n)\n)\n,\n(\nx\n3\n(\n1\n)\n,\nx\n3\n(\n2\n)\n)\n,\n.\n.\n.\n]\n{\\displaystyle [(x_{1}^{(1)},x_{1}^{(2)}),(x_{2}^{(1)},x_{2}^{(2)}),(x_{3}^{(1)},x_{3}^{(2)}),...]}\n. Now pick some angle\nθ\n{\\displaystyle \\theta }\n. Then RoPE encoding is\nRoPE\n(\nx\nm\n(\n1\n)\n,\nx\nm\n(\n2\n)\n,\nm\n)\n=\n(\ncos\n⁡\nm\nθ\n−\nsin\n⁡\nm\nθ\nsin\n⁡\nm\nθ\ncos\n⁡\nm\nθ\n)\n(\nx\nm\n(\n1\n)\nx\nm\n(\n2\n)\n)\n=\n(\nx\nm\n(\n1\n)\ncos\n⁡\nm\nθ\n−\nx\nm\n(\n2\n)\nsin\n⁡\nm\nθ\nx\nm\n(\n2\n)\ncos\n⁡\nm\nθ\n+\nx\nm\n(\n1\n)\nsin\n⁡\nm\nθ\n)\n{\\displaystyle {\\text{RoPE}}{\\big (}x_{m}^{(1)},x_{m}^{(2)},m{\\big )}={\\begin{pmatrix}\\cos m\\theta &-\\sin m\\theta \\\\\\sin m\\theta &\\cos m\\theta \\end{pmatrix}}{\\begin{pmatrix}x_{m}^{(1)}\\\\x_{m}^{(2)}\\\\\\end{pmatrix}}={\\begin{pmatrix}x_{m}^{(1)}\\cos m\\theta -x_{m}^{(2)}\\sin m\\theta \\\\x_{m}^{(2)}\\cos m\\theta +x_{m}^{(1)}\\sin m\\theta \\\\\\end{pmatrix}}}\nEquivalently, if we write the 2-dimensional vectors as complex numbers\nz\nm\n:=\nx\nm\n(\n1\n)\n+\ni\nx\nm\n(\n2\n)\n{\\displaystyle z_{m}:=x_{m}^{(1)}+ix_{m}^{(2)}}\n, then RoPE encoding is just multiplication by an angle:\nRoPE\n(\nz\nm\n,\nm\n)\n=\ne\ni\nm\nθ\nz\nm\n{\\displaystyle {\\text{RoPE}}{\\big (}z_{m},m{\\big )}=e^{im\\theta }z_{m}}\nFor a list of\n2\nn\n{\\displaystyle 2n}\n-dimensional vectors, a RoPE encoder is defined by a sequence of angles\nθ\n(\n1\n)\n,\n.\n.\n.\n,\nθ\n(\nn\n)\n{\\displaystyle \\theta ^{(1)},...,\\theta ^{(n)}}\n. Then the RoPE encoding is applied to each pair of coordinates.\nThe benefit of RoPE is that the dot-product between two vectors depends on their relative location only:\nRoPE\n(\nx\n,\nm\n)\nT\nRoPE\n(\ny\n,\nn\n)\n=\nRoPE\n(\nx\n,\nm\n+\nk\n)\nT\nRoPE\n(\ny\n,\nn\n+\nk\n)\n{\\displaystyle {\\text{RoPE}}{\\big (}x,m{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n{\\big )}={\\text{RoPE}}{\\big (}x,m+k{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n+k{\\big )}}\nfor any integer\nk\n{\\displaystyle k}\n.\nALiBi\n[\nedit\n]\nALiBi (Attention with Linear Biases)\n[\n70\n]\nis not a\nreplacement\nfor the positional encoder on the original transformer. Instead, it is an\nadditional\npositional encoder that is directly plugged into the attention mechanism. Specifically, the ALiBi attention mechanism is\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n+\ns\nB\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+sB\\right)V\\end{aligned}}}\nHere,\ns\n{\\displaystyle s}\nis a real number (\"scalar\"), and\nB\n{\\displaystyle B}\nis the\nlinear bias\nmatrix defined by\nB\n=\n(\n0\n1\n2\n3\n⋯\n−\n1\n0\n1\n2\n⋯\n−\n2\n−\n1\n0\n1\n⋯\n−\n3\n−\n2\n−\n1\n0\n⋯\n⋮\n⋮\n⋮\n⋮\n⋱\n)\n{\\displaystyle B={\\begin{pmatrix}0&1&2&3&\\cdots \\\\-1&0&1&2&\\cdots \\\\-2&-1&0&1&\\cdots \\\\-3&-2&-1&0&\\cdots \\\\\\vdots &\\vdots &\\vdots &\\vdots &\\ddots \\\\\\end{pmatrix}}}\nin other words,\nB\ni\n,\nj\n=\nj\n−\ni\n{\\displaystyle B_{i,j}=j-i}\n. The idea being that the linear bias matrix is a softened mask. Just as\n0\n{\\displaystyle 0}\nrepresent full attention paid, and\n−\n∞\n{\\displaystyle -\\infty }\nrepresents no attention paid, the linear bias matrix increases attention paid in one direction and decreases attention paid in the other direction.\nALiBi allows pretraining on short context windows, then fine-tuning on longer context windows. Since it is directly plugged into the attention mechanism, it can be combined with any positional encoder that is plugged into the \"bottom\" of the entire network (which is where the sinusoidal encoder on the original transformer, as well as RoPE and many others, are located).\nRelative Position Encodings\n[\nedit\n]\nRelative Position Encodings\n[\n71\n]\nis similar to ALiBi, but more generic:\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n+\nB\n)\nV\n{\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+B\\right)V\\end{aligned}}}\nwhere\nB\n{\\displaystyle B}\nis a\nToeplitz matrix\n, that is,\nB\ni\n,\nj\n=\nB\ni\n′\n,\nj\n′\n{\\displaystyle B_{i,j}=B_{i',j'}}\nwhenever\ni\n−\nj\n=\ni\n′\n−\nj\n′\n{\\displaystyle i-j=i'-j'}\n. This is contrasted with the original sinusoidal positional encoding, which is an \"absolute positional encoding\".\n[\n72\n]\nEfficient implementation\n[\nedit\n]\nThe transformer model has been implemented in standard deep learning\nframeworks\nsuch as\nTensorFlow\nand\nPyTorch\n.\nTransformers\nis a library produced by\nHugging Face\nthat supplies transformer-based architectures and pretrained models.\n[\n11\n]\nKV caching\n[\nedit\n]\nWhen an autoregressive transformer is used for inference, such as generating text, the query vector is different at each step, but the already-computed key and value vectors are always the same. The\nKV caching\nmethod saves the computed key and value vectors at each attention block, so that they are not recomputed at each new token.\nPagedAttention\napplies\nmemory paging\nto KV caching.\n[\n73\n]\n[\n74\n]\n[\n75\n]\nIf a transformer is used with a baked-in prompt, such as [\"You are a customer support agent...\"], then the key and value vectors can be computed for the prompt, and saved on disk. The saving in compute is significant when the model is used for many short real-time interactions, such as in online chatbots.\nFlashAttention\n[\nedit\n]\nFlashAttention\n[\n76\n]\nis an algorithm that implements the transformer attention mechanism efficiently on a\nGPU\n. It is a communication-avoiding algorithm that performs\nmatrix multiplications in blocks\n, such that each block fits within the\ncache\nof a GPU, and by careful management of the blocks it minimizes data copying between GPU caches (as data movement is slow). See the page on\nsoftmax\nfor details.\nAn improved version, FlashAttention-2,\n[\n77\n]\n[\n78\n]\n[\n79\n]\nwas developed to cater to the rising demand for language models capable of handling longer context lengths. It offers enhancements in work partitioning and parallelism, enabling it to achieve up to 230 TFLOPs/s on\nA100\nGPUs (\nFP16\n/\nBF16\n), a 2x speed increase over the original FlashAttention.\nKey advancements in FlashAttention-2 include the reduction of non-matmul FLOPs, improved parallelism over the sequence length dimension, better work partitioning between GPU warps, and added support for head dimensions up to 256 and multi-query attention (MQA) and grouped-query attention (GQA).\n[\n80\n]\nBenchmarks revealed FlashAttention-2 to be up to 2x faster than FlashAttention and up to 9x faster than a standard attention implementation in PyTorch. Future developments include optimization for new hardware like\nH100\nGPUs and new data types like\nFP8\n.\nFlashAttention-4 focuses on\npipelining\nto increase instruction\nthroughput\n, and was developed to perform particularly well on\nBlackwell GPUs\n.\n[\n81\n]\nMulti-Query Attention\n[\nedit\n]\nComparison between several different forms of attention mechanism and the amount of KV caching necessary for each\nMulti-Query Attention changes the Multihead Attention mechanism.\n[\n82\n]\nWhereas normally,\nMultiheadAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\ni\n∈\n[\nn\nheads\n]\n(\nAttention\n(\nX\nW\ni\nQ\n,\nX\nW\ni\nK\n,\nX\nW\ni\nV\n)\n)\nW\nO\n{\\displaystyle {\\text{MultiheadAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V})\\right)W^{O}}\nwith Multi-Query Attention, there is just one\nW\nK\n,\nW\nV\n{\\displaystyle W^{K},W^{V}}\n, thus:\nMultiQueryAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\ni\n∈\n[\nn\nheads\n]\n(\nAttention\n(\nX\nW\ni\nQ\n,\nX\nW\nK\n,\nX\nW\nV\n)\n)\nW\nO\n{\\displaystyle {\\text{MultiQueryAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW^{K},XW^{V})\\right)W^{O}}\nThis has a neutral effect on model quality and training speed, but increases inference speed.\nMore generally, grouped-query attention (GQA) partitions attention heads into groups, each of which shares the key-value pair. MQA is GQA with one group, while standard Multihead Attention is GQA with the maximal number of groups.\n[\n83\n]\nThe architecture of V2, showing both MLA and a variant of\nmixture of experts\n[\n84\n]\n: Figure 2\nMultihead Latent Attention (MLA) is a\nlow-rank approximation\nto standard MHA. Specifically, each hidden vector, before entering the attention mechanism, is first projected to two low-dimensional spaces (\"latent space\"), one for query and one for key-value (KV vector). This design minimizes the KV cache, as only the low-dimensional KV vector needs to be cached.\n[\n84\n]\nSpeculative decoding\n[\nedit\n]\nSpeculative decoding\n[\n85\n]\n[\n86\n]\nis a method to accelerate token decoding. Similarly to\nspeculative execution\nin CPUs, future tokens are computed quickly, then verified. If the quickly computed tokens are incorrect, they are discarded and computed slowly.\nThe key factor in speculative decoding is that a transformer decoder can verify faster than it can decode, in the following sense.\nSuppose we have two transformer models like GPT-3 and GPT-3-small, both with a context window size of 512. To generate an entire context window autoregressively with greedy decoding with GPT-3, it must be run for 512 times, each time generating a token\nx\n1\n,\nx\n2\n,\n.\n.\n.\n,\nx\n512\n{\\displaystyle x_{1},x_{2},...,x_{512}}\n, taking time\n512\nT\nGPT-3\n{\\displaystyle 512T_{\\text{GPT-3}}}\n. However, if we had some educated guess for the values of these tokens, we could verify all of them in parallel, in one run of the model, by checking that each\nx\nt\n{\\displaystyle x_{t}}\nis indeed the token with the largest log-likelihood in the\nt\n{\\displaystyle t}\n-th output.\nIn speculative decoding, a smaller model or some other simple heuristic is used to generate a few speculative tokens that are subsequently verified by the larger model. For example, suppose we use GPT-3-small to generate four speculative tokens:\nx\n~\n1\n,\nx\n~\n2\n,\nx\n~\n3\n,\nx\n~\n4\n{\\displaystyle {\\tilde {x}}_{1},{\\tilde {x}}_{2},{\\tilde {x}}_{3},{\\tilde {x}}_{4}}\n. This only takes\n4\nT\nGPT-3-small\n{\\displaystyle 4T_{\\text{GPT-3-small}}}\n. These tokens are then run through the larger GPT-3 in one go. Suppose that\nx\n~\n1\n{\\displaystyle {\\tilde {x}}_{1}}\nand\nx\n~\n2\n{\\displaystyle {\\tilde {x}}_{2}}\nare verified by GPT-3 as what it would have picked, then those are kept, but\nx\n~\n3\n{\\displaystyle {\\tilde {x}}_{3}}\nis not, so\nx\n~\n3\n,\nx\n~\n4\n{\\displaystyle {\\tilde {x}}_{3},{\\tilde {x}}_{4}}\nare discarded, and GPT-3 is run on those. This would take\n4\nT\nGPT-3-small\n+\n3\nT\nGPT-3\n{\\displaystyle 4T_{\\text{GPT-3-small}}+3T_{\\text{GPT-3}}}\n, which might be shorter than\n4\nT\nGPT-3\n{\\displaystyle 4T_{\\text{GPT-3}}}\n.\nFor non-greedy decoding, similar ideas apply, except the speculative tokens are accepted or rejected stochastically, in a way that guarantees the final output distribution is the same as if speculative decoding was not used.\n[\n85\n]\n[\n87\n]\nMulti-token prediction\nIn Multi-Token Prediction, a single forward pass creates a final embedding vector, which then is un-embedded into a token probability. However, that vector can then be further processed by another transformer block to predict the\nnext\ntoken, and so on for arbitrarily many steps into the future. This trades off accuracy for speed, since each new token costs just one more transformer block, rather than the entire stack.\n[\n88\n]\n[\n89\n]\nSub-quadratic transformers\n[\nedit\n]\nTraining transformer-based architectures can be expensive, especially for long inputs.\n[\n90\n]\nMany methods have been developed to attempt to address the issue. In the image domain, Swin transformer is an efficient architecture that performs attention inside shifting windows.\n[\n91\n]\nIn the audio domain, SepTr decouples the attention in time and frequency domains.\n[\n92\n]\nLong Range Arena\n(2020)\n[\n93\n]\nis a standard benchmark for comparing the behavior of transformer architectures over long inputs.\nAlternative attention graphs\n[\nedit\n]\nThe standard attention graph is either all-to-all or causal, both of which scales as\nO\n(\nN\n2\n)\n{\\displaystyle O(N^{2})}\nwhere\nN\n{\\displaystyle N}\nis the number of tokens in a sequence.\nReformer (2020)\n[\n90\n]\n[\n94\n]\nreduces the computational load from\nO\n(\nN\n2\n)\n{\\displaystyle O(N^{2})}\nto\nO\n(\nN\nln\n⁡\nN\n)\n{\\displaystyle O(N\\ln N)}\nby using\nlocality-sensitive hashing\nand reversible layers.\n[\n95\n]\nSparse attention\n[\n96\n]\nuses attention graphs that grows slower than\nO\n(\nN\n2\n)\n{\\displaystyle O(N^{2})}\n. For example, BigBird (2020)\n[\n97\n]\nuses random\nsmall-world networks\nwhich grows as\nO\n(\nN\n)\n{\\displaystyle O(N)}\n.\nOrdinary transformers require a memory size that is quadratic in the size of the context window. Attention-free transformers\n[\n98\n]\nreduce this to a linear dependence while still retaining the advantages of a transformer by linking the key to the value.\nRandom Feature Attention\n[\nedit\n]\nRandom Feature Attention (2021)\n[\n99\n]\nuses\nFourier random features\n:\nφ\n(\nx\n)\n=\n1\nD\n[\ncos\n⁡\n⟨\nw\n1\n,\nx\n⟩\n,\nsin\n⁡\n⟨\nw\n1\n,\nx\n⟩\n,\n⋯\ncos\n⁡\n⟨\nw\nD\n,\nx\n⟩\n,\nsin\n⁡\n⟨\nw\nD\n,\nx\n⟩\n]\nT\n{\\displaystyle \\varphi (x)={\\frac {1}{\\sqrt {D}}}[\\cos \\langle w_{1},x\\rangle ,\\sin \\langle w_{1},x\\rangle ,\\cdots \\cos \\langle w_{D},x\\rangle ,\\sin \\langle w_{D},x\\rangle ]^{T}}\nwhere\nw\n1\n,\n.\n.\n.\n,\nw\nD\n{\\displaystyle w_{1},...,w_{D}}\nare independent samples from the normal distribution\nN\n(\n0\n,\nσ\n2\nI\n)\n{\\displaystyle N(0,\\sigma ^{2}I)}\n. This choice of parameters satisfy\nE\n[\n⟨\nφ\n(\nx\n)\n,\nφ\n(\ny\n)\n⟩\n]\n=\ne\n−\n‖\nx\n−\ny\n‖\n2\n2\nσ\n2\n{\\displaystyle \\mathbb {E} [\\langle \\varphi (x),\\varphi (y)\\rangle ]=e^{-{\\frac {\\|x-y\\|^{2}}{2\\sigma ^{2}}}}}\n, or\ne\n⟨\nx\n,\ny\n⟩\n/\nσ\n2\n=\nE\n[\n⟨\ne\n‖\nx\n‖\n2\n/\n2\nσ\n2\nφ\n(\nx\n)\n,\ne\n‖\ny\n‖\n2\n/\n2\nσ\n2\nφ\n(\ny\n)\n⟩\n]\n≈\n⟨\ne\n‖\nx\n‖\n2\n/\n2\nσ\n2\nφ\n(\nx\n)\n,\ne\n‖\ny\n‖\n2\n/\n2\nσ\n2\nφ\n(\ny\n)\n⟩\n{\\displaystyle e^{\\langle x,y\\rangle /\\sigma ^{2}}=\\mathbb {E} [\\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle ]\\approx \\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle }\nConsequently, the one-headed attention, with one query, can be written as\nAttention\n(\nq\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nq\nK\nT\nd\nk\n)\nV\n≈\nφ\n(\nq\n)\nT\n∑\ni\ne\n‖\nk\ni\n‖\n2\n/\n2\nσ\n2\nφ\n(\nk\ni\n)\nv\ni\nT\nφ\n(\nq\n)\nT\n∑\ni\ne\n‖\nk\ni\n‖\n2\n/\n2\nσ\n2\nφ\n(\nk\ni\n)\n{\\displaystyle {\\text{Attention}}(q,K,V)={\\text{softmax}}\\left({\\frac {qK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx {\\frac {\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})v_{i}^{T}}{\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})}}}\nwhere\nσ\n=\nd\nK\n1\n/\n4\n{\\displaystyle \\sigma =d_{K}^{1/4}}\n. Similarly for multiple queries, and for multihead attention.\nThis approximation can be computed in linear time, as we can compute the matrix\nφ\n(\nk\ni\n)\nv\ni\nT\n{\\displaystyle \\varphi (k_{i})v_{i}^{T}}\nfirst, then multiply it with the query. In essence, we have managed to obtain a more precise version of\nAttention\n(\nQ\n,\nK\n,\nV\n)\n=\nsoftmax\n(\nQ\nK\nT\nd\nk\n)\nV\n≈\nQ\n(\nK\nT\nV\n/\nd\nk\n)\n{\\displaystyle {\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx Q(K^{T}V/{\\sqrt {d_{k}}})}\nPerformer (2022)\n[\n100\n]\nuses the same Random Feature Attention, but\nw\n1\n,\n.\n.\n.\n,\nw\nD\n{\\displaystyle w_{1},...,w_{D}}\nare first independently sampled from the normal distribution\nN\n(\n0\n,\nσ\n2\nI\n)\n{\\displaystyle N(0,\\sigma ^{2}I)}\n, then they are\nGram-Schmidt processed\n.\nMultimodality\n[\nedit\n]\nTransformers can also be used/adapted for modalities (input or output) beyond just text, usually by finding a way to \"tokenize\" the modality.\nMultimodal models can either be trained from scratch, or by finetuning. A 2022 study found that transformers pretrained only on natural language can be finetuned on only 0.03% of parameters and become competitive with\nLSTMs\non a variety of logical and visual tasks, demonstrating\ntransfer learning\n.\n[\n101\n]\nThe LLaVA was a vision-language model composed of a language model (Vicuna-13B)\n[\n102\n]\nand a vision model (\nViT\n-L/14), connected by a linear layer. Only the linear layer is finetuned.\n[\n103\n]\nVision transformers\n[\n41\n]\nadapt the transformer to computer vision by breaking down input images as a series of patches, turning them into vectors, and treating them like embedding vector of tokens in a standard transformer.\nConformer\n[\n42\n]\nand later\nWhisper\n[\n104\n]\nfollow the same pattern for\nspeech recognition\n, first turning the speech signal into a\nspectrogram\n, which is then treated like an image, i.e. broken down into a series of patches, turned into vectors and treated like embedding vector of tokens in a standard transformer.\nPerceivers\n[\n105\n]\n[\n106\n]\nare a variant of transformers designed for multimodality.\nFor image generation, notable architectures are\nDALL-E 1\n(2021), Parti (2022),\n[\n107\n]\nPhenaki (2023),\n[\n108\n]\nand Muse (2023).\n[\n109\n]\nUnlike later models, DALL-E is not a\ndiffusion model\n. Instead, it uses a decoder-only transformer that autoregressively generates a text, followed by the token representation of an image, which is then converted by a\nvariational autoencoder\nto an image.\n[\n110\n]\nParti is an encoder–decoder transformer, where the encoder processes a text prompt, and the decoder generates a token representation of an image.\n[\n111\n]\nMuse is an encoder-only transformer that is trained to predict masked image tokens from unmasked image tokens. During generation, all input tokens are masked, and the highest-confidence predictions are included for the next iteration, until all tokens are predicted.\n[\n109\n]\nPhenaki is a text-to-video model. It is a bidirectional masked transformer conditioned on pre-computed text tokens. The generated tokens are then decoded to a video.\n[\n108\n]\nApplications\n[\nedit\n]\nThe transformer has had great success in\nnatural language processing\n(NLP). Many\nlarge language models\nsuch as\nGPT-2\n,\nGPT-3\n,\nGPT-4\n,\nGemini\n, AlbertAGPT,\nClaude\n,\nBERT\n,\nGrok\n,\nXLNet\n,\nRoBERTa\nand\nChatGPT\ndemonstrate the ability of transformers to perform a wide variety of NLP-related subtasks and their related real-world applications, including:\nmachine translation\ntime series\nprediction\ndocument summarization\ndocument generation\nnamed entity recognition\n(NER)\n[\n112\n]\nwriting computer code\nbased on requirements expressed in natural language.\nspeech-to-text\nBeyond traditional NLP, the transformer architecture has had success in other applications, such as:\nbiological sequence analysis\nvideo understanding\nprotein folding\n(such as\nAlphaFold\n)\nevaluating\nchess board positions. Using static evaluation alone (that is, with no\nMinimax\nsearch) transformer achieved an\nElo\nof 2895, putting it at\ngrandmaster\nlevel.\n[\n10\n]\nSee also\n[\nedit\n]\nseq2seq\n– Family of machine learning approaches\nPerceiver\n– Variant of Transformer designed for multimodal data\nVision transformer\n– Machine learning model for vision processing\nLarge language model\n– Type of machine learning model\nBERT (language model)\n– Series of language models developed by Google AI\nGenerative pre-trained transformer\n– Type of large language model\nT5 (language model)\n– Series of large language models developed by Google AI\nNotes\n[\nedit\n]\n^\nGated recurrent units\n(2014) further reduced its complexity.\n^\nSome architectures, such as RWKV or state space models, avoid the issue.\nReferences\n[\nedit\n]\n^\na\nb\nc\nd\ne\nf\ng\nh\ni\nj\nk\nl\nVaswani, Ashish\n; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion;\nGomez, Aidan N\n; Kaiser, Łukasz; Polosukhin, Illia (2017).\n\"Attention is All you Need\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n30\n. Curran Associates, Inc.\n^\nHochreiter, Sepp\n;\nSchmidhuber, Jürgen\n(1 November 1997). \"Long Short-Term Memory\".\nNeural Computation\n.\n9\n(8):\n1735–\n1780.\ndoi\n:\n10.1162/neco.1997.9.8.1735\n.\nISSN\n0899-7667\n.\nPMID\n9377276\n.\nS2CID\n1915014\n.\n^\na\nb\n\"Better Language Models and Their Implications\"\n.\nOpenAI\n. 2019-02-14.\nArchived\nfrom the original on 2020-12-19\n. Retrieved\n2019-08-25\n.\n^\na\nb\nBahdanau; Cho, Kyunghyun; Bengio, Yoshua (September 1, 2014). \"Neural Machine Translation by Jointly Learning to Align and Translate\".\narXiv\n:\n1409.0473\n[\ncs.CL\n].\n^\nLuong, Minh-Thang; Pham, Hieu; Manning, Christopher D. (August 17, 2015). \"Effective Approaches to Attention-based Neural Machine Translation\".\narXiv\n:\n1508.04025\n[\ncs.CL\n].\n^\na\nb\nChen, Lili; Lu, Kevin; Rajeswaran, Aravind; Lee, Kimin; Grover, Aditya; Laskin, Michael; Abbeel, Pieter; Srinivas, Aravind; Mordatch, Igor (2021-06-24),\nDecision Transformer: Reinforcement Learning via Sequence Modeling\n,\narXiv\n:\n2106.01345\n^\nParisotto, Emilio; Song, Francis; Rae, Jack; Pascanu, Razvan; Gulcehre, Caglar; Jayakumar, Siddhant; Jaderberg, Max; Kaufman, Raphaël Lopez; Clark, Aidan; Noury, Seb; Botvinick, Matthew; Heess, Nicolas; Hadsell, Raia (2020-11-21).\n\"Stabilizing Transformers for Reinforcement Learning\"\n.\nProceedings of the 37th International Conference on Machine Learning\n. PMLR:\n7487–\n7498.\n^\nRadford, Alec; Jong Wook Kim; Xu, Tao; Brockman, Greg; McLeavey, Christine; Sutskever, Ilya (2022). \"Robust Speech Recognition via Large-Scale Weak Supervision\".\narXiv\n:\n2212.04356\n[\neess.AS\n].\n^\nMonastirsky, Maxim; Azulay, Osher; Sintov, Avishai (February 2023). \"Learning to Throw With a Handful of Samples Using Decision Transformers\".\nIEEE Robotics and Automation Letters\n.\n8\n(2):\n576–\n583.\nBibcode\n:\n2023IRAL....8..576M\n.\ndoi\n:\n10.1109/LRA.2022.3229266\n.\nISSN\n2377-3766\n.\n^\na\nb\nRuoss, Anian; Delétang, Grégoire; Medapati, Sourabh; Grau-Moya, Jordi; Wenliang, Li; Catt, Elliot; Reid, John; Genewein, Tim (2024-02-07). \"Grandmaster-Level Chess Without Search\".\narXiv\n:\n2402.04494v1\n[\ncs.LG\n].\n^\na\nb\nWolf, Thomas; Debut, Lysandre; Sanh, Victor; Chaumond, Julien; Delangue, Clement; Moi, Anthony; Cistac, Pierric; Rault, Tim; Louf, Remi; Funtowicz, Morgan; Davison, Joe; Shleifer, Sam; von Platen, Patrick; Ma, Clara; Jernite, Yacine; Plu, Julien; Xu, Canwen; Le Scao, Teven; Gugger, Sylvain; Drame, Mariama; Lhoest, Quentin; Rush, Alexander (2020). \"Transformers: State-of-the-Art Natural Language Processing\".\nProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\n. pp.\n38–\n45.\ndoi\n:\n10.18653/v1/2020.emnlp-demos.6\n.\nS2CID\n208117506\n.\n^\na\nb\nc\n\"Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing\"\n.\nGoogle AI Blog\n. 2 November 2018.\nArchived\nfrom the original on 2021-01-13\n. Retrieved\n2019-08-25\n.\n^\nFeldman, J. A.; Ballard, D. H. (1982-07-01).\n\"Connectionist models and their properties\"\n.\nCognitive Science\n.\n6\n(3):\n205–\n254.\ndoi\n:\n10.1016/S0364-0213(82)80001-3\n.\nISSN\n0364-0213\n.\n^\nRumelhart, David E.; McClelland, James L.; Hinton, Geoffrey E. (1987-07-29).\nParallel Distributed Processing, Volume 1: Explorations in the Microstructure of Cognition: Foundations, Chapter 2\n(PDF)\n. Cambridge, Mass: Bradford Books.\nISBN\n978-0-262-68053-0\n.\n^\nGiles, C. Lee; Maxwell, Tom (1987-12-01).\n\"Learning, invariance, and generalization in high-order neural networks\"\n.\nApplied Optics\n.\n26\n(23):\n4972–\n4978.\ndoi\n:\n10.1364/AO.26.004972\n.\nISSN\n0003-6935\n.\nPMID\n20523475\n.\n^\na\nb\nSchmidhuber, Jürgen\n(1992).\n\"Learning to control fast-weight memories: an alternative to recurrent nets\"\n(PDF)\n.\nNeural Computation\n.\n4\n(1):\n131–\n139.\ndoi\n:\n10.1162/neco.1992.4.1.131\n.\nS2CID\n16683347\n.\n^\nChristoph von der Malsburg: The correlation theory of brain function. Internal Report 81-2, MPI Biophysical Chemistry, 1981.\nhttp://cogprints.org/1380/1/vdM_correlation.pdf\nSee Reprint in Models of Neural Networks II, chapter 2, pages 95–119. Springer, Berlin, 1994.\n^\nJerome A. Feldman, \"Dynamic connections in neural networks,\" Biological Cybernetics, vol. 46, no. 1, pp. 27–39, Dec. 1982.\n^\nHinton, Geoffrey E.; Plaut, David C. (1987).\n\"Using Fast Weights to Deblur Old Memories\"\n.\nProceedings of the Annual Meeting of the Cognitive Science Society\n.\n9\n.\n^\nKatharopoulos, Angelos; Vyas, Apoorv; Pappas, Nikolaos; Fleuret, François (2020).\n\"Transformers are RNNs: Fast autoregressive Transformers with linear attention\"\n.\nICML 2020\n. PMLR. pp.\n5156–\n5165.\n^\nSchlag, Imanol; Irie, Kazuki;\nSchmidhuber, Jürgen\n(2021). \"Linear Transformers Are Secretly Fast Weight Programmers\".\nICML 2021\n. Springer. pp.\n9355–\n9366.\n^\na\nb\nCho, Kyunghyun; van Merriënboer, Bart; Gulcehre, Caglar; Bahdanau, Dzmitry; Bougares, Fethi; Schwenk, Holger; Bengio, Yoshua (October 2014).\n\"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation\"\n. In Moschitti, Alessandro; Pang, Bo; Daelemans, Walter (eds.).\nProceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n. Doha, Qatar: Association for Computational Linguistics. pp.\n1724–\n1734.\narXiv\n:\n1406.1078\n.\ndoi\n:\n10.3115/v1/D14-1179\n.\n^\na\nb\nSutskever, Ilya; Vinyals, Oriol; Le, Quoc Viet (14 Dec 2014). \"Sequence to sequence learning with neural networks\".\narXiv\n:\n1409.3215\n[\ncs.CL\n].\n[first version posted to arXiv on 10 Sep 2014]\n^\nChung, Junyoung; Gulcehre, Caglar; Cho, KyungHyun; Bengio, Yoshua (2014). \"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\".\narXiv\n:\n1412.3555\n[\ncs.NE\n].\n^\nGruber, N.; Jockisch, A. (2020), \"Are GRU cells more specific and LSTM cells more sensitive in motive classification of text?\",\nFrontiers in Artificial Intelligence\n,\n3\n40,\ndoi\n:\n10.3389/frai.2020.00040\n,\nPMC\n7861254\n,\nPMID\n33733157\n,\nS2CID\n220252321\n^\nSutskever, Ilya; Vinyals, Oriol; Le, Quoc V (2014).\n\"Sequence to Sequence Learning with Neural Networks\"\n.\nAdvances in Neural Information Processing Systems\n.\n27\n. Curran Associates, Inc.\narXiv\n:\n1409.3215\n.\n^\nLuong, Minh-Thang; Pham, Hieu; Manning, Christopher D. (2015). \"Effective Approaches to Attention-based Neural Machine Translation\".\narXiv\n:\n1508.04025\n[\ncs.CL\n].\n^\nWu, Yonghui; et al. (2016-09-01). \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\".\narXiv\n:\n1609.08144\n[\ncs.CL\n].\n^\nLewis-Kraus, Gideon (2016-12-14).\n\"The Great A.I. Awakening\"\n.\nThe New York Times\n.\nISSN\n0362-4331\n. Archived from\nthe original\non 24 May 2023\n. Retrieved\n2023-06-22\n.\n^\nParikh, Ankur P.; Täckström, Oscar; Das, Dipanjan; Uszkoreit, Jakob (2016-09-25). \"A Decomposable Attention Model for Natural Language Inference\".\narXiv\n:\n1606.01933\n[\ncs.CL\n].\n^\na\nb\nLevy, Steven.\n\"8 Google Employees Invented Modern AI. Here's the Inside Story\"\n.\nWired\n.\nISSN\n1059-1028\n.\nArchived\nfrom the original on 20 Mar 2024\n. Retrieved\n2024-08-06\n.\n^\nCheng, Jianpeng; Dong, Li; Lapata, Mirella (November 2016).\n\"Long Short-Term Memory-Networks for Machine Reading\"\n. In Su, Jian; Duh, Kevin; Carreras, Xavier (eds.).\nProceedings of the 2016 Conference on Empirical Methods in Natural Language Processing\n. Austin, Texas: Association for Computational Linguistics. pp.\n551–\n561.\ndoi\n:\n10.18653/v1/D16-1053\n.\n^\nPeng, Bo; Alcaide, Eric; Anthony, Quentin; Albalak, Alon; Arcadinho, Samuel; Biderman, Stella; Cao, Huanqi; Cheng, Xin; Chung, Michael (2023-12-10),\nRWKV: Reinventing RNNs for the transformer Era\n,\narXiv\n:\n2305.13048\n^\nMarche, Stephen (2024-08-23).\n\"Was Linguistic A.I. Created by Accident?\"\n.\nThe New Yorker\n.\nISSN\n0028-792X\n. Retrieved\n2024-08-27\n.\n^\na\nb\nc\nd\ne\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\".\narXiv\n:\n1810.04805v2\n[\ncs.CL\n].\n^\n\"Google: BERT now used on almost every English query\"\n.\nSearch Engine Land\n. 2020-10-15\n. Retrieved\n2020-11-24\n.\n^\na\nb\nCaswell, Isaac; Liang, Bowen (June 8, 2020).\n\"Recent Advances in Google Translate\"\n.\nGoogle Research\n.\nArchived\nfrom the original on 4 Jul 2024\n. Retrieved\n2024-08-07\n.\n^\n\"The inside story of how ChatGPT was built from the people who made it\"\n.\nMIT Technology Review\n. Retrieved\n2024-08-06\n.\n^\n\"Improving language understanding with unsupervised learning\"\n.\nopenai.com\n. June 11, 2018.\nArchived\nfrom the original on 2023-03-18\n. Retrieved\n2023-03-18\n.\n^\nfinetune-transformer-lm\n, OpenAI, June 11, 2018\n, retrieved\n2023-05-01\n^\na\nb\nDosovitskiy, Alexey; Beyer, Lucas; Kolesnikov, Alexander; Weissenborn, Dirk; Zhai, Xiaohua; Unterthiner, Thomas; Dehghani, Mostafa; Minderer, Matthias; Heigold, Georg; Gelly, Sylvain; Uszkoreit, Jakob (2021-06-03). \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\".\narXiv\n:\n2010.11929\n[\ncs.CV\n].\n^\na\nb\nGulati, Anmol; Qin, James; Chiu, Chung-Cheng; Parmar, Niki; Zhang, Yu; Yu, Jiahui; Han, Wei; Wang, Shibo; Zhang, Zhengdong; Wu, Yonghui; Pang, Ruoming (2020). \"Conformer: Convolution-augmented Transformer for Speech Recognition\".\narXiv\n:\n2005.08100\n[\neess.AS\n].\n^\nChoromanski, Krzysztof; Likhosherstov, Valerii; Dohan, David; Song, Xingyou; Gane, Andreea; Sarlos, Tamas; Hawkins, Peter; Davis, Jared; Mohiuddin, Afroz (2022-11-19),\nRethinking Attention with Performers\n,\narXiv\n:\n2009.14794\n^\nLiu, Zhuang; Mao, Hanzi; Wu, Chao-Yuan; Feichtenhofer, Christoph; Darrell, Trevor; Xie, Saining (2022).\nA ConvNet for the 2020s\n. Conference on Computer Vision and Pattern Recognition (\nCVPR\n). pp.\n11976–\n11986.\n^\nEsser, Patrick; Kulal, Sumith; Blattmann, Andreas; Entezari, Rahim; Müller, Jonas; Saini, Harry; Levi, Yam; Lorenz, Dominik; Sauer, Axel (2024-03-05),\nScaling Rectified Flow Transformers for High-Resolution Image Synthesis\n,\narXiv\n:\n2403.03206\n^\na\nb\nXiong, Ruibin; Yang, Yunchang; He, Di; Zheng, Kai; Zheng, Shuxin; Xing, Chen; Zhang, Huishuai; Lan, Yanyan; Wang, Liwei; Liu, Tie-Yan (2020-06-29). \"On Layer Normalization in the Transformer Architecture\".\narXiv\n:\n2002.04745\n[\ncs.LG\n].\n^\nRaffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2020-01-01).\n\"Exploring the limits of transfer learning with a unified text-to-text transformer\"\n.\nThe Journal of Machine Learning Research\n.\n21\n(1): 140:5485–140:5551.\narXiv\n:\n1910.10683\n.\nISSN\n1532-4435\n.\n^\nRaffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2019). \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\".\narXiv\n:\n1910.10683\n[\ncs.LG\n].\n^\na\nb\n\"Masked language modeling\"\n.\nhuggingface.co\n. Retrieved\n2023-10-05\n.\n^\na\nb\n\"Causal language modeling\"\n.\nhuggingface.co\n. Retrieved\n2023-10-05\n.\n^\na\nb\nc\nd\nTay, Yi; Dehghani, Mostafa; Tran, Vinh Q.; Garcia, Xavier; Wei, Jason; Wang, Xuezhi; Chung, Hyung Won; Shakeri, Siamak; Bahri, Dara (2023-02-28),\nUL2: Unifying Language Learning Paradigms\n,\narXiv\n:\n2205.05131\n^\nPress, Ofir; Wolf, Lior (2017-02-21),\nUsing the Output Embedding to Improve Language Models\n,\narXiv\n:\n1608.05859\n^\nLintz, Nathan (2016-04-18).\n\"Sequence Modeling with Neural Networks (Part 2): Attention Models\"\n.\nIndico\n.\nArchived\nfrom the original on 2020-10-21\n. Retrieved\n2019-10-15\n.\n^\na\nb\nc\nAlammar, Jay.\n\"The Illustrated transformer\"\n.\njalammar.github.io\n.\nArchived\nfrom the original on 2020-10-18\n. Retrieved\n2019-10-15\n.\n^\nTeam, Keras.\n\"Keras documentation: GPT2Backbone model\"\n.\nkeras.io\n. Retrieved\n2024-08-08\n.\n^\nClark, Kevin; Khandelwal, Urvashi; Levy, Omer; Manning, Christopher D. (August 2019).\n\"What Does BERT Look at? An Analysis of BERT's Attention\"\n.\nProceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP\n. Florence, Italy: Association for Computational Linguistics:\n276–\n286.\narXiv\n:\n1906.04341\n.\ndoi\n:\n10.18653/v1/W19-4828\n.\nArchived\nfrom the original on 2020-10-21\n. Retrieved\n2020-05-20\n.\n^\nYang, Zhilin; Dai, Zihang; Yang, Yiming; Carbonell, Jaime; Salakhutdinov, Russ R; Le, Quoc V (2019).\n\"XLNet: Generalized Autoregressive Pretraining for Language Understanding\"\n.\nAdvances in Neural Information Processing Systems\n.\n32\n. Curran Associates, Inc.\narXiv\n:\n1906.08237\n.\n^\nWang, Qiang; Li, Bei; Xiao, Tong; Zhu, Jingbo; Li, Changliang; Wong, Derek F.; Chao, Lidia S. (2019-06-04),\nLearning Deep Transformer Models for Machine Translation\n,\narXiv\n:\n1906.01787\n^\nPhuong, Mary; Hutter, Marcus (2022-07-19),\nFormal Algorithms for Transformers\n,\narXiv\n:\n2207.09238\n^\na\nb\nc\nRaffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2020).\n\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"\n.\nJournal of Machine Learning Research\n.\n21\n(140):\n1–\n67.\narXiv\n:\n1910.10683\n.\nISSN\n1533-7928\n.\n^\na\nb\nShazeer, Noam (2020-02-01). \"GLU Variants Improve Transformer\".\narXiv\n:\n2002.05202\n[\ncs.LG\n].\n^\nHendrycks, Dan; Gimpel, Kevin (2016-06-27). \"Gaussian Error Linear Units (GELUs)\".\narXiv\n:\n1606.08415v5\n[\ncs.LG\n].\n^\nZhang, Biao; Sennrich, Rico (2019).\n\"Root Mean Square Layer Normalization\"\n.\nAdvances in Neural Information Processing Systems\n.\n32\n. Curran Associates, Inc.\narXiv\n:\n1910.07467\n.\n^\nTembine, Hamidou, Manzoor Ahmed Khan, and Issa Bamia. 2024. \"Mean-Field-Type Transformers\" Mathematics 12, no. 22: 3506.\nhttps://doi.org/10.3390/math12223506\n^\na\nb\nNguyen, Toan Q.; Salazar, Julian (2019-11-02). Niehues, Jan; Cattoni, Rolando; Stüker, Sebastian; Negri, Matteo; Turchi, Marco; Ha, Thanh-Le; Salesky, Elizabeth; Sanabria, Ramon; Barrault, Loic (eds.).\n\"Transformers without Tears: Improving the Normalization of Self-Attention\"\n.\nProceedings of the 16th International Conference on Spoken Language Translation\n. Hong Kong: Association for Computational Linguistics.\narXiv\n:\n1910.05895\n.\ndoi\n:\n10.5281/zenodo.3525484\n.\n^\nDufter, Philipp; Schmitt, Martin; Schütze, Hinrich (2022-06-06).\n\"Position Information in transformers: An Overview\"\n.\nComputational Linguistics\n.\n48\n(3):\n733–\n763.\narXiv\n:\n2102.11090\n.\ndoi\n:\n10.1162/coli_a_00445\n.\nISSN\n0891-2017\n.\nS2CID\n231986066\n.\n^\nGehring, Jonas; Auli, Michael; Grangier, David; Yarats, Denis; Dauphin, Yann N. (2017-07-17).\n\"Convolutional Sequence to Sequence Learning\"\n.\nProceedings of the 34th International Conference on Machine Learning\n. PMLR:\n1243–\n1252.\n^\nHaviv, Adi; Ram, Ori; Press, Ofir; Izsak, Peter; Levy, Omer (2022-12-05),\nTransformer Language Models without Positional Encodings Still Learn Positional Information\n,\narXiv\n:\n2203.16634\n^\nSu, Jianlin; Lu, Yu; Pan, Shengfeng; Murtadha, Ahmed; Wen, Bo; Liu, Yunfeng (2021-04-01). \"RoFormer: Enhanced Transformer with Rotary Position Embedding\".\narXiv\n:\n2104.09864\n[\ncs.CL\n].\n^\nPress, Ofir; Smith, Noah A.; Lewis, Mike (2021-08-01). \"Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation\".\narXiv\n:\n2108.12409\n[\ncs.CL\n].\n^\nShaw, Peter; Uszkoreit, Jakob; Vaswani, Ashish (2018). \"Self-Attention with Relative Position Representations\".\narXiv\n:\n1803.02155\n[\ncs.CL\n].\n^\nKe, Guolin; He, Di; Liu, Tie-Yan (2021-03-15),\nRethinking Positional Encoding in Language Pre-training\n,\narXiv\n:\n2006.15595\n^\nKwon, Woosuk; Li, Zhuohan; Zhuang, Siyuan; Sheng, Ying; Zheng, Lianmin; Yu, Cody Hao; Gonzalez, Joseph; Zhang, Hao; Stoica, Ion (2023-10-23).\n\"Efficient Memory Management for Large Language Model Serving with PagedAttention\"\n.\nProceedings of the 29th Symposium on Operating Systems Principles\n. SOSP '23. New York, NY, USA: Association for Computing Machinery. pp.\n611–\n626.\narXiv\n:\n2309.06180\n.\ndoi\n:\n10.1145/3600006.3613165\n.\nISBN\n979-8-4007-0229-7\n.\n^\nvllm-project/vllm\n, vLLM, 2024-06-20\n, retrieved\n2024-06-20\n^\nZhuohan Li, Woosuk Kwon; Zhuang, Siyuan; Sheng, Ying; Zheng, Lianmin; Yu, Cody; Gonzalez, Joey; Zhang, Hao; Stoica, Ion (2023-06-20).\n\"vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention\"\n.\nvLLM Blog\n. Retrieved\n2024-06-20\n.\n^\nDao, Tri; Fu, Dan; Ermon, Stefano; Rudra, Atri; Ré, Christopher (2022-12-06).\n\"FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\"\n.\nAdvances in Neural Information Processing Systems\n.\n35\n:\n16344–\n16359.\narXiv\n:\n2205.14135\n.\n^\n\"Stanford CRFM\"\n.\ncrfm.stanford.edu\n. Retrieved\n2023-07-18\n.\n^\n\"FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning\"\n.\nPrinceton NLP\n. 2023-06-17\n. Retrieved\n2023-07-18\n.\n^\n\"Introducing Together AI Chief Scientist Tri Dao, as he releases FlashAttention-2 to speed up model training and inference\"\n.\nTOGETHER\n. Retrieved\n2023-07-18\n.\n^\nAinslie, Joshua; Lee-Thorp, James; de Jong, Michiel; Zemlyanskiy, Yury; Lebrón, Federico; Sanghai, Sumit (2023-12-23). \"GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\".\narXiv\n:\n2305.13245\n[\ncs.CL\n].\n^\n\"We reverse-engineered Flash Attention 4\"\n.\nModal\n. Retrieved\n2025-09-26\n.\n^\nChowdhery, Aakanksha; Narang, Sharan; Devlin, Jacob; Bosma, Maarten; Mishra, Gaurav; Roberts, Adam; Barham, Paul; Chung, Hyung Won; Sutton, Charles; Gehrmann, Sebastian; Schuh, Parker; Shi, Kensen; Tsvyashchenko, Sasha; Maynez, Joshua; Rao, Abhishek (2022-04-01). \"PaLM: Scaling Language Modeling with Pathways\".\narXiv\n:\n2204.02311\n[\ncs.CL\n].\n^\nAinslie, Joshua; Lee-Thorp, James; de Jong, Michiel; Zemlyanskiy, Yury; Lebrón, Federico; Sanghai, Sumit (2023-12-23),\nGQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\n,\narXiv\n:\n2305.13245\n^\na\nb\nDeepSeek-AI; Liu, Aixin; Feng, Bei; Wang, Bin; Wang, Bingxuan; Liu, Bo; Zhao, Chenggang; Dengr, Chengqi; Ruan, Chong (19 June 2024),\nDeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model\n,\narXiv\n:\n2405.04434\n.\n^\na\nb\nLeviathan, Yaniv; Kalman, Matan; Matias, Yossi (2023-05-18),\nFast Inference from Transformers via Speculative Decoding\n,\narXiv\n:\n2211.17192\n^\nFu, Yao (2023-12-13).\n\"Towards 100x Speedup: Full Stack Transformer Inference Optimization\"\n.\n^\nChen, Charlie; Borgeaud, Sebastian; Irving, Geoffrey; Lespiau, Jean-Baptiste; Sifre, Laurent; Jumper, John (2023-02-02),\nAccelerating Large Language Model Decoding with Speculative Sampling\n,\narXiv\n:\n2302.01318\n^\nGloeckle, Fabian; Badr Youbi Idrissi; Rozière, Baptiste; Lopez-Paz, David; Synnaeve, Gabriel (2024). \"Better & Faster Large Language Models via Multi-token Prediction\".\narXiv\n:\n2404.19737\n[\ncs.CL\n].\n^\nDeepSeek-AI; et al. (2024). \"DeepSeek-V3 Technical Report\".\narXiv\n:\n2412.19437\n[\ncs.CL\n].\n^\na\nb\nKitaev, Nikita; Kaiser, Łukasz; Levskaya, Anselm (2020). \"Reformer: The Efficient Transformer\".\narXiv\n:\n2001.04451\n[\ncs.LG\n].\n^\nLiu, Ze; Lin, Yutong; Cao, Yue; Hu, Han; Wei, Yixuan; Zhang, Zheng; Lin, Stephen; Guo, Baining (2021). \"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\".\n2021 IEEE/CVF International Conference on Computer Vision (ICCV)\n. IEEE. pp.\n9992–\n10002.\narXiv\n:\n2103.14030\n.\ndoi\n:\n10.1109/ICCV48922.2021.00986\n.\nISBN\n978-1-6654-2812-5\n.\n^\nRistea, Nicolaea Catalin; Ionescu, Radu Tudor; Khan, Fahad Shahbaz (2022-09-18).\n\"SepTr: Separable Transformer for Audio Spectrogram Processing\"\n.\nInterspeech\n. ISCA:\n4103–\n4107.\narXiv\n:\n2203.09581\n.\ndoi\n:\n10.21437/Interspeech.2022-249\n.\n^\nTay, Yi; Dehghani, Mostafa; Abnar, Samira; Shen, Yikang; Bahri, Dara; Pham, Philip; Rao, Jinfeng; Yang, Liu; Ruder, Sebastian; Metzler, Donald (2020-11-08). \"Long Range Arena: A Benchmark for Efficient Transformers\".\narXiv\n:\n2011.04006\n[\ncs.LG\n].\n^\n\"Reformer: The Efficient Transformer\"\n.\nGoogle AI Blog\n. 16 January 2020.\nArchived\nfrom the original on 2020-10-22\n. Retrieved\n2020-10-22\n.\n^\nGomez, Aidan N; Ren, Mengye; Urtasun, Raquel; Grosse, Roger B (2017).\n\"The Reversible Residual Network: Backpropagation Without Storing Activations\"\n.\nAdvances in Neural Information Processing Systems\n.\n30\n. Curran Associates, Inc.\narXiv\n:\n1707.04585\n.\n^\nChild, Rewon; Gray, Scott; Radford, Alec; Sutskever, Ilya (2019-04-23),\nGenerating Long Sequences with Sparse Transformers\n,\narXiv\n:\n1904.10509\n^\n\"Constructing Transformers For Longer Sequences with Sparse Attention Methods\"\n.\nGoogle AI Blog\n. 25 March 2021.\nArchived\nfrom the original on 2021-09-18\n. Retrieved\n2021-05-28\n.\n^\nZhai, Shuangfei; Talbott, Walter; Srivastava, Nitish; Huang, Chen; Goh, Hanlin; Zhang, Ruixiang; Susskind, Josh (2021-09-21). \"An Attention Free Transformer\".\narXiv\n:\n2105.14103\n[\ncs.LG\n].\n^\nPeng, Hao; Pappas, Nikolaos; Yogatama, Dani; Schwartz, Roy; Smith, Noah A.; Kong, Lingpeng (2021-03-19). \"Random Feature Attention\".\narXiv\n:\n2103.02143\n[\ncs.CL\n].\n^\nChoromanski, Krzysztof; Likhosherstov, Valerii; Dohan, David; Song, Xingyou; Gane, Andreea; Sarlos, Tamas; Hawkins, Peter; Davis, Jared; Belanger, David; Colwell, Lucy; Weller, Adrian (2020-09-30). \"Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers\".\narXiv\n:\n2006.03555\n[\ncs.LG\n].\n^\nLu, Kevin; Grover, Aditya; Abbeel, Pieter; Mordatch, Igor (2022-06-28).\n\"Frozen Pretrained Transformers as Universal Computation Engines\"\n.\nProceedings of the AAAI Conference on Artificial Intelligence\n.\n36\n(7):\n7628–\n7636.\ndoi\n:\n10.1609/aaai.v36i7.20729\n.\nISSN\n2374-3468\n.\n^\n\"Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality | LMSYS Org\"\n.\nlmsys.org\n. Retrieved\n2024-08-11\n.\n^\nLiu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-12-15).\n\"Visual Instruction Tuning\"\n.\nAdvances in Neural Information Processing Systems\n.\n36\n:\n34892–\n34916.\n^\nRadford, Alec; Kim, Jong Wook; Xu, Tao; Brockman, Greg; McLeavey, Christine; Sutskever, Ilya (2022). \"Robust Speech Recognition via Large-Scale Weak Supervision\".\narXiv\n:\n2212.04356\n[\neess.AS\n].\n^\nJaegle, Andrew; Gimeno, Felix; Brock, Andrew; Zisserman, Andrew; Vinyals, Oriol; Carreira, Joao (2021-06-22). \"Perceiver: General Perception with Iterative Attention\".\narXiv\n:\n2103.03206\n[\ncs.CV\n].\n^\nJaegle, Andrew; Borgeaud, Sebastian; Alayrac, Jean-Baptiste; Doersch, Carl; Ionescu, Catalin; Ding, David; Koppula, Skanda; Zoran, Daniel; Brock, Andrew; Shelhamer, Evan; Hénaff, Olivier (2021-08-02). \"Perceiver IO: A General Architecture for Structured Inputs & Outputs\".\narXiv\n:\n2107.14795\n[\ncs.LG\n].\n^\n\"Parti: Pathways Autoregressive Text-to-Image Model\"\n.\nsites.research.google\n. Retrieved\n2024-08-09\n.\n^\na\nb\nVillegas, Ruben; Babaeizadeh, Mohammad; Kindermans, Pieter-Jan; Moraldo, Hernan; Zhang, Han; Saffar, Mohammad Taghi; Castro, Santiago; Kunze, Julius; Erhan, Dumitru (2022-09-29). \"Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions\".\narXiv\n:\n2210.02399\n[\ncs.CV\n].\n^\na\nb\nChang, Huiwen; Zhang, Han; Barber, Jarred; Maschinot, A. J.; Lezama, Jose; Jiang, Lu; Yang, Ming-Hsuan; Murphy, Kevin; Freeman, William T. (2023-01-02). \"Muse: Text-To-Image Generation via Masked Generative Transformers\".\narXiv\n:\n2301.00704\n[\ncs.CV\n].\n^\nRamesh, Aditya; Pavlov, Mikhail; Goh, Gabriel; Gray, Scott; Voss, Chelsea; Radford, Alec; Chen, Mark; Sutskever, Ilya (2021-02-26),\nZero-Shot Text-to-Image Generation\n,\narXiv\n:\n2102.12092\n^\nYu, Jiahui; Xu, Yuanzhong; Koh, Jing Yu; Luong, Thang; Baid, Gunjan; Wang, Zirui; Vasudevan, Vijay; Ku, Alexander; Yang, Yinfei (2022-06-21),\nScaling Autoregressive Models for Content-Rich Text-to-Image Generation\n,\narXiv\n:\n2206.10789\n^\nKariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Mathé, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023).\n\"Precision information extraction for rare disease epidemiology at scale\"\n.\nJournal of Translational Medicine\n.\n21\n(1): 157.\ndoi\n:\n10.1186/s12967-023-04011-y\n.\nPMC\n9972634\n.\nPMID\n36855134\n.\nFurther reading\n[\nedit\n]\nAlexander Rush,\nThe Annotated transformer\nArchived\n2021-09-22 at the\nWayback Machine\n, Harvard NLP group, 3 April 2018\nPhuong, Mary; Hutter, Marcus (2022). \"Formal Algorithms for Transformers\".\narXiv\n:\n2207.09238\n[\ncs.LG\n].\nFerrando, Javier; Sarti, Gabriele; Bisazza, Arianna; Costa-jussà, Marta R. (2024-05-01). \"A Primer on the Inner Workings of Transformer-based Language Models\".\narXiv\n:\n2405.00208\n[\ncs.CL\n].\nLeech, Gavin (2024-11-06).\n\"Transformer++\"\n.\nargmin gravitas\n. Archived from\nthe original\non 2025-02-26\n. Retrieved\n2025-05-08\n.\nKitamura, Felipe; Moreno Júdice de Mattos Farina, Eduardo; Pedro Mazuco, João; Moy, Linda; M. Prevedello, Luciano (2025-08-25).\n\"Texts Are More than Notes, They Are Data: A Glimpse into How Machines Understand Text\"\n.\nRadiology\n.\n316\n(2) e243217.\ndoi\n:\n10.1148/radiol.243217\n.\nPMID\n40892454\n.\nv\nt\ne\nGoogle AI\nGoogle\nGoogle Brain\nGoogle DeepMind\nComputer\nprograms\nAlphaGo\nVersions\nAlphaGo\n(2015)\nMaster\n(2016)\nAlphaGo Zero\n(2017)\nAlphaZero\n(2017)\nMuZero\n(2019)\nCompetitions\nFan Hui\n(2015)\nLee Sedol\n(2016)\nKe Jie\n(2017)\nIn popular culture\nAlphaGo\n(2017)\nThe MANIAC\n(2023)\nOther\nAlphaFold\n(2018)\nAlphaStar\n(2019)\nAlphaDev\n(2023)\nAlphaGeometry\n(2024)\nAlphaGenome\n(2025)\nMachine\nlearning\nNeural networks\nInception\n(2014)\nWaveNet\n(2016)\nMobileNet\n(2017)\nTransformer\n(2017)\nEfficientNet\n(2019)\nGato\n(2022)\nOther\nQuantum Artificial Intelligence Lab\nTensorFlow\nTensor Processing Unit\nGenerative\nAI\nChatbots\nAssistant\n(2016)\nSparrow\n(2022)\nGemini\n(2023)\nNano Banana\n(2025)\nModels\nBERT\n(2018)\nXLNet\n(2019)\nT5\n(2019)\nLaMDA\n(2021)\nChinchilla\n(2022)\nPaLM\n(2022)\nImagen\n(2023)\nGemini\n(2023)\nVideoPoet\n(2024)\nGemma\n(2024)\nVeo\n(2024)\nOther\nDreamBooth\n(2022)\nNotebookLM\n(2023)\nVids\n(2024)\nGemini Robotics\n(2025)\nAntigravity\n(2025)\nSee also\n\"\nAttention Is All You Need\n\"\nFuture of Go Summit\nGenerative pre-trained transformer\nGoogle Labs\nGoogle Pixel\nGoogle Workspace\nRobot Constitution\nCategory\nCommons\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Transformer_(deep_learning)&oldid=1327414157\n\"\nCategories\n:\nGoogle software\nNeural network architectures\n2017 in artificial intelligence\nHidden categories:\nArticles with short description\nShort description is different from Wikidata\nWebarchive template wayback links\nThis page was last edited on 14 December 2025, at 06:23\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nTransformer (deep learning)\n30 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:23.902848",
      "status": "success",
      "content_length": 99935,
      "topic": "llm"
    },
    {
      "title": "Prompt engineering - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Prompt_engineering",
      "content": "Prompt engineering - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\n2\nText-to-text\nToggle Text-to-text subsection\n2.1\nChain-of-thought\n2.2\nIn-context learning\n2.3\nSelf-consistency\n2.4\nTree-of-thought\n2.5\nPrompting to estimate model sensitivity\n2.6\nAutomatic prompt generation\n2.6.1\nRetrieval-augmented generation\n2.6.2\nGraph retrieval-augmented generation\n2.6.3\nUsing language models to generate prompts\n2.6.4\nAutomatic prompt optimization\n2.7\nContext engineering\n3\nText-to-image\nToggle Text-to-image subsection\n3.1\nPrompt formats\n3.2\nArtist styles\n4\nNon-text prompts\nToggle Non-text prompts subsection\n4.1\nTextual inversion and embeddings\n4.2\nImage prompting\n4.3\nUsing gradient descent to search for prompts\n5\nLimitations\n6\nPrompt injection\n7\nReferences\nToggle the table of contents\nPrompt engineering\n37 languages\nالعربية\nবাংলা\nBosanski\nCatalà\nČeština\nDeutsch\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\n한국어\nՀայերեն\nहिन्दी\nIdo\nBahasa Indonesia\nIsiZulu\nעברית\nJawa\nMagyar\nमराठी\nNederlands\n日本語\nNorsk nynorsk\nPolski\nPortuguês\nRomână\nРусский\nSlovenščina\nSuomi\nSvenska\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nStructuring text as input to generative artificial intelligence\nPrompt engineering\nis the process of structuring or crafting an instruction in order to produce better outputs from a\ngenerative artificial intelligence\n(AI) model. It typically involves designing clear queries, adding relevant context, and refining wording to guide the model toward more accurate, useful, and consistent responses.\n[\n1\n]\nA\nprompt\nis\nnatural language\ntext describing the task that an AI should perform.\n[\n2\n]\nA prompt for a text-to-text\nlanguage model\ncan be a query, a command, or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, choice of words and grammar,\n[\n3\n]\nproviding relevant context, or describing a character for the AI to mimic.\n[\n1\n]\nWhen communicating with a\ntext-to-image\nor a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\"\n[\n4\n]\nor \"Lo-fi slow BPM electro chill with organic samples\".\n[\n5\n]\nPrompting a text-to-image model may involve adding, removing, or emphasizing words to achieve a desired subject, style, layout, lighting, and aesthetic.\n[\n6\n]\nHistory\n[\nedit\n]\nIn 2018, researchers first proposed that all previously separate tasks in\nnatural language processing\n(NLP) could be cast as a question-answering problem over a context. In addition, they trained a first single, joint, multi-task model that would answer any task-related question like \"What is the sentiment\" or \"Translate this sentence to German\" or \"Who is the president?\"\n[\n7\n]\nThe\nAI boom\nsaw an increase in the amount of \"prompting technique\" to get the model to output the desired outcome and avoid\nnonsensical output\n, a process characterized by\ntrial-and-error\n.\n[\n8\n]\nAfter the release of\nChatGPT\nin 2022, prompt engineering was soon seen as an important business skill, albeit one with an uncertain economic future.\n[\n1\n]\nA repository for prompts reported that over 2,000 public prompts for around 170 datasets were available in February 2022.\n[\n9\n]\nIn 2022, the\nchain-of-thought\nprompting technique was proposed by\nGoogle\nresearchers.\n[\n10\n]\n[\n11\n]\nIn 2023, several text-to-text and text-to-image prompt databases were made publicly available.\n[\n12\n]\n[\n13\n]\nThe Personalized Image-Prompt (PIP) dataset, a generated image-text dataset that has been categorized by 3,115 users, has also been made available publicly in 2024.\n[\n14\n]\nText-to-text\n[\nedit\n]\nA comprehensive 2024 survey of the field identified over 50 distinct text-based prompting techniques and around 40 multimodal variants, demonstrating rapid diversification in prompting strategies. The study also documented a controlled vocabulary of 33 terms used across prompting research, highlighting the growing need for standardization.\n[\n15\n]\nThe survey found that the performance of large language models is highly sensitive to choices such as the ordering of examples, the quality of demonstration labels, and even small variations in phrasing. In some cases, reordering examples in a prompt produced accuracy shifts of more than 40 percent, emphasizing the importance of methodical prompt construction.\n[\n15\n]\nChain-of-thought\n[\nedit\n]\nSee also:\nReflection (artificial intelligence)\nAccording to Google Research,\nchain-of-thought\n(CoT) prompting is a technique that allows\nlarge language models\n(LLMs) to solve a problem as a series of intermediate steps before giving a final answer. In 2022,\nGoogle Brain\nreported that chain-of-thought prompting improves\nreasoning\nability by inducing the model to answer a multi-step problem with steps of reasoning that mimic a\ntrain of thought\n.\n[\n10\n]\n[\n16\n]\nChain-of-thought techniques were developed to help LLMs handle multi-step reasoning tasks, such as\narithmetic\nor\ncommonsense reasoning\nquestions.\n[\n17\n]\n[\n18\n]\nFor example, given the question \"Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\", CoT prompting induced an LLM to answer \"A: The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9.\"\n[\n10\n]\nWhen applied to\nPaLM\n, a 540 billion parameter\nlanguage model\n, according to Google, CoT prompting significantly aided the model, allowing it to perform comparably with task-specific\nfine-tuned\nmodels on several tasks, achieving\nstate-of-the-art\nresults at the time on the GSM8K\nmathematical reasoning\nbenchmark\n.\n[\n10\n]\nIt is possible to fine-tune models on CoT reasoning datasets to enhance this capability further and stimulate better\ninterpretability\n.\n[\n19\n]\n[\n20\n]\nAs originally proposed by Google,\n[\n10\n]\neach CoT prompt is accompanied by a set of input/output examples—called\nexemplars\n—to demonstrate the desired model output, making it a\nfew-shot\nprompting technique. However, according to a later paper from researchers at Google and the\nUniversity of Tokyo\n, simply appending the words \"Let's think step-by-step\"\n[\n21\n]\nwas also effective, which allowed for CoT to be employed as a\nzero-shot\ntechnique.\nAn example format of\nfew-shot\nCoT prompting with in-context exemplars:\n[\n22\n]\nQ: {example question 1}\n   A: {example answer 1}\n   ...\n   Q: {example question\nn\n}\n   A: {example answer\nn\n}\n   \n   Q: {question}\n   A: {LLM output}\nAn example format of\nzero-shot\nCoT prompting:\n[\n21\n]\nQ: {question}. Let's think step by step.\n   A: {LLM output}\nIn-context learning\n[\nedit\n]\nIn-context learning\n, refers to a model's ability to temporarily learn from prompts. For example, a prompt may include a few examples for a model to learn from, such as asking the model to complete \"\nmaison\n→ house,\nchat\n→ cat,\nchien\n→\" (the expected response being\ndog\n),\n[\n23\n]\nan approach called\nfew-shot learning\n.\n[\n24\n]\nIn-context learning is an\nemergent ability\n[\n25\n]\nof large language models. It is an emergent property of model scale, meaning that\nbreaks\n[\n26\n]\nin downstream scaling laws occur, leading to its efficacy increasing at a different rate in larger models than in smaller models.\n[\n25\n]\n[\n10\n]\nUnlike training and\nfine-tuning\n, which produce lasting changes, in-context learning is temporary.\n[\n27\n]\nTraining models to perform in-context learning can be viewed as a form of\nmeta-learning\n, or \"learning to learn\".\n[\n28\n]\nSelf-consistency\n[\nedit\n]\nSelf-consistency\nperforms several chain-of-thought rollouts, then selects the most commonly reached conclusion out of all the rollouts.\n[\n29\n]\n[\n30\n]\nTree-of-thought\n[\nedit\n]\nTree-of-thought\nprompting generalizes chain-of-thought by generating multiple lines of reasoning in parallel, with the ability to backtrack or explore other paths. It can use\ntree search algorithms\nlike\nbreadth-first\n,\ndepth-first\n, or\nbeam\n.\n[\n30\n]\n[\n31\n]\nPrompting to estimate model sensitivity\n[\nedit\n]\nResearch consistently demonstrates that LLMs are highly sensitive to subtle variations in prompt formatting, structure, and linguistic properties. Some studies have shown up to 76 accuracy points across formatting changes in few-shot settings.\n[\n32\n]\nLinguistic features significantly influence prompt effectiveness—such as morphology, syntax, and lexico-semantic changes—which meaningfully enhance task performance across a variety of tasks.\n[\n3\n]\n[\n33\n]\nClausal syntax, for example, improves consistency and reduces uncertainty in knowledge retrieval.\n[\n34\n]\nThis sensitivity persists even with larger model sizes, additional few-shot examples, or instruction tuning.\nTo address sensitivity of models and make them more robust, several methods have been proposed. FormatSpread facilitates systematic analysis by evaluating a range of plausible prompt formats, offering a more comprehensive performance interval.\n[\n32\n]\nSimilarly, PromptEval estimates performance distributions across diverse prompts, enabling robust metrics such as performance quantiles and accurate evaluations under constrained budgets.\n[\n35\n]\nAutomatic prompt generation\n[\nedit\n]\nRecent research has explored automated prompt engineering, using optimization algorithms to generate or refine prompts without human intervention. These automated approaches aim to identify effective prompt patterns by analyzing model gradients, reinforcement feedback, or evolutionary processes, reducing the need for manual experimentation.\n[\n36\n]\nRetrieval-augmented generation\n[\nedit\n]\nMain article:\nRetrieval-augmented generation\nRetrieval-augmented generation (RAG) is a technique that enables\ngenerative artificial intelligence\n(Gen AI) models to retrieve and incorporate new information. It modifies interactions with an LLM so that the model responds to user queries with reference to a specified set of documents, using this information to supplement information from its pre-existing\ntraining data\n. This allows LLMs to use domain-specific and/or updated information.\n[\n37\n]\nRAG improves large language models by incorporating\ninformation retrieval\nbefore generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to\nArs\nTechnica\n, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce\nAI hallucinations\n, which have led to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases. By dynamically retrieving information, RAG enables AI to provide more accurate responses without frequent retraining.\n[\n38\n]\nGraph retrieval-augmented generation\n[\nedit\n]\nGraphRAG with a knowledge graph combining access patterns for unstructured, structured, and mixed data\nGraphRAG (coined by\nMicrosoft Research\n) is a technique that extends RAG with the use of a knowledge graph (usually, LLM-generated) to allow the model to connect disparate pieces of information, synthesize insights, and holistically understand summarized semantic concepts over large data collections. It was shown to be effective on datasets like the Violent Incident Information from News Articles (VIINA).\n[\n39\n]\n[\n40\n]\nEarlier work showed the effectiveness of using a\nknowledge graph\nfor question answering using text-to-query generation.\n[\n41\n]\nThese techniques can be combined to search across both unstructured and structured data, providing expanded context, and improved ranking.\nUsing language models to generate prompts\n[\nedit\n]\nLLMs themselves can be used to compose prompts for LLMs.\n[\n42\n]\nThe\nautomatic prompt engineer\nalgorithm uses one LLM to\nbeam search\nover prompts for another LLM:\n[\n43\n]\n[\n44\n]\nThere are two LLMs. One is the target LLM, and another is the prompting LLM.\nPrompting LLM is presented with example input-output pairs, and asked to generate instructions that could have caused a model following the instructions to generate the outputs, given the inputs.\nEach of the generated instructions is used to prompt the target LLM, followed by each of the inputs. The log-probabilities of the outputs are computed and added. This is the score of the instruction.\nThe highest-scored instructions are given to the prompting LLM for further variations.\nRepeat until some stopping criteria is reached, then output the highest-scored instructions.\nCoT examples can be generated by LLM themselves. In \"auto-CoT\", a library of questions are converted to vectors by a model such as\nBERT\n. The question vectors are\nclustered\n. Questions close to the\ncentroid\nof each cluster are selected, in order to have a subset of diverse questions. An LLM does zero-shot CoT on each selected question. The question and the corresponding CoT answer are added to a dataset of demonstrations. These diverse demonstrations can then added to prompts for few-shot learning.\n[\n45\n]\nAutomatic prompt optimization\n[\nedit\n]\nAutomatic prompt optimization techniques refine prompts for large language models (LLMs) by automatically searching over alternative prompt strings using evaluation datasets and task-specific metrics. MIPRO (Multi-prompt Instruction Proposal Optimizer) optimizes the instructions and few-shot demonstrations of multi-stage language model programs, proposing small changes to module prompts and retaining those that improve a downstream performance metric without access to module-level labels or gradients.\n[\n46\n]\nGEPA (Genetic-Pareto) is a reflective prompt optimizer for compound AI systems that combines language-model-based analysis of execution traces and textual feedback with a Pareto-based evolutionary search over a population of candidate systems; across four tasks, GEPA reports average gains of about 10% over reinforcement-learning-based Group Relative Policy Optimization and over 10% over the MIPROv2 prompt optimizer, while using up to 35 times fewer rollouts than GRPO.\n[\n47\n]\nOpen-source frameworks such as DSPy and Opik expose these and related optimizers, allowing prompt search to be expressed as part of a programmatic pipeline rather than through manual trial and error.\n[\n48\n]\n[\n49\n]\nContext engineering\n[\nedit\n]\nContext engineering is an emerging, practitioner-focused term describing the discipline of designing, curating and governing the elements that accompany user prompts. This includes system instructions, retrieved knowledge, tool definitions, conversation summaries, and task metadata to improve reliability, provenance and token efficiency in production LLM systems.\n[\n50\n]\n[\n51\n]\nThe concept emphasises operational practices such as token budgeting, provenance tags, versioning of context artifacts, observability (logging which context was supplied), and context regression tests to ensure that changes to supplied context do not silently alter system behaviour. A July 2025 survey provides a formal taxonomy of context engineering components (context retrieval/generation, context processing, and context management) and argues for treating the context window as a managed engineering surface rather than only a passive source of retrieved documents.\n[\n52\n]\nText-to-image\n[\nedit\n]\nSee also:\nArtificial intelligence visual art § Prompt engineering and sharing\n, and\nArtificial intelligence visual art\nIn 2022,\ntext-to-image\nmodels like\nDALL-E 2\n,\nStable Diffusion\n, and\nMidjourney\nwere released to the public. These models take text prompts as input and use them to generate images.\n[\n53\n]\n[\n6\n]\nDemonstration of the effect of negative prompts on images generated with\nStable Diffusion\nTop\n: no negative prompt\nCentre\n: \"green trees\"\nBottom\n: \"round stones, round rocks\"\nPrompt formats\n[\nedit\n]\nEarly text-to-image models typically do not understand negation, grammar and sentence structure in the same way as\nlarge language models\n, and may thus require a different set of prompting techniques. The prompt \"a party with no cake\" may produce an image including a cake.\n[\n54\n]\nAs an alternative,\nnegative prompts\nallow a user to indicate, in a separate prompt, which terms should\nnot\nappear in the resulting image.\n[\n55\n]\nTechniques such as framing the normal prompt into a\nsequence-to-sequence\nlanguage modeling problem can be used to automatically generate an output for the negative prompt.\n[\n56\n]\nA text-to-image prompt commonly includes a description of the subject of the art, the desired medium (such as\ndigital painting\nor\nphotography\n), style (such as\nhyperrealistic\nor\npop-art\n), lighting (such as\nrim lighting\nor\ncrepuscular rays\n), color, and texture.\n[\n57\n]\nWord order also affects the output of a text-to-image prompt. Words closer to the start of a prompt may be emphasized more heavily.\n[\n58\n]\nThe\nMidjourney\ndocumentation encourages short, descriptive prompts: instead of \"Show me a picture of lots of blooming California poppies, make them bright, vibrant orange, and draw them in an illustrated style with colored pencils\", an effective prompt might be \"Bright orange California poppies drawn with colored pencils\".\n[\n54\n]\nArtist styles\n[\nedit\n]\nSome text-to-image models are capable of imitating the style of particular artists by name. For example, the phrase\nin the style of Greg Rutkowski\nhas been used in Stable Diffusion and Midjourney prompts to generate images in the distinctive style of Polish digital artist\nGreg Rutkowski\n.\n[\n59\n]\nFamous artists such as\nVincent van Gogh\nand\nSalvador Dalí\nhave also been used for styling and testing.\n[\n60\n]\nNon-text prompts\n[\nedit\n]\nSome approaches augment or replace natural language text prompts with non-text input.\nTextual inversion and embeddings\n[\nedit\n]\nFor text-to-image models,\ntextual inversion\nperforms an optimization process to create a new\nword embedding\nbased on a set of example images. This embedding vector acts as a \"pseudo-word\" which can be included in a prompt to express the content or style of the examples.\n[\n61\n]\nImage prompting\n[\nedit\n]\nIn 2023,\nMeta\n's AI research released Segment Anything, a\ncomputer vision\nmodel that can perform\nimage segmentation\nby prompting. As an alternative to text prompts, Segment Anything can accept bounding boxes, segmentation masks, and foreground/background points.\n[\n62\n]\nUsing gradient descent to search for prompts\n[\nedit\n]\nIn \"prefix-tuning\",\n[\n63\n]\n\"prompt tuning\", or \"soft prompting\",\n[\n64\n]\nfloating-point-valued vectors are searched directly by\ngradient descent\nto maximize the log-likelihood on outputs.\nFormally, let\nE\n=\n{\ne\n1\n,\n…\n,\ne\nk\n}\n{\\displaystyle \\mathbf {E} =\\{\\mathbf {e_{1}} ,\\dots ,\\mathbf {e_{k}} \\}}\nbe a set of soft prompt tokens (tunable embeddings), while\nX\n=\n{\nx\n1\n,\n…\n,\nx\nm\n}\n{\\displaystyle \\mathbf {X} =\\{\\mathbf {x_{1}} ,\\dots ,\\mathbf {x_{m}} \\}}\nand\nY\n=\n{\ny\n1\n,\n…\n,\ny\nn\n}\n{\\displaystyle \\mathbf {Y} =\\{\\mathbf {y_{1}} ,\\dots ,\\mathbf {y_{n}} \\}}\nbe the token embeddings of the input and output respectively. During training, the tunable embeddings, input, and output tokens are concatenated into a single sequence\nconcat\n(\nE\n;\nX\n;\nY\n)\n{\\displaystyle {\\text{concat}}(\\mathbf {E} ;\\mathbf {X} ;\\mathbf {Y} )}\n, and fed to the LLMs. The\nlosses\nare computed over the\nY\n{\\displaystyle \\mathbf {Y} }\ntokens; the gradients are\nbackpropagated\nto prompt-specific parameters: in prefix-tuning, they are parameters associated with the prompt tokens at each layer; in prompt tuning, they are merely the soft tokens added to the vocabulary.\n[\n65\n]\nMore formally, this is prompt tuning. Let an LLM be written as\nL\nL\nM\n(\nX\n)\n=\nF\n(\nE\n(\nX\n)\n)\n{\\displaystyle LLM(X)=F(E(X))}\n, where\nX\n{\\displaystyle X}\nis a sequence of linguistic tokens,\nE\n{\\displaystyle E}\nis the token-to-vector function, and\nF\n{\\displaystyle F}\nis the rest of the model. In prefix-tuning, one provides a set of input-output pairs\n{\n(\nX\ni\n,\nY\ni\n)\n}\ni\n{\\displaystyle \\{(X^{i},Y^{i})\\}_{i}}\n, and then use gradient descent to search for\narg\n⁡\nmax\nZ\n~\n∑\ni\nlog\n⁡\nP\nr\n[\nY\ni\n|\nZ\n~\n∗\nE\n(\nX\ni\n)\n]\n{\\displaystyle \\arg \\max _{\\tilde {Z}}\\sum _{i}\\log Pr[Y^{i}|{\\tilde {Z}}\\ast E(X^{i})]}\n. In words,\nlog\n⁡\nP\nr\n[\nY\ni\n|\nZ\n~\n∗\nE\n(\nX\ni\n)\n]\n{\\displaystyle \\log Pr[Y^{i}|{\\tilde {Z}}\\ast E(X^{i})]}\nis the log-likelihood of outputting\nY\ni\n{\\displaystyle Y^{i}}\n, if the model first encodes the input\nX\ni\n{\\displaystyle X^{i}}\ninto the vector\nE\n(\nX\ni\n)\n{\\displaystyle E(X^{i})}\n, then prepend the vector with the \"prefix vector\"\nZ\n~\n{\\displaystyle {\\tilde {Z}}}\n, then apply\nF\n{\\displaystyle F}\n. For prefix tuning, it is similar, but the \"prefix vector\"\nZ\n~\n{\\displaystyle {\\tilde {Z}}}\nis pre-appended to the hidden states in every layer of the model.\n[\ncitation needed\n]\nAn earlier result uses the same idea of gradient descent search, but is designed for masked language models like BERT, and searches only over token sequences, rather than numerical vectors. Formally, it searches for\narg\n⁡\nmax\nX\n~\n∑\ni\nlog\n⁡\nP\nr\n[\nY\ni\n|\nX\n~\n∗\nX\ni\n]\n{\\displaystyle \\arg \\max _{\\tilde {X}}\\sum _{i}\\log Pr[Y^{i}|{\\tilde {X}}\\ast X^{i}]}\nwhere\nX\n~\n{\\displaystyle {\\tilde {X}}}\nis ranges over token sequences of a specified length.\n[\n66\n]\nLimitations\n[\nedit\n]\nWhile the process of writing and refining a prompt for an LLM or generative AI shares some parallels with an iterative engineering design process, such as through discovering 'best principles' to reuse and discovery through reproducible experimentation, the actual learned principles and skills depend heavily on the specific model being learned rather than being generalizable across the entire field of prompt-based generative models. Such patterns are also volatile and exhibit significantly different results from seemingly insignificant prompt changes.\n[\n67\n]\n[\n68\n]\nAccording to\nThe Wall Street Journal\nin 2025, the job of prompt engineer was one of the hottest in 2023, but has become obsolete due to models that better intuit user intent and to company trainings.\n[\n69\n]\nPrompt injection\n[\nedit\n]\nMain article:\nPrompt injection\nSee also:\nSQL injection\n,\nCross-site scripting\n, and\nSocial engineering (security)\nPrompt injection is a\ncybersecurity\nexploit in which adversaries craft inputs that appear legitimate but are designed to cause unintended behavior in\nmachine learning models\n, particularly large language models. This attack takes advantage of the model's inability to distinguish between developer-defined prompts and user inputs, allowing adversaries to bypass safeguards and influence model behaviour. While LLMs are designed to follow trusted instructions, they can be manipulated into carrying out unintended responses through carefully crafted inputs.\n[\n70\n]\n[\n71\n]\nReferences\n[\nedit\n]\n^\na\nb\nc\nGenkina, Dina (March 6, 2024).\n\"AI Prompt Engineering is Dead: Long live AI prompt engineering\"\n.\nIEEE Spectrum\n. Retrieved\nJanuary 18,\n2025\n.\n^\nRadford, Alec; Wu, Jeffrey; Child, Rewon; Luan, David;\nAmodei, Dario\n;\nSutskever, Ilya\n(2019).\n\"Language Models are Unsupervised Multitask Learners\"\n(PDF)\n. OpenAI.\nWe demonstrate language models can perform down-stream tasks in a zero-shot setting – without any parameter or architecture modification\n^\na\nb\nWahle, Jan Philip; Ruas, Terry; Xu, Yang; Gipp, Bela (2024).\n\"Paraphrase Types Elicit Prompt Engineering Capabilities\"\n. In Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung (eds.).\nProceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\n. Miami, Florida, USA: Association for Computational Linguistics. pp.\n11004–\n11033.\narXiv\n:\n2406.19898\n.\ndoi\n:\n10.18653/v1/2024.emnlp-main.617\n.\n^\nHeaven, Will Douglas (April 6, 2022).\n\"This horse-riding astronaut is a milestone on AI's long road towards understanding\"\n.\nMIT Technology Review\n. Retrieved\nAugust 14,\n2023\n.\n^\nWiggers, Kyle (June 12, 2023).\n\"Meta open sources an AI-powered music generator\"\n. TechCrunch\n. Retrieved\nAugust 15,\n2023\n.\nNext, I gave a more complicated prompt to attempt to throw MusicGen for a loop: \"Lo-fi slow BPM electro chill with organic samples.\"\n^\na\nb\nMittal, Aayush (July 27, 2023).\n\"Mastering AI Art: A Concise Guide to Midjourney and Prompt Engineering\"\n.\nUnite.AI\n. Retrieved\nMay 9,\n2025\n.\n^\nMcCann, Bryan; Keskar, Nitish; Xiong, Caiming; Socher, Richard (June 20, 2018).\nThe Natural Language Decathlon: Multitask Learning as Question Answering\n. ICLR.\narXiv\n:\n1806.08730\n.\n^\nKnoth, Nils; Tolzin, Antonia; Janson, Andreas; Leimeister, Jan Marco (June 1, 2024).\n\"AI literacy and its implications for prompt engineering strategies\"\n.\nComputers and Education: Artificial Intelligence\n.\n6\n100225.\ndoi\n:\n10.1016/j.caeai.2024.100225\n.\nISSN\n2666-920X\n.\n^\nPromptSource: An Integrated Development Environment and Repository for Natural Language Prompts\n. Association for Computational Linguistics. 2022.\n^\na\nb\nc\nd\ne\nf\nWei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bosma, Maarten; Ichter, Brian; Xia, Fei; Chi, Ed H.; Le, Quoc V.; Zhou, Denny (October 31, 2022).\nChain-of-Thought Prompting Elicits Reasoning in Large Language Models\n. Advances in Neural Information Processing Systems (NeurIPS 2022). Vol. 35.\narXiv\n:\n2201.11903\n.\n^\nBrubaker, Ben (March 21, 2024).\n\"How Chain-of-Thought Reasoning Helps Neural Networks Compute\"\n.\nQuanta Magazine\n. Retrieved\nMay 9,\n2025\n.\n^\nChen, Brian X. (June 23, 2023).\n\"How to Turn Your Chatbot Into a Life Coach\"\n.\nThe New York Times\n.\n^\nChen, Brian X. (May 25, 2023).\n\"Get the Best From ChatGPT With These Golden Prompts\"\n.\nThe New York Times\n.\nISSN\n0362-4331\n. Retrieved\nAugust 16,\n2023\n.\n^\nChen, Zijie; Zhang, Lichao; Weng, Fangsheng; Pan, Lili; Lan, Zhenzhong (June 16, 2024).\n\"Tailored Visions: Enhancing Text-to-Image Generation with Personalized Prompt Rewriting\"\n.\n2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n. IEEE. pp.\n7727–\n7736.\narXiv\n:\n2310.08129\n.\ndoi\n:\n10.1109/cvpr52733.2024.00738\n.\nISBN\n979-8-3503-5300-6\n.\n^\na\nb\nSchulhoff, Sander; et al. (2024). \"The Prompt Report: A Systematic Survey of Prompt Engineering Techniques\".\narXiv\n:\n2406.06608\n[\ncs.CL\n].\n^\nNarang, Sharan; Chowdhery, Aakanksha (April 4, 2022).\n\"Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance\"\n.\nai.googleblog.com\n.\n^\nDang, Ekta (February 8, 2023).\n\"Harnessing the power of GPT-3 in scientific research\"\n.\nVentureBeat\n. Retrieved\nMarch 10,\n2023\n.\n^\nMontti, Roger (May 13, 2022).\n\"Google's Chain of Thought Prompting Can Boost Today's Best Algorithms\"\n.\nSearch Engine Journal\n. Retrieved\nMarch 10,\n2023\n.\n^\n\"Scaling Instruction-Finetuned Language Models\"\n(PDF)\n.\nJournal of Machine Learning Research\n. 2024.\n^\nWei, Jason; Tay, Yi (November 29, 2022).\n\"Better Language Models Without Massive Compute\"\n.\nai.googleblog.com\n. Retrieved\nMarch 10,\n2023\n.\n^\na\nb\nKojima, Takeshi; Shixiang Shane Gu; Reid, Machel; Matsuo, Yutaka; Iwasawa, Yusuke (2022). \"Large Language Models are Zero-Shot Reasoners\".\nNeurIPS\n.\narXiv\n:\n2205.11916\n.\n^\nweipaper\n^\nGarg, Shivam; Tsipras, Dimitris; Liang, Percy; Valiant, Gregory (2022). \"What Can Transformers Learn In-Context? A Case Study of Simple Function Classes\".\nNeurIPS\n.\narXiv\n:\n2208.01066\n.\n^\nBrown, Tom; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared D.; Dhariwal, Prafulla; Neelakantan, Arvind (2020). \"Language models are few-shot learners\".\nAdvances in Neural Information Processing Systems\n.\n33\n:\n1877–\n1901.\narXiv\n:\n2005.14165\n.\n^\na\nb\nWei, Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; Borgeaud, Sebastian; Yogatama, Dani; Bosma, Maarten; Zhou, Denny; Metzler, Donald; Chi, Ed H.; Hashimoto, Tatsunori; Vinyals, Oriol; Liang, Percy; Dean, Jeff; Fedus, William (October 2022). \"Emergent Abilities of Large Language Models\".\nTransactions on Machine Learning Research\n.\narXiv\n:\n2206.07682\n.\nIn prompting, a pre-trained language model is given a prompt (e.g. a natural language instruction) of a task and completes the response without any further training or gradient updates to its parameters... The ability to perform a task via few-shot prompting is emergent when a model has random performance until a certain scale, after which performance increases to well-above random\n^\nCaballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2023). \"Broken Neural Scaling Laws\".\nICLR\n.\narXiv\n:\n2210.14891\n.\n^\nMusser, George\n.\n\"How AI Knows Things No One Told It\"\n.\nScientific American\n. Retrieved\nMay 17,\n2023\n.\nBy the time you type a query into ChatGPT, the network should be fixed; unlike humans, it should not continue to learn. So it came as a surprise that LLMs do, in fact, learn from their users' prompts—an ability known as in-context learning.\n^\nGarg, Shivam; Tsipras, Dimitris; Liang, Percy; Valiant, Gregory (2022). \"What Can Transformers Learn In-Context? A Case Study of Simple Function Classes\".\nNeurIPS\n.\narXiv\n:\n2208.01066\n.\nTraining a model to perform in-context learning can be viewed as an instance of the more general learning-to-learn or meta-learning paradigm\n^\nSelf-Consistency Improves Chain of Thought Reasoning in Language Models\n. ICLR. 2023.\narXiv\n:\n2203.11171\n.\n^\na\nb\nMittal, Aayush (May 27, 2024).\n\"Latest Modern Advances in Prompt Engineering: A Comprehensive Guide\"\n.\nUnite.AI\n. Retrieved\nMay 8,\n2025\n.\n^\nTree of Thoughts: Deliberate Problem Solving with Large Language Models\n. NeurIPS. 2023.\narXiv\n:\n2305.10601\n.\n^\na\nb\nQuantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting\n. ICLR. 2024.\narXiv\n:\n2310.11324\n.\n^\nLeidinger, Alina; van Rooij, Robert; Shutova, Ekaterina (2023). Bouamor, Houda; Pino, Juan; Bali, Kalika (eds.).\n\"The language of prompting: What linguistic properties make a prompt successful?\"\n.\nFindings of the Association for Computational Linguistics: EMNLP 2023\n. Singapore: Association for Computational Linguistics:\n9210–\n9232.\narXiv\n:\n2311.01967\n.\ndoi\n:\n10.18653/v1/2023.findings-emnlp.618\n.\n^\nLinzbach, Stephan; Dimitrov, Dimitar; Kallmeyer, Laura; Evang, Kilian; Jabeen, Hajira; Dietze, Stefan (June 2024).\n\"Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary Information on Knowledge Retrieval from Pretrained Language Models\"\n. In Duh, Kevin; Gomez, Helena; Bethard, Steven (eds.).\nProceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\n. Mexico City, Mexico: Association for Computational Linguistics. pp.\n3645–\n3655.\narXiv\n:\n2404.01992\n.\ndoi\n:\n10.18653/v1/2024.naacl-long.201\n.\n^\nEfficient multi-prompt evaluation of LLMs\n. NeurIPS. 2024.\narXiv\n:\n2405.17202\n.\n^\nLi, Wenwu; Wang, Xiangfeng; Li, Wenhao; Jin, Bo (2025). \"A Survey of Automatic Prompt Engineering: An Optimization Perspective\".\narXiv\n:\n2502.11560\n[\ncs.AI\n].\n^\n\"Why Google's AI Overviews gets things wrong\"\n.\nMIT Technology Review\n. May 31, 2024\n. Retrieved\nMarch 7,\n2025\n.\n^\n\"Can a technology called RAG keep AI models from making stuff up?\"\n.\nArs Technica\n. June 6, 2024\n. Retrieved\nMarch 7,\n2025\n.\n^\nLarson, Jonathan; Truitt, Steven (February 13, 2024),\nGraphRAG: Unlocking LLM discovery on narrative private data\n, Microsoft\n^\n\"An Introduction to Graph RAG\"\n.\nKDnuggets\n. Retrieved\nMay 9,\n2025\n.\n^\nSequeda, Juan; Allemang, Dean; Jacob, Bryon (2023). \"A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases\".\nGrades-Nda\n.\narXiv\n:\n2311.07509\n.\n^\nExplaining Patterns in Data with Language Models via Interpretable Autoprompting\n(PDF)\n. BlackboxNLP Workshop. 2023.\narXiv\n:\n2210.01848\n.\n^\nLarge Language Models are Human-Level Prompt Engineers\n. ICLR. 2023.\narXiv\n:\n2211.01910\n.\n^\nPryzant, Reid; Iter, Dan; Li, Jerry; Lee, Yin Tat; Zhu, Chenguang; Zeng, Michael (2023).\n\"Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search\"\n.\nConference on Empirical Methods in Natural Language Processing\n:\n7957–\n7968.\narXiv\n:\n2305.03495\n.\ndoi\n:\n10.18653/v1/2023.emnlp-main.494\n.\n^\nAutomatic Chain of Thought Prompting in Large Language Models\n. ICLR. 2023.\narXiv\n:\n2210.03493\n.\n^\nOpsahl-Ong, Krista; Ryan, Michael J.; Purtell, Josh; Broman, David; Potts, Christopher; Zaharia, Matei; Khattab, Omar (2024).\nOptimizing Instructions and Demonstrations for Multi-Stage Language Model Programs\n. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP). Miami, Florida: Association for Computational Linguistics.\narXiv\n:\n2406.11695\n.\ndoi\n:\n10.18653/v1/2024.emnlp-main.525\n.\n^\nAgrawal, Lakshya A. (2025). \"GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning\".\narXiv\n:\n2507.19457\n[\ncs.CL\n].\n^\nKhattab, Omar (2023). \"DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines\".\narXiv\n:\n2310.03714\n[\ncs.CL\n].\n^\n\"Agent Optimization\"\n.\ncomet.com\n. Retrieved\nNovember 29,\n2025\n.\n^\nCasey, Matt M. (November 5, 2025).\n\"Context Engineering: The Discipline Behind Reliable LLM Applications & Agents\"\n. Comet\n. Retrieved\nNovember 10,\n2025\n.\n^\n\"Context Engineering\"\n. LangChain. July 2, 2025\n. Retrieved\nNovember 10,\n2025\n.\n^\nMei, Lingrui (July 17, 2025). \"A Survey of Context Engineering for Large Language Models\".\narXiv\n:\n2507.13334\n[\ncs.CL\n].\n^\nGoldman, Sharon (January 5, 2023).\n\"Two years after DALL-E debut, its inventor is \"surprised\" by impact\"\n.\nVentureBeat\n. Retrieved\nMay 9,\n2025\n.\n^\na\nb\n\"Prompts\"\n.\ndocs.midjourney.com\n. Retrieved\nAugust 14,\n2023\n.\n^\n\"Why Does This Horrifying Woman Keep Appearing in AI-Generated Images?\"\n.\nVICE\n. September 7, 2022\n. Retrieved\nMay 9,\n2025\n.\n^\nGoldblum, R.; Pillarisetty, R.; Dauphinee, M. J.; Talal, N. (1975).\n\"Acceleration of autoimmunity in NZB/NZW F1 mice by graft-versus-host disease\"\n.\nClinical and Experimental Immunology\n.\n19\n(2):\n377–\n385.\nISSN\n0009-9104\n.\nPMC\n1538084\n.\nPMID\n2403\n.\n^\n\"Stable Diffusion prompt: a definitive guide\"\n. May 14, 2023\n. Retrieved\nAugust 14,\n2023\n.\n^\nDiab, Mohamad; Herrera, Julian; Chernow, Bob (October 28, 2022).\n\"Stable Diffusion Prompt Book\"\n(PDF)\n. Retrieved\nAugust 7,\n2023\n.\nPrompt engineering is the process of structuring words that can be interpreted and understood by a\ntext-to-image\nmodel. Think of it as the language you need to speak in order to tell an AI model what to draw.\n^\nHeikkilä, Melissa (September 16, 2022).\n\"This Artist Is Dominating AI-Generated Art and He's Not Happy About It\"\n.\nMIT Technology Review\n. Retrieved\nAugust 14,\n2023\n.\n^\nSolomon, Tessa (August 28, 2024).\n\"The AI-Powered Ask Dalí and Hello Vincent Installations Raise Uncomfortable Questions about Ventriloquizing the Dead\"\n.\nARTnews.com\n. Retrieved\nJanuary 10,\n2025\n.\n^\nGal, Rinon; Alaluf, Yuval; Atzmon, Yuval; Patashnik, Or; Bermano, Amit H.; Chechik, Gal; Cohen-Or, Daniel (2023). \"An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion\".\nICLR\n.\narXiv\n:\n2208.01618\n.\nUsing only 3-5 images of a user-provided concept, like an object or a style, we learn to represent it through new \"words\" in the embedding space of a frozen text-to-image model.\n^\nSegment Anything\n(PDF)\n. ICCV. 2023.\n^\nLi, Xiang Lisa; Liang, Percy (2021). \"Prefix-Tuning: Optimizing Continuous Prompts for Generation\".\nProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\n. pp.\n4582–\n4597.\ndoi\n:\n10.18653/V1/2021.ACL-LONG.353\n.\nS2CID\n230433941\n.\nIn this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning... Prefix-tuning draws inspiration from prompting\n^\nLester, Brian; Al-Rfou, Rami; Constant, Noah (2021). \"The Power of Scale for Parameter-Efficient Prompt Tuning\".\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\n. pp.\n3045–\n3059.\narXiv\n:\n2104.08691\n.\ndoi\n:\n10.18653/V1/2021.EMNLP-MAIN.243\n.\nS2CID\n233296808\n.\nIn this work, we explore \"prompt tuning,\" a simple yet effective mechanism for learning \"soft prompts\"...Unlike the discrete text prompts used by GPT-3, soft prompts are learned through back-propagation\n^\nHow Does In-Context Learning Help Prompt Tuning?\n. EACL. 2024.\narXiv\n:\n2302.11521\n.\n^\nShin, Taylor; Razeghi, Yasaman; Logan IV, Robert L.; Wallace, Eric; Singh, Sameer (November 2020).\n\"AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts\"\n.\nProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n. Online: Association for Computational Linguistics. pp.\n4222–\n4235.\ndoi\n:\n10.18653/v1/2020.emnlp-main.346\n.\nS2CID\n226222232\n.\n^\nMeincke, Lennart and Mollick, Ethan R. and Mollick, Lilach and Shapiro, Dan, Prompting Science Report 1: Prompt Engineering is Complicated and Contingent (March 04, 2025). Available at SSRN:\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=5165270\n^\n\"\n'AI is already eating its own': Prompt engineering is quickly going extinct\"\n.\nFast Company\n. May 6, 2025.\n^\nBousquette, Isabelle (April 25, 2025).\n\"The Hottest AI Job of 2023 Is Already Obsolete\"\n.\nWall Street Journal\n.\nISSN\n0099-9660\n. Retrieved\nMay 7,\n2025\n.\n^\nVigliarolo, Brandon (September 19, 2022).\n\"GPT-3 'prompt injection' attack causes bot bad manners\"\n.\nThe Register\n. Retrieved\nFebruary 9,\n2023\n.\n^\n\"What is a prompt injection attack?\"\n.\nIBM\n. March 26, 2024\n. Retrieved\nMarch 7,\n2025\n.\nScholia\nhas a\ntopic\nprofile for\nPrompt engineering\n.\nv\nt\ne\nGenerative AI\nConcepts\nAutoencoder\nDeep learning\nFine-tuning\nFoundation model\nGenerative adversarial network\nGenerative pre-trained transformer\nLarge language model\nModel Context Protocol\nNeural network\nPrompt engineering\nReinforcement learning from human feedback\nRetrieval-augmented generation\nSelf-supervised learning\nStochastic parrot\nSynthetic data\nTop-p sampling\nTransformer\nVariational autoencoder\nVibe coding\nVision transformer\nWord embedding\nChatbots\nCharacter.ai\nChatGPT\nCopilot\nDeepSeek\nErnie\nGemini\nGrok\nModels\nText\nClaude\nGemini\nGemma\nGPT\n1\n2\n3\nJ\n4\n4o\n4.5\n4.1\nOSS\n5\nLlama\no1\no3\no4-mini\nQwen\nVelvet\nCoding\nClaude Code\nCursor\nDevstral\nGitHub Copilot\nKimi\nQwen3-Coder\nReplit\nImage\nAurora\nFirefly\nFlux\nGPT Image 1\nIdeogram\nImagen\nMidjourney\nQwen-Image\nRecraft\nSeedream\nStable Diffusion\nVideo\nDream Machine\nHailuo AI\nKling\nRunway Gen\nSeedance\nLTX-2\nSora\nVeo\nWan\nSpeech\n15.ai\nEleven\nMiniMax Speech 2.5\nWaveNet\nMusic\nEleven Music\nEndel\nLyria\nRiffusion\nSuno\nUdio\nControversies\nDeepfake pornography\nGenerative AI pornography\nTaylor Swift deepfake pornography controversy\nGoogle Gemini image generation controversy\nPause Giant AI Experiments\nRemoval of Sam Altman from OpenAI\nStatement on AI Risk\nTay (chatbot)\nThéâtre D'opéra Spatial\nVoiceverse NFT plagiarism scandal\nAgents\nAgentforce\nAutoGLM\nAutoGPT\nChatGPT Agent\nDevin AI\nManus\nOpenAI Codex\nOperator\nReplit Agent\nCompanies\n01.AI\nAleph Alpha\nAnthropic\nAnysphere\nBaichuan\nCognition AI\nCohere\nContextual AI\nDeepSeek\nEleutherAI\nElevenLabs\nGoogle DeepMind\nHeyGen\nHugging Face\nInflection AI\nKrikey AI\nKuaishou\nLightricks\nLuma Labs\nMeta AI\nMiniMax\nMistral AI\nMoonshot AI\nOpenAI\nPerplexity AI\nRunway\nSafe Superintelligence\nSalesforce\nScale AI\nSoundHound\nStability AI\nSynthesia\nThinking Machines Lab\nUpstage\nxAI\nZ.ai\nCategory\nv\nt\ne\nArtificial intelligence\n(AI)\nHistory\ntimeline\nGlossary\nCompanies\nProjects\nConcepts\nParameter\nHyperparameter\nLoss functions\nRegression\nBias–variance tradeoff\nDouble descent\nOverfitting\nClustering\nGradient descent\nSGD\nQuasi-Newton method\nConjugate gradient method\nBackpropagation\nAttention\nConvolution\nNormalization\nBatchnorm\nActivation\nSoftmax\nSigmoid\nRectifier\nGating\nWeight initialization\nRegularization\nDatasets\nAugmentation\nPrompt engineering\nReinforcement learning\nQ-learning\nSARSA\nImitation\nPolicy gradient\nDiffusion\nLatent diffusion model\nAutoregression\nAdversary\nRAG\nUncanny valley\nRLHF\nSelf-supervised learning\nReflection\nRecursive self-improvement\nHallucination\nWord embedding\nVibe coding\nSafety\n(\nAlignment\n)\nApplications\nMachine learning\nIn-context learning\nArtificial neural network\nDeep learning\nLanguage model\nLarge\nNMT\nReasoning\nModel Context Protocol\nIntelligent agent\nArtificial human companion\nHumanity's Last Exam\nArtificial general intelligence (AGI)\nImplementations\nAudio–visual\nAlexNet\nWaveNet\nHuman image synthesis\nHWR\nOCR\nComputer vision\nSpeech synthesis\n15.ai\nElevenLabs\nSpeech recognition\nWhisper\nFacial recognition\nAlphaFold\nText-to-image models\nAurora\nDALL-E\nFirefly\nFlux\nIdeogram\nImagen\nMidjourney\nRecraft\nStable Diffusion\nText-to-video models\nDream Machine\nRunway Gen\nHailuo AI\nKling\nSora\nVeo\nMusic generation\nRiffusion\nSuno AI\nUdio\nText\nWord2vec\nSeq2seq\nGloVe\nBERT\nT5\nLlama\nChinchilla AI\nPaLM\nGPT\n1\n2\n3\nJ\nChatGPT\n4\n4o\no1\no3\n4.5\n4.1\no4-mini\n5\n5.1\nClaude\nGemini\nGemini (language model)\nGemma\nGrok\nLaMDA\nBLOOM\nDBRX\nProject Debater\nIBM Watson\nIBM Watsonx\nGranite\nPanGu-Σ\nDeepSeek\nQwen\nDecisional\nAlphaGo\nAlphaZero\nOpenAI Five\nSelf-driving car\nMuZero\nAction selection\nAutoGPT\nRobot control\nPeople\nAlan Turing\nWarren Sturgis McCulloch\nWalter Pitts\nJohn von Neumann\nChristopher D. Manning\nClaude Shannon\nShun'ichi Amari\nKunihiko Fukushima\nTakeo Kanade\nMarvin Minsky\nJohn McCarthy\nNathaniel Rochester\nAllen Newell\nCliff Shaw\nHerbert A. Simon\nOliver Selfridge\nFrank Rosenblatt\nBernard Widrow\nJoseph Weizenbaum\nSeymour Papert\nSeppo Linnainmaa\nPaul Werbos\nGeoffrey Hinton\nJohn Hopfield\nJürgen Schmidhuber\nYann LeCun\nYoshua Bengio\nLotfi A. Zadeh\nStephen Grossberg\nAlex Graves\nJames Goodnight\nAndrew Ng\nFei-Fei Li\nAlex Krizhevsky\nIlya Sutskever\nOriol Vinyals\nQuoc V. Le\nIan Goodfellow\nDemis Hassabis\nDavid Silver\nAndrej Karpathy\nAshish Vaswani\nNoam Shazeer\nAidan Gomez\nJohn Schulman\nMustafa Suleyman\nJan Leike\nDaniel Kokotajlo\nFrançois Chollet\nArchitectures\nNeural Turing machine\nDifferentiable neural computer\nTransformer\nVision transformer (ViT)\nRecurrent neural network (RNN)\nLong short-term memory (LSTM)\nGated recurrent unit (GRU)\nEcho state network\nMultilayer perceptron (MLP)\nConvolutional neural network (CNN)\nResidual neural network (RNN)\nHighway network\nMamba\nAutoencoder\nVariational autoencoder (VAE)\nGenerative adversarial network (GAN)\nGraph neural network (GNN)\nCategory\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Prompt_engineering&oldid=1327253893\n\"\nCategories\n:\nDeep learning\nMachine learning\nNatural language processing\nUnsupervised learning\n2022 neologisms\nLinguistics\nGenerative artificial intelligence\nHidden categories:\nArticles with short description\nShort description is different from Wikidata\nUse mdy dates from January 2025\nPages using multiple image with auto scaled images\nAll articles with unsourced statements\nArticles with unsourced statements from May 2025\nThis page was last edited on 13 December 2025, at 13:47\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nPrompt engineering\n37 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:26.485798",
      "status": "success",
      "content_length": 43724,
      "topic": "llm"
    },
    {
      "title": "Transfer learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Transfer_learning",
      "content": "Transfer learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\n2\nDefinition\n3\nApplications\n4\nSee also\n5\nReferences\n6\nSources\nToggle the table of contents\nTransfer learning\n17 languages\nالعربية\nCatalà\nDeutsch\nEspañol\nفارسی\nFrançais\n한국어\nItaliano\n日本語\nPolski\nPortuguês\nRomână\nRuna Simi\nСрпски / srpski\nไทย\nУкраїнська\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nMachine learning technique\nNot to be confused with\nTransfer of learning\nor\nknowledge transfer\n.\nIllustration of transfer learning\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nTransfer learning\n(\nTL\n) is a technique in\nmachine learning\n(ML) in which knowledge learned from a task is re-used in order to boost performance on a related task.\n[\n1\n]\nFor example, for\nimage classification\n, knowledge gained while learning to\nrecognize\ncars could be applied when trying to recognize trucks. This topic is related to the psychological literature on\ntransfer of learning\n, although practical ties between the two fields are limited. Reusing or transferring information from previously learned tasks to new tasks has the potential to significantly improve learning efficiency.\n[\n2\n]\nSince transfer learning makes use of training with multiple objective functions it is related to\ncost-sensitive machine learning\nand\nmulti-objective optimization\n.\n[\n3\n]\nHistory\n[\nedit\n]\nIn 1976, Bozinovski and Fulgosi published a paper addressing transfer learning in\nneural network\ntraining.\n[\n4\n]\n[\n5\n]\nThe paper gives a mathematical and geometrical model of the topic. In 1981, a report considered the application of transfer learning to a dataset of images representing letters of computer terminals, experimentally demonstrating positive and negative transfer learning.\n[\n6\n]\nIn 1992,\nLorien Pratt\nformulated the discriminability-based transfer (DBT) algorithm.\n[\n7\n]\nBy 1998, the field had advanced to include\nmulti-task learning\n,\n[\n8\n]\nalong with more formal theoretical foundations.\n[\n9\n]\nInfluential publications on transfer learning include the book\nLearning to Learn\nin 1998,\n[\n10\n]\na 2009 survey\n[\n11\n]\nand a 2019 survey.\n[\n12\n]\nNg\nsaid in his NIPS 2016 tutorial\n[\n13\n]\n[\n14\n]\nthat TL would become the next driver of\nmachine learning\ncommercial success after\nsupervised learning\n.\nIn the 2020 paper, \"Rethinking Pre-Training and self-training\",\n[\n15\n]\nZoph et al. reported that pre-training can hurt accuracy, and advocate self-training instead.\nDefinition\n[\nedit\n]\nThe definition of transfer learning is given in terms of domains and tasks. A domain\nD\n{\\displaystyle {\\mathcal {D}}}\nconsists of: a\nfeature space\nX\n{\\displaystyle {\\mathcal {X}}}\nand a\nmarginal probability distribution\nP\n(\nX\n)\n{\\displaystyle P(X)}\n, where\nX\n=\n{\nx\n1\n,\n.\n.\n.\n,\nx\nn\n}\n∈\nX\n{\\displaystyle X=\\{x_{1},...,x_{n}\\}\\in {\\mathcal {X}}}\n. Given a specific domain,\nD\n=\n{\nX\n,\nP\n(\nX\n)\n}\n{\\displaystyle {\\mathcal {D}}=\\{{\\mathcal {X}},P(X)\\}}\n, a task consists of two components: a label space\nY\n{\\displaystyle {\\mathcal {Y}}}\nand an objective predictive function\nf\n:\nX\n→\nY\n{\\displaystyle f:{\\mathcal {X}}\\rightarrow {\\mathcal {Y}}}\n. The function\nf\n{\\displaystyle f}\nis used to predict the corresponding label\nf\n(\nx\n)\n{\\displaystyle f(x)}\nof a new instance\nx\n{\\displaystyle x}\n. This task, denoted by\nT\n=\n{\nY\n,\nf\n(\nx\n)\n}\n{\\displaystyle {\\mathcal {T}}=\\{{\\mathcal {Y}},f(x)\\}}\n, is learned from the training data consisting of pairs\n{\nx\ni\n,\ny\ni\n}\n{\\displaystyle \\{x_{i},y_{i}\\}}\n, where\nx\ni\n∈\nX\n{\\displaystyle x_{i}\\in {\\mathcal {X}}}\nand\ny\ni\n∈\nY\n{\\displaystyle y_{i}\\in {\\mathcal {Y}}}\n.\n[\n16\n]\nGiven a source domain\nD\nS\n{\\displaystyle {\\mathcal {D}}_{S}}\nand learning task\nT\nS\n{\\displaystyle {\\mathcal {T}}_{S}}\n, a target domain\nD\nT\n{\\displaystyle {\\mathcal {D}}_{T}}\nand learning task\nT\nT\n{\\displaystyle {\\mathcal {T}}_{T}}\n, where\nD\nS\n≠\nD\nT\n{\\displaystyle {\\mathcal {D}}_{S}\\neq {\\mathcal {D}}_{T}}\n, or\nT\nS\n≠\nT\nT\n{\\displaystyle {\\mathcal {T}}_{S}\\neq {\\mathcal {T}}_{T}}\n, transfer learning aims to help improve the learning of the target predictive function\nf\nT\n(\n⋅\n)\n{\\displaystyle f_{T}(\\cdot )}\nin\nD\nT\n{\\displaystyle {\\mathcal {D}}_{T}}\nusing the knowledge in\nD\nS\n{\\displaystyle {\\mathcal {D}}_{S}}\nand\nT\nS\n{\\displaystyle {\\mathcal {T}}_{S}}\n.\n[\n16\n]\nApplications\n[\nedit\n]\nAlgorithms for transfer learning are available in\nMarkov logic networks\n[\n17\n]\nand\nBayesian networks\n.\n[\n18\n]\nTransfer learning has been applied to cancer subtype discovery,\n[\n19\n]\nbuilding utilization,\n[\n20\n]\n[\n21\n]\ngeneral game playing\n,\n[\n22\n]\ntext classification\n,\n[\n23\n]\n[\n24\n]\ndigit recognition,\n[\n25\n]\nmedical imaging and\nspam filtering\n.\n[\n26\n]\nIn 2020, it was discovered that, due to their similar physical natures, transfer learning is possible between\nelectromyographic\n(EMG) signals from the muscles and classifying the behaviors of\nelectroencephalographic\n(EEG) brainwaves, from the\ngesture recognition\ndomain to the mental state recognition domain. It was noted that this relationship worked in both directions, showing that\nelectroencephalographic\ncan likewise be used to classify EMG.\n[\n27\n]\nThe experiments noted that the accuracy of\nneural networks\nand\nconvolutional neural networks\nwere improved\n[\n28\n]\nthrough transfer learning both prior to any learning (compared to standard random weight distribution) and at the end of the learning process (asymptote). That is, results are improved by exposure to another domain. Moreover, the end-user of a pre-trained model can change the structure of fully-connected layers to improve performance.\n[\n29\n]\nSee also\n[\nedit\n]\nCrossover (genetic algorithm)\nDomain adaptation\nGeneral game playing\nMulti-task learning\nMultitask optimization\nTransfer of learning\nin\neducational psychology\nZero-shot learning\nFeature learning\nexternal validity\nReferences\n[\nedit\n]\n^\nWest, Jeremy; Ventura, Dan; Warnick, Sean (2007).\n\"Spring Research Presentation: A Theoretical Foundation for Inductive Transfer\"\n. Brigham Young University, College of Physical and Mathematical Sciences. Archived from\nthe original\non 2007-08-01\n. Retrieved\n2007-08-05\n.\n^\nGeorge Karimpanal, Thommen; Bouffanais, Roland (2019). \"Self-organizing maps for storage and transfer of knowledge in reinforcement learning\".\nAdaptive Behavior\n.\n27\n(2):\n111–\n126.\narXiv\n:\n1811.08318\n.\ndoi\n:\n10.1177/1059712318818568\n.\nISSN\n1059-7123\n.\nS2CID\n53774629\n.\n^\nCost-Sensitive Machine Learning. (2011). USA: CRC Press, Page 63,\nhttps://books.google.com/books?id=8TrNBQAAQBAJ&pg=PA63\n^\nStevo. Bozinovski and Ante Fulgosi (1976). \"The influence of pattern similarity and transfer learning on the base perceptron training.\" (original in Croatian) Proceedings of Symposium Informatica 3-121-5, Bled.\n^\nStevo Bozinovski (2020)\n\"Reminder of the first paper on transfer learning in neural networks, 1976\"\n. Informatica 44: 291–302.\n^\nS. Bozinovski (1981). \"Teaching space: A representation concept for adaptive pattern classification.\" COINS Technical Report, the University of Massachusetts at Amherst, No 81-28 [available\nonline\n]\n^\nPratt, L. Y. (1992).\n\"Discriminability-based transfer between neural networks\"\n(PDF)\n.\nNIPS Conference: Advances in Neural Information Processing Systems 5\n. Morgan Kaufmann Publishers. pp.\n204–\n211.\n^\nCaruana, R., \"Multitask Learning\", pp. 95-134 in\nThrun & Pratt 2012\n^\nBaxter, J., \"Theoretical Models of Learning to Learn\", pp. 71-95\nThrun & Pratt 2012\n^\nThrun & Pratt 2012\n.\n^\nPan, Sinno Jialin; Yang, Qiang (2010).\n\"A Survey on Transfer Learning\"\n(PDF)\n.\nIEEE Transactions on Knowledge and Data Engineering\n.\n22\n(10):\n1345–\n1359.\nBibcode\n:\n2010ITKDE..22.1345P\n.\ndoi\n:\n10.1109/TKDE.2009.191\n.\n^\nZhuang, Fuzhen; Qi, Zhiyuan; Duan, Keyu; Xi, Dongbo; Zhu, Yongchun; Zhu, Hengshu; Xiong, Hui; He, Qing (2019). \"A Comprehensive Survey on Transfer Learning\".\narXiv\n:\n1911.02685\n[\ncs.LG\n].\n^\nNIPS 2016 tutorial: \"Nuts and bolts of building AI applications using Deep Learning\" by Andrew Ng\n, 6 May 2018,\narchived\nfrom the original on 2021-12-19\n, retrieved\n2019-12-28\n^\n\"Nuts and bolts of building AI applications using Deep Learning, slides\"\n(PDF)\n.\n^\nZoph, Barret (2020).\n\"Rethinking pre-training and self-training\"\n(PDF)\n.\nAdvances in Neural Information Processing Systems\n.\n33\n:\n3833–\n3845.\narXiv\n:\n2006.06882\n. Retrieved\n2022-12-20\n.\n^\na\nb\nLin, Yuan-Pin; Jung, Tzyy-Ping (27 June 2017).\n\"Improving EEG-Based Emotion Classification Using Conditional Transfer Learning\"\n.\nFrontiers in Human Neuroscience\n.\n11\n334.\ndoi\n:\n10.3389/fnhum.2017.00334\n.\nPMC\n5486154\n.\nPMID\n28701938\n.\nMaterial was copied from this source, which is available under a\nCreative Commons Attribution 4.0 International License\n.\n^\nMihalkova, Lilyana; Huynh, Tuyen; Mooney, Raymond J. (July 2007),\n\"Mapping and Revising Markov Logic Networks for Transfer\"\n(PDF)\n,\nLearning Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI-2007)\n, Vancouver, BC, pp.\n608–\n614\n, retrieved\n2007-08-05\n{{\ncitation\n}}\n:  CS1 maint: location missing publisher (\nlink\n)\n^\nNiculescu-Mizil, Alexandru; Caruana, Rich (March 21–24, 2007),\n\"Inductive Transfer for Bayesian Network Structure Learning\"\n(PDF)\n,\nProceedings of the Eleventh International Conference on Artificial Intelligence and Statistics (AISTATS 2007)\n, retrieved\n2007-08-05\n^\nHajiramezanali, E. & Dadaneh, S. Z. & Karbalayghareh, A. & Zhou, Z. & Qian, X. Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada.\narXiv\n:\n1810.09433\n^\nArief-Ang, I.B.; Salim, F.D.; Hamilton, M. (2017-11-08).\nDA-HOC: semi-supervised domain adaptation for room occupancy prediction using CO2 sensor data\n. 4th ACM International Conference on Systems for Energy-Efficient Built Environments (BuildSys). Delft, Netherlands. pp.\n1–\n10.\ndoi\n:\n10.1145/3137133.3137146\n.\nISBN\n978-1-4503-5544-5\n.\n^\nArief-Ang, I.B.; Hamilton, M.; Salim, F.D. (2018-12-01). \"A Scalable Room Occupancy Prediction with Transferable Time Series Decomposition of CO2 Sensor Data\".\nACM Transactions on Sensor Networks\n.\n14\n(\n3–\n4): 21:1–21:28.\ndoi\n:\n10.1145/3217214\n.\nS2CID\n54066723\n.\n^\nBanerjee, Bikramjit, and Peter Stone. \"\nGeneral Game Learning Using Knowledge Transfer\n.\" IJCAI. 2007.\n^\nDo, Chuong B.; Ng, Andrew Y. (2005). \"Transfer learning for text classification\".\nNeural Information Processing Systems Foundation, NIPS*2005\n(PDF)\n. Retrieved\n2007-08-05\n.\n^\nRajat, Raina; Ng, Andrew Y.; Koller, Daphne (2006). \"Constructing Informative Priors using Transfer Learning\".\nTwenty-third International Conference on Machine Learning\n(PDF)\n. Retrieved\n2007-08-05\n.\n^\nMaitra, D. S.; Bhattacharya, U.; Parui, S. K. (August 2015). \"CNN based common approach to handwritten character recognition of multiple scripts\".\n2015 13th International Conference on Document Analysis and Recognition (ICDAR)\n. pp.\n1021–\n1025.\ndoi\n:\n10.1109/ICDAR.2015.7333916\n.\nISBN\n978-1-4799-1805-8\n.\nS2CID\n25739012\n.\n^\nBickel, Steffen (2006). \"ECML-PKDD Discovery Challenge 2006 Overview\".\nECML-PKDD Discovery Challenge Workshop\n(PDF)\n. Retrieved\n2007-08-05\n.\n^\nBird, Jordan J.; Kobylarz, Jhonatan; Faria, Diego R.; Ekart, Aniko; Ribeiro, Eduardo P. (2020).\n\"Cross-Domain MLP and CNN Transfer Learning for Biological Signal Processing: EEG and EMG\"\n.\nIEEE Access\n.\n8\n. Institute of Electrical and Electronics Engineers (IEEE):\n54789–\n54801.\nBibcode\n:\n2020IEEEA...854789B\n.\ndoi\n:\n10.1109/access.2020.2979074\n.\nISSN\n2169-3536\n.\n^\nMaitra, Durjoy Sen; Bhattacharya, Ujjwal; Parui, Swapan K. (August 2015). \"CNN based common approach to handwritten character recognition of multiple scripts\".\n2015 13th International Conference on Document Analysis and Recognition (ICDAR)\n. pp.\n1021–\n1025.\ndoi\n:\n10.1109/ICDAR.2015.7333916\n.\nISBN\n978-1-4799-1805-8\n.\nS2CID\n25739012\n.\n^\nKabir, H. M. Dipu; Abdar, Moloud; Jalali, Seyed Mohammad Jafar; Khosravi, Abbas; Atiya, Amir F.; Nahavandi, Saeid;\nSrinivasan, Dipti\n(January 7, 2022). \"SpinalNet: Deep Neural Network with Gradual Input\".\nIEEE Transactions on Artificial Intelligence\n.\n4\n(5):\n1165–\n1177.\narXiv\n:\n2007.03347\n.\ndoi\n:\n10.1109/TAI.2022.3185179\n.\nS2CID\n220381239\n.\nSources\n[\nedit\n]\nThrun, Sebastian; Pratt, Lorien (6 December 2012).\nLearning to Learn\n. Springer Science & Business Media.\nISBN\n978-1-4615-5529-2\n.\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Transfer_learning&oldid=1320350486\n\"\nCategory\n:\nMachine learning\nHidden categories:\nCS1 maint: location missing publisher\nArticles with short description\nShort description is different from Wikidata\nThis page was last edited on 4 November 2025, at 04:25\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nTransfer learning\n17 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:28.589769",
      "status": "success",
      "content_length": 16081,
      "topic": "llm"
    },
    {
      "title": "Information retrieval - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Information_retrieval",
      "content": "Information retrieval - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nOverview\n2\nHistory\n3\nApplications\nToggle Applications subsection\n3.1\nGeneral applications\n3.2\nDomain-specific applications\n3.3\nOther retrieval methods\n4\nModel types\nToggle Model types subsection\n4.1\nFirst dimension: mathematical basis\n4.2\nSecond dimension: properties of the model\n4.3\nThird Dimension: representational approach-based classification\n5\nPerformance and correctness measures\n6\nLibraries for searching and indexing\n7\nTimeline\n8\nMajor conferences\n9\nAwards in the field\n10\nSee also\n11\nReferences\n12\nFurther reading\n13\nExternal links\nToggle the table of contents\nInformation retrieval\n40 languages\nالعربية\nAzərbaycanca\nБългарски\nCatalà\nČeština\nDansk\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaeilge\nGalego\n한국어\nहिन्दी\nBahasa Indonesia\nItaliano\nBahasa Melayu\nМонгол\nNederlands\n日本語\nNorsk bokmål\nNorsk nynorsk\nPolski\nPortuguês\nРусский\nSimple English\nСрпски / srpski\nSuomi\nSvenska\nதமிழ்\nТоҷикӣ\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikiquote\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nFinding information for an information need\nThis article\nneeds additional citations for\nverification\n.\nPlease help\nimprove this article\nby\nadding citations to reliable sources\n. Unsourced material may be challenged and removed.\nFind sources:\n\"Information retrieval\"\n–\nnews\n·\nnewspapers\n·\nbooks\n·\nscholar\n·\nJSTOR\n(\nFebruary 2025\n)\n(\nLearn how and when to remove this message\n)\nInformation science\nGeneral aspects\nAccess\nArchitecture\nBehavior\nManagement\nRetrieval\nSeeking\nSociety\nKnowledge organization\nOntology\nPhilosophy\nScience and technology studies\nTaxonomy\nRelated fields and subfields\nBibliometrics\nCategorization\nCensorship\nClassification\nComputer data storage\nCultural studies\nData modeling\nInformatics\nInformation technology\nIntellectual freedom\nIntellectual property\nLibrary and information science\nMemory\nPreservation\nPrivacy\nQuantum information science\nv\nt\ne\nInformation retrieval\n(\nIR\n) in\ncomputing\nand\ninformation science\nis the task of identifying and retrieving\ninformation system\nresources that are relevant to an\ninformation need\n. The information need can be specified in the form of a search query. In the case of document retrieval, queries can be based on\nfull-text\nor other content-based indexing. Information retrieval is the\nscience\n[\n1\n]\nof searching for information in a document, searching for documents themselves, and also searching for the\nmetadata\nthat describes data, and for\ndatabases\nof texts, images or sounds.\nCross-modal retrieval\nimplies retrieval across modalities.\nAutomated information retrieval systems are used to reduce what has been called\ninformation overload\n. An IR system is a software system that provides access to books, journals and other documents; it also stores and manages those documents.\nWeb search engines\nare the most visible IR applications.\nOverview\n[\nedit\n]\nAn information retrieval process begins when a user enters a query into the system. Queries are formal statements of information needs, for example search strings in web search engines. In information retrieval, a query does not uniquely identify a single object in the collection. Instead, several objects may match the query, perhaps with different degrees of\nrelevance\n.\nAn object is an entity that is represented by information in a content collection or\ndatabase\n. User queries are matched against the database information. However, as opposed to classical SQL queries of a database, in information retrieval the results returned may or may not match the query, so results are typically ranked. This\nranking\nof results is a key difference of information retrieval searching compared to database searching.\n[\n2\n]\nDepending on the\napplication\nthe data objects may be, for example, text documents, images,\n[\n3\n]\naudio,\n[\n4\n]\nmind maps\n[\n5\n]\nor videos. Often the documents themselves are not kept or stored directly in the IR system, but are instead represented in the system by document surrogates or\nmetadata\n.\nMost IR systems compute a numeric score on how well each object in the database matches the query, and rank the objects according to this value. The top ranking objects are then shown to the user. The process may then be iterated if the user wishes to refine the query.\n[\n6\n]\nHistory\n[\nedit\n]\nthere is ... a machine called the Univac ... whereby letters and figures are coded as a pattern of magnetic spots on a long steel tape. By this means the text of a document, preceded by its subject code symbol, can be recorded ... the machine ... automatically selects and types out those references which have been coded in any desired way at a rate of 120 words a minute\n— J. E. Holmstrom, 1948\nThe idea of using computers to search for relevant pieces of information was popularized in the article\nAs We May Think\nby\nVannevar Bush\nin 1945.\n[\n7\n]\nIt would appear that Bush was inspired by patents for a 'statistical machine' – filed by\nEmanuel Goldberg\nin the 1920s and 1930s – that searched for documents stored on film.\n[\n8\n]\nThe first description of a computer searching for information was described by Holmstrom in 1948,\n[\n9\n]\ndetailing an early mention of the\nUnivac\ncomputer. Automated information retrieval systems were introduced in the 1950s: one even featured in the 1957 romantic comedy\nDesk Set\n. In the 1960s, the first large information retrieval research group was formed by\nGerard Salton\nat Cornell. By the 1970s several different retrieval techniques had been shown to perform well on small\ntext corpora\nsuch as the Cranfield collection (several thousand documents).\n[\n7\n]\nLarge-scale retrieval systems, such as the Lockheed Dialog system, came into use early in the 1970s.\nIn 1992, the US Department of Defense along with the\nNational Institute of Standards and Technology\n(NIST), cosponsored the\nText Retrieval Conference\n(TREC) as part of the TIPSTER text program. The aim of this was to look into the information retrieval community by supplying the infrastructure that was needed for evaluation of text retrieval methodologies on a very large text collection. This catalyzed research on methods that\nscale\nto huge corpora. The introduction of\nweb search engines\nhas boosted the need for very large scale retrieval systems even further.\nBy the late 1990s, the rise of the World Wide Web fundamentally transformed information retrieval. While early search engines such as\nAltaVista\n(1995) and\nYahoo!\n(1994) offered keyword-based retrieval, they were limited in scale and ranking refinement. The breakthrough came in 1998 with the founding of\nGoogle\n, which introduced the\nPageRank\nalgorithm,\n[\n10\n]\nusing the web's hyperlink structure to assess page importance and improve relevance ranking.\nDuring the 2000s, web search systems evolved rapidly with the integration of machine learning techniques. These systems began to incorporate user behavior data (e.g., click-through logs), query reformulation, and content-based signals to improve search accuracy and personalization. In 2009,\nMicrosoft\nlaunched\nBing\n, introducing features that would later incorporate\nsemantic\nweb technologies through the development of its Satori knowledge base. Academic analysis\n[\n11\n]\nhave highlighted Bing's semantic capabilities, including structured data use and entity recognition, as part of a broader industry shift toward improving search relevance and understanding user intent through natural language processing.\nA major leap occurred in 2018, when Google deployed\nBERT\n(\nB\nidirectional\nE\nncoder\nR\nepresentations from\nT\nransformers) to better understand the contextual meaning of queries and documents. This marked one of the first times deep neural language models were used at scale in real-world retrieval systems.\n[\n12\n]\nBERT's bidirectional training enabled a more refined comprehension of word relationships in context, improving the handling of natural language queries. Because of its success, transformer-based models gained traction in academic research and commercial search applications.\n[\n13\n]\nSimultaneously, the research community began exploring neural ranking models that outperformed traditional lexical-based methods. Long-standing benchmarks such as the\nT\next\nRE\ntrieval\nC\nonference (\nTREC\n), initiated in 1992, and more recent evaluation frameworks Microsoft MARCO(\nMA\nchine\nR\neading\nCO\nmprehension) (2019)\n[\n14\n]\nbecame central to training and evaluating retrieval systems across multiple tasks and domains. MS MARCO has also been adopted in the TREC Deep Learning Tracks, where it serves as a core dataset for evaluating advances in neural ranking models within a standardized benchmarking environment.\n[\n15\n]\nAs deep learning became integral to information retrieval systems, researchers began to categorize neural approaches into three broad classes:\nsparse\n,\ndense\n, and\nhybrid\nmodels. Sparse models, including traditional term-based methods and learned variants like SPLADE, rely on interpretable representations and inverted indexes to enable efficient exact term matching with added semantic signals.\n[\n16\n]\nDense models, such as dual-encoder architectures like ColBERT, use continuous\nvector embeddings\nto support semantic similarity beyond keyword overlap.\n[\n17\n]\nHybrid models aim to combine the advantages of both, balancing the lexical (token)\nprecision\nof sparse methods with the semantic depth of dense models. This way of categorizing models balances scalability, relevance, and efficiency in retrieval systems.\n[\n18\n]\nAs IR systems increasingly rely on deep learning, concerns around bias, fairness, and explainability have also come to the picture. Research is now focused not just on relevance and efficiency, but on transparency, accountability, and user trust in retrieval algorithms.\nApplications\n[\nedit\n]\nAreas where information retrieval techniques are employed include (the entries are in alphabetical order within each category):\nGeneral applications\n[\nedit\n]\nDigital libraries\nInformation filtering\nRecommender systems\nMedia search\nBlog search\nImage retrieval\n3D retrieval\nMusic retrieval\nNews search\nSpeech retrieval\nVideo retrieval\nSearch engines\nSite search\nDesktop search\nEnterprise search\nFederated search\nMobile search\nSocial search\nWeb search\nDomain-specific applications\n[\nedit\n]\nExpert search finding\nGenomic information retrieval\nGeographic information retrieval\nInformation retrieval for chemical structures\nInformation retrieval in\nsoftware engineering\nLegal information retrieval\nVertical search\nOther retrieval methods\n[\nedit\n]\nMethods/Techniques in which information retrieval techniques are employed include:\nCross-modal retrieval\nAdversarial information retrieval\nAutomatic summarization\nMulti-document summarization\nCompound term processing\nCross-lingual retrieval\nDocument classification\nSpam filtering\nQuestion answering\nModel types\n[\nedit\n]\nCategorization of IR-models (translated from\nGerman entry\n, original source\nDominik Kuropka\n)\nIn order to effectively retrieve relevant documents by IR strategies, the documents are typically transformed into a suitable representation. Each retrieval strategy incorporates a specific model for its document representation purposes. The picture on the right illustrates the relationship of some common models. In the picture, the models are categorized according to two dimensions: the mathematical basis and the properties of the model.\nFirst dimension: mathematical basis\n[\nedit\n]\nSet-theoretic\nmodels represent documents as\nsets\nof words or phrases. Similarities are usually derived from set-theoretic operations on those sets. Common models are:\nStandard Boolean model\nExtended Boolean model\nFuzzy retrieval\nAlgebraic models\nrepresent documents and queries usually as vectors, matrices, or tuples. The similarity of the query vector and document vector is represented as a scalar value.\nVector space model\nGeneralized vector space model\n(Enhanced) Topic-based Vector Space Model\nExtended Boolean model\nLatent semantic indexing\na.k.a.\nlatent semantic analysis\nProbabilistic models\ntreat the process of document retrieval as a probabilistic inference. Similarities are computed as probabilities that a document is relevant for a given query. Probabilistic theorems like\nBayes' theorem\nare often used in these models.\nBinary Independence Model\nProbabilistic relevance model\non which is based the\nokapi (BM25)\nrelevance function\nUncertain inference\nLanguage models\nDivergence-from-randomness model\nLatent Dirichlet allocation\nFeature-based retrieval models\nview documents as vectors of values of\nfeature functions\n(or just\nfeatures\n) and seek the best way to combine these features into a single relevance score, typically by\nlearning to rank\nmethods. Feature functions are arbitrary functions of document and query, and as such can easily incorporate almost any other retrieval model as just another feature.\nSecond dimension: properties of the model\n[\nedit\n]\nModels without term-interdependencies\ntreat different terms/words as independent. This fact is usually represented in vector space models by the\northogonality\nassumption of term vectors or in probabilistic models by an\nindependency\nassumption for term variables.\nModels with immanent term interdependencies\nallow a representation of interdependencies between terms. However the degree of the interdependency between two terms is defined by the model itself. It is usually directly or indirectly derived (e.g. by\ndimensional reduction\n) from the\nco-occurrence\nof those terms in the whole set of documents.\nModels with transcendent term interdependencies\nallow a representation of interdependencies between terms, but they do not allege how the interdependency between two terms is defined. They rely on an external source for the degree of interdependency between two terms. (For example, a human or sophisticated algorithms.)\nThird Dimension: representational approach-based classification\n[\nedit\n]\nIn addition to the theoretical distinctions, modern information retrieval models are also categorized on how queries and documents are represented and compared, using a practical classification distinguishing between sparse, dense and hybrid models.\n[\n16\n]\nSparse\nmodels utilize interpretable, term-based representations and typically rely on inverted index structures. Classical methods such as TF-IDF and BM25 fall under this category, along with more recent learned sparse models that integrate neural architectures while retaining sparsity.\n[\n19\n]\nDense\nmodels represent queries and documents as continuous vectors using deep learning models, typically transformer-based encoders. These models enable semantic similarity matching beyond exact term overlap and are used in tasks involving semantic search and question answering.\n[\n20\n]\nHybrid\nmodels aim to combine the strengths of both approaches, integrating lexical (tokens) and semantic signals through score fusion, late interaction, or multi-stage ranking pipelines.\n[\n21\n]\nThis classification has become increasingly common in both academic and the real world applications and is getting widely adopted and used in evaluation benchmarks for Information Retrieval models.\n[\n18\n]\n[\n19\n]\nPerformance and correctness measures\n[\nedit\n]\nMain article:\nEvaluation measures (information retrieval)\nThe evaluation of an information retrieval system' is the process of assessing how well a system meets the information needs of its users. In general, measurement considers a collection of documents to be searched and a search query. Traditional evaluation metrics, designed for\nBoolean retrieval\n[\nclarification needed\n]\nor top-k retrieval, include\nprecision and recall\n. All measures assume a\nground truth\nnotion of relevance: every document is known to be either relevant or non-relevant to a particular query. In practice, queries may be\nill-posed\nand there may be different shades of relevance.\nLibraries for searching and indexing\n[\nedit\n]\nLemur\nLucene\nSolr\nElasticsearch\nManatee\nManticore search\nSphinx\nTerrier Search Engine\nXapian\nTimeline\n[\nedit\n]\nBefore the\n1900s\n1801\n:\nJoseph Marie Jacquard\ninvents the\nJacquard loom\n, the first machine to use punched cards to control a sequence of operations.\n1880s\n:\nHerman Hollerith\ninvents an electro-mechanical data tabulator using punch cards as a machine readable medium.\n1890\nHollerith\ncards\n,\nkeypunches\nand\ntabulators\nused to process the\n1890 US census\ndata.\n1920s–1930s\nEmanuel Goldberg\nsubmits patents for his \"Statistical Machine\", a document search engine that used photoelectric cells and pattern recognition to search the metadata on rolls of microfilmed documents.\n1940s–1950s\nlate 1940s\n: The US military confronted problems of indexing and retrieval of wartime scientific research documents captured from Germans.\n1945\n:\nVannevar Bush\n's\nAs We May Think\nappeared in\nAtlantic Monthly\n.\n1947\n:\nHans Peter Luhn\n(research engineer at IBM since 1941) began work on a mechanized punch card-based system for searching chemical compounds.\n1950s\n: Growing concern in the US for a \"science gap\" with the USSR motivated, encouraged funding and provided a backdrop for mechanized literature searching systems (\nAllen Kent\net al.\n) and the invention of the\ncitation index\nby\nEugene Garfield\n.\n1950\n: The term \"information retrieval\" was coined by\nCalvin Mooers\n.\n[\n22\n]\n1951\n: Philip Bagley conducted the earliest experiment in computerized document retrieval in a master thesis at\nMIT\n.\n[\n23\n]\n1955\n: Allen Kent joined\nCase Western Reserve University\n, and eventually became associate director of the Center for Documentation and Communications Research. That same year, Kent and colleagues published a paper in American Documentation describing the precision and recall measures as well as detailing a proposed \"framework\" for evaluating an IR system which included statistical sampling methods for determining the number of relevant documents not retrieved.\n[\n24\n]\n1958\n: International Conference on Scientific Information Washington DC included consideration of IR systems as a solution to problems identified. See:\nProceedings of the International Conference on Scientific Information, 1958\n(National Academy of Sciences, Washington, DC, 1959)\n1959\n:\nHans Peter Luhn\npublished \"Auto-encoding of documents for information retrieval\".\n1960s\n:\nearly 1960s\n:\nGerard Salton\nbegan work on IR at Harvard, later moved to Cornell.\n1960\n:\nMelvin Earl Maron\nand John Lary Kuhns\n[\n25\n]\npublished \"On relevance, probabilistic indexing, and information retrieval\" in the Journal of the ACM 7(3):216–244, July 1960.\n1962\n:\n*\nCyril W. Cleverdon\npublished early findings of the Cranfield studies, developing a model for IR system evaluation. See: Cyril W. Cleverdon, \"Report on the Testing and Analysis of an Investigation into the Comparative Efficiency of Indexing Systems\". Cranfield Collection of Aeronautics, Cranfield, England, 1962.\n* Kent published\nInformation Analysis and Retrieval\n.\n1963\n:\n* Weinberg report \"Science, Government and Information\" gave a full articulation of the idea of a \"crisis of scientific information\". The report was named after Dr.\nAlvin Weinberg\n.\n* Joseph Becker and\nRobert M. Hayes\npublished text on information retrieval. Becker, Joseph; Hayes, Robert Mayo.\nInformation storage and retrieval: tools, elements, theories\n. New York, Wiley (1963).\n1964\n:\n*\nKaren Spärck Jones\nfinished her thesis at Cambridge,\nSynonymy and Semantic Classification\n, and continued work on\ncomputational linguistics\nas it applies to IR.\n* The\nNational Bureau of Standards\nsponsored a symposium titled \"Statistical Association Methods for Mechanized Documentation\". Several highly significant papers, including G. Salton's first published reference (we believe) to the\nSMART\nsystem.\nmid-1960s\n:\n*\nNational Library of Medicine\n(NLM) developed\nMEDLARS\nMedical Literature Analysis and Retrieval System, the first major machine-readable database and batch-retrieval system.\n* Project Intrex at MIT.\n1965\n:\nJ. C. R. Licklider\npublished\nLibraries of the Future\n.\n1966\n:\nDon Swanson\nwas involved in studies at University of Chicago on Requirements for Future Catalogs.\nlate 1960s\n:\nF. Wilfrid Lancaster\ncompleted evaluation studies of the MEDLARS system and published the first edition of his text on information retrieval.\n1968\n:\n* Gerard Salton published\nAutomatic Information Organization and Retrieval\n.\n* John W. Sammon, Jr.'s RADC Tech report \"Some Mathematics of Information Storage and Retrieval...\" outlined the vector model.\n1969\n: Sammon's \"\nA nonlinear mapping for data structure analysis\nArchived\n2017-08-08 at the\nWayback Machine\n\" (IEEE Transactions on Computers) was the first proposal for visualization interface to an IR system.\n1970s\nearly 1970s\n:\n* First online systems—NLM's AIM-TWX, MEDLINE; Lockheed's Dialog; SDC's ORBIT.\n*\nTheodor Nelson\npromoting concept of\nhypertext\n, published\nComputer Lib/Dream Machines\n.\n1971\n:\nNicholas Jardine\nand\nCornelis J. van Rijsbergen\npublished \"The use of\nhierarchic clustering\nin information retrieval\", which articulated the \"cluster hypothesis\".\n[\n26\n]\n1975\n: Three highly influential publications by Salton fully articulated his vector processing framework and\nterm discrimination\nmodel:\n*\nA Theory of Indexing\n(Society for Industrial and Applied Mathematics)\n*\nA Theory of Term Importance in Automatic Text Analysis\n(\nJASIS\nv. 26)\n*\nA Vector Space Model for Automatic Indexing\n(\nCACM\n18:11)\n1978\n: The First\nACM\nSIGIR\nconference.\n1979\n: C. J. van Rijsbergen published\nInformation Retrieval\n(Butterworths). Heavy emphasis on probabilistic models.\n1979\n: Tamas Doszkocs implemented the CITE\nnatural language user interface\nfor MEDLINE at the National Library of Medicine. The CITE system supported free form query input, ranked output and relevance feedback.\n[\n27\n]\n1980s\n1980\n: First international ACM SIGIR conference, joint with British Computer Society IR group in Cambridge.\n1982\n:\nNicholas J. Belkin\n, Robert N. Oddy, and Helen M. Brooks proposed the ASK (Anomalous State of Knowledge) viewpoint for information retrieval. This was an important concept, though their automated analysis tool proved ultimately disappointing.\n1983\n: Salton (and Michael J. McGill) published\nIntroduction to Modern Information Retrieval\n(McGraw-Hill), with heavy emphasis on vector models.\n1985\n: David Blair and\nBill Maron\npublish:\nAn Evaluation of Retrieval Effectiveness for a Full-Text Document-Retrieval System\n.\n[\n28\n]\n1986\n:\nDonald A.B. Lindberg\nM.D., NLM Director, implemented a direct health professional interface to MEDLINE and other MEDLARS databases.\nGrateful Med\n, a pun on the\nGrateful Dead\n, was adapted from Microsearch, an ELHILL user interface that assembled query language prior to connecting to the NLM mainframe. After retrieving the query results, Grateful Med disconnected from the mainframe to keep search costs low.\n[\n29\n]\nmid-1980s\n: Efforts to develop end-user versions of commercial IR systems.\n1985–1993\n: Key papers on and experimental systems for visualization interfaces.\nWork by\nDonald B. Crouch\n,\nRobert R. Korfhage\n, Matthew Chalmers, Anselm Spoerri and others.\n1989\n: First\nWorld Wide Web\nproposals by\nTim Berners-Lee\nat\nCERN\n.\n1990s\n1992\n: First\nTREC\nconference.\n1997\n: Publication of\nKorfhage\n's\nInformation Storage and Retrieval\n[\n30\n]\nwith emphasis on visualization and multi-reference point systems.\n1998:\nGoogle\nis founded by\nLarry Page\nand\nSergey Brin\n. It introduces the PageRank algorithm, which evaluates the importance of web pages based on hyperlink structure.\n[\n10\n]\n1999\n: Publication of\nRicardo Baeza-Yates\nand Berthier Ribeiro-Neto's\nModern Information Retrieval\nby Addison Wesley, the first book that attempts to cover all IR.\n2000s\n2001:\nWikipedia\nlaunches as a free, collaborative online encyclopedia. It quickly becomes a major resource for information retrieval, particularly for natural language processing and semantic search benchmarks.\n[\n31\n]\n2009:\nMicrosoft launches Bing, introducing features such as related searches, semantic suggestions, and later incorporating deep learning techniques into its ranking algorithms.\n[\n11\n]\n2010s\n2013:\nGoogle's Hummingbird algorithm goes live, marking a shift from keyword matching toward understanding query intent and\nsemantic context\nin search queries.\n[\n32\n]\n2018:\nGoogle AI researchers release\nBERT\n(Bidirectional Encoder Representations from Transformers), enabling deep bidirectional understanding of language and improving document ranking and query understanding in IR.\n[\n12\n]\n2019:\nMicrosoft introduces MS MARCO (Microsoft\nMA\nchine\nR\neading\nCO\nmprehension), a large-scale dataset designed for training and evaluating machine reading and passage ranking models.\n[\n14\n]\n2020s\n2020:\nThe\nColBERT\n(Contextualized Late Interaction over BERT) model, designed for efficient passage retrieval using contextualized embeddings, was introduced at SIGIR 2020.\n[\n33\n]\n[\n17\n]\n2021:\nSPLADE\nis introduced at SIGIR 2021. It's a sparse neural retrieval model that balances lexical and semantic features using masked language modeling and sparsity regularization.\n[\n34\n]\n2022:\nThe\nBEIR\nbenchmark is released to evaluate zero-shot IR across 18 datasets covering diverse tasks. It standardizes comparisons between dense, sparse, and hybrid IR models.\n[\n19\n]\nMajor conferences\n[\nedit\n]\nSIGIR:\nSpecial Interest Group on Information Retrieval\nECIR:\nEuropean Conference on Information Retrieval\nCIKM: Conference on Information and Knowledge Management\nWWW:\nInternational World Wide Web Conference\nAwards in the field\n[\nedit\n]\nTony Kent Strix award\nGerard Salton Award\nKaren Spärck Jones Award\nSee also\n[\nedit\n]\nAdversarial information retrieval\n– Information retrieval strategies in datasets\nComputer memory\n– Component that stores information\nControlled vocabulary\n– Method of organizing knowledge\nCross-language information retrieval\nData mining\n– Process of extracting and discovering patterns in large data sets\nData retrieval\n– Way to obtain data from a database\nHuman–computer information retrieval\n(\nHCIR\n)\nInformation extraction\n– Machine reading of unstructured documents\nInformation seeking\n– Type of activity in information science\nInformation seeking § Compared to information retrieval\nCollaborative information seeking\nSocial information seeking\nInformation Retrieval Facility\n– Organization in Vienna, Austria 2006–2012\nKnowledge visualization\n– Set of techniques for creating images, diagrams, or animations to communicate a message\nPages displaying short descriptions of redirect targets\nMultimedia information retrieval\nPersonal information management\n– Tools and systems for managing one's own data\nPearl growing\n– Type of search strategy\nQuery understanding\n– Search engine processing step\nRelevance (information retrieval)\n– Measure of a document's applicability to a given subject or search query\nRelevance feedback\n– Data used in information retrieval and recommendation systems\nRetrievability\n– Property of being able to access something\nRocchio classification\n– A classification model in machine learning based on centroids\nSearch engine indexing\n– Method for data management\nSpecial Interest Group on Information Retrieval\n– Subgroup of the Association for Computing Machinery\nSubject indexing\n– Classifying a document by index terms\nTemporal information retrieval\n– Area of research related to information retrieval centered on timeliness\ntf–idf\n– Estimate of the importance of a word in a document\nXML retrieval\n– Content-based retrieval of XML documents\nWeb mining\n– Process of extracting and discovering patterns in large data sets\nPages displaying short descriptions of redirect targets\nReferences\n[\nedit\n]\n^\nLuk, R. W. P. (2022). \"Why is information retrieval a scientific discipline?\".\nFoundations of Science\n.\n27\n(2):\n427–\n453.\ndoi\n:\n10.1007/s10699-020-09685-x\n.\nhdl\n:\n10397/94873\n.\nS2CID\n220506422\n.\n^\nJansen, B.J.; Rieh, S. (2010).\n\"The Seventeen Theoretical Constructs of Information Searching and Information Retrieval\"\n(PDF)\n.\nJournal of the American Society for Information Sciences and Technology\n.\n61\n(8):\n1517–\n34.\ndoi\n:\n10.1002/asi.21358\n.\n^\nGoodrum, Abby A. (2000).\n\"Image Information Retrieval: An Overview of Current Research\"\n(PDF)\n.\nInforming Science\n.\n3\n(2):\n063–\n066.\ndoi\n:\n10.28945/578\n.\n^\nFoote, Jonathan (1999). \"An overview of audio information retrieval\".\nMultimedia Systems\n.\n7\n:\n2–\n10.\nCiteSeerX\n10.1.1.39.6339\n.\ndoi\n:\n10.1007/s005300050106\n.\nS2CID\n2000641\n.\n^\nBeel, Jöran; Gipp, Bela; Stiller, Jan-Olaf (2009).\nInformation Retrieval On Mind Maps — What Could It Be Good For?\n(PDF)\n. Proceedings of the 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom'09). IEEE.\ndoi\n:\n10.4108/ICST.COLLABORATECOM2009.8298\n.\nISBN\n978-963-9799-76-9\n.\n^\nFrakes, William B.; Baeza-Yates, Ricardo (1992).\nInformation Retrieval Data Structures & Algorithms\n. Prentice-Hall, Inc.\nISBN\n978-0-13-463837-9\n. Archived from\nthe original\non 2013-09-28.\n^\na\nb\nSinghal, Amit (2001).\n\"Modern Information Retrieval: A Brief Overview\"\n(PDF)\n.\nBulletin of the IEEE Computer Society Technical Committee on Data Engineering\n.\n24\n(4):\n35–\n43.\n^\nMark Sanderson & W. Bruce Croft (2012).\n\"The History of Information Retrieval Research\"\n.\nProceedings of the IEEE\n.\n100\n:\n1444–\n51.\ndoi\n:\n10.1109/jproc.2012.2189916\n.\n^\nJE Holmstrom (1948).\n\"\n'Section III. Opening Plenary Session\"\n.\nThe Royal Society Scientific Information Conference, 21 June-2 July 1948: Report and Papers Submitted\n: 85.\n^\na\nb\nBrin, Sergey; Page, Lawrence (1998).\n\"The Anatomy of a Large-Scale Hypertextual Web Search Engine\"\n(PDF)\n.\nComputer Networks and ISDN Systems\n.\n30\n(\n1–\n7):\n107–\n117.\ndoi\n:\n10.1016/S0169-7552(98)00110-X\n.\n^\na\nb\nUyar, Ahmet; Aliyu, Farouk Musa (2015-01-01).\n\"Evaluating search features of Google Knowledge Graph and Bing Satori: Entity types, list searches and query interfaces\"\n.\nOnline Information Review\n.\n39\n(2):\n197–\n213.\ndoi\n:\n10.1108/OIR-10-2014-0257\n.\nISSN\n1468-4527\n.\n^\na\nb\nDevlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\".\narXiv\n:\n1810.04805\n[\ncs.CL\n].\n^\nGardazi, Nadia Mushtaq; Daud, Ali; Malik, Muhammad Kamran; Bukhari, Amal; Alsahfi, Tariq; Alshemaimri, Bader (2025-03-15).\n\"BERT applications in natural language processing: a review\"\n.\nArtificial Intelligence Review\n.\n58\n(6): 166.\ndoi\n:\n10.1007/s10462-025-11162-5\n.\nISSN\n1573-7462\n.\n^\na\nb\nBajaj, Payal; Campos, Daniel; Craswell, Nick; Deng, Li; Gao, Jianfeng; Liu, Xiaodong; Majumder, Rangan; McNamara, Andrew; Mitra, Bhaskar; Nguyen, Tri; Rosenberg, Mir; Song, Xia; Stoica, Alina; Tiwary, Saurabh; Wang, Tong (2016). \"MS MARCO: A Human Generated MAchine Reading COmprehension Dataset\".\narXiv\n:\n1611.09268\n[\ncs.CL\n].\n^\nCraswell, Nick; Mitra, Bhaskar; Yilmaz, Emine; Rahmani, Hossein A.; Campos, Daniel; Lin, Jimmy; Voorhees, Ellen M.; Soboroff, Ian (February 2024).\n\"Overview of the TREC 2023 Deep Learning Track\"\n.\nText REtrieval Conference (TREC)\n– via Microsoft.\n^\na\nb\nKim, Dohyun; Zhao, Lina; Chung, Eric; Park, Eun-Jae (2021). \"Pressure-robust staggered DG methods for the Navier-Stokes equations on general meshes\".\narXiv\n:\n2107.09226\n[\nmath.NA\n].\n^\na\nb\nKhattab, Omar; Zaharia, Matei (2020-07-25).\n\"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\"\n.\nProceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval\n. SIGIR '20. New York, NY, USA: Association for Computing Machinery. pp.\n39–\n48.\ndoi\n:\n10.1145/3397271.3401075\n.\nISBN\n978-1-4503-8016-4\n.\n^\na\nb\nLin, Jimmy; Nogueira, Rodrigo; Yates, Andrew (2020). \"Pretrained Transformers for Text Ranking: BERT and Beyond\".\narXiv\n:\n2010.06467\n[\ncs.IR\n].\n^\na\nb\nc\nThakur, Nandan; Reimers, Nils; Rücklé, Andreas; Srivastava, Abhishek; Gurevych, Iryna (2021). \"BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models\".\narXiv\n:\n2104.08663\n[\ncs.IR\n].\n^\nLau, Jey Han; Armendariz, Carlos; Lappin, Shalom; Purver, Matthew; Shu, Chang (2020). Johnson, Mark; Roark, Brian; Nenkova, Ani (eds.).\n\"How Furiously Can Colorless Green Ideas Sleep? Sentence Acceptability in Context\"\n.\nTransactions of the Association for Computational Linguistics\n.\n8\n:\n296–\n310.\ndoi\n:\n10.1162/tacl_a_00315\n.\n^\nArabzadeh, Negar; Yan, Xinyi; Clarke, Charles L. A. (2021). \"Predicting Efficiency/Effectiveness Trade-offs for Dense vs. Sparse Retrieval Strategy Selection\".\narXiv\n:\n2109.10739\n[\ncs.IR\n].\n^\nMooers, Calvin N. (1951).\nThe Theory of Digital Handling of Non-numerical Information and its Implications to Machine Economics\n.\nZator Technical Bulletin\n(Technical report). 48.\n, cited in\nFairthorne, R. A. (1958).\n\"Automatic Retrieval of Recorded Information\"\n.\nThe Computer Journal\n.\n1\n(1): 37.\ndoi\n:\n10.1093/comjnl/1.1.36\n.\n^\nDoyle, Lauren; Becker, Joseph (1975).\nInformation Retrieval and Processing\n. Melville.\nISBN\n978-0-471-22151-7\n.\n^\nPerry, James W.; Kent, Allen; Berry, Madeline M. (1955). \"Machine literature searching X. Machine language; factors underlying its design and development\".\nAmerican Documentation\n.\n6\n(4):\n242–\n254.\ndoi\n:\n10.1002/asi.5090060411\n.\n^\nMaron, Melvin E. (2008).\n\"An Historical Note on the Origins of Probabilistic Indexing\"\n(PDF)\n.\nInformation Processing and Management\n.\n44\n(2):\n971–\n2.\ndoi\n:\n10.1016/j.ipm.2007.02.012\n.\n^\nN. Jardine, C.J. van Rijsbergen (December 1971). \"The use of hierarchic clustering in information retrieval\".\nInformation Storage and Retrieval\n.\n7\n(5):\n217–\n240.\ndoi\n:\n10.1016/0020-0271(71)90051-9\n.\n^\nDoszkocs, T.E.; Rapp, B.A. (1979).\n\"Searching MEDLINE in English: a Prototype User Interface with Natural Language Query, Ranked Output, and relevance feedback\"\n.\nInformation choices and policies : 42nd annual meeting, Minneapolis, Minnesota, October 14-18, 1979\n. American Society for Information Science. Vol. 16. Knowledge Industry Publications. pp.\n131–\n9.\nOCLC\n271407392\n.\nOSTI\n5047496\n.\n^\nBlair, D.C.; Maron, M.E. (1985). \"An evaluation of retrieval effectiveness for a full-text document-retrieval system\".\nCommunications of the ACM\n.\n28\n(3):\n289–\n299.\ndoi\n:\n10.1145/3166.3197\n.\n^\nDorsch JL, Faughnan JG, Humphreys BL (June 2022).\n\"Grateful Med: Direct access to MEDLINE for health professionals with personal computers\"\n.\nInf Serv Use\n.\n42\n(2):\n151–\n160.\ndoi\n:\n10.3233/ISU-220147\n.\nPMC\n9196098\n.\nPMID\n35720429\n.\n^\nKorfhage, Robert R. (1997).\nInformation Storage and Retrieval\n. Wiley. pp.\n368 pp\n.\nISBN\n978-0-471-14338-3\n.\n^\n\"History of Wikipedia\"\n,\nWikipedia\n, 2025-02-21\n, retrieved\n2025-04-09\n^\nSullivan, Danny (2013-09-26).\n\"FAQ: All About The New Google \"Hummingbird\" Algorithm\"\n.\nSearch Engine Land\n. Retrieved\n2025-04-09\n.\n^\nKhattab, Omar; Zaharia, Matei (2020). \"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\".\narXiv\n:\n2004.12832\n[\ncs.IR\n].\n^\nJones, Rosie; Zamani, Hamed; Schedl, Markus; Chen, Ching-Wei; Reddy, Sravana; Clifton, Ann; Karlgren, Jussi; Hashemi, Helia; Pappu, Aasish; Nazari, Zahra; Yang, Longqi; Semerci, Oguz; Bouchard, Hugues; Carterette, Ben (2021-07-11).\n\"Current Challenges and Future Directions in Podcast Information Access\"\n.\nProceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval\n. SIGIR '21. New York, NY, USA: Association for Computing Machinery. pp.\n1554–\n65.\narXiv\n:\n2106.09227\n.\ndoi\n:\n10.1145/3404835.3462805\n.\nISBN\n978-1-4503-8037-9\n.\nFurther reading\n[\nedit\n]\nBaeza-Yates, Ricardo; Ribeiro-Neto, Berthier (2011).\nModern Information Retrieval: The Concepts and Technology behind Search\n(2nd ed.). Addison-Wesley.\nISBN\n978-0-321-41691-9\n.\nBüttcher, Stefan; Clarke, Charles L.A.; Cormack, Gordon V. (2010).\nInformation Retrieval: Implementing and Evaluating Search Engines\n. MIT Press.\nISBN\n978-0-262-02651-2\n.\nOCLC\n473652398\n.\n\"Information Retrieval System\"\n.\nLibrary & Information Science Network\n. 24 April 2015. Archived from\nthe original\non 11 May 2020\n. Retrieved\n3 May\n2020\n.\nManning, Christopher D.; Raghavan, Prabhakar; Schütze, Hinrich (2008).\nIntroduction to Information Retrieval\n. Cambridge University Press.\nISBN\n0-521-86571-9\n.\nShinJoung, Yeo (2023).\nBehind the Search Box: Google and the Global Internet Industry\n. University of Illinois Press.\nISBN\n978-0-252-05417-4\n.\nJSTOR\njj.4116455\n.\nOCLC\n1371410330\n.\nExternal links\n[\nedit\n]\nWikiquote has quotations related to\nInformation retrieval\n.\nWikimedia Commons has media related to\nInformation retrieval\n.\nACM SIGIR: Information Retrieval Special Interest Group\nBCS IRSG: British Computer Society – Information Retrieval Specialist Group\nText Retrieval Conference (TREC)\nForum for Information Retrieval Evaluation (FIRE)\nInformation Retrieval\n(online book) by\nC. J. van Rijsbergen\nInformation Retrieval Wiki\nArchived\n2015-11-24 at the\nWayback Machine\nInformation Retrieval Facility\nArchived\n2008-05-22 at the\nWayback Machine\nTREC report on information retrieval evaluation techniques\nHow eBay measures search relevance\nInformation retrieval performance evaluation tool @ Athena Research Centre\nAuthority control databases\nInternational\nGND\nNational\nUnited States\nFrance\nBnF data\nJapan\nCzech Republic\nSpain\nIsrael\nOther\nYale LUX\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Information_retrieval&oldid=1326979819\n\"\nCategories\n:\nInformation retrieval\nNatural language processing\nHidden categories:\nArticles with short description\nShort description is different from Wikidata\nArticles needing additional references from February 2025\nAll articles needing additional references\nWikipedia articles needing clarification from June 2018\nWebarchive template wayback links\nPages displaying short descriptions of redirect targets via Module:Annotated link\nCommons category link from Wikidata\nThis page was last edited on 11 December 2025, at 23:38\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nInformation retrieval\n40 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:30.787607",
      "status": "success",
      "content_length": 38958,
      "topic": "rag"
    },
    {
      "title": "Document retrieval - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Document_retrieval",
      "content": "Document retrieval - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nDescription\n2\nVariations\nToggle Variations subsection\n2.1\nForm based\n2.2\nContent based\n3\nExample: PubMed\n4\nSee also\n5\nReferences\n6\nFurther reading\n7\nExternal links\nToggle the table of contents\nDocument retrieval\n8 languages\nالعربية\nDeutsch\nEspañol\nفارسی\nFrançais\n한국어\n日本語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nDocument retrieval\nis defined as the matching of some stated user query against a set of\nfree-text\nrecords. These records could be any type of mainly\nunstructured text\n, such as\nnewspaper articles\n, real estate records or paragraphs in a manual. User queries can range from multi-sentence full descriptions of an information need to a few words.\nDocument retrieval is sometimes referred to as, or as a branch of,\ntext retrieval\n. Text retrieval is a branch of\ninformation retrieval\nwhere the information is stored primarily in the form of\ntext\n. Text databases became decentralized thanks to the\npersonal computer\n. Text retrieval is a critical area of study today, since it is the fundamental basis of all\ninternet\nsearch engines\n.\nDescription\n[\nedit\n]\nDocument retrieval systems find information to given criteria by matching text records (\ndocuments\n) against user queries, as opposed to\nexpert systems\nthat answer questions by\ninferring\nover a logical\nknowledge database\n. A document retrieval system consists of a database of documents, a\nclassification algorithm\nto build a full text index, and a user interface to access the database.\nA document retrieval system has two main tasks:\nFind relevant documents to user queries\nEvaluate the matching results and sort them according to relevance, using algorithms such as\nPageRank\n.\nInternet\nsearch engines\nare classical applications of document retrieval. The vast majority of retrieval systems currently in use range from simple Boolean systems through to systems using\nstatistical\nor\nnatural language processing\ntechniques.\nVariations\n[\nedit\n]\nThere are two main classes of indexing schemata for document retrieval systems:\nform based\n(or\nword based\n), and\ncontent based\nindexing. The document classification scheme (or\nindexing algorithm\n) in use determines the nature of the document retrieval system.\nForm based\n[\nedit\n]\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A\nsuffix tree\nalgorithm is an example for form based indexing.\nContent based\n[\nedit\n]\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an\ninverted index\nalgorithm.\nA\nsignature file\nis a technique that creates a\nquick and dirty\nfilter, for example a\nBloom filter\n, that will keep all the documents that match to the query and\nhopefully\na few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to\ninverted indexes\nin terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted indexes in certain environments.\nExample: PubMed\n[\nedit\n]\nThe\nPubMed\n[\n1\n]\nform interface features the \"related articles\" search which works through a comparison of words from the documents' title, abstract, and\nMeSH\nterms using a word-weighted algorithm.\n[\n2\n]\n[\n3\n]\nSee also\n[\nedit\n]\nCompound term processing\nDocument classification\nEnterprise search\nEvaluation measures (information retrieval)\nFull text search\nInformation retrieval\nLatent semantic indexing\nSearch engine\nReferences\n[\nedit\n]\n^\nKim W, Aronson AR, Wilbur WJ (2001).\n\"Automatic MeSH term assignment and quality assessment\"\n.\nProc AMIA Symp\n:\n319–\n23.\nPMC\n2243528\n.\nPMID\n11825203\n.\n^\nComputation of Related Citations\n. National Center for Biotechnology Information (US). 2019-02-06.\n^\nLin J1, Wilbur WJ (Oct 30, 2007).\n\"PubMed related articles: a probabilistic topic-based model for content similarity\"\n.\nBMC Bioinformatics\n.\n8\n: 423.\ndoi\n:\n10.1186/1471-2105-8-423\n.\nPMC\n2212667\n.\nPMID\n17971238\n.\n{{\ncite journal\n}}\n:  CS1 maint: numeric names: authors list (\nlink\n)\nFurther reading\n[\nedit\n]\nFaloutsos, Christos; Christodoulakis, Stavros (1984).\n\"Signature files: An access method for documents and its analytical performance evaluation\"\n.\nACM Transactions on Information Systems\n.\n2\n(4):\n267–\n288.\ndoi\n:\n10.1145/2275.357411\n.\nS2CID\n8120705\n.\nJustin Zobel; Alistair Moffat; Kotagiri Ramamohanarao (1998).\n\"Inverted files versus signature files for text indexing\"\n(PDF)\n.\nACM Transactions on Database Systems\n.\n23\n(4):\n453–\n490.\nCiteSeerX\n10.1.1.54.8753\n.\ndoi\n:\n10.1145/296854.277632\n.\nS2CID\n7293918\n.\nBen Carterette; Fazli Can (2005).\n\"Comparing inverted files and signature files for searching a large lexicon\"\n(PDF)\n.\nInformation Processing and Management\n.\n41\n(3):\n613–\n633.\ndoi\n:\n10.1016/j.ipm.2003.12.003\n.\nExternal links\n[\nedit\n]\nWikimedia Commons has media related to\nDocument retrieval\n.\nFormal Foundation of Information Retrieval\n, Buckinghamshire Chilterns University College\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Document_retrieval&oldid=1316600641\n\"\nCategories\n:\nInformation retrieval genres\nElectronic documents\nSubstring indices\nSearch engine software\nHidden categories:\nCS1 maint: numeric names: authors list\nCommons category link from Wikidata\nThis page was last edited on 13 October 2025, at 12:30\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nDocument retrieval\n8 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:32.773517",
      "status": "success",
      "content_length": 6986,
      "topic": "rag"
    },
    {
      "title": "Semantic search - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Semantic_search",
      "content": "Semantic search - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nModels and tools\n2\nSee also\n3\nReferences\n4\nExternal links\nToggle the table of contents\nSemantic search\n9 languages\nالعربية\nCatalà\nDeutsch\nEspañol\nفارسی\nFrançais\nItaliano\nРусский\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nContextual queries\nSemantic search\ndenotes search with meaning, as distinguished from lexical search where the search engine looks for literal matches of the query words or variants of them, without understanding the overall meaning of the query.\n[\n1\n]\nSemantic search is an approach to\ninformation retrieval\nthat seeks to improve\nsearch\naccuracy by understanding\nthe searcher's intent\nand the\ncontextual\nmeaning of terms as they appear in the searchable dataspace, whether on the\nWeb\nor within a closed system, to generate more relevant results. Modern semantic search systems often use vector embeddings to represent words, phrases, or documents as numerical vectors, allowing the retrieval engine to measure similarity based on meaning rather than exact keyword matches.\n[\n2\n]\n[\n3\n]\nSome authors regard semantic search as a set of techniques for retrieving knowledge from richly structured data sources like\nontologies\nand\nXML\nas found on the\nSemantic Web\n.\n[\n4\n]\nSuch technologies enable the formal articulation of\ndomain knowledge\nat a high level of expressiveness and could enable the user to specify their intent in more detail at query time.\n[\n5\n]\nThe articulation enhances content relevance and depth by including specific places, people, or concepts relevant to the query.\nModels and tools\n[\nedit\n]\nTools like Google's\nKnowledge Graph\nprovide structured relationships between entities to enrich query interpretation.\n[\n6\n]\nModels like\nBERT\nand Sentence-BERT convert words or sentences into dense vectors for similarity comparison.\n[\n7\n]\nSemantic ontologies like\nWeb Ontology Language\n,\nResource Description Framework\n, and\nSchema.org\norganize concepts and relationships, allowing systems to infer related terms and deeper meanings.\n[\n8\n]\nHybrid search models combine\nlexical retrieval\n(e.g., BM25) with\nsemantic ranking\nusing pretrained transformer models for optimal performance.\n[\n9\n]\nSee also\n[\nedit\n]\nList of search engines\nSemantic web\nSemantic unification\nResource Description Framework\nNatural language search engine\nSemantic query\nVector database\nWord embeddings\nReferences\n[\nedit\n]\n^\nBast, Hannah; Buchhold, Björn; Haussmann, Elmar (2016).\n\"Semantic search on text and knowledge bases\"\n.\nFoundations and Trends in Information Retrieval\n.\n10\n(\n2–\n3):\n119–\n271.\ndoi\n:\n10.1561/1500000032\n. Retrieved\n1 December\n2018\n.\n^\nKlampanos, Iraklis A. (2009-06-02).\n\"Manning Christopher, Prabhakar Raghavan, Hinrich Schütze: Introduction to information retrieval\"\n.\nInformation Retrieval\n.\n12\n(5):\n609–\n612.\ndoi\n:\n10.1007/s10791-009-9096-x\n.\nISSN\n1386-4564\n.\n^\nKim, Bosung; Hong, Taesuk; Ko, Youngjoong; Seo, Jungyun (2020).\n\"Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models\"\n.\nProceedings of the 28th International Conference on Computational Linguistics\n. Stroudsburg, PA, USA: International Committee on Computational Linguistics.\ndoi\n:\n10.18653/v1/2020.coling-main.153\n.\n^\nDong, Hai (2008).\nA survey in semantic search technologies\n. IEEE. pp.\n403–\n408\n. Retrieved\n1 May\n2009\n.\n^\nRuotsalo, T. (May 2012). \"Domain Specific Data Retrieval on the Semantic Web\".\nThe Semantic Web: Research and Applications\n. Eswc2012. Lecture Notes in Computer Science. Vol. 7295. pp.\n422–\n436.\ndoi\n:\n10.1007/978-3-642-30284-8_35\n.\nISBN\n978-3-642-30283-1\n.\n^\nSinghal, A. (2012). Introducing the Knowledge Graph: things, not strings. Google Blog.\nhttps://blog.google/products/search/introducing-knowledge-graph-things-not/\n^\nReimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.\nEMNLP 2019\n.\nhttps://arxiv.org/abs/1908.10084\n^\nBodenreider, O. (2004). The Unified Medical Language System (UMLS): integrating biomedical terminology.\nNucleic Acids Research\n, 32(suppl_1), D267–D270.\n^\nLin, J., et al. (2021). Pretrained Transformers for Text Ranking: BERT and Beyond.\nhttps://arxiv.org/abs/2010.06467\nExternal links\n[\nedit\n]\nSemantic Search 2008 Workshop at ESWC'08\nSemantic Search 2010 Workshop at WWW2010\nWorkshop on Exploiting Semantic Annotations in Information Retrieval at ECIR'08\n.\nv\nt\ne\nSemantic Web\nBackground\nDatabases\nHypertext\nInternet\nOntologies\nSemantics\nSemantic networks\nWorld Wide Web\nSub-topics\nDataspaces\nHyperdata\nLinked data\nRule-based systems\nApplications\nSemantic analytics\nSemantic computing\nSemantic mapper\nSemantic matching\nSemantic publishing\nSemantic reasoner\nSemantic search\nSemantic service-oriented architecture\nSemantic wiki\nSolid\nRelated topics\nCollective intelligence\nDescription logic\nFolksonomy\nGeotagging\nInformation architecture\niXBRL\nKnowledge extraction\nKnowledge management\nKnowledge representation and reasoning\nLibrary 2.0\nDigital library\nDigital humanities\nMetadata\nReferences\nTopic map\nWeb 2.0\nWeb engineering\nWeb Science Trust\nStandards\nSyntax and supporting technologies\nHTTP\nIRI\nURI\nRDF\ntriples\nRDF/XML\nJSON-LD\nTurtle\nTriG\nNotation3\nN-Triples\nTriX\n(no W3C standard)\nRRID\nSPARQL\nXML\nSemantic HTML\nSchemas, ontologies and rules\nCommon Logic\nOWL\nRDFS\nRule Interchange Format\nSemantic Web Rule Language\nSHACL\nSemantic annotation\nCOinS\nGRDDL\nMicrodata\nMicroformats\nRDFa\nSAWSDL\nFacebook Platform\nCommon vocabularies\nBIBFRAME\nBIBO\nDOAP\nDublin Core\nMODS\n/\nMADS\nFOAF\nSchema.org\nSIOC\nSKOS\nMicroformat vocabularies\nhAtom\nhCalendar\nhCard\nhProduct\nhRecipe\nhReview\nv\nt\ne\nInternet search\nTypes\nWeb search engine\n(\nList\n)\nMetasearch engine\nMultimedia search\nCollaborative search engine\nCross-language search\nLocal search\nVertical search\nSocial search\nImage search\nAudio search\nVideo search engine\nEnterprise search\nSemantic search\nNatural language search engine\nVoice search\nTools\nCross-language information retrieval\nSearch by sound\nSearch engine marketing\nSearch engine optimization\nEvaluation measures\nSearch oriented architecture\nSelection-based search\nDocument retrieval\nText mining\nWeb crawler\nMultisearch\nFederated search\nSearch aggregator\nIndex\n/\nWeb indexing\nFocused crawler\nSpider trap\nRobots exclusion standard\nDistributed web crawling\nWeb archiving\nWebsite mirroring software\nWeb query\nWeb query classification\nProtocols\nand standards\nZ39.50\nSearch/Retrieve Web Service\nSearch/Retrieve via URL\nOpenSearch\nRepresentational State Transfer\nWide area information server\nSee also\nSearch engine\nDesktop search\nOnline search\nThis Internet-related article is a\nstub\n. You can help Wikipedia by\nexpanding it\n.\nv\nt\ne\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Semantic_search&oldid=1326520974\n\"\nCategories\n:\nInternet search engines\nSemantic Web\nInformation retrieval genres\nInternet stubs\nHidden categories:\nArticles with short description\nShort description matches Wikidata\nAll stub articles\nThis page was last edited on 9 December 2025, at 10:53\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nSemantic search\n9 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:34.838448",
      "status": "success",
      "content_length": 8142,
      "topic": "rag"
    },
    {
      "title": "Artificial intelligence - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Artificial_intelligence",
      "content": "Artificial intelligence - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nGoals\nToggle Goals subsection\n1.1\nReasoning and problem-solving\n1.2\nKnowledge representation\n1.3\nPlanning and decision-making\n1.4\nLearning\n1.5\nNatural language processing\n1.6\nPerception\n1.7\nSocial intelligence\n1.8\nGeneral intelligence\n2\nTechniques\nToggle Techniques subsection\n2.1\nSearch and optimization\n2.1.1\nState space search\n2.1.2\nLocal search\n2.2\nLogic\n2.3\nProbabilistic methods for uncertain reasoning\n2.4\nClassifiers and statistical learning methods\n2.5\nArtificial neural networks\n2.6\nDeep learning\n2.7\nGPT\n2.8\nHardware and software\n3\nApplications\nToggle Applications subsection\n3.1\nHealth and medicine\n3.2\nGames\n3.3\nMathematics\n3.4\nFinance\n3.5\nMilitary\n3.6\nGenerative AI\n3.7\nAgents\n3.8\nWeb search\n3.9\nSexuality\n3.10\nOther industry-specific tasks\n4\nEthics\nToggle Ethics subsection\n4.1\nRisks and harm\n4.1.1\nPrivacy and copyright\n4.1.2\nDominance by tech giants\n4.1.3\nPower needs and environmental impacts\n4.1.4\nMisinformation\n4.1.5\nAlgorithmic bias and fairness\n4.1.6\nLack of transparency\n4.1.7\nBad actors and weaponized AI\n4.1.8\nTechnological unemployment\n4.1.9\nExistential risk\n4.2\nEthical machines and alignment\n4.3\nOpen source\n4.4\nFrameworks\n4.5\nRegulation\n5\nHistory\n6\nPhilosophy\nToggle Philosophy subsection\n6.1\nDefining artificial intelligence\n6.2\nEvaluating approaches to AI\n6.2.1\nSymbolic AI and its limits\n6.2.2\nNeat vs. scruffy\n6.2.3\nSoft vs. hard computing\n6.2.4\nNarrow vs. general AI\n6.3\nMachine consciousness, sentience, and mind\n6.3.1\nConsciousness\n6.3.2\nComputationalism and functionalism\n6.3.3\nAI welfare and rights\n7\nFuture\nToggle Future subsection\n7.1\nSuperintelligence and the singularity\n7.2\nTranshumanism\n8\nIn fiction\n9\nSee also\n10\nExplanatory notes\n11\nReferences\nToggle References subsection\n11.1\nAI textbooks\n11.2\nHistory of AI\n11.3\nOther sources\n12\nFurther reading\n13\nExternal links\nToggle the table of contents\nArtificial intelligence\n173 languages\nAfrikaans\nAlemannisch\nአማርኛ\nअंगिका\nالعربية\nAragonés\nԱրեւմտահայերէն\nঅসমীয়া\nAsturianu\nAvañe'ẽ\nAzərbaycanca\nتۆرکجه\nবাংলা\n閩南語 / Bân-lâm-gí\nБашҡортса\nБеларуская\nБеларуская (тарашкевіца)\nभोजपुरी\nBikol Central\nБългарски\nBoarisch\nབོད་ཡིག\nBosanski\nBrezhoneg\nБуряад\nCatalà\nЧӑвашла\nCebuano\nČeština\nCymraeg\nDansk\nالدارجة\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEstremeñu\nEuskara\nفارسی\nFiji Hindi\nFrançais\nFurlan\nGaeilge\nGaelg\nGàidhlig\nGalego\n贛語\nGĩkũyũ\nगोंयची कोंकणी / Gõychi Konknni\n한국어\nHausa\nՀայերեն\nहिन्दी\nHrvatski\nIdo\nIgbo\nIlokano\nBahasa Indonesia\nInterlingua\nInterlingue\nIsiZulu\nÍslenska\nItaliano\nעברית\nJawa\nಕನ್ನಡ\nქართული\nکٲشُر\nҚазақша\nKiswahili\nKreyòl ayisyen\nKriyòl gwiyannen\nKurdî\nКыргызча\nລາວ\nLatina\nLatviešu\nLëtzebuergesch\nLietuvių\nLigure\nLimburgs\nLa .lojban.\nLombard\nMagyar\nMadhurâ\nМакедонски\nMalagasy\nമലയാളം\nMalti\nमराठी\nმარგალური\nمصرى\nBahasa Melayu\nMinangkabau\nМонгол\nမြန်မာဘာသာ\nNederlands\nNedersaksies\nनेपाली\nनेपाल भाषा\n日本語\nNordfriisk\nNorsk bokmål\nNorsk nynorsk\nOccitan\nଓଡ଼ିଆ\nOʻzbekcha / ўзбекча\nਪੰਜਾਬੀ\nپنجابی\nပအိုဝ်ႏဘာႏသာႏ\nپښتو\nPatois\nភាសាខ្មែរ\nPicard\nPiemontèis\nPlattdüütsch\nPolski\nPortuguês\nQaraqalpaqsha\nQırımtatarca\nReo tahiti\nRipoarisch\nRomână\nRuna Simi\nРусиньскый\nРусский\nСаха тыла\nसंस्कृतम्\nSängö\nScots\nSesotho sa Leboa\nShqip\nSicilianu\nසිංහල\nSimple English\nسنڌي\nSlovenčina\nSlovenščina\nکوردی\nСрпски / srpski\nSrpskohrvatski / српскохрватски\nSuomi\nSvenska\nTagalog\nதமிழ்\nТатарча / tatarça\nతెలుగు\nไทย\nТоҷикӣ\nTürkçe\nTürkmençe\nУкраїнська\nاردو\nئۇيغۇرچە / Uyghurche\nVèneto\nTiếng Việt\nVõro\nWalon\n文言\nWinaray\n吴语\nייִדיש\n粵語\nZazaki\nŽemaitėška\n中文\nBetawi\nKadazandusun\nFɔ̀ngbè\nJaku Iban\nꠍꠤꠟꠐꠤ\nⵜⴰⵎⴰⵣⵉⵖⵜ ⵜⴰⵏⴰⵡⴰⵢⵜ\nEdit links\nArticle\nTalk\nEnglish\nRead\nView source\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nView source\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikibooks\nWikiquote\nWikiversity\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nIntelligence of machines\n\"AI\" redirects here. For other uses, see\nAI (disambiguation)\nand\nArtificial intelligence (disambiguation)\n.\nPart of\na series\non\nArtificial intelligence (AI)\nMajor goals\nArtificial general intelligence\nIntelligent agent\nRecursive self-improvement\nPlanning\nComputer vision\nGeneral game playing\nKnowledge representation\nNatural language processing\nRobotics\nAI safety\nApproaches\nMachine learning\nSymbolic\nDeep learning\nBayesian networks\nEvolutionary algorithms\nHybrid intelligent systems\nSystems integration\nOpen-source\nApplications\nBioinformatics\nDeepfake\nEarth sciences\nFinance\nGenerative AI\nArt\nAudio\nMusic\nGovernment\nHealthcare\nMental health\nIndustry\nSoftware development\nTranslation\nMilitary\nPhysics\nProjects\nPhilosophy\nAI alignment\nArtificial consciousness\nThe bitter lesson\nChinese room\nFriendly AI\nEthics\nExistential risk\nTuring test\nUncanny valley\nHuman–AI interaction\nHistory\nTimeline\nProgress\nAI winter\nAI boom\nAI bubble\nControversies\nDeepfake pornography\nTaylor Swift deepfake pornography controversy\nGoogle Gemini image generation controversy\nPause Giant AI Experiments\nRemoval of Sam Altman from OpenAI\nStatement on AI Risk\nTay (chatbot)\nThéâtre D'opéra Spatial\nVoiceverse NFT plagiarism scandal\nGlossary\nGlossary\nv\nt\ne\nArtificial intelligence\n(\nAI\n) is the capability of\ncomputational systems\nto perform tasks typically associated with\nhuman intelligence\n, such as\nlearning\n,\nreasoning\n,\nproblem-solving\n,\nperception\n, and\ndecision-making\n. It is a\nfield of research\nin\ncomputer science\nthat develops and studies methods and\nsoftware\nthat enable machines to\nperceive their environment\nand use\nlearning\nand\nintelligence\nto take actions that maximize their chances of achieving defined goals.\n[\n1\n]\nHigh-profile\napplications of AI\ninclude advanced\nweb search engines\n(e.g.,\nGoogle Search\n);\nrecommendation systems\n(used by\nYouTube\n,\nAmazon\n, and\nNetflix\n);\nvirtual assistants\n(e.g.,\nGoogle Assistant\n,\nSiri\n, and\nAlexa\n);\nautonomous vehicles\n(e.g.,\nWaymo\n);\ngenerative\nand\ncreative\ntools (e.g.,\nlanguage models\nand\nAI art\n); and\nsuperhuman\nplay and analysis in\nstrategy games\n(e.g.,\nchess\nand\nGo\n). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's\nnot labeled AI anymore\n.\"\n[\n2\n]\n[\n3\n]\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning,\nreasoning\n,\nknowledge representation\n,\nplanning\n,\nnatural language processing\n,\nperception\n, and support for\nrobotics\n.\n[\na\n]\nTo reach these goals, AI researchers have adapted and integrated a wide range of techniques, including\nsearch\nand\nmathematical optimization\n,\nformal logic\n,\nartificial neural networks\n, and methods based on\nstatistics\n,\noperations research\n, and\neconomics\n.\n[\nb\n]\nAI also draws upon\npsychology\n,\nlinguistics\n,\nphilosophy\n,\nneuroscience\n, and other fields.\n[\n4\n]\nSome companies, such as\nOpenAI\n,\nGoogle DeepMind\nand\nMeta\n,\n[\n5\n]\naim to create\nartificial general intelligence\n(AGI) – AI that can complete virtually any cognitive task at least as well as a human.\nArtificial intelligence was founded as an academic discipline in 1956,\n[\n6\n]\nand the field went through multiple cycles of optimism throughout\nits history\n,\n[\n7\n]\n[\n8\n]\nfollowed by periods of disappointment and loss of funding, known as\nAI winters\n.\n[\n9\n]\n[\n10\n]\nFunding and interest vastly increased after 2012 when\ngraphics processing units\nstarted being used to accelerate neural networks, and\ndeep learning\noutperformed previous AI techniques.\n[\n11\n]\nThis growth accelerated further after 2017 with the\ntransformer architecture\n.\n[\n12\n]\nIn the 2020s, an ongoing period of rapid\nprogress\nin advanced generative AI became known as the\nAI boom\n. Generative AI's ability to create and modify content has led to several\nunintended consequences and harms\n.\nEthical concerns\nhave been raised about\nAI's long-term effects\nand\npotential existential risks\n, prompting discussions about\nregulatory policies\nto ensure\nthe safety\nand benefits of the technology.\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n[\na\n]\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical\ndeductions\n.\n[\n13\n]\nBy the late 1980s and 1990s, methods were developed for dealing with\nuncertain\nor incomplete information, employing concepts from\nprobability\nand\neconomics\n.\n[\n14\n]\nMany of these\nalgorithms\nare insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.\n[\n15\n]\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\n[\n16\n]\nAccurate and efficient reasoning is an unsolved problem.\nKnowledge representation\nAn ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.\nKnowledge representation\nand\nknowledge engineering\n[\n17\n]\nallow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,\n[\n18\n]\nscene interpretation,\n[\n19\n]\nclinical decision support,\n[\n20\n]\nknowledge discovery (mining \"interesting\" and actionable inferences from large\ndatabases\n),\n[\n21\n]\nand other areas.\n[\n22\n]\nA\nknowledge base\nis a body of knowledge represented in a form that can be used by a program. An\nontology\nis the set of objects, relations, concepts, and properties used by a particular domain of knowledge.\n[\n23\n]\nKnowledge bases need to represent things such as objects, properties, categories, and relations between objects;\n[\n24\n]\nsituations, events, states, and time;\n[\n25\n]\ncauses and effects;\n[\n26\n]\nknowledge about knowledge (what we know about what other people know);\n[\n27\n]\ndefault reasoning\n(things that humans assume are true until they are told differently and will remain true even when other facts are changing);\n[\n28\n]\nand many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of\ncommonsense knowledge\n(the set of atomic facts that the average person knows is enormous);\n[\n29\n]\nand the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).\n[\n16\n]\nThere is also the difficulty of\nknowledge acquisition\n, the problem of obtaining knowledge for AI applications.\n[\nc\n]\nPlanning and decision-making\nAn \"agent\" is anything that perceives and takes actions in the world. A\nrational agent\nhas goals or preferences and takes actions to make them happen.\n[\nd\n]\n[\n32\n]\nIn\nautomated planning\n, the agent has a specific goal.\n[\n33\n]\nIn\nautomated decision-making\n, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"\nutility\n\") that measures how much the agent prefers it. For each possible action, it can calculate the \"\nexpected utility\n\": the\nutility\nof all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\n[\n34\n]\nIn\nclassical planning\n, the agent knows exactly what the effect of any action will be.\n[\n35\n]\nIn most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\n[\n36\n]\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with\ninverse reinforcement learning\n), or the agent can seek information to improve its preferences.\n[\n37\n]\nInformation value theory\ncan be used to weigh the value of exploratory or experimental actions.\n[\n38\n]\nThe space of possible future actions and situations is typically\nintractably\nlarge, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA\nMarkov decision process\nhas a\ntransition model\nthat describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A\npolicy\nassociates a decision with each possible state. The policy could be calculated (e.g., by\niteration\n), be\nheuristic\n, or it can be learned.\n[\n39\n]\nGame theory\ndescribes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n[\n40\n]\nLearning\nMachine learning\nis the study of programs that can improve their performance on a given task automatically.\n[\n41\n]\nIt has been a part of AI from the beginning.\n[\ne\n]\nIn\nsupervised learning\n, the training data is labelled with the expected answers, while in\nunsupervised learning\n, the model identifies patterns or structures in unlabelled data.\nThere are several kinds of machine learning.\nUnsupervised learning\nanalyzes a stream of data and finds patterns and makes predictions without any other guidance.\n[\n44\n]\nSupervised learning\nrequires labeling the training data with the expected answers, and comes in two main varieties:\nclassification\n(where the program must learn to predict what category the input belongs in) and\nregression\n(where the program must deduce a numeric function based on numeric input).\n[\n45\n]\nIn\nreinforcement learning\n, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".\n[\n46\n]\nTransfer learning\nis when the knowledge gained from one problem is applied to a new problem.\n[\n47\n]\nDeep learning\nis a type of machine learning that runs inputs through biologically inspired\nartificial neural networks\nfor all of these types of learning.\n[\n48\n]\nComputational learning theory\ncan assess learners by\ncomputational complexity\n, by\nsample complexity\n(how much data is required), or by other notions of\noptimization\n.\n[\n49\n]\nNatural language processing\nNatural language processing\n(NLP) allows programs to read, write and communicate in human languages.\n[\n50\n]\nSpecific problems include\nspeech recognition\n,\nspeech synthesis\n,\nmachine translation\n,\ninformation extraction\n,\ninformation retrieval\nand\nquestion answering\n.\n[\n51\n]\nEarly work, based on\nNoam Chomsky\n's\ngenerative grammar\nand\nsemantic networks\n, had difficulty with\nword-sense disambiguation\n[\nf\n]\nunless restricted to small domains called \"\nmicro-worlds\n\" (due to the\ncommon sense knowledge problem\n[\n29\n]\n).\nMargaret Masterman\nbelieved that it was meaning and not grammar that was the key to understanding languages, and that\nthesauri\nand not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include\nword embedding\n(representing words, typically as\nvectors\nencoding their meaning),\n[\n52\n]\ntransformers\n(a deep learning architecture using an\nattention\nmechanism),\n[\n53\n]\nand others.\n[\n54\n]\nIn 2019,\ngenerative pre-trained transformer\n(or \"GPT\") language models began to generate coherent text,\n[\n55\n]\n[\n56\n]\nand by 2023, these models were able to get human-level scores on the\nbar exam\n,\nSAT\ntest,\nGRE\ntest, and many other real-world applications.\n[\n57\n]\nPerception\nMachine perception\nis the ability to use input from sensors (such as cameras, microphones, wireless signals, active\nlidar\n, sonar, radar, and\ntactile sensors\n) to deduce aspects of the world.\nComputer vision\nis the ability to analyze visual input.\n[\n58\n]\nThe field includes\nspeech recognition\n,\n[\n59\n]\nimage classification\n,\n[\n60\n]\nfacial recognition\n,\nobject recognition\n,\n[\n61\n]\nobject tracking\n,\n[\n62\n]\nand\nrobotic perception\n.\n[\n63\n]\nSocial intelligence\nKismet\n, a robot head which was made in the 1990s; it is a machine that can recognize and simulate emotions.\n[\n64\n]\nAffective computing\nis a field that comprises systems that recognize, interpret, process, or simulate human\nfeeling, emotion, and mood\n.\n[\n65\n]\nFor example, some\nvirtual assistants\nare programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate\nhuman–computer interaction\n.\nHowever, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.\n[\n66\n]\nModerate successes related to affective computing include textual\nsentiment analysis\nand, more recently,\nmultimodal sentiment analysis\n, wherein AI classifies the effects displayed by a videotaped subject.\n[\n67\n]\nGeneral intelligence\nA machine with\nartificial general intelligence\nwould be able to solve a wide variety of problems with breadth and versatility similar to\nhuman intelligence\n.\n[\n68\n]\nTechniques\nAI research uses a wide variety of techniques to accomplish the goals above.\n[\nb\n]\nSearch and optimization\nAI can solve many problems by intelligently searching through many possible solutions.\n[\n69\n]\nThere are two very different kinds of search used in AI:\nstate space search\nand\nlocal search\n.\nState space search\nState space search\nsearches through a tree of possible states to try to find a goal state.\n[\n70\n]\nFor example,\nplanning\nalgorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called\nmeans-ends analysis\n.\n[\n71\n]\nSimple exhaustive searches\n[\n72\n]\nare rarely sufficient for most real-world problems: the\nsearch space\n(the number of places to search) quickly grows to\nastronomical numbers\n. The result is a search that is\ntoo slow\nor never completes.\n[\n15\n]\n\"\nHeuristics\n\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.\n[\n73\n]\nAdversarial search\nis used for\ngame-playing\nprograms, such as chess or Go. It searches through a\ntree\nof possible moves and countermoves, looking for a winning position.\n[\n74\n]\nLocal search\nIllustration of\ngradient descent\nfor 3 different starting points; two parameters (represented by the plan coordinates) are adjusted in order to minimize the\nloss function\n(the height)\nLocal search\nuses\nmathematical optimization\nto find a solution to a problem. It begins with some form of guess and refines it incrementally.\n[\n75\n]\nGradient descent\nis a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a\nloss function\n. Variants of gradient descent are commonly used to train\nneural networks\n,\n[\n76\n]\nthrough the\nbackpropagation\nalgorithm.\nAnother type of local search is\nevolutionary computation\n, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them,\nselecting\nonly the fittest to survive each generation.\n[\n77\n]\nDistributed search processes can coordinate via\nswarm intelligence\nalgorithms. Two popular swarm algorithms used in search are\nparticle swarm optimization\n(inspired by bird\nflocking\n) and\nant colony optimization\n(inspired by\nant trails\n).\n[\n78\n]\nLogic\nFormal\nlogic\nis used for\nreasoning\nand\nknowledge representation\n.\n[\n79\n]\nFormal logic comes in two main forms:\npropositional logic\n(which operates on statements that are true or false and uses\nlogical connectives\nsuch as \"and\", \"or\", \"not\" and \"implies\")\n[\n80\n]\nand\npredicate logic\n(which also operates on objects, predicates and relations and uses\nquantifiers\nsuch as \"\nEvery\nX\nis a\nY\n\" and \"There are\nsome\nX\ns that are\nY\ns\").\n[\n81\n]\nDeductive reasoning\nin logic is the process of\nproving\na new statement (\nconclusion\n) from other statements that are given and assumed to be true (the\npremises\n).\n[\n82\n]\nProofs can be structured as proof\ntrees\n, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by\ninference rules\n.\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose\nleaf nodes\nare labelled by premises or\naxioms\n. In the case of\nHorn clauses\n, problem-solving search can be performed by reasoning\nforwards\nfrom the premises or\nbackwards\nfrom the problem.\n[\n83\n]\nIn the more general case of the clausal form of\nfirst-order logic\n,\nresolution\nis a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.\n[\n84\n]\nInference in both Horn clause logic and first-order logic is\nundecidable\n, and therefore\nintractable\n. However, backward reasoning with Horn clauses, which underpins computation in the\nlogic programming\nlanguage\nProlog\n, is\nTuring complete\n. Moreover, its efficiency is competitive with computation in other\nsymbolic programming\nlanguages.\n[\n85\n]\nFuzzy logic\nassigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.\n[\n86\n]\nNon-monotonic logics\n, including logic programming with\nnegation as failure\n, are designed to handle\ndefault reasoning\n.\n[\n28\n]\nOther specialized versions of logic have been developed to describe many complex domains.\nProbabilistic methods for uncertain reasoning\nA simple\nBayesian network\n, with the associated\nconditional probability tables\nMany problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from\nprobability\ntheory and economics.\n[\n87\n]\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using\ndecision theory\n,\ndecision analysis\n,\n[\n88\n]\nand\ninformation value theory\n.\n[\n89\n]\nThese tools include models such as\nMarkov decision processes\n,\n[\n90\n]\ndynamic\ndecision networks\n,\n[\n91\n]\ngame theory\nand\nmechanism design\n.\n[\n92\n]\nBayesian networks\n[\n93\n]\nare a tool that can be used for\nreasoning\n(using the\nBayesian inference\nalgorithm),\n[\ng\n]\n[\n95\n]\nlearning\n(using the\nexpectation–maximization algorithm\n),\n[\nh\n]\n[\n97\n]\nplanning\n(using\ndecision networks\n)\n[\n98\n]\nand\nperception\n(using\ndynamic Bayesian networks\n).\n[\n91\n]\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g.,\nhidden Markov models\nor\nKalman filters\n).\n[\n91\n]\nExpectation–maximization\nclustering\nof\nOld Faithful\neruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption.\nClassifiers and statistical learning methods\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand.\nClassifiers\n[\n99\n]\nare functions that use\npattern matching\nto determine the closest match. They can be fine-tuned based on chosen examples using\nsupervised learning\n. Each pattern (also called an \"\nobservation\n\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a\ndata set\n. When a new observation is received, that observation is classified based on previous experience.\n[\n45\n]\nThere are many kinds of classifiers in use.\n[\n100\n]\nThe\ndecision tree\nis the simplest and most widely used symbolic machine learning algorithm.\n[\n101\n]\nK-nearest neighbor\nalgorithm was the most widely used analogical AI until the mid-1990s, and\nKernel methods\nsuch as the\nsupport vector machine\n(SVM) displaced k-nearest neighbor in the 1990s.\n[\n102\n]\nThe\nnaive Bayes classifier\nis reportedly the \"most widely used learner\"\n[\n103\n]\nat Google, due in part to its scalability.\n[\n104\n]\nNeural networks\nare also used as classifiers.\n[\n105\n]\nArtificial neural networks\nA neural network is an interconnected group of nodes, akin to the vast network of\nneurons\nin the\nhuman brain\n.\nAn artificial neural network is based on a collection of nodes also known as\nartificial neurons\n, which loosely model the\nneurons\nin a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the\nweight\ncrosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.\n[\n105\n]\nLearning algorithms for neural networks use\nlocal search\nto choose the weights that will get the right output for each input during training. The most common training technique is the\nbackpropagation\nalgorithm.\n[\n106\n]\nNeural networks learn to model complex relationships between inputs and outputs and\nfind patterns\nin data. In theory, a neural network can learn any function.\n[\n107\n]\nIn\nfeedforward neural networks\nthe signal passes in only one direction.\n[\n108\n]\nThe term\nperceptron\ntypically refers to a single-layer neural network.\n[\n109\n]\nIn contrast, deep learning uses many layers.\n[\n110\n]\nRecurrent neural networks\n(RNNs) feed the output signal back into the input, which allows short-term memories of previous input events.\nLong short-term memory\nnetworks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to the\nvanishing gradient problem\n.\n[\n111\n]\nConvolutional neural networks\n(CNNs) use layers of\nkernels\nto more efficiently process local patterns. This local processing is especially important in\nimage processing\n, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects.\n[\n112\n]\nDeep learning\nDeep learning\nis a subset of\nmachine learning\n, which is itself a subset of artificial intelligence.\n[\n113\n]\nDeep learning\nuses several layers of neurons between the network's inputs and outputs.\n[\n110\n]\nThe multiple layers can progressively extract higher-level features from the raw input. For example, in\nimage processing\n, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.\n[\n114\n]\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including\ncomputer vision\n,\nspeech recognition\n,\nnatural language processing\n,\nimage classification\n,\n[\n115\n]\nand others. The reason that deep learning performs so well in so many applications is not known as of 2021.\n[\n116\n]\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)\n[\ni\n]\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to\nGPUs\n) and the availability of vast amounts of training data, especially the giant\ncurated datasets\nused for benchmark testing, such as\nImageNet\n.\n[\nj\n]\nGPT\nGenerative pre-trained transformers\n(GPT) are\nlarge language models\n(LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large\ncorpus of text\nthat can be from the Internet. The pretraining consists of predicting the next\ntoken\n(a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called\nreinforcement learning from human feedback\n(RLHF). Current GPT models are prone to generating falsehoods called \"\nhallucinations\n\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.\n[\n124\n]\nSuch systems are used in\nchatbots\n, which allow people to ask a question or request a task in simple text.\n[\n125\n]\n[\n126\n]\nCurrent models and services include\nChatGPT\n,\nClaude\n,\nGemini\n,\nCopilot\n, and\nMeta AI\n.\n[\n127\n]\nMultimodal\nGPT models can process different types of data (\nmodalities\n) such as images, videos, sound, and text.\n[\n128\n]\nHardware and software\nMain articles:\nProgramming languages for artificial intelligence\nand\nHardware for artificial intelligence\nRaspberry Pi AI Kit\nIn the late 2010s,\ngraphics processing units\n(GPUs) that were increasingly designed with AI-specific enhancements and used with specialized\nTensorFlow\nsoftware had replaced previously used\ncentral processing unit\n(CPUs) as the dominant means for large-scale (commercial and academic)\nmachine learning\nmodels' training.\n[\n129\n]\nSpecialized\nprogramming languages\nsuch as\nProlog\nwere used in early AI research,\n[\n130\n]\nbut\ngeneral-purpose programming languages\nlike\nPython\nhave become predominant.\n[\n131\n]\nThe transistor density in\nintegrated circuits\nhas been observed to roughly double every 18 months—a trend known as\nMoore's law\n, named after the\nIntel\nco-founder\nGordon Moore\n, who first identified it. Improvements in\nGPUs\nhave been even faster,\n[\n132\n]\na trend sometimes called\nHuang's law\n,\n[\n133\n]\nnamed after\nNvidia\nco-founder and CEO\nJensen Huang\n.\nApplications\nMain article:\nApplications of artificial intelligence\nAI and machine learning technology is used in most of the essential applications of the 2020s, including:\nsearch engines\n(such as\nGoogle Search\n),\ntargeting online advertisements\n,\nrecommendation systems\n(offered by\nNetflix\n,\nYouTube\nor\nAmazon\n), driving\ninternet traffic\n,\ntargeted advertising\n(\nAdSense\n,\nFacebook\n),\nvirtual assistants\n(such as\nSiri\nor\nAlexa\n),\nautonomous vehicles\n(including\ndrones\n,\nADAS\nand\nself-driving cars\n),\nautomatic language translation\n(\nMicrosoft Translator\n,\nGoogle Translate\n),\nfacial recognition\n(\nApple\n's\nFaceID\nor\nMicrosoft\n's\nDeepFace\nand\nGoogle\n's\nFaceNet\n) and\nimage labeling\n(used by\nFacebook\n, Apple's\nPhotos\nand\nTikTok\n). The deployment of AI may be overseen by a\nchief automation officer\n(CAO).\nHealth and medicine\nMain article:\nArtificial intelligence in healthcare\nIt has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.\n[\n134\n]\nAlphaFold 2\n(2021) demonstrated the ability to approximate, in hours rather than months, the 3D\nstructure of a protein\n.\n[\n135\n]\nIn 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.\n[\n136\n]\nIn 2024, researchers used machine learning to accelerate the search for\nParkinson's disease\ndrug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of\nalpha-synuclein\n(the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.\n[\n137\n]\n[\n138\n]\nGames\nMain article:\nArtificial intelligence in video games\nGame playing\nprograms have been used since the 1950s to demonstrate and test AI's most advanced techniques.\n[\n139\n]\nDeep Blue\nbecame the first computer chess-playing system to beat a reigning world chess champion,\nGarry Kasparov\n, on 11 May 1997.\n[\n140\n]\nIn 2011, in a\nJeopardy!\nquiz show\nexhibition match,\nIBM\n's\nquestion answering system\n,\nWatson\n, defeated the two greatest\nJeopardy!\nchampions,\nBrad Rutter\nand\nKen Jennings\n, by a significant margin.\n[\n141\n]\nIn March 2016,\nAlphaGo\nwon 4 out of 5 games of\nGo\nin a match with Go champion\nLee Sedol\n, becoming the first\ncomputer Go\n-playing system to beat a professional Go player without\nhandicaps\n. Then, in 2017, it\ndefeated Ke Jie\n, who was the best Go player in the world.\n[\n142\n]\nOther programs handle\nimperfect-information\ngames, such as the\npoker\n-playing program\nPluribus\n.\n[\n143\n]\nDeepMind\ndeveloped increasingly generalistic\nreinforcement learning\nmodels, such as with\nMuZero\n, which could be trained to play chess, Go, or\nAtari\ngames.\n[\n144\n]\nIn 2019, DeepMind's AlphaStar achieved grandmaster level in\nStarCraft II\n, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.\n[\n145\n]\nIn 2021, an AI agent competed in a PlayStation\nGran Turismo\ncompetition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.\n[\n146\n]\nIn 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen\nopen-world\nvideo games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.\n[\n147\n]\nMathematics\nLarge language models, such as\nGPT-4\n,\nGemini\n,\nClaude\n,\nLlama\nor\nMistral\n, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of\nhallucinations\n. They sometimes need a large database of mathematical problems to learn from, but also methods such as\nsupervised\nfine-tuning\n[\n148\n]\nor trained\nclassifiers\nwith human-annotated data to improve answers for new problems and learn from corrections.\n[\n149\n]\nA February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.\n[\n150\n]\nOne technique to improve their performance involves training the models to produce correct\nreasoning\nsteps, rather than just the correct result.\n[\n151\n]\nThe\nAlibaba Group\ndeveloped a version of its\nQwen\nmodels called\nQwen2-Math\n, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.\n[\n152\n]\nIn January 2025, Microsoft proposed the technique\nrStar-Math\nthat leverages\nMonte Carlo tree search\nand step-by-step reasoning, enabling a relatively small language model like\nQwen-7B\nto solve 53% of the\nAIME\n2024 and 90% of the MATH benchmark problems.\n[\n153\n]\nAlternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as\nAlphaTensor\n,\nAlphaGeometry\n,\nAlphaProof\nand\nAlphaEvolve\n[\n154\n]\nall from\nGoogle DeepMind\n,\n[\n155\n]\nLlemma\nfrom\nEleutherAI\n[\n156\n]\nor\nJulius\n.\n[\n157\n]\nWhen natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as\nLean\nto define mathematical tasks. The experimental model\nGemini Deep Think\naccepts natural language prompts directly and achieved gold medal results in the\nInternational Math Olympiad\nof 2025.\n[\n158\n]\nSome models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.\n[\n159\n]\nTopological deep learning\nintegrates various\ntopological\napproaches.\nFinance\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.\n[\n160\n]\nAccording to Nicolas Firzli, director of the\nWorld Pensions & Investments Forum\n, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"\n[\n161\n]\nMilitary\nMain article:\nMilitary applications of artificial intelligence\nVarious countries are deploying AI military applications.\n[\n162\n]\nThe main applications enhance\ncommand and control\n, communications, sensors, integration and interoperability.\n[\n163\n]\nResearch is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and\nautonomous vehicles\n.\n[\n162\n]\nAI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions,\ntarget acquisition\n, coordination and deconfliction of distributed\nJoint Fires\nbetween networked combat vehicles, both human-operated and\nautonomous\n.\n[\n163\n]\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n[\n162\n]\n[\n164\n]\n[\n165\n]\n[\n166\n]\nGenerative AI\nVincent van Gogh\nin watercolour created by generative AI software\nThese paragraphs are an excerpt from\nGenerative artificial intelligence\n.\n[\nedit\n]\nGenerative artificial intelligence\n(Generative AI, or GenAI\n[\n167\n]\n) is a subfield of artificial intelligence that uses\ngenerative models\nto generate text,\nimages\n,\nvideos\n,\naudio\n,\nsoftware code\nor other forms of data.\n[\n168\n]\n[\n169\n]\nThese models\nlearn\nthe underlying patterns and structures of their\ntraining data\nand use them to produce new data\n[\n170\n]\n[\n171\n]\nin response to input, which often comes in the form of natural language\nprompts\n.\n[\n172\n]\n[\n173\n]\nThe prevalence of generative AI tools has increased significantly since the\nAI boom\nin the 2020s. This boom was made possible by improvements in\ndeep\nneural networks\n, particularly\nlarge language models\n(LLMs), which are based on the\ntransformer\narchitecture. Major tools include LLM-based\nchatbots\nsuch as\nChatGPT\n,\nClaude\n,\nCopilot\n,\nDeepSeek\n,\nGoogle Gemini\nand\nGrok\n;\ntext-to-image\nmodels such as\nStable Diffusion\n,\nMidjourney\n, and\nDALL-E\n; and\ntext-to-video\nmodels such as\nVeo\nand\nSora\n.\n[\n174\n]\n[\n175\n]\n[\n176\n]\nTechnology companies developing generative AI include\nAlibaba\n,\nAnthropic\n,\nBaidu\n,\nDeepSeek\n,\nGoogle\n,\nMeta AI\n,\nMicrosoft\n,\nMistral AI\n,\nOpenAI\n,\nPerplexity AI\n,\nxAI\n,\n[\n177\n]\nand\nYandex\n.\n[\n178\n]\nGenerative AI has been adopted in a variety of sectors, including software development,\n[\n179\n]\nhealthcare,\n[\n180\n]\nfinance,\n[\n181\n]\nentertainment,\n[\n182\n]\ncustomer service,\n[\n183\n]\nsales and marketing,\n[\n184\n]\nart, writing,\n[\n185\n]\nfashion,\n[\n186\n]\nand product design.\n[\n187\n]\nAgents\nMain article:\nAgentic AI\nAI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including\nvirtual assistants\n,\nchatbots\n,\nautonomous vehicles\n,\ngame-playing systems\n, and\nindustrial robotics\n. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.\n[\n188\n]\n[\n189\n]\n[\n190\n]\nWeb search\nMicrosoft introduced\nCopilot Search\nin February 2023 under the name\nBing Chat\n, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summaries\n[\n191\n]\nand step-by-step reasoning based of information from web publishers, ranked in Bing Search.\n[\n192\n]\nFor safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content.\n[\n193\n]\nGoogle officially pushed its AI Search at its Google I/O event on 20 May 2025.\n[\n194\n]\nIt keeps people looking at Google instead of clicking on a search result.\nAI Overviews\nuses Gemini 2.5 to provide contextual answers to user queries based on web content.\n[\n195\n]\nSexuality\nApplications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,\n[\n196\n]\nAI-integrated sex toys (e.g.,\nteledildonics\n),\n[\n197\n]\nAI-generated sexual education content,\n[\n198\n]\nand AI agents that simulate sexual and romantic partners (e.g.,\nReplika\n).\n[\n199\n]\nAI is also used for the production of non-consensual\ndeepfake pornography\n, raising significant ethical and legal concerns.\n[\n200\n]\nAI technologies have also been used to attempt to identify\nonline gender-based violence\nand online\nsexual grooming\nof minors.\n[\n201\n]\n[\n202\n]\nOther industry-specific tasks\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.\n[\n203\n]\nA few examples are\nenergy storage\n, medical diagnosis, military logistics, applications that predict the result of judicial decisions,\nforeign policy\n, or supply chain management.\nAI applications for evacuation and\ndisaster\nmanagement are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.\n[\n204\n]\n[\n205\n]\n[\n206\n]\nIn agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct\npredictive analytics\n, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nDuring the\n2024 Indian elections\n, US$50 million was spent on authorized AI-generated content, notably by creating\ndeepfakes\nof allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.\n[\n207\n]\nEthics\nMain article:\nEthics of artificial intelligence\nStreet art in Tel Aviv\n[\n208\n]\n[\n209\n]\nAI has potential benefits and potential risks.\n[\n210\n]\nAI may be able to advance science and find solutions for serious problems:\nDemis Hassabis\nof\nDeepMind\nhopes to \"solve intelligence, and then use that to solve everything else\".\n[\n211\n]\nHowever, as the use of AI has become widespread, several unintended consequences and risks have been identified.\n[\n212\n]\n[\n213\n]\nIn-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\n[\n214\n]\nRisks and harm\nPrivacy and copyright\nFurther information:\nInformation privacy\nand\nArtificial intelligence and copyright\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about\nprivacy\n,\nsurveillance\nand\ncopyright\n.\nAI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\nSensitive user data collected may include online activity records, geolocation data, video, or audio.\n[\n215\n]\nFor example, in order to build\nspeech recognition\nalgorithms,\nAmazon\nhas recorded millions of private conversations and allowed\ntemporary workers\nto listen to and transcribe some of them.\n[\n216\n]\nOpinions about this widespread surveillance range from those who see it as a\nnecessary evil\nto those for whom it is clearly\nunethical\nand a violation of the\nright to privacy\n.\n[\n217\n]\nAI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as\ndata aggregation\n,\nde-identification\nand\ndifferential privacy\n.\n[\n218\n]\nSince 2016, some privacy experts, such as\nCynthia Dwork\n, have begun to view privacy in terms of\nfairness\n.\nBrian Christian\nwrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"\n[\n219\n]\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"\nfair use\n\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".\n[\n220\n]\n[\n221\n]\nWebsite owners can indicate that they do not want their content scraped via a \"\nrobots.txt\n\" file.\n[\n222\n]\nHowever, some companies will scrape content regardless\n[\n223\n]\n[\n224\n]\nbecause the robots.txt file has no real authority. In 2023, leading authors (including\nJohn Grisham\nand\nJonathan Franzen\n) sued AI companies for using their work to train generative AI.\n[\n225\n]\n[\n226\n]\nAnother discussed approach is to envision a separate\nsui generis\nsystem of protection for creations generated by AI to ensure fair attribution and compensation for human authors.\n[\n227\n]\nDominance by tech giants\nThe commercial AI scene is dominated by\nBig Tech\ncompanies such as\nAlphabet Inc.\n,\nAmazon\n,\nApple Inc.\n,\nMeta Platforms\n, and\nMicrosoft\n.\n[\n228\n]\n[\n229\n]\n[\n230\n]\nSome of these players already own the vast majority of existing\ncloud infrastructure\nand\ncomputing\npower from\ndata centers\n, allowing them to entrench further in the marketplace.\n[\n231\n]\n[\n232\n]\nPower needs and environmental impacts\nSee also:\nEnvironmental impacts of artificial intelligence\nIn January 2024, the\nInternational Energy Agency\n(IEA) released\nElectricity 2024, Analysis and Forecast to 2026\n, forecasting electric power use.\n[\n233\n]\nThis is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.\n[\n234\n]\nProdigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.\n[\n235\n]\nA 2024\nGoldman Sachs\nResearch Paper,\nAI Data Centers and the Coming US Power Demand Surge\n, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.\n[\n236\n]\nData centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.\n[\n237\n]\nIn 2024, the\nWall Street Journal\nreported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.\n[\n238\n]\nNvidia\nCEO\nJensen Huang\nsaid nuclear power is a good option for the data centers.\n[\n239\n]\nIn September 2024,\nMicrosoft\nannounced an agreement with\nConstellation Energy\nto re-open the\nThree Mile Island\nnuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US\nNuclear Regulatory Commission\n. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US\nInflation Reduction Act\n.\n[\n240\n]\nThe US government and the state of Michigan are investing almost US$2 billion to reopen the\nPalisades Nuclear\nreactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of\nExelon\nwho was responsible for Exelon's spinoff of Constellation.\n[\n241\n]\nAfter the last approval in September 2023,\nTaiwan\nsuspended the approval of data centers north of\nTaoyuan\nwith a capacity of more than 5 MW in 2024, due to power supply shortages.\n[\n242\n]\nTaiwan aims to\nphase out nuclear power\nby 2025.\n[\n242\n]\nOn the other hand,\nSingapore\nimposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.\n[\n242\n]\nAlthough most nuclear plants in Japan have been shut down after the 2011\nFukushima nuclear accident\n, according to an October 2024\nBloomberg\narticle in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.\n[\n243\n]\nUbitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.\n[\n243\n]\nOn 1 November 2024, the\nFederal Energy Regulatory Commission\n(FERC) rejected an application submitted by\nTalen Energy\nfor approval to supply some electricity from the nuclear power station\nSusquehanna\nto Amazon's data center.\n[\n244\n]\nAccording to the Commission Chairman\nWillie L. Phillips\n, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.\n[\n244\n]\nIn 2025, a report prepared by the International Energy Agency estimated the\ngreenhouse gas emissions\nfrom the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but\nrebound effects\n(for example if people switch from public transport to autonomous cars) can reduce it.\n[\n245\n]\nMisinformation\nSee also:\nContent moderation\nYouTube\n,\nFacebook\nand others use\nrecommender systems\nto guide users to more content. These AI programs were given the goal of\nmaximizing\nuser engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose\nmisinformation\n,\nconspiracy theories\n, and extreme\npartisan\ncontent, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into\nfilter bubbles\nwhere they received multiple versions of the same misinformation.\n[\n246\n]\nThis convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.\n[\n247\n]\nThe AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.\n[\n248\n]\nIn the early 2020s,\ngenerative AI\nbegan to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,\n[\n249\n]\nwhile realistic AI-generated videos became feasible in the mid-2020s.\n[\n250\n]\n[\n251\n]\n[\n252\n]\nIt is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;\n[\n253\n]\none such potential malicious use is deepfakes for\ncomputational propaganda\n.\n[\n254\n]\nAI pioneer\nGeoffrey Hinton\nexpressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\n[\n255\n]\nThe ability to influence electorates has been proved in at least one study. This same study shows more inaccurate statements from the models when they advocate for candidates of the political right.\n[\n256\n]\nAI researchers at\nMicrosoft\n,\nOpenAI\n, universities and other organisations have suggested using \"\npersonhood credentials\n\" as a way to overcome online deception enabled by AI models.\n[\n257\n]\nAlgorithmic bias and fairness\nMain articles:\nAlgorithmic bias\nand\nFairness (machine learning)\nMachine learning applications can be\nbiased\n[\nk\n]\nif they learn from biased data.\n[\n259\n]\nThe developers may not be aware that the bias exists.\n[\n260\n]\nDiscriminatory behavior by some LLMs can be observed in their output.\n[\n261\n]\nBias can be introduced by the way\ntraining data\nis selected and by the way a model is deployed.\n[\n262\n]\n[\n259\n]\nIf a biased algorithm is used to make decisions that can seriously\nharm\npeople (as it can in\nmedicine\n,\nfinance\n,\nrecruitment\n,\nhousing\nor\npolicing\n) then the algorithm may cause\ndiscrimination\n.\n[\n263\n]\nThe field of\nfairness\nstudies how to prevent harms from algorithmic biases.\nOn 28 June 2015,\nGoogle Photos\n's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,\n[\n264\n]\na problem called \"sample size disparity\".\n[\n265\n]\nGoogle \"fixed\" this problem by preventing the system from labelling\nanything\nas a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.\n[\n266\n]\nCOMPAS\nis a commercial program widely used by\nU.S. courts\nto assess the likelihood of a\ndefendant\nbecoming a\nrecidivist\n. In 2016,\nJulia Angwin\nat\nProPublica\ndiscovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.\n[\n267\n]\nIn 2017, several researchers\n[\nl\n]\nshowed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.\n[\n269\n]\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".\n[\n270\n]\nMoritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"\n[\n271\n]\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as\nrecommendations\n, some of these \"recommendations\" will likely be racist.\n[\n272\n]\nThus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be\nbetter\nthan the past. It is descriptive rather than prescriptive.\n[\nm\n]\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.\n[\n265\n]\nThere are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is\ndistributive fairness\n, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative\nstereotypes\nor render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with\nanti-discrimination laws\n.\n[\n258\n]\nAt its 2022\nConference on Fairness, Accountability, and Transparency\n(ACM FAccT 2022), the\nAssociation for Computing Machinery\n, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\n[\ndubious\n–\ndiscuss\n]\n[\n274\n]\nLack of transparency\nSee also:\nExplainable AI\n,\nAlgorithmic transparency\n, and\nRight to explanation\nMany AI systems are so complex that their designers cannot explain how they reach their decisions.\n[\n275\n]\nParticularly with\ndeep neural networks\n, in which there are many non-\nlinear\nrelationships between inputs and outputs. But some popular explainability techniques exist.\n[\n276\n]\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a\nruler\nas \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.\n[\n277\n]\nAnother machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.\n[\n278\n]\nPeople who have been harmed by an algorithm's decision have a right to an explanation.\n[\n279\n]\nDoctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's\nGeneral Data Protection Regulation\nin 2016 included an explicit statement that this right exists.\n[\nn\n]\nIndustry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.\n[\n280\n]\nDARPA\nestablished the\nXAI\n(\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.\n[\n281\n]\nSeveral approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.\n[\n282\n]\nLIME can locally approximate a model's outputs with a simpler, interpretable model.\n[\n283\n]\nMultitask learning\nprovides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.\n[\n284\n]\nDeconvolution\n,\nDeepDream\nand other\ngenerative\nmethods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.\n[\n285\n]\nFor\ngenerative pre-trained transformers\n,\nAnthropic\ndeveloped a technique based on\ndictionary learning\nthat associates patterns of neuron activations with human-understandable concepts.\n[\n286\n]\nBad actors and weaponized AI\nMain articles:\nLethal autonomous weapon\n,\nArtificial intelligence arms race\n, and\nAI safety\nArtificial intelligence provides a number of tools that are useful to\nbad actors\n, such as\nauthoritarian governments\n,\nterrorists\n,\ncriminals\nor\nrogue states\n.\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.\n[\no\n]\nWidely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially\nweapons of mass destruction\n.\n[\n288\n]\nEven when used in conventional warfare, they currently cannot reliably choose targets and could potentially\nkill an innocent person\n.\n[\n288\n]\nIn 2014, 30 nations (including China) supported a ban on autonomous weapons under the\nUnited Nations\n'\nConvention on Certain Conventional Weapons\n, however the\nUnited States\nand others disagreed.\n[\n289\n]\nBy 2015, over fifty countries were reported to be researching battlefield robots.\n[\n290\n]\nAI tools make it easier for\nauthoritarian governments\nto efficiently control their citizens in several ways.\nFace\nand\nvoice recognition\nallow widespread\nsurveillance\n.\nMachine learning\n, operating this data, can\nclassify\npotential enemies of the state and prevent them from hiding.\nRecommendation systems\ncan precisely target\npropaganda\nand\nmisinformation\nfor maximum effect.\nDeepfakes\nand\ngenerative AI\naid in producing misinformation. Advanced AI can make authoritarian\ncentralized decision-making\nmore competitive than liberal and decentralized systems such as\nmarkets\n. It lowers the cost and difficulty of\ndigital warfare\nand\nadvanced spyware\n.\n[\n291\n]\nAll these technologies have been available since 2020 or earlier—AI\nfacial recognition systems\nare already being used for\nmass surveillance\nin China.\n[\n292\n]\n[\n293\n]\nThere are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.\n[\n294\n]\nTechnological unemployment\nMain articles:\nWorkplace impact of artificial intelligence\nand\nTechnological unemployment\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.\n[\n295\n]\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.\n[\n296\n]\nA survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term\nunemployment\n, but they generally agree that it could be a net benefit if\nproductivity\ngains are\nredistributed\n.\n[\n297\n]\nRisk estimates vary; for example, in the 2010s, Michael Osborne and\nCarl Benedikt Frey\nestimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".\n[\np\n]\n[\n299\n]\nThe methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.\n[\n295\n]\nIn April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.\n[\n300\n]\n[\n301\n]\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence;\nThe Economist\nstated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".\n[\n302\n]\nJobs at extreme risk range from\nparalegals\nto fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.\n[\n303\n]\nIn July 2025,\nFord\nCEO\nJim Farley\npredicted that \"artificial intelligence is going to replace literally half of all\nwhite-collar workers\nin the U.S.\"\n[\n304\n]\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by\nJoseph Weizenbaum\n, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.\n[\n305\n]\nExistential risk\nMain article:\nExistential risk from artificial intelligence\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist\nStephen Hawking\nstated, \"\nspell the end of the human race\n\".\n[\n306\n]\nThis scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.\n[\nq\n]\nThese sci-fi scenarios are misleading in several ways.\nFirst, AI does not require human-like\nsentience\nto be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher\nNick Bostrom\nargued that if one gives\nalmost any\ngoal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of an\nautomated paperclip factory\nthat destroys the world to get more iron for paperclips).\n[\n308\n]\nStuart Russell\ngives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"\n[\n309\n]\nIn order to be safe for humanity, a\nsuperintelligence\nwould have to be genuinely\naligned\nwith humanity's morality and values so that it is \"fundamentally on our side\".\n[\n310\n]\nSecond,\nYuval Noah Harari\nargues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like\nideologies\n,\nlaw\n,\ngovernment\n,\nmoney\nand the\neconomy\nare built on\nlanguage\n; they exist because there are stories that billions of people believe. The current prevalence of\nmisinformation\nsuggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.\n[\n311\n]\nGeoffrey Hinton said in 2025 that\nmodern AI\nis particularly \"good at persuasion\" and getting better all the time. He asks \"Suppose you wanted to invade the capital of the US. Do you have to go there and do it yourself? No. You just have to be good at persuasion.\"\n[\n312\n]\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.\n[\n313\n]\nPersonalities such as\nStephen Hawking\n,\nBill Gates\n, and\nElon Musk\n,\n[\n314\n]\nas well as AI pioneers such as\nYoshua Bengio\n,\nStuart Russell\n,\nDemis Hassabis\n, and\nSam Altman\n, have expressed concerns about existential risk from AI.\nIn May 2023,\nGeoffrey Hinton\nannounced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".\n[\n315\n]\nHe notably mentioned risks of an\nAI takeover\n,\n[\n316\n]\nand stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.\n[\n317\n]\nIn 2023, many leading AI experts endorsed\nthe joint statement\nthat \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\n[\n318\n]\nSome other researchers were more optimistic. AI pioneer\nJürgen Schmidhuber\ndid not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"\n[\n319\n]\nWhile the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"\n[\n320\n]\n[\n321\n]\nAndrew Ng\nalso argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"\n[\n322\n]\nYann LeCun\n\"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"\n[\n323\n]\nIn the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.\n[\n324\n]\nHowever, after 2016, the study of current and future risks and possible solutions became a serious area of research.\n[\n325\n]\nEthical machines and alignment\nMain articles:\nMachine ethics\n,\nAI safety\n,\nFriendly artificial intelligence\n,\nArtificial moral agents\n, and\nHuman Compatible\nSee also:\nHuman-AI interaction\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans.\nEliezer Yudkowsky\n, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\n[\n326\n]\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\n[\n327\n]\nThe field of machine ethics is also called computational morality,\n[\n327\n]\nand was founded at an\nAAAI\nsymposium in 2005.\n[\n328\n]\nOther approaches include\nWendell Wallach\n's \"artificial moral agents\"\n[\n329\n]\nand\nStuart J. Russell\n's\nthree principles\nfor developing provably beneficial machines.\n[\n330\n]\nOpen source\nSee also:\nLists of open-source artificial intelligence software\nActive organizations in the AI open-source community include\nHugging Face\n,\n[\n331\n]\nGoogle\n,\n[\n332\n]\nEleutherAI\nand\nMeta\n.\n[\n333\n]\nVarious AI models, such as\nLlama 2\n,\nMistral\nor\nStable Diffusion\n, have been made open-weight,\n[\n334\n]\n[\n335\n]\nmeaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely\nfine-tuned\n, which allows companies to specialize them with their own data and for their own use-case.\n[\n336\n]\nOpen-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate\nbioterrorism\n) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.\n[\n337\n]\nFrameworks\nArtificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the\nAlan Turing Institute\nand based on the SUM values, outlines four main ethical dimensions, defined as follows:\n[\n338\n]\n[\n339\n]\nRespect\nthe dignity of individual people\nConnect\nwith other people sincerely, openly, and inclusively\nCare\nfor the wellbeing of everyone\nProtect\nsocial values, justice, and the public interest\nOther developments in ethical frameworks include those decided upon during the\nAsilomar Conference\n, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;\n[\n340\n]\nhowever, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.\n[\n341\n]\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\n[\n342\n]\nThe\nUK AI Safety Institute\nreleased in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.\n[\n343\n]\nRegulation\nMain articles:\nRegulation of artificial intelligence\n,\nRegulation of algorithms\n, and\nAI safety\nThe first global\nAI Safety Summit\nwas held in the United Kingdom in November 2023 with a declaration calling for international cooperation.\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.\n[\n344\n]\nThe regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.\n[\n345\n]\nAccording to AI Index at\nStanford\n, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.\n[\n346\n]\n[\n347\n]\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.\n[\n348\n]\nMost EU member states had released national AI strategies, as had\nCanada\n, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.\n[\n348\n]\nThe\nGlobal Partnership on Artificial Intelligence\nwas launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.\n[\n348\n]\nHenry Kissinger\n,\nEric Schmidt\n, and\nDaniel Huttenlocher\npublished a joint statement in November 2021 calling for a government commission to regulate AI.\n[\n349\n]\nIn 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.\n[\n350\n]\nIn 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.\n[\n351\n]\nOn 1 August 2024, the EU\nArtificial Intelligence Act\nentered into force, establishing the first comprehensive EU-wide AI regulation.\n[\n352\n]\nIn 2024, the\nCouncil of Europe\ncreated the first international legally binding treaty on AI, called the \"\nFramework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\n\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.\n[\n353\n]\nIn a 2022\nIpsos\nsurvey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".\n[\n346\n]\nA 2023\nReuters\n/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.\n[\n354\n]\nIn a 2023\nFox News\npoll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".\n[\n355\n]\n[\n356\n]\nIn November 2023, the first global\nAI Safety Summit\nwas held in\nBletchley Park\nin the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.\n[\n357\n]\n28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.\n[\n358\n]\n[\n359\n]\nIn May 2024 at the\nAI Seoul Summit\n, 16 global AI tech companies agreed to safety commitments on the development of AI.\n[\n360\n]\n[\n361\n]\nHistory\nMain article:\nHistory of artificial intelligence\nFor a chronological guide, see\nTimeline of artificial intelligence\n.\nIn 2024, AI patents in China and the US numbered more than three-fourths of AI patents worldwide.\n[\n362\n]\nThough China had more AI patents, the US had 35% more patents per AI patent-applicant company than China.\n[\n362\n]\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to\nAlan Turing\n's\ntheory of computation\n, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.\n[\n363\n]\n[\n364\n]\nThis, along with concurrent discoveries in\ncybernetics\n,\ninformation theory\nand\nneurobiology\n, led researchers to consider the possibility of building an \"electronic brain\".\n[\nr\n]\nThey developed several areas of research that would become part of AI,\n[\n366\n]\nsuch as\nMcCulloch\nand\nPitts\ndesign for \"artificial neurons\" in 1943,\n[\n117\n]\nand Turing's influential 1950 paper '\nComputing Machinery and Intelligence\n', which introduced the\nTuring test\nand showed that \"machine intelligence\" was plausible.\n[\n367\n]\n[\n364\n]\nThe field of AI research was founded at\na workshop\nat\nDartmouth College\nin 1956.\n[\ns\n]\n[\n6\n]\nThe attendees became the leaders of AI research in the 1960s.\n[\nt\n]\nThey and their students produced programs that the press described as \"astonishing\":\n[\nu\n]\ncomputers were learning\ncheckers\nstrategies, solving word problems in algebra, proving\nlogical theorems\nand speaking English.\n[\nv\n]\n[\n7\n]\nArtificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.\n[\n364\n]\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with\ngeneral intelligence\nand considered this the goal of their field.\n[\n371\n]\nIn 1965\nHerbert Simon\npredicted, \"machines will be capable, within twenty years, of doing any work a man can do\".\n[\n372\n]\nIn 1967\nMarvin Minsky\nagreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".\n[\n373\n]\nThey had, however, underestimated the difficulty of the problem.\n[\nw\n]\nIn 1974, both the U.S. and British governments cut off exploratory research in response to the\ncriticism\nof\nSir James Lighthill\n[\n375\n]\nand ongoing pressure from the U.S. Congress to\nfund more productive projects\n.\n[\n376\n]\nMinsky\nand\nPapert\n's book\nPerceptrons\nwas understood as proving that\nartificial neural networks\nwould never be useful for solving real-world tasks, thus discrediting the approach altogether.\n[\n377\n]\nThe \"\nAI winter\n\", a period when obtaining funding for AI projects was difficult, followed.\n[\n9\n]\nIn the early 1980s, AI research was revived by the commercial success of\nexpert systems\n,\n[\n378\n]\na form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's\nfifth generation computer\nproject inspired the U.S. and British governments to restore funding for\nacademic research\n.\n[\n8\n]\nHowever, beginning with the collapse of the\nLisp Machine\nmarket in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\n[\n10\n]\nUp to this point, most of AI's funding had gone to projects that used high-level\nsymbols\nto represent\nmental objects\nlike plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially\nperception\n,\nrobotics\n,\nlearning\nand\npattern recognition\n,\n[\n379\n]\nand began to look into \"sub-symbolic\" approaches.\n[\n380\n]\nRodney Brooks\nrejected \"representation\" in general and focussed directly on engineering machines that move and survive.\n[\nx\n]\nJudea Pearl\n,\nLotfi Zadeh\n, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.\n[\n87\n]\n[\n385\n]\nBut the most important development was the revival of \"\nconnectionism\n\", including neural network research, by\nGeoffrey Hinton\nand others.\n[\n386\n]\nIn 1990,\nYann LeCun\nsuccessfully showed that\nconvolutional neural networks\ncan recognize handwritten digits, the first of many successful applications of neural networks.\n[\n387\n]\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"\nnarrow\n\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as\nstatistics\n,\neconomics\nand\nmathematics\n).\n[\n388\n]\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the\nAI effect\n).\n[\n389\n]\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of\nartificial general intelligence\n(or \"AGI\"), which had several well-funded institutions by the 2010s.\n[\n68\n]\nDeep learning\nbegan to dominate industry benchmarks in 2012 and was adopted throughout the field.\n[\n11\n]\nFor many specific tasks, other methods were abandoned.\n[\ny\n]\nDeep learning's success was based on both hardware improvements (\nfaster computers\n,\n[\n391\n]\ngraphics processing units\n,\ncloud computing\n[\n392\n]\n) and access to\nlarge amounts of data\n[\n393\n]\n(including curated datasets,\n[\n392\n]\nsuch as\nImageNet\n). Deep learning's success led to an enormous increase in interest and funding in AI.\n[\nz\n]\nThe amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.\n[\n348\n]\nThe number of Google searches for the term \"AI\" accelerated in 2022.\nIn 2016, issues of\nfairness\nand the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The\nalignment problem\nbecame a serious field of academic study.\n[\n325\n]\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015,\nAlphaGo\n, developed by\nDeepMind\n, beat the world champion\nGo player\n. The program taught only the game's rules and developed a strategy by itself.\nGPT-3\nis a\nlarge language model\nthat was released in 2020 by\nOpenAI\nand is capable of generating high-quality human-like text.\n[\n394\n]\nChatGPT\n, launched on 30 November 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.\n[\n395\n]\nIt marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.\n[\n396\n]\nThese programs, and others, inspired an aggressive\nAI boom\n, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".\n[\n397\n]\nAbout 800,000 \"AI\"-related U.S. job openings existed in 2022.\n[\n398\n]\nAccording to PitchBook research, 22% of newly funded\nstartups\nin 2024 claimed to be AI companies.\n[\n399\n]\nPhilosophy\nMain article:\nPhilosophy of artificial intelligence\nPhilosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.\n[\n400\n]\nAnother major focus has been whether machines can be conscious, and the associated ethical implications.\n[\n401\n]\nMany other topics in philosophy are relevant to AI, such as\nepistemology\nand\nfree will\n.\n[\n402\n]\nRapid advancements have intensified public discussions on the philosophy and\nethics of AI\n.\n[\n401\n]\nDefining artificial intelligence\nSee also:\nSynthetic intelligence\n,\nIntelligent agent\n,\nArtificial mind\n,\nVirtual intelligence\n, and\nDartmouth workshop\nAlan Turing\nwrote in 1950 \"I propose to consider the question 'can machines think'?\"\n[\n403\n]\nHe advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".\n[\n403\n]\nHe devised the\nTuring test\n, which measures the ability of a machine to simulate human conversation.\n[\n367\n]\nSince we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that\nwe can not determine these things about other people\nbut \"it is usual to have a polite convention that everyone thinks.\"\n[\n404\n]\nThe Turing test can provide some evidence of intelligence, but it penalizes non-human intelligent behavior.\n[\n405\n]\nRussell\nand\nNorvig\nagree with Turing that intelligence must be defined in terms of external behavior, not internal structure.\n[\n1\n]\nHowever, they are critical that the test requires the machine to imitate humans. \"\nAeronautical engineering\ntexts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like\npigeons\nthat they can fool other pigeons.\n'\n\"\n[\n406\n]\nAI founder\nJohn McCarthy\nagreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".\n[\n407\n]\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".\n[\n408\n]\nAnother AI founder,\nMarvin Minsky\n, similarly describes it as \"the ability to solve hard problems\".\n[\n409\n]\nThe leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.\n[\n1\n]\nThese definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine – and no other philosophical discussion is required, or may not even be possible.\nAnother definition has been adopted by Google,\n[\n410\n]\na major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\nAs a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself\n[\n411\n]\nincluding discussing the many AI narratives and myths to be found within societal, political and academic discourses.\n[\n412\n]\nSimilarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,\n[\n413\n]\nwith many companies during the early 2020s AI boom using the term as a marketing\nbuzzword\n, often even if they did \"not actually use AI in a material way\".\n[\n414\n]\nThere has been debate over whether\nlarge language models\nexhibit genuine intelligence or merely simulate it by\nimitating human text\n.\n[\n415\n]\nEvaluating approaches to AI\nNo established unifying theory or\nparadigm\nhas guided AI research for most of its history.\n[\naa\n]\nThe unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly\nsub-symbolic\n,\nsoft\nand\nnarrow\n. Critics argue that these questions may have to be revisited by future generations of AI researchers.\nSymbolic AI and its limits\nSymbolic AI\n(or \"\nGOFAI\n\")\n[\n417\n]\nsimulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the\nphysical symbol systems hypothesis\n: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"\n[\n418\n]\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or\ncommonsense reasoning\n.\nMoravec's paradox\nis the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.\n[\n419\n]\nPhilosopher\nHubert Dreyfus\nhad\nargued\nsince the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.\n[\n420\n]\nAlthough his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.\n[\nab\n]\n[\n16\n]\nThe issue is not resolved:\nsub-symbolic\nreasoning can make many of the same inscrutable mistakes that human intuition does, such as\nalgorithmic bias\n. Critics such as\nNoam Chomsky\nargue continuing research into symbolic AI will still be necessary to attain general intelligence,\n[\n422\n]\n[\n423\n]\nin part because sub-symbolic AI is a move away from\nexplainable AI\n: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of\nneuro-symbolic artificial intelligence\nattempts to bridge the two approaches.\nNeat vs. scruffy\nMain article:\nNeats and scruffies\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as\nlogic\n,\noptimization\n, or\nneural networks\n). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,\n[\n424\n]\nbut eventually was seen as irrelevant. Modern AI has elements of both.\nSoft vs. hard computing\nMain article:\nSoft computing\nFinding a provably correct or optimal solution is\nintractable\nfor many important problems.\n[\n15\n]\nSoft computing is a set of techniques, including\ngenetic algorithms\n,\nfuzzy logic\nand neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\nNarrow vs. general AI\nMain articles:\nWeak artificial intelligence\nand\nArtificial general intelligence\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and\nsuperintelligence\ndirectly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.\n[\n425\n]\n[\n426\n]\nGeneral intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\nMachine consciousness, sentience, and mind\nMain articles:\nPhilosophy of artificial intelligence\nand\nArtificial consciousness\nThere is no settled consensus in\nphilosophy of mind\non whether a machine can have a\nmind\n,\nconsciousness\nand\nmental states\nin the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence.\nRussell\nand\nNorvig\nadd that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"\n[\n427\n]\nHowever, the question has become central to the philosophy of mind. It is also typically the central question at issue in\nartificial intelligence in fiction\n.\nConsciousness\nMain articles:\nHard problem of consciousness\nand\nTheory of mind\nDavid Chalmers\nidentified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.\n[\n428\n]\nThe easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this\nfeels\nor why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human\ninformation processing\nis easy to explain, human\nsubjective experience\nis difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to\nknow what red looks like\n.\n[\n429\n]\nComputationalism and functionalism\nMain articles:\nComputational theory of mind\nand\nFunctionalism (philosophy of mind)\nComputationalism is the position in the\nphilosophy of mind\nthat the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the\nmind–body problem\n. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers\nJerry Fodor\nand\nHilary Putnam\n.\n[\n430\n]\nPhilosopher\nJohn Searle\ncharacterized this position as \"\nstrong AI\n\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"\n[\nac\n]\nSearle challenges this claim with his\nChinese room\nargument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.\n[\n434\n]\nAI welfare and rights\nIt is difficult or impossible to reliably evaluate whether an advanced\nAI is sentient\n(has the ability to feel), and if so, to what degree.\n[\n435\n]\nBut if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.\n[\n436\n]\n[\n437\n]\nSapience\n(a set of capacities related to high intelligence, such as discernment or\nself-awareness\n) may provide another moral basis for AI rights.\n[\n436\n]\nRobot rights\nare also sometimes proposed as a practical way to integrate autonomous agents into society.\n[\n438\n]\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.\n[\n439\n]\nCritics argued in 2018 that granting rights to AI systems would downplay the importance of\nhuman rights\n, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.\n[\n440\n]\n[\n441\n]\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a\nmoral blind spot\nanalogous to\nslavery\nor\nfactory farming\n, which could lead to\nlarge-scale suffering\nif sentient AI is created and carelessly exploited.\n[\n437\n]\n[\n436\n]\nFuture\nSuperintelligence and the singularity\nA\nsuperintelligence\nis a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.\n[\n426\n]\nIf research into\nartificial general intelligence\nproduced sufficiently intelligent software, it might be able to\nreprogram and improve itself\n. The improved software would be even better at improving itself, leading to what\nI. J. Good\ncalled an \"\nintelligence explosion\n\" and\nVernor Vinge\ncalled a \"\nsingularity\n\".\n[\n442\n]\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an\nS-shaped curve\n, slowing when they reach the physical limits of what the technology can do.\n[\n443\n]\nTranshumanism\nMain article:\nTranshumanism\nRobot designer\nHans Moravec\n, cyberneticist\nKevin Warwick\nand inventor\nRay Kurzweil\nhave predicted that humans and machines may merge in the future into\ncyborgs\nthat are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of\nAldous Huxley\nand\nRobert Ettinger\n.\n[\n444\n]\nEdward Fredkin\nargues that \"artificial intelligence is the next step in evolution\", an idea first proposed by\nSamuel Butler\n's \"\nDarwin among the Machines\n\" as far back as 1863, and expanded upon by\nGeorge Dyson\nin his 1998 book\nDarwin Among the Machines: The Evolution of Global Intelligence\n.\n[\n445\n]\nIn fiction\nMain article:\nArtificial intelligence in fiction\nThe word \"robot\" itself was coined by\nKarel Čapek\nin his 1921 play\nR.U.R.\n, the title standing for \"Rossum's Universal Robots\".\nThought-capable artificial beings have appeared as storytelling devices since antiquity,\n[\n446\n]\nand have been a persistent theme in\nscience fiction\n.\n[\n447\n]\nA common\ntrope\nin these works began with\nMary Shelley\n's\nFrankenstein\n, where a human creation becomes a threat to its masters. This includes such works as\nArthur C. Clarke's\nand\nStanley Kubrick's\n2001: A Space Odyssey\n(both 1968), with\nHAL 9000\n, the murderous computer in charge of the\nDiscovery One\nspaceshi",
      "scraped_at": "2025-12-16T17:26:38.120667",
      "status": "success",
      "content_length": 231770,
      "topic": "ai_basics"
    },
    {
      "title": "Machine learning - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Machine_learning_model",
      "content": "Machine learning - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nHistory\n2\nRelationships to other fields\nToggle Relationships to other fields subsection\n2.1\nArtificial intelligence\n2.2\nData compression\n2.3\nData mining\n2.4\nGeneralization\n2.5\nStatistics\n2.6\nStatistical physics\n3\nTheory\n4\nApproaches\nToggle Approaches subsection\n4.1\nSupervised learning\n4.2\nUnsupervised learning\n4.3\nSemi-supervised learning\n4.4\nReinforcement learning\n4.5\nDimensionality reduction\n4.6\nOther types\n4.6.1\nSelf-learning\n4.6.2\nFeature learning\n4.6.3\nSparse dictionary learning\n4.6.4\nAnomaly detection\n4.6.5\nRobot learning\n4.6.6\nAssociation rules\n5\nModels\nToggle Models subsection\n5.1\nArtificial neural networks\n5.2\nDecision trees\n5.3\nRandom forest regression\n5.4\nSupport-vector machines\n5.5\nRegression analysis\n5.6\nBayesian networks\n5.7\nGaussian processes\n5.8\nGenetic algorithms\n5.9\nBelief functions\n5.10\nRule-based models\n5.11\nTraining models\n5.11.1\nFederated learning\n6\nApplications\n7\nLimitations\nToggle Limitations subsection\n7.1\nExplainability\n7.2\nOverfitting\n7.3\nOther limitations and vulnerabilities\n8\nModel assessments\n9\nEthics\nToggle Ethics subsection\n9.1\nBias\n9.2\nFinancial incentives\n10\nHardware\nToggle Hardware subsection\n10.1\nTensor Processing Units (TPUs)\n10.2\nNeuromorphic computing\n10.2.1\nPhysical neural networks\n10.3\nEmbedded machine learning\n11\nSoftware\nToggle Software subsection\n11.1\nFree and open-source software\n11.2\nProprietary software with free and open-source editions\n11.3\nProprietary software\n12\nJournals\n13\nConferences\n14\nSee also\n15\nReferences\n16\nSources\n17\nFurther reading\n18\nExternal links\nToggle the table of contents\nMachine learning\n88 languages\nAfrikaans\nالعربية\nঅসমীয়া\nAzərbaycanca\nتۆرکجه\nবাংলা\n閩南語 / Bân-lâm-gí\nБашҡортса\nБеларуская\nभोजपुरी\nБългарски\nབོད་ཡིག\nBosanski\nCatalà\nČeština\nCymraeg\nDansk\nالدارجة\nDeutsch\nEesti\nΕλληνικά\nEspañol\nEsperanto\nEuskara\nفارسی\nFrançais\nGaelg\nGalego\n한국어\nՀայերեն\nहिन्दी\nIdo\nBahasa Indonesia\nIsiZulu\nÍslenska\nItaliano\nעברית\nJawa\nಕನ್ನಡ\nქართული\nКыргызча\nLatviešu\nLietuvių\nLigure\nMagyar\nМакедонски\nമലയാളം\nमराठी\nBahasa Melayu\nМонгол\nNederlands\n日本語\nNorsk bokmål\nNorsk nynorsk\nOccitan\nଓଡ଼ିଆ\nOʻzbekcha / ўзбекча\nਪੰਜਾਬੀ\nپنجابی\nپښتو\nPolski\nPortuguês\nQaraqalpaqsha\nRomână\nRuna Simi\nРусский\nᱥᱟᱱᱛᱟᱲᱤ\nShqip\nSimple English\nSlovenščina\nکوردی\nСрпски / srpski\nSrpskohrvatski / српскохрватски\nSuomi\nSvenska\nTagalog\nதமிழ்\nతెలుగు\nไทย\nTürkçe\nУкраїнська\nاردو\nئۇيغۇرچە / Uyghurche\nTiếng Việt\nVõro\n吴语\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikimedia Commons\nWikiquote\nWikiversity\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\n(Redirected from\nMachine learning model\n)\nStudy of algorithms that improve automatically through experience\nFor the journal, see\nMachine Learning (journal)\n.\n\"Statistical learning\" redirects here. For statistical learning in linguistics, see\nStatistical learning in language acquisition\n.\nPart of a series on\nMachine learning\nand\ndata mining\nParadigms\nSupervised learning\nUnsupervised learning\nSemi-supervised learning\nSelf-supervised learning\nReinforcement learning\nMeta-learning\nOnline learning\nBatch learning\nCurriculum learning\nRule-based learning\nNeuro-symbolic AI\nNeuromorphic engineering\nQuantum machine learning\nProblems\nClassification\nGenerative modeling\nRegression\nClustering\nDimensionality reduction\nDensity estimation\nAnomaly detection\nData cleaning\nAutoML\nAssociation rules\nSemantic analysis\nStructured prediction\nFeature engineering\nFeature learning\nLearning to rank\nGrammar induction\nOntology learning\nMultimodal learning\nSupervised learning\n(\nclassification\n•\nregression\n)\nApprenticeship learning\nDecision trees\nEnsembles\nBagging\nBoosting\nRandom forest\nk\n-NN\nLinear regression\nNaive Bayes\nArtificial neural networks\nLogistic regression\nPerceptron\nRelevance vector machine (RVM)\nSupport vector machine (SVM)\nClustering\nBIRCH\nCURE\nHierarchical\nk\n-means\nFuzzy\nExpectation–maximization (EM)\nDBSCAN\nOPTICS\nMean shift\nDimensionality reduction\nFactor analysis\nCCA\nICA\nLDA\nNMF\nPCA\nPGD\nt-SNE\nSDL\nStructured prediction\nGraphical models\nBayes net\nConditional random field\nHidden Markov\nAnomaly detection\nRANSAC\nk\n-NN\nLocal outlier factor\nIsolation forest\nNeural networks\nAutoencoder\nDeep learning\nFeedforward neural network\nRecurrent neural network\nLSTM\nGRU\nESN\nreservoir computing\nBoltzmann machine\nRestricted\nGAN\nDiffusion model\nSOM\nConvolutional neural network\nU-Net\nLeNet\nAlexNet\nDeepDream\nNeural field\nNeural radiance field\nPhysics-informed neural networks\nTransformer\nVision\nMamba\nSpiking neural network\nMemtransistor\nElectrochemical RAM\n(ECRAM)\nReinforcement learning\nQ-learning\nPolicy gradient\nSARSA\nTemporal difference (TD)\nMulti-agent\nSelf-play\nLearning with humans\nActive learning\nCrowdsourcing\nHuman-in-the-loop\nMechanistic interpretability\nRLHF\nModel diagnostics\nCoefficient of determination\nConfusion matrix\nLearning curve\nROC curve\nMathematical foundations\nKernel machines\nBias–variance tradeoff\nComputational learning theory\nEmpirical risk minimization\nOccam learning\nPAC learning\nStatistical learning\nVC theory\nTopological deep learning\nJournals and conferences\nAAAI\nECML PKDD\nNeurIPS\nICML\nICLR\nIJCAI\nML\nJMLR\nRelated articles\nGlossary of artificial intelligence\nList of datasets for machine-learning research\nList of datasets in computer vision and image processing\nOutline of machine learning\nv\nt\ne\nPart of\na series\non\nArtificial intelligence (AI)\nMajor goals\nArtificial general intelligence\nIntelligent agent\nRecursive self-improvement\nPlanning\nComputer vision\nGeneral game playing\nKnowledge representation\nNatural language processing\nRobotics\nAI safety\nApproaches\nMachine learning\nSymbolic\nDeep learning\nBayesian networks\nEvolutionary algorithms\nHybrid intelligent systems\nSystems integration\nOpen-source\nApplications\nBioinformatics\nDeepfake\nEarth sciences\nFinance\nGenerative AI\nArt\nAudio\nMusic\nGovernment\nHealthcare\nMental health\nIndustry\nSoftware development\nTranslation\nMilitary\nPhysics\nProjects\nPhilosophy\nAI alignment\nArtificial consciousness\nThe bitter lesson\nChinese room\nFriendly AI\nEthics\nExistential risk\nTuring test\nUncanny valley\nHuman–AI interaction\nHistory\nTimeline\nProgress\nAI winter\nAI boom\nAI bubble\nControversies\nDeepfake pornography\nTaylor Swift deepfake pornography controversy\nGoogle Gemini image generation controversy\nPause Giant AI Experiments\nRemoval of Sam Altman from OpenAI\nStatement on AI Risk\nTay (chatbot)\nThéâtre D'opéra Spatial\nVoiceverse NFT plagiarism scandal\nGlossary\nGlossary\nv\nt\ne\nMachine learning\n(\nML\n) is a\nfield of study\nin\nartificial intelligence\nconcerned with the development and study of\nstatistical algorithms\nthat can learn from\ndata\nand\ngeneralise\nto unseen data, and thus perform\ntasks\nwithout explicit\ninstructions\n.\n[\n1\n]\nWithin a subdiscipline in machine learning, advances in the field of\ndeep learning\nhave allowed\nneural networks\n, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\nML finds application in many fields, including\nnatural language processing\n,\ncomputer vision\n,\nspeech recognition\n,\nemail filtering\n,\nagriculture\n, and\nmedicine\n. The application of ML to business problems is known as\npredictive analytics\n.\nStatistics\nand\nmathematical optimisation\n(mathematical programming) methods comprise the foundations of machine learning.\nData mining\nis a related field of study, focusing on\nexploratory data analysis\n(EDA) via\nunsupervised learning\n.\n[\n3\n]\n[\n4\n]\nFrom a theoretical viewpoint,\nprobably approximately correct learning\nprovides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as\nempirical risk minimisation\nunder this framework.\nHistory\n[\nedit\n]\nSee also:\nTimeline of machine learning\nThe term\nmachine learning\nwas coined in 1959 by\nArthur Samuel\n, an\nIBM\nemployee and pioneer in the field of\ncomputer gaming\nand\nartificial intelligence\n.\n[\n5\n]\n[\n6\n]\nThe synonym\nself-teaching computers\nwas also used in this time period.\n[\n7\n]\n[\n8\n]\nThe earliest machine learning program was introduced in the 1950s when\nArthur Samuel\ninvented a\ncomputer program\nthat calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.\n[\n9\n]\nIn 1949,\nCanadian\npsychologist\nDonald Hebb\npublished the book\nThe Organization of Behavior\n, in which he introduced a\ntheoretical neural structure\nformed by certain interactions among\nnerve cells\n.\n[\n10\n]\nHebb's model\nof\nneurons\ninteracting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or\nartificial neurons\nused by computers to communicate data.\n[\n9\n]\nOther researchers who have studied human\ncognitive systems\ncontributed to the modern machine learning technologies as well, including logician\nWalter Pitts\nand\nWarren McCulloch\n, who proposed the early mathematical models of neural networks to come up with\nalgorithms\nthat mirror human thought processes.\n[\n9\n]\nBy the early 1960s, an experimental \"learning machine\" with\npunched tape\nmemory, called Cybertron, had been developed by\nRaytheon Company\nto analyse\nsonar\nsignals,\nelectrocardiograms\n, and speech patterns using rudimentary\nreinforcement learning\n. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"\ngoof\n\" button to cause it to reevaluate incorrect decisions.\n[\n11\n]\nA representative book on research into machine learning during the 1960s was\nNils Nilsson\n's book on Learning Machines, dealing mostly with machine learning for pattern classification.\n[\n12\n]\nInterest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.\n[\n13\n]\nIn 1981, a report was given on using teaching strategies so that an\nartificial neural network\nlearns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.\n[\n14\n]\nTom M. Mitchell\nprovided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience\nE\nwith respect to some class of tasks\nT\nand performance measure\nP\nif its performance at tasks in\nT\n, as measured by\nP\n,  improves with experience\nE\n.\"\n[\n15\n]\nThis definition of the tasks in which machine learning is concerned offers a fundamentally\noperational definition\nrather than defining the field in cognitive terms. This follows\nAlan Turing\n's proposal in his paper \"\nComputing Machinery and Intelligence\n\", in which the question, \"Can machines think?\", is replaced with the question, \"Can machines do what we (as thinking entities) can do?\".\n[\n16\n]\nModern-day Machine Learning algorithms are broken into 3 algorithm types: Supervised Learning Algorithms, Unsupervised Learning Algorithms, and Reinforcement Learning Algorithms.\n[\n17\n]\nCurrent Supervised Learning Algorithms have objectives of classification and regression.\nCurrent Unsupervised Learning Algorithms have objectives of clustering, dimensionality reduction, and association rule.\nCurrent Reinforcement Learning Algorithms focus on decisions that must be made with respect to some previous, unknown time and are broken down to either be studies of model-based methods or model-free methods.\nIn 2014 Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis.\n[\n18\n]\nBy 2016 AlphaGo obtained victory against top human players using reinforcement learning techniques.\n[\n19\n]\nRelationships to other fields\n[\nedit\n]\nArtificial intelligence\n[\nedit\n]\nDeep learning\nis a subset of machine learning, which is itself a subset of\nartificial intelligence\n.\n[\n20\n]\nAs a scientific endeavour, machine learning grew out of the quest for\nartificial intelligence\n(AI). In the early days of AI as an\nacademic discipline\n, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"\nneural networks\n\"; these were mostly\nperceptrons\nand\nother models\nthat were later found to be reinventions of the\ngeneralised linear models\nof statistics.\n[\n21\n]\nProbabilistic reasoning\nwas also employed, especially in\nautomated medical diagnosis\n.\n[\n22\n]\n: 488\nHowever, an increasing emphasis on the\nlogical, knowledge-based approach\ncaused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.\n[\n22\n]\n: 488\nBy 1980,\nexpert systems\nhad come to dominate AI, and statistics was out of favour.\n[\n23\n]\nWork on symbolic/knowledge-based learning did continue within AI, leading to\ninductive logic programming\n(ILP), but the more statistical line of research was now outside the field of AI proper, in\npattern recognition\nand\ninformation retrieval\n.\n[\n22\n]\n: 708–710, 755\nNeural networks research had been abandoned by AI and\ncomputer science\naround the same time. This line, too, was continued outside the AI/CS field, as \"\nconnectionism\n\", by researchers from other disciplines, including\nJohn Hopfield\n,\nDavid Rumelhart\n, and\nGeoffrey Hinton\n. Their main success came in the mid-1980s with the reinvention of\nbackpropagation\n.\n[\n22\n]\n: 25\nMachine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the\nsymbolic approaches\nit had inherited from AI, and toward methods and models borrowed from statistics,\nfuzzy logic\n, and\nprobability theory\n.\n[\n23\n]\nData compression\n[\nedit\n]\nThis section is an excerpt from\nData compression § Machine learning\n.\n[\nedit\n]\nThere is a close connection between machine learning and compression. A system that predicts the\nposterior probabilities\nof a sequence given its entire history can be used for optimal data compression (by using\narithmetic coding\non the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".\n[\n24\n]\n[\n25\n]\n[\n26\n]\nAn alternative view can show compression algorithms implicitly map strings into implicit\nfeature space vectors\n, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.\n[\n27\n]\nAccording to\nAIXI\ntheory, a connection more directly explained in\nHutter Prize\n, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.\nExamples of AI-powered audio/video compression software include\nNVIDIA Maxine\n, AIVC.\n[\n28\n]\nExamples of software that can perform AI-powered image compression include\nOpenCV\n,\nTensorFlow\n,\nMATLAB\n's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.\n[\n29\n]\nIn\nunsupervised machine learning\n,\nk-means clustering\ncan be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as\nimage compression\n.\n[\n30\n]\nData compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the\ncentroid\nof its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in\nimage\nand\nsignal processing\n, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.\n[\n31\n]\nLarge language models\n(LLMs) are also efficient lossless data compressors on some data sets, as demonstrated by\nDeepMind\n's research with the Chinchilla 70B model. Developed by DeepMind, Chinchilla 70B effectively compressed data, outperforming conventional methods such as\nPortable Network Graphics\n(PNG) for images and\nFree Lossless Audio Codec\n(FLAC) for audio. It achieved compression of image and audio data to 43.4% and 16.4% of their original sizes, respectively. There is, however, some reason to be concerned that the data set used for testing overlaps the LLM training data set, making it possible that the Chinchilla 70B model is only an efficient compression tool on data it has already been trained on.\n[\n32\n]\n[\n33\n]\nData mining\n[\nedit\n]\nMachine learning and\ndata mining\noften employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on\nknown\nproperties learned from the training data, data mining focuses on the\ndiscovery\nof (previously)\nunknown\nproperties in the data (this is the analysis step of\nknowledge discovery\nin databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"\nunsupervised learning\n\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals,\nECML PKDD\nbeing a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to\nreproduce known\nknowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously\nunknown\nknowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\n[\ncitation needed\n]\nMachine learning also has intimate ties to\noptimisation\n: Many learning problems are formulated as minimisation of some\nloss function\non a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a\nlabel\nto instances, and models are trained to correctly predict the preassigned labels of a set of examples).\n[\n34\n]\nGeneralization\n[\nedit\n]\nCharacterizing the generalisation of various learning algorithms is an active topic of current research, especially for\ndeep learning\nalgorithms.\nStatistics\n[\nedit\n]\nMachine learning and\nstatistics\nare closely related fields in terms of methods, but distinct in their principal goal: statistics draws population\ninferences\nfrom a\nsample\n, while machine learning finds generalisable predictive patterns.\n[\n35\n]\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.\n[\n36\n]\nLeo Breiman\ndistinguished two statistical modelling paradigms: data model and algorithmic model,\n[\n37\n]\nwherein \"algorithmic model\" means more or less the machine learning algorithms like\nRandom Forest\n.\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call\nstatistical learning\n.\n[\n38\n]\nStatistical physics\n[\nedit\n]\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of\ndeep neural networks\n.\n[\n39\n]\nStatistical physics is thus finding applications in the area of\nmedical diagnostics\n.\n[\n40\n]\nTheory\n[\nedit\n]\nMain articles:\nComputational learning theory\nand\nStatistical learning theory\nA core objective of a learner is to generalise from its experience.\n[\n2\n]\n[\n41\n]\nGeneralization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\nThe computational analysis of machine learning algorithms and their performance is a branch of\ntheoretical computer science\nknown as\ncomputational learning theory\nvia the\nprobably approximately correct learning\nmodel. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The\nbias–variance decomposition\nis one way to quantify generalisation\nerror\n.\nFor the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to\noverfitting\nand generalisation will be poorer.\n[\n42\n]\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in\npolynomial time\n. There are two kinds of\ntime complexity\nresults: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\nApproaches\n[\nedit\n]\nIn\nsupervised learning\n, the training data is labelled with the expected answers, while in\nunsupervised learning\n, the model identifies patterns or structures in unlabelled data.\nMachine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\nSupervised learning\n: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that\nmaps\ninputs to outputs.\nUnsupervised learning\n: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (\nfeature learning\n).\nReinforcement learning\n: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as\ndriving a vehicle\nor playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximise.\n[\n2\n]\nAlthough each algorithm has advantages and limitations, no single algorithm works for all problems.\n[\n43\n]\n[\n44\n]\n[\n45\n]\nSupervised learning\n[\nedit\n]\nMain article:\nSupervised learning\nA\nsupport-vector machine\nis a supervised learning model that divides the data into regions separated by a\nlinear boundary\n. Here, the linear boundary divides the black circles from the white.\nSupervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.\n[\n46\n]\nThe data, known as\ntraining data\n, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an\narray\nor vector, sometimes called a\nfeature vector\n, and the training data is represented by a\nmatrix\n. Through\niterative optimisation\nof an\nobjective function\n, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.\n[\n47\n]\nAn optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.\n[\n15\n]\nTypes of supervised-learning algorithms include\nactive learning\n,\nclassification\nand\nregression\n.\n[\n48\n]\nClassification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email. In contrast, regression is used for tasks such as predicting a person's height based on factors like age and genetics or forecasting future temperatures based on historical data.\n[\n49\n]\nSimilarity learning\nis an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in\nranking\n,\nrecommendation systems\n, visual identity tracking, face verification, and speaker verification.\nUnsupervised learning\n[\nedit\n]\nMain article:\nUnsupervised learning\nSee also:\nCluster analysis\nUnsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering,\ndimensionality reduction\n,\n[\n4\n]\nand\ndensity estimation\n.\n[\n50\n]\nCluster analysis is the assignment of a set of observations into subsets (called\nclusters\n) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some\nsimilarity metric\nand evaluated, for example, by\ninternal compactness\n, or the similarity between members of the same cluster, and\nseparation\n, the difference between clusters. Other methods are based on\nestimated density\nand\ngraph connectivity\n.\nA special type of unsupervised learning called,\nself-supervised learning\ninvolves training a model by generating the supervisory signal from the data itself.\n[\n51\n]\n[\n52\n]\nSemi-supervised learning\n[\nedit\n]\nMain article:\nSemi-supervised learning\nSemi-supervised learning falls between\nunsupervised learning\n(without any labelled training data) and\nsupervised learning\n(with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy.\nIn\nweakly supervised learning\n, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.\n[\n53\n]\nReinforcement learning\n[\nedit\n]\nMain article:\nReinforcement learning\nIn reinforcement learning, an agent takes actions in an environment: these produce a reward and/or a representation of the state, which is fed back to the agent.\nReinforcement learning is an area of machine learning concerned with how\nsoftware agents\nought to take\nactions\nin an environment to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as\ngame theory\n,\ncontrol theory\n,\noperations research\n,\ninformation theory\n,\nsimulation-based optimisation\n,\nmulti-agent systems\n,\nswarm intelligence\n,\nstatistics\nand\ngenetic algorithms\n. In reinforcement learning, the environment is typically represented as a\nMarkov decision process\n(MDP). Many reinforcement learning algorithms use\ndynamic programming\ntechniques.\n[\n54\n]\nReinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\nDimensionality reduction\n[\nedit\n]\nDimensionality reduction\nis a process of reducing the number of random variables under consideration by obtaining a set of principal variables.\n[\n55\n]\nIn other words, it is a process of reducing the dimension of the\nfeature\nset, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or\nextraction\n. One of the popular methods of dimensionality reduction is\nprincipal component analysis\n(PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\nThe\nmanifold hypothesis\nproposes that high-dimensional data sets lie along low-dimensional\nmanifolds\n, and many dimensionality reduction techniques make this assumption, leading to the areas of\nmanifold learning\nand\nmanifold regularisation\n.\nOther types\n[\nedit\n]\nOther approaches have been developed which do not fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example,\ntopic modelling\n,\nmeta-learning\n.\n[\n56\n]\nSelf-learning\n[\nedit\n]\nSelf-learning, as a machine learning paradigm, was introduced in 1982 along with a neural network capable of self-learning, named\ncrossbar adaptive array\n(CAA).\n[\n57\n]\n[\n58\n]\nIt gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward. Emotion is used as a state evaluation of a self-learning agent. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.\n[\n59\n]\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine:\nin situation\ns\nact\na\nreceive a consequence situation\ns\n'\ncompute emotion of being in the consequence situation\nv(s')\nupdate crossbar memory\nw'(a,s) = w(a,s) + v(s')\nIt is a system with only one input, situation, and only one output, action (or behaviour) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioural environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behaviour in an environment that contains both desirable and undesirable situations.\n[\n60\n]\nFeature learning\n[\nedit\n]\nMain article:\nFeature learning\nSeveral learning algorithms aim at discovering better representations of the inputs provided during training.\n[\n61\n]\nClassic examples include\nprincipal component analysis\nand cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual\nfeature engineering\n, and allows a machine to both learn the features and use them to perform a specific task.\nFeature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labelled input data. Examples include\nartificial neural networks\n,\nmultilayer perceptrons\n, and supervised\ndictionary learning\n. In unsupervised feature learning, features are learned with unlabelled input data.  Examples include dictionary learning,\nindependent component analysis\n,\nautoencoders\n,\nmatrix factorisation\n[\n62\n]\nand various forms of\nclustering\n.\n[\n63\n]\n[\n64\n]\n[\n65\n]\nManifold learning\nalgorithms attempt to do so under the constraint that the learned representation is low-dimensional.\nSparse coding\nalgorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros.\nMultilinear subspace learning\nalgorithms aim to learn low-dimensional representations directly from\ntensor\nrepresentations for multidimensional data, without reshaping them into higher-dimensional vectors.\n[\n66\n]\nDeep learning\nalgorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine learns a representation that disentangles the underlying factors of variation that explain the observed data.\n[\n67\n]\nFeature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data have not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\nSparse dictionary learning\n[\nedit\n]\nMain article:\nSparse dictionary learning\nSparse dictionary learning is a feature learning method where a training example is represented as a linear combination of\nbasis functions\nand assumed to be a\nsparse matrix\n. The method is\nstrongly NP-hard\nand difficult to solve approximately.\n[\n68\n]\nA popular\nheuristic\nmethod for sparse dictionary learning is the\nk\n-SVD\nalgorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in\nimage denoising\n. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.\n[\n69\n]\nAnomaly detection\n[\nedit\n]\nMain article:\nAnomaly detection\nIn\ndata mining\n, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations that raise suspicions by differing significantly from the majority of the data.\n[\n70\n]\nTypically, the anomalous items represent an issue such as\nbank fraud\n, a structural defect, medical problems or errors in a text. Anomalies are referred to as\noutliers\n, novelties, noise, deviations and exceptions.\n[\n71\n]\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.\n[\n72\n]\nThree broad categories of anomaly detection techniques exist.\n[\n73\n]\nUnsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance being generated by the model.\nRobot learning\n[\nedit\n]\nRobot learning\nis inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,\n[\n74\n]\n[\n75\n]\nand finally\nmeta-learning\n(e.g. MAML).\nAssociation rules\n[\nedit\n]\nMain article:\nAssociation rule learning\nSee also:\nInductive logic programming\nAssociation rule learning is a\nrule-based machine learning\nmethod for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".\n[\n76\n]\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.\n[\n77\n]\nRule-based machine learning approaches include\nlearning classifier systems\n, association rule learning, and\nartificial immune systems\n.\nBased on the concept of strong rules,\nRakesh Agrawal\n,\nTomasz Imieliński\nand Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by\npoint-of-sale\n(POS) systems in supermarkets.\n[\n78\n]\nFor example, the rule\n{\no\nn\ni\no\nn\ns\n,\np\no\nt\na\nt\no\ne\ns\n}\n⇒\n{\nb\nu\nr\ng\ne\nr\n}\n{\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\nfound in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional\npricing\nor\nproduct placements\n. In addition to\nmarket basket analysis\n, association rules are employed today in application areas including\nWeb usage mining\n,\nintrusion detection\n,\ncontinuous production\n, and\nbioinformatics\n. In contrast with\nsequence mining\n, association rule learning typically does not consider the order of items either within a transaction or across transactions.\nLearning classifier systems\n(LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a\ngenetic algorithm\n, with a learning component, performing either\nsupervised learning\n,\nreinforcement learning\n, or\nunsupervised learning\n. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a\npiecewise\nmanner to make predictions.\n[\n79\n]\nInductive logic programming\n(ILP) is an approach to rule learning using\nlogic programming\nas a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that\nentails\nall positive and no negative examples.\nInductive programming\nis a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as\nfunctional programs\n.\nInductive logic programming is particularly useful in\nbioinformatics\nand\nnatural language processing\n.\nGordon Plotkin\nand\nEhud Shapiro\nlaid the initial theoretical foundation for inductive machine learning in a logical setting.\n[\n80\n]\n[\n81\n]\n[\n82\n]\nShapiro built their first implementation (Model Inference System) in 1981: a\nProlog\nprogram that inductively inferred logic programs from positive and negative examples.\n[\n83\n]\nThe term\ninductive\nhere refers to\nphilosophical\ninduction, suggesting a theory to explain observed facts, rather than\nmathematical induction\n, proving a property for all members of a well-ordered set.\nModels\n[\nedit\n]\nA\nmachine learning model\nis a type of\nmathematical model\nthat, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions.\n[\n84\n]\nBy extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.\n[\n85\n]\nVarious types of models have been used and researched for machine learning systems, picking the best model for a task is called\nmodel selection\n.\nArtificial neural networks\n[\nedit\n]\nMain article:\nArtificial neural network\nSee also:\nDeep learning\nAn artificial neural network is an interconnected group of nodes, akin to the vast network of\nneurons\nin a\nbrain\n. Here, each circular node represents an\nartificial neuron\nand an arrow represents a connection from the output of one artificial neuron to the input of another.\nArtificial neural networks (ANNs), or\nconnectionist\nsystems, are computing systems vaguely inspired by the\nbiological neural networks\nthat constitute animal\nbrains\n. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"\nartificial neurons\n\", which loosely model the\nneurons\nin a biological brain. Each connection, like the\nsynapses\nin a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a\nreal number\n, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a\nweight\nthat adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a\nhuman brain\nwould. However, over time, attention moved to performing specific tasks, leading to deviations from\nbiology\n. Artificial neural networks have been used on a variety of tasks, including\ncomputer vision\n,\nspeech recognition\n,\nmachine translation\n,\nsocial network\nfiltering,\nplaying board and video games\nand\nmedical diagnosis\n.\nDeep learning\nconsists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.\n[\n86\n]\nDecision trees\n[\nedit\n]\nMain article:\nDecision tree learning\nA decision tree showing survival probability of passengers on the\nTitanic\nDecision tree learning uses a\ndecision tree\nas a\npredictive model\nto go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures,\nleaves\nrepresent class labels, and branches represent\nconjunctions\nof features that lead to those class labels. Decision trees where the target variable can take continuous values (typically\nreal numbers\n) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and\ndecision making\n. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\nRandom forest regression\n[\nedit\n]\nRandom forest regression\n(RFR) falls under the umbrella of decision\ntree-based models\n. RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting. To build decision trees, RFR uses bootstrapped sampling; for instance, each decision tree is trained on random data from the training set. This random selection of RFR for training enables the model to reduce biased predictions and achieve a higher degree of accuracy. RFR generates independent decision trees, and it can work on single-output data as well as multiple regressor tasks. This makes RFR compatible to be use in various applications.\n[\n87\n]\n[\n88\n]\nSupport-vector machines\n[\nedit\n]\nMain article:\nSupport-vector machine\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related\nsupervised learning\nmethods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.\n[\n89\n]\nAn SVM training algorithm is a non-\nprobabilistic\n,\nbinary\n,\nlinear classifier\n, although methods such as\nPlatt scaling\nexist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the\nkernel trick\n, implicitly mapping their inputs into high-dimensional feature spaces.\nRegression analysis\n[\nedit\n]\nMain article:\nRegression analysis\nIllustration of linear regression on a data set\nRegression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is\nlinear regression\n, where a single line is drawn to best fit the given data according to a mathematical criterion such as\nordinary least squares\n. The latter is often extended by\nregularisation\nmethods to mitigate overfitting and bias, as in\nridge regression\n. When dealing with non-linear problems, go-to models include\npolynomial regression\n(for example, used for trendline fitting in Microsoft Excel\n[\n90\n]\n),\nlogistic regression\n(often used in\nstatistical classification\n) or even\nkernel regression\n, which introduces non-linearity by taking advantage of the\nkernel trick\nto implicitly map input variables to higher-dimensional space.\nMultivariate linear regression\nextends the concept of linear regression to handle multiple dependent variables simultaneously. This approach estimates the relationships between a set of input variables and several output variables by fitting a\nmultidimensional\nlinear model. It is particularly useful in scenarios where outputs are interdependent or share underlying patterns, such as predicting multiple economic indicators or reconstructing images,\n[\n91\n]\nwhich are inherently multi-dimensional.\nBayesian networks\n[\nedit\n]\nMain article:\nBayesian network\nA simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet.\nA Bayesian network, belief network, or directed acyclic graphical model is a probabilistic\ngraphical model\nthat represents a set of\nrandom variables\nand their\nconditional independence\nwith a\ndirected acyclic graph\n(DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform\ninference\nand learning. Bayesian networks that model sequences of variables, like\nspeech signals\nor\nprotein sequences\n, are called\ndynamic Bayesian networks\n. Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called\ninfluence diagrams\n.\nGaussian processes\n[\nedit\n]\nMain article:\nGaussian processes\nAn example of Gaussian Process Regression (prediction) compared with other regression models\n[\n92\n]\nA Gaussian process is a\nstochastic process\nin which every finite collection of the random variables in the process has a\nmultivariate normal distribution\n, and it relies on a pre-defined\ncovariance function\n, or kernel, that models how pairs of points relate to each other depending on their locations.\nGiven a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as a function of its input data can be directly computed by looking at the observed points and the covariances between those points and the new, unobserved point.\nGaussian processes are popular surrogate models in\nBayesian optimisation\nused to do\nhyperparameter optimisation\n.\nGenetic algorithms\n[\nedit\n]\nMain article:\nGenetic algorithm\nA genetic algorithm (GA) is a\nsearch algorithm\nand\nheuristic\ntechnique that mimics the process of\nnatural selection\n, using methods such as\nmutation\nand\ncrossover\nto generate new\ngenotypes\nin the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.\n[\n93\n]\n[\n94\n]\nConversely, machine learning techniques have been used to improve the performance of genetic and\nevolutionary algorithms\n.\n[\n95\n]\nBelief functions\n[\nedit\n]\nMain article:\nDempster–Shafer theory\nThe theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as\nprobability\n,\npossibility\nand\nimprecise probability theories\n. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster's rule of combination), just like how in a\npmf\n-based Bayesian approach would combine probabilities.\n[\n96\n]\nHowever, there are many caveats to these beliefs functions when compared to Bayesian approaches to incorporate ignorance and\nuncertainty quantification\n. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various\nensemble methods\nto better handle the learner's\ndecision boundary\n, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.\n[\n97\n]\n[\n6\n]\nHowever, the computational complexity of these algorithms is dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.\nRule-based models\n[\nedit\n]\nMain article:\nRule-based machine learning\nRule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns 'rules' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes\nlearning classifier systems\n,\n[\n98\n]\nassociation rule learning\n,\n[\n99\n]\nartificial immune systems\n,\n[\n100\n]\nand other similar models. These methods extract patterns from data and evolve rules over time.\nTraining models\n[\nedit\n]\nTypically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative\nsample\nof data. Data from the training set can be as varied as a\ncorpus of text\n, a collection of images,\nsensor\ndata, and data collected from individual users of a service.\nOverfitting\nis something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives.\nAlgorithmic bias\nis a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and, notably, becoming integrated within machine learning engineering teams.\nFederated learning\n[\nedit\n]\nMain article:\nFederated learning\nFederated learning is an adapted form of\ndistributed artificial intelligence\nto train machine learning models that decentralises the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example,\nGboard\nuses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to\nGoogle\n.\n[\n101\n]\nApplications\n[\nedit\n]\nThere are many applications for machine learning, including:\nAgriculture\nAnatomy\nAdaptive website\nAffective computing\nAstronomy\nAutomated decision-making\nBanking\nBehaviorism\nBioinformatics\nBrain–machine interfaces\nCheminformatics\nCitizen Science\nClimate Science\nComputer networks\nComputer vision\nCredit-card fraud\ndetection\nData quality\nDNA sequence\nclassification\nEconomics\nFinancial data analysis\n[\n102\n]\nGeneral game playing\nHandwriting recognition\nHealthcare\nInformation retrieval\nInsurance\nInternet fraud\ndetection\nInvestment management\n[\n103\n]\nKnowledge graph embedding\nLinguistics\nMachine learning control\nMachine perception\nMachine translation\nMaterial Engineering\nMarketing\nMedical diagnosis\nNatural language processing\nNatural language understanding\nOnline advertising\nOptimisation\nRecommender systems\nRobot locomotion\nSearch engines\nSentiment analysis\nSequence mining\nSoftware engineering\nSpeech recognition\nStructural health monitoring\nSyntactic pattern recognition\nTelecommunications\nTheorem proving\nTime-series forecasting\nTomographic reconstruction\n[\n104\n]\nUser behaviour analytics\nIn 2006, the media-services provider\nNetflix\nheld the first \"\nNetflix Prize\n\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from\nAT&T Labs\n-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an\nensemble model\nto win the Grand Prize in 2009 for $1 million.\n[\n105\n]\nShortly after the prize was awarded, Netflix realised that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.\n[\n106\n]\nIn 2010, an article in\nThe Wall Street Journal\nnoted the use of machine learning by Rebellion Research to predict the\n2008 financial crisis\n.\n[\n107\n]\nIn 2012, co-founder of\nSun Microsystems\n,\nVinod Khosla\n, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.\n[\n108\n]\nIn 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists.\n[\n109\n]\nIn 2019\nSpringer Nature\npublished the first research book created using machine learning.\n[\n110\n]\nIn 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.\n[\n111\n]\nMachine learning was recently applied to predict the pro-environmental behaviour of travellers.\n[\n112\n]\nRecently, machine learning technology was also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.\n[\n113\n]\n[\n114\n]\n[\n115\n]\nWhen applied correctly, machine learning algorithms (MLAs) can utilise a wide range of company characteristics to predict stock returns without\noverfitting\n. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like\nOLS\n.\n[\n116\n]\nRecent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.\n[\n117\n]\nMachine Learning is becoming a useful tool to investigate and predict evacuation decision-making in large-scale and small-scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.\n[\n118\n]\n[\n119\n]\n[\n120\n]\nOther applications have been focusing on pre evacuation decisions in building fires.\n[\n121\n]\n[\n122\n]\nLimitations\n[\nedit\n]\nAlthough machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.\n[\n123\n]\n[\n124\n]\n[\n125\n]\nReasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.\n[\n126\n]\nThe \"\nblack box theory\n\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted from the data.\n[\n127\n]\nThe House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual's life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.\n[\n127\n]\nIn 2018, a self-driving car from\nUber\nfailed to detect a pedestrian, who was killed after a collision.\n[\n128\n]\nAttempts to use machine learning in healthcare with the\nIBM Watson\nsystem failed to deliver even after years of time and billions of dollars invested.\n[\n129\n]\n[\n130\n]\nMicrosoft's\nBing Chat\nchatbot has been reported to produce hostile and offensive response against its users.\n[\n131\n]\nMachine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research itself.\n[\n132\n]\nExplainability\n[\nedit\n]\nMain article:\nExplainable artificial intelligence\nExplainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.\n[\n133\n]\nIt contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.\n[\n134\n]\nBy refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\nOverfitting\n[\nedit\n]\nMain article:\nOverfitting\nThe blue line could be an example of overfitting a linear function due to random noise.\nSettling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is.\n[\n135\n]\nOther limitations and vulnerabilities\n[\nedit\n]\nLearners can also be disappointed by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.\n[\n136\n]\nA real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.\n[\n137\n]\n[\n138\n]\nAdversarial vulnerabilities can also result in nonlinear systems or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.\n[\n139\n]\nMachine learning models are often vulnerable to manipulation or evasion via\nadversarial machine learning\n.\n[\n140\n]\nResearchers have demonstrated how\nbackdoors\ncan be placed undetectably into classifying (e.g., for categories \"spam\" and \"not spam\" of posts) machine learning models that are often developed or trained by third parties. Parties can change the classification of any input, including in cases for which a type of\ndata/software transparency\nis provided, possibly including\nwhite-box access\n.\n[\n141\n]\n[\n142\n]\n[\n143\n]\nModel assessments\n[\nedit\n]\nClassification of machine learning models can be validated by accuracy estimation techniques like the\nholdout\nmethod, which splits the data into a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-\ncross-validation\nmethod randomly partitions the data into K subsets and then K experiments are performed each considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods,\nbootstrap\n, which samples n instances with replacement from the dataset, can be used to assess model accuracy.\n[\n144\n]\nIn addition to overall accuracy, investigators frequently report\nsensitivity and specificity\n, meaning true positive rate (TPR) and true negative rate (TNR), respectively. Similarly, investigators sometimes report the\nfalse positive rate\n(FPR) as well as the\nfalse negative rate\n(FNR). However, these rates are ratios that fail to reveal their numerators and denominators.\nReceiver operating characteristic\n(ROC), along with the accompanying Area Under the ROC Curve (AUC), offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.\n[\n145\n]\nEthics\n[\nedit\n]\nThis section is an excerpt from\nEthics of artificial intelligence\n.\n[\nedit\n]\nThe\nethics\nof\nartificial intelligence\ncovers a broad range of topics within AI that are considered to have particular ethical stakes.\n[\n146\n]\nThis includes\nalgorithmic biases\n,\nfairness\n,\naccountability\n, transparency, privacy, and\nregulation\n, particularly where systems influence or automate human decision-making.\n[\n147\n]\nIt also covers various emerging or potential future challenges such as\nmachine ethics\n(how to make machines that behave ethically),\nlethal autonomous weapon systems\n,\narms race\ndynamics,\nAI safety\nand\nalignment\n,\ntechnological unemployment\n, AI-enabled\nmisinformation\n,\n[\n148\n]\nhow to treat certain AI systems if they have a\nmoral status\n(AI welfare and rights),\nartificial superintelligence\nand\nexistential risks\n.\n[\n146\n]\nSome application areas may also have particularly important ethical implications, like\nhealthcare\n, education, criminal justice, or the military.\nBias\n[\nedit\n]\nMain article:\nAlgorithmic bias\nDifferent machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.\n[\n149\n]\nSystems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.\n[\n150\n]\nFor example, in 1988, the UK's\nCommission for Racial Equality\nfound that\nSt. George's Medical School\nhad been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to either be women or have non-European-sounding names.\n[\n149\n]\nUsing job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.\n[\n151\n]\n[\n152\n]\nAnother example includes predictive policing company\nGeolitica\n's predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.\n[\n153\n]\nWhile responsible\ncollection of data\nand documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame the lack of participation and representation of minority populations in the field of AI for machine learning's vulnerability to biases.\n[\n154\n]\nIn fact, according to research carried out by the Computing Research Association in 2021, \"female faculty make up just 16.1%\" of all faculty members who focus on AI among several universities around the world.\n[\n155\n]\nFurthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.\n[\n155\n]\nLanguage models learned from data have been shown to contain human-like biases.\n[\n156\n]\n[\n157\n]\nBecause human languages contain biases, machines trained on language\ncorpora\nwill necessarily also learn these biases.\n[\n158\n]\n[\n159\n]\nIn 2016, Microsoft tested\nTay\n, a\nchatbot\nthat learned from Twitter, and it quickly picked up racist and sexist language.\n[\n160\n]\nIn an experiment carried out by\nProPublica\n, an\ninvestigative journalism\norganisation, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants\".\n[\n153\n]\nIn 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognise gorillas.\n[\n161\n]\nSimilar issues with recognising non-white people have been found in many other systems.\n[\n162\n]\nBecause of such challenges, the effective use of machine learning may take longer to be adopted in other domains.\n[\n163\n]\nConcern for\nfairness\nin machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including\nFei-Fei Li\n, who said that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"\n[\n164\n]\nFinancial incentives\n[\nedit\n]\nThere are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States, where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals with an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.\n[\n165\n]\nHardware\n[\nedit\n]\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training\ndeep neural networks\n(a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.\n[\n166\n]\nBy 2019, graphics processing units (\nGPUs\n), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.\n[\n167\n]\nOpenAI\nestimated the hardware compute used in the largest deep learning projects from\nAlexNet\n(2012) to\nAlphaZero\n(2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.\n[\n168\n]\n[\n169\n]\nTensor Processing Units (TPUs)\n[\nedit\n]\nTensor Processing Units (TPUs)\nare specialised hardware accelerators developed by\nGoogle\nspecifically for machine learning workloads. Unlike general-purpose\nGPUs\nand\nFPGAs\n, TPUs are optimised for tensor computations, making them particularly efficient for deep learning tasks such as training and inference. They are widely used in Google Cloud AI services and large-scale machine learning models like Google's DeepMind AlphaFold and large language models. TPUs leverage matrix multiplication units and high-bandwidth memory to accelerate computations while maintaining energy efficiency.\n[\n170\n]\nSince their introduction in 2016, TPUs have become a key component of AI infrastructure, especially in cloud-based environments.\nNeuromorphic computing\n[\nedit\n]\nNeuromorphic computing\nrefers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialised hardware architectures.\n[\n171\n]\nPhysical neural networks\n[\nedit\n]\nA\nphysical neural network\nis a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of\nneural synapses\n. The term \"physical neural network\" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.\n[\n172\n]\n[\n173\n]\nEmbedded machine learning\n[\nedit\n]\nEmbedded machine learning is a sub-field of machine learning where models are deployed on\nembedded systems\nwith limited computing resources, such as\nwearable computers\n,\nedge devices\nand\nmicrocontrollers\n.\n[\n174\n]\n[\n175\n]\n[\n176\n]\n[\n177\n]\nRunning models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as\nhardware acceleration\n,\n[\n178\n]\n[\n179\n]\napproximate computing\n,\n[\n180\n]\nand model optimisation.\n[\n181\n]\n[\n182\n]\nCommon optimisation techniques include\npruning\n,\nquantisation\n,\nknowledge distillation\n, low-rank factorisation, network architecture search, and parameter sharing.\nSoftware\n[\nedit\n]\nSoftware suites\ncontaining a variety of machine learning algorithms include the following:\nFree and open-source software\n[\nedit\n]\nSee also:\nLists of open-source artificial intelligence software\nCaffe\nDeeplearning4j\nDeepSpeed\nELKI\nGoogle JAX\nInfer.NET\nJASP\nJubatus\nKeras\nKubeflow\nLightGBM\nMahout\nMallet\nMicrosoft Cognitive Toolkit\nML.NET\nmlpack\nMXNet\nOpenNN\nOrange\npandas (software)\nROOT\n(TMVA with ROOT)\nscikit-learn\nShogun\nSpark MLlib\nSystemML\nTheano\nTensorFlow\nTorch\n/\nPyTorch\nWeka\n/\nMOA\nXGBoost\nYooreeka\nProprietary software with free and open-source editions\n[\nedit\n]\nKNIME\nRapidMiner\nProprietary software\n[\nedit\n]\nAmazon Machine Learning\nAngoss\nKnowledgeSTUDIO\nAzure Machine Learning\nIBM Watson Studio\nGoogle Cloud Vertex AI\nGoogle Prediction API\nIBM SPSS Modeller\nKXEN Modeller\nLIONsolver\nMathematica\nMATLAB\nNeural Designer\nNeuroSolutions\nOracle Data Mining\nOracle AI Platform Cloud Service\nPolyAnalyst\nRCASE\nSAS Enterprise Miner\nSequenceL\nSplunk\nSTATISTICA\nData Miner\nJournals\n[\nedit\n]\nJournal of Machine Learning Research\nMachine Learning\nNature Machine Intelligence\nNeural Computation\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nConferences\n[\nedit\n]\nAAAI Conference on Artificial Intelligence\nAssociation for Computational Linguistics (\nACL\n)\nEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (\nECML PKDD\n)\nInternational Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (\nCIBB\n)\nInternational Conference on Machine Learning (\nICML\n)\nInternational Conference on Learning Representations (\nICLR\n)\nInternational Conference on Intelligent Robots and Systems (\nIROS\n)\nConference on Knowledge Discovery and Data Mining (\nKDD\n)\nConference on Neural Information Processing Systems (\nNeurIPS\n)\nSee also\n[\nedit\n]\nAutomated machine learning\n– Process of automating the application of machine learning\nBig data\n– Extremely large or complex datasets\nDeep learning\n— branch of ML concerned with\nartificial neural networks\nDifferentiable programming\n– Programming paradigm\nList of datasets for machine-learning research\nList of machine learning algorithms\nand\nList of algorithms for machine learning and statistical classification\nM-theory (learning framework)\n– Framework in machine learning\nMachine unlearning\n– Field of study in artificial intelligence\nOutline of machine learning\nSolomonoff's theory of inductive inference\n– Mathematical theory\nReferences\n[\nedit\n]\n^\nThe definition \"without being explicitly programmed\" is often attributed to\nArthur Samuel\n, who coined the term \"machine learning\" in 1959, but the phrase is not found verbatim in this publication, and may be a\nparaphrase\nthat appeared later. Confer \"Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?\" in\nKoza, John R.; Bennett, Forrest H.; Andre, David; Keane, Martin A. (1996). \"Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming\".\nArtificial Intelligence in Design '96\n. Artificial Intelligence in Design '96. Dordrecht, Netherlands: Springer Netherlands. pp.\n151–\n170.\ndoi\n:\n10.1007/978-94-009-0279-4_9\n.\nISBN\n978-94-010-6610-5\n.\n^\na\nb\nc\nBishop, C. M.\n(2006),\nPattern Recognition and Machine Learning\n, Springer,\nISBN\n978-0-387-31073-2\n^\nMachine learning and pattern recognition \"can be viewed as two facets of the same field\".\n[\n2\n]\n: vii\n^\na\nb\nFriedman, Jerome H.\n(1998). \"Data Mining and Statistics: What's the connection?\".\nComputing Science and Statistics\n.\n29\n(1):\n3–\n9.\n^\nSamuel, Arthur (1959). \"Some Studies in Machine Learning Using the Game of Checkers\".\nIBM Journal of Research and Development\n.\n3\n(3):\n210–\n229.\nCiteSeerX\n10.1.1.368.2254\n.\ndoi\n:\n10.1147/rd.33.0210\n.\nS2CID\n2126705\n.\n^\na\nb\nR. Kohavi and F. Provost, \"Glossary of terms\", Machine Learning, vol. 30, no. 2–3, pp. 271–274, 1998.\n^\nGerovitch, Slava (9 April 2015).\n\"How the Computer Got Its Revenge on the Soviet Union\"\n.\nNautilus\n. Archived from\nthe original\non 22 September 2021\n. Retrieved\n19 September\n2021\n.\n^\nLindsay, Richard P. (1 September 1964).\n\"The Impact of Automation On Public Administration\"\n.\nWestern Political Quarterly\n.\n17\n(3):\n78–\n81.\ndoi\n:\n10.1177/106591296401700364\n.\nISSN\n0043-4078\n.\nS2CID\n154021253\n.\nArchived\nfrom the original on 6 October 2021\n. Retrieved\n6 October\n2021\n.\n^\na\nb\nc\n\"History and Evolution of Machine Learning: A Timeline\"\n.\nWhatIs\n.\nArchived\nfrom the original on 8 December 2023\n. Retrieved\n8 December\n2023\n.\n^\nMilner, Peter M. (1993). \"The Mind and Donald O. Hebb\".\nScientific American\n.\n268\n(1):\n124–\n129.\nBibcode\n:\n1993SciAm.268a.124M\n.\ndoi\n:\n10.1038/scientificamerican0193-124\n.\nISSN\n0036-8733\n.\nJSTOR\n24941344\n.\nPMID\n8418480\n.\n^\n\"Science: The Goof Button\",\nTime\n, 18 August 1961.\n^\nNilsson, Nils J. (1965).\nLearning Machines\n. McGraw-Hill.\n^\nDuda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973\n^\nS. Bozinovski, \"Teaching space: A representation concept for adaptive pattern classification\" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981.\nhttps://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf\nArchived\n25 February 2021 at the\nWayback Machine\n^\na\nb\nMitchell, T. (1997).\nMachine Learning\n. McGraw Hill. p. 2.\nISBN\n978-0-07-042807-2\n.\n^\nHarnad, Stevan\n(2008),\n\"The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence\"\n, in Epstein, Robert; Peters, Grace (eds.),\nThe Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer\n, Kluwer, pp.\n23–\n66,\nISBN\n978-1-4020-6708-2\n, archived from\nthe original\non 9 March 2012\n, retrieved\n11 December\n2012\n^\n\"Machine Learning Algorithms\"\n.\nGeeksforGeeks\n. 17 August 2023\n. Retrieved\n3 September\n2025\n.\n^\nGoodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi (2014).\nGenerative adversarial nets\n(PDF)\n. Advances in Neural Information Processing Systems 27 (2014).\n^\nSilver, David; Huang, Aja; Maddison, Christopher J. (2016).\n\"Mastering the game of Go with deep neural networks and tree search\"\n.\nNature\n.\n529\n:\n484–\n489.\ndoi\n:\n10.1038/nature16961\n.\n^\nSindhu V, Nivedha S, Prakash M (February 2020).\n\"An Empirical Science Research on Bioinformatics in Machine Learning\"\n.\nJournal of Mechanics of Continua and Mathematical Sciences\n(7).\ndoi\n:\n10.26782/jmcms.spl.7/2020.02.00006\n.\n^\nSarle, Warren S. (1994). \"Neural Networks and statistical models\".\nSUGI 19: proceedings of the Nineteenth Annual SAS Users Group International Conference\n. SAS Institute. pp.\n1538–\n50.\nISBN\n978-1-55544-611-6\n.\nOCLC\n35546178\n.\n^\na\nb\nc\nd\nRussell, Stuart\n;\nNorvig, Peter\n(2003) [1995].\nArtificial Intelligence: A Modern Approach\n(2nd ed.). Prentice Hall.\nISBN\n978-0137903955\n.\n^\na\nb\nLangley, Pat (2011).\n\"The changing science of machine learning\"\n.\nMachine Learning\n.\n82\n(3):\n275–\n9.\ndoi\n:\n10.1007/s10994-011-5242-y\n.\n^\nMahoney, Matt.\n\"Rationale for a Large Text Compression Benchmark\"\n. Florida Institute of Technology. Archived from\nthe original\non 18 August 2006\n. Retrieved\n5 March\n2013\n.\n^\nShmilovici A.; Kahiri Y.; Ben-Gal I.; Hauser S. (2009).\n\"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\"\n(PDF)\n.\nComputational Economics\n.\n33\n(2):\n131–\n154.\nCiteSeerX\n10.1.1.627.3751\n.\ndoi\n:\n10.1007/s10614-008-9153-3\n.\nS2CID\n17234503\n.\nArchived\n(PDF)\nfrom the original on 9 July 2009.\n^\nBen-Gal, I. (2008).\n\"On the Use of Data Compression Measures to Analyze Robust Designs\"\n(PDF)\n.\nIEEE Transactions on Reliability\n.\n54\n(3):\n381–\n388.\ndoi\n:\n10.1109/TR.2005.853280\n.\nS2CID\n9376086\n. Archived from\nthe original\n(PDF)\non 26 September 2020\n. Retrieved\n6 April\n2016\n.\n^\nD. Scully;\nCarla E. Brodley\n(2006). \"Compression and Machine Learning: A New Perspective on Feature Space Vectors\".\nData Compression Conference (DCC'06)\n. p. 332.\ndoi\n:\n10.1109/DCC.2006.13\n.\nISBN\n0-7695-2545-8\n.\nS2CID\n12311412\n.\n^\nGary Adcock (5 January 2023).\n\"What Is AI Video Compression?\"\n.\nmassive.io\n. Retrieved\n6 April\n2023\n.\n^\nMentzer, Fabian; Toderici, George; Tschannen, Michael; Agustsson, Eirikur (2020). \"High-Fidelity Generative Image Compression\".\narXiv\n:\n2006.09965\n[\neess.IV\n].\n^\n\"What is Unsupervised Learning? | IBM\"\n.\nwww.ibm.com\n. 23 September 2021\n. Retrieved\n5 February\n2024\n.\n^\n\"Differentially private clustering for large-scale datasets\"\n.\nblog.research.google\n. 25 May 2023\n. Retrieved\n16 March\n2024\n.\n^\nEdwards, Benj (28 September 2023).\n\"AI language models can exceed PNG and FLAC in lossless compression, says study\"\n.\nArs Technica\n. Retrieved\n7 March\n2024\n.\n^\nDelétang, Grégoire; Ruoss, Anian; Duquenne, Paul-Ambroise; Catt, Elliot; Genewein, Tim; Mattern, Christopher; Grau-Moya, Jordi; Li Kevin Wenliang; Aitchison, Matthew; Orseau, Laurent; Hutter, Marcus; Veness, Joel (2023). \"Language Modeling is Compression\".\narXiv\n:\n2309.10668\n[\ncs.LG\n].\n^\nLe Roux, Nicolas; Bengio, Yoshua; Fitzgibbon, Andrew (2012).\n\"Improving First and Second-Order Methods by Modeling Uncertainty\"\n. In Sra, Suvrit; Nowozin, Sebastian; Wright, Stephen J. (eds.).\nOptimization for Machine Learning\n. MIT Press. p. 404.\nISBN\n978-0-262-01646-9\n.\nArchived\nfrom the original on 17 January 2023\n. Retrieved\n12 November\n2020\n.\n^\nBzdok, Danilo;\nAltman, Naomi\n; Krzywinski, Martin (2018).\n\"Statistics versus Machine Learning\"\n.\nNature Methods\n.\n15\n(4):\n233–\n234.\ndoi\n:\n10.1038/nmeth.4642\n.\nPMC\n6082636\n.\nPMID\n30100822\n.\n^\nHung et al. Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery. JAMA Surg. 2018\n^\nCornell University Library (August 2001).\n\"Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\"\n.\nStatistical Science\n.\n16\n(3).\ndoi\n:\n10.1214/ss/1009213726\n.\nS2CID\n62729017\n.\nArchived\nfrom the original on 26 June 2017\n. Retrieved\n8 August\n2015\n.\n^\nGareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013).\nAn Introduction to Statistical Learning\n. Springer. p. vii.\nArchived\nfrom the original on 23 June 2019\n. Retrieved\n25 October\n2014\n.\n^\nRamezanpour, A.; Beam, A.L.; Chen, J.H.; Mashaghi, A. (17 November 2020).\n\"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\"\n.\nDiagnostics\n.\n10\n(11): 972.\ndoi\n:\n10.3390/diagnostics10110972\n.\nPMC\n7699346\n.\nPMID\n33228143\n.\n^\nMashaghi, A.; Ramezanpour, A. (16 March 2018). \"Statistical physics of medical diagnostics: Study of a probabilistic model\".\nPhysical Review E\n.\n97\n(\n3–\n1) 032118.\narXiv\n:\n1803.10019\n.\nBibcode\n:\n2018PhRvE..97c2118M\n.\ndoi\n:\n10.1103/PhysRevE.97.032118\n.\nPMID\n29776109\n.\nS2CID\n4955393\n.\n^\nMohri, Mehryar\n; Rostamizadeh, Afshin; Talwalkar, Ameet (2012).\nFoundations of Machine Learning\n. US, Massachusetts: MIT Press.\nISBN\n9780262018258\n.\n^\nAlpaydin, Ethem (2010).\nIntroduction to Machine Learning\n. London: The MIT Press.\nISBN\n978-0-262-01243-0\n. Retrieved\n4 February\n2017\n.\n^\nJordan, M. I.; Mitchell, T. M. (17 July 2015). \"Machine learning: Trends, perspectives, and prospects\".\nScience\n.\n349\n(6245):\n255–\n260.\nBibcode\n:\n2015Sci...349..255J\n.\ndoi\n:\n10.1126/science.aaa8415\n.\nPMID\n26185243\n.\nS2CID\n677218\n.\n^\nEl Naqa, Issam; Murphy, Martin J. (2015). \"What is Machine Learning?\".\nMachine Learning in Radiation Oncology\n. pp.\n3–\n11.\ndoi\n:\n10.1007/978-3-319-18305-3_1\n.\nISBN\n978-3-319-18304-6\n.\nS2CID\n178586107\n.\n^\nOkolie, Jude A.; Savage, Shauna; Ogbaga, Chukwuma C.; Gunes, Burcu (June 2022).\n\"Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon\"\n.\nTotal Environment Research Themes\n.\n1–\n2\n100001.\nBibcode\n:\n2022TERT....100001O\n.\ndoi\n:\n10.1016/j.totert.2022.100001\n.\nS2CID\n249022386\n.\n^\nRussell, Stuart J.; Norvig, Peter (2010).\nArtificial Intelligence: A Modern Approach\n(Third ed.). Prentice Hall.\nISBN\n978-0-13-604259-4\n.\n^\nMohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012).\nFoundations of Machine Learning\n. The MIT Press.\nISBN\n978-0-262-01825-8\n.\n^\nAlpaydin, Ethem (2010).\nIntroduction to Machine Learning\n. MIT Press. p. 9.\nISBN\n978-0-262-01243-0\n.\nArchived\nfrom the original on 17 January 2023\n. Retrieved\n25 November\n2018\n.\n^\nDe Sa, Christopher (Spring 2022).\n\"Lecture 2 Notes: Supervised Learning\"\n.\nCornell: Computer Science\n. Retrieved\n1 July\n2024\n.\n^\nJordan, Michael I.; Bishop, Christopher M. (2004). \"Neural Networks\". In Allen B. Tucker (ed.).\nComputer Science Handbook, Second Edition (Section VII: Intelligent Systems)\n. Boca Raton, Florida: Chapman & Hall/CRC Press LLC.\nISBN\n978-1-58488-360-9\n.\n^\nMisra, Ishan; Maaten, Laurens van der (2020).\nSelf-Supervised Learning of Pretext-Invariant Representations\n. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Seattle, WA, US:\nIEEE\n. pp.\n6707–\n6717.\narXiv\n:\n1912.01991\n.\ndoi\n:\n10.1109/CVPR42600.2020.00674\n.\n^\nJaiswal, Ashish; Babu, Ashwin Ramesh; Zadeh, Mohammad Zaki; Banerjee, Debapriya; Makedon, Fillia (March 2021).\n\"A Survey on Contrastive Self-Supervised Learning\"\n.\nTechnologies\n.\n9\n(1): 2.\narXiv\n:\n2011.00362\n.\ndoi\n:\n10.3390/technologies9010002\n.\nISSN\n2227-7080\n.\n^\nAlex Ratner; Stephen Bach; Paroma Varma; Chris.\n\"Weak Supervision: The New Programming Paradigm for Machine Learning\"\n.\nhazyresearch.github.io\n. referencing work by many other members of Hazy Research. Archived from\nthe original\non 6 June 2019\n. Retrieved\n6 June\n2019\n.\n^\nvan Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\".\nReinforcement Learning\n. Adaptation, Learning, and Optimization. Vol. 12. pp.\n3–\n42.\ndoi\n:\n10.1007/978-3-642-27645-3_1\n.\nISBN\n978-3-642-27644-6\n.\n^\nRoweis, Sam T.; Saul, Lawrence K. (22 December 2000).\n\"Nonlinear Dimensionality Reduction by Locally Linear Embedding\"\n.\nScience\n.\n290\n(5500):\n2323–\n2326.\nBibcode\n:\n2000Sci...290.2323R\n.\ndoi\n:\n10.1126/science.290.5500.2323\n.\nPMID\n11125150\n.\nS2CID\n5987139\n.\nArchived\nfrom the original on 15 August 2021\n. Retrieved\n17 July\n2023\n.\n^\nPavel Brazdil; Christophe Giraud Carrier; Carlos Soares; Ricardo Vilalta (2009).\nMetalearning: Applications to Data Mining\n(Fourth ed.).\nSpringer Science+Business Media\n. pp.\n10–\n14,\npassim\n.\nISBN\n978-3-540-73262-4\n.\n^\nBozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402.\nISBN\n978-0-444-86488-8\n.\n^\nBozinovski, S. (1999) \"Crossbar Adaptive Array: The first connectionist network that solved the delayed reinforcement learning problem\" In A. Dobnikar, N. Steele, D. Pearson, R. Albert (eds.) Artificial Neural Networks and Genetic Algorithms, Springer Verlag, p. 320–325, ISBN 3-211-83364-1\n^\nBozinovski, Stevo (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255–263\n^\nBozinovski, S. (2001) \"Self-learning agents: A connectionist theory of emotion based on crossbar value judgment.\" Cybernetics and Systems 32(6) 637–667.\n^\nY. Bengio; A. Courville; P. Vincent (2013). \"Representation Learning: A Review and New Perspectives\".\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n.\n35\n(8):\n1798–\n1828.\narXiv\n:\n1206.5538\n.\nBibcode\n:\n2013ITPAM..35.1798B\n.\ndoi\n:\n10.1109/tpami.2013.50\n.\nPMID\n23787338\n.\nS2CID\n393948\n.\n^\nNathan Srebro; Jason D. M. Rennie; Tommi S. Jaakkola (2004).\nMaximum-Margin Matrix Factorization\n.\nNIPS\n.\n^\nCoates, Adam; Lee, Honglak; Ng, Andrew Y. (2011).\nAn analysis of single-layer networks in unsupervised feature learning\n(PDF)\n. Int'l Conf. on AI and Statistics (AISTATS). Archived from\nthe original\n(PDF)\non 13 August 2017\n. Retrieved\n25 November\n2018\n.\n^\nCsurka, Gabriella; Dance, Christopher C.; Fan, Lixin; Willamowski, Jutta; Bray, Cédric (2004).\nVisual categorization with bags of keypoints\n(PDF)\n. ECCV Workshop on Statistical Learning in Computer Vision.\nArchived\n(PDF)\nfrom the original on 13 July 2019\n. Retrieved\n29 August\n2019\n.\n^\nDaniel Jurafsky; James H. Martin (2009).\nSpeech and Language Processing\n. Pearson Education International. pp.\n145–\n146.\n^\nLu, Haiping; Plataniotis, K.N.; Venetsanopoulos, A.N. (2011).\n\"A Survey of Multilinear Subspace Learning for Tensor Data\"\n(PDF)\n.\nPattern Recognition\n.\n44\n(7):\n1540–\n1551.\nBibcode\n:\n2011PatRe..44.1540L\n.\ndoi\n:\n10.1016/j.patcog.2011.01.004\n.\nArchived\n(PDF)\nfrom the original on 10 July 2019\n. Retrieved\n4 September\n2015\n.\n^\nYoshua Bengio\n(2009).\nLearning Deep Architectures for AI\n. Now Publishers Inc. pp.\n1–\n3.\nISBN\n978-1-60198-294-0\n.\nArchived\nfrom the original on 17 January 2023\n. Retrieved\n15 February\n2016\n.\n^\nTillmann, A. M. (2015). \"On the Computational Intractability of Exact and Approximate Dictionary Learning\".\nIEEE Signal Processing Letters\n.\n22\n(1):\n45–\n49.\narXiv\n:\n1405.6664\n.\nBibcode\n:\n2015ISPL...22...45T\n.\ndoi\n:\n10.1109/LSP.2014.2345761\n.\nS2CID\n13342762\n.\n^\nAharon, M\n, M Elad, and A Bruckstein. 2006. \"\nK-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation\nArchived\n2018-11-23 at the\nWayback Machine\n.\" Signal Processing, IEEE Transactions on 54 (11): 4311–4322\n^\nZimek, Arthur; Schubert, Erich (2017), \"Outlier Detection\",\nEncyclopedia of Database Systems\n, Springer New York, pp.\n1–\n5,\ndoi\n:\n10.1007/978-1-4899-7993-3_80719-1\n,\nISBN\n978-1-4899-7993-3\n^\nHodge, V. J.; Austin, J. (2004).\n\"A Survey of Outlier Detection Methodologies\"\n(PDF)\n.\nArtificial Intelligence Review\n.\n22\n(2):\n85–\n126.\nCiteSeerX\n10.1.1.318.4023\n.\ndoi\n:\n10.1007/s10462-004-4304-y\n.\nS2CID\n59941878\n.\nArchived\n(PDF)\nfrom the original on 22 June 2015\n. Retrieved\n25 November\n2018\n.\n^\nDokas, Paul; Ertoz, Levent; Kumar, Vipin; Lazarevic, Aleksandar; Srivastava, Jaideep; Tan, Pang-Ning (2002).\n\"Data mining for network intrusion detection\"\n(PDF)\n.\nProceedings NSF Workshop on Next Generation Data Mining\n.\nArchived\n(PDF)\nfrom the original on 23 September 2015\n. Retrieved\n26 March\n2023\n.\n^\nChandola, V.; Banerjee, A.; Kumar, V. (2009). \"Anomaly detection: A survey\".\nACM Computing Surveys\n.\n41\n(3):\n1–\n58.\ndoi\n:\n10.1145/1541880.1541882\n.\nS2CID\n207172599\n.\n^\nFleer, S.; Moringen, A.; Klatzky, R. L.; Ritter, H. (2020).\n\"Learning efficient haptic shape exploration with a rigid tactile sensor array, S. Fleer, A. Moringen, R. Klatzky, H. Ritter\"\n.\nPLOS ONE\n.\n15\n(1) e0226880.\narXiv\n:\n1902.07501\n.\ndoi\n:\n10.1371/journal.pone.0226880\n.\nPMC\n6940144\n.\nPMID\n31896135\n.\n^\nMoringen, Alexandra; Fleer, Sascha; Walck, Guillaume; Ritter, Helge (2020), Nisky, Ilana; Hartcher-O'Brien, Jess; Wiertlewski, Michaël; Smeets, Jeroen (eds.), \"Attention-Based Robot Learning of Haptic Interaction\",\nHaptics: Science, Technology, Applications\n, Lecture Notes in Computer Science, vol. 12272, Cham: Springer International Publishing, pp.\n462–\n470,\ndoi\n:\n10.1007/978-3-030-58147-3_51\n,\nISBN\n978-3-030-58146-6\n,\nS2CID\n220069113\n^\nPiatetsky-Shapiro, Gregory (1991),\nDiscovery, analysis, and presentation of strong rules\n, in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds.,\nKnowledge Discovery in Databases\n, AAAI/MIT Press, Cambridge, MA.\n^\nBassel, George W.; Glaab, Enrico; Marquez, Julietta; Holdsworth, Michael J.; Bacardit, Jaume (1 September 2011).\n\"Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets\"\n.\nThe Plant Cell\n.\n23\n(9):\n3101–\n3116.\nBibcode\n:\n2011PlanC..23.3101B\n.\ndoi\n:\n10.1105/tpc.111.088153\n.\nISSN\n1532-298X\n.\nPMC\n3203449\n.\nPMID\n21896882\n.\n^\nAgrawal, R.; Imieliński, T.; Swami, A. (1993). \"Mining association rules between sets of items in large databases\".\nProceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD '93\n. p. 207.\nCiteSeerX\n10.1.1.40.6984\n.\ndoi\n:\n10.1145/170035.170072\n.\nISBN\n978-0-89791-592-2\n.\nS2CID\n490415\n.\n^\nUrbanowicz, Ryan J.; Moore, Jason H. (22 September 2009).\n\"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\"\n.\nJournal of Artificial Evolution and Applications\n.\n2009\n:\n1–\n25.\ndoi\n:\n10.1155/2009/736398\n.\nISSN\n1687-6229\n.\n^\nPlotkin G.D.\nAutomatic Methods of Inductive Inference\nArchived\n22 December 2017 at the\nWayback Machine\n, PhD thesis, University of Edinburgh, 1970.\n^\nShapiro, Ehud Y.\nInductive inference of theories from facts\nArchived\n21 August 2021 at the\nWayback Machine\n, Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199–254.\n^\nShapiro, Ehud Y. (1983).\nAlgorithmic program debugging\n. Cambridge, Mass: MIT Press.\nISBN\n0-262-19218-7\n^\nShapiro, Ehud Y. \"\nThe model inference system\nArchived\n2023-04-06 at the\nWayback Machine\n.\" Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981.\n^\nBurkov, Andriy (2019).\nThe hundred-page machine learning book\n. Polen: Andriy Burkov.\nISBN\n978-1-9995795-0-0\n.\n^\nRussell, Stuart J.; Norvig, Peter (2021).\nArtificial intelligence: a modern approach\n. Pearson series in artificial intelligence (Fourth ed.). Hoboken: Pearson.\nISBN\n978-0-13-461099-3\n.\n^\nHonglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. \"\nConvolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations\nArchived\n2017-10-18 at the\nWayback Machine\n\" Proceedings of the 26th Annual International Conference on Machine Learning, 2009.\n^\n\"RandomForestRegressor\"\n.\nscikit-learn\n. Retrieved\n12 February\n2025\n.\n^\n\"What Is Random Forest? | IBM\"\n.\nwww.ibm.com\n. 20 October 2021\n. Retrieved\n12 February\n2025\n.\n^\nCortes, Corinna\n; Vapnik, Vladimir N. (1995).\n\"Support-vector networks\"\n.\nMachine Learning\n.\n20\n(3):\n273–\n297.\ndoi\n:\n10.1007/BF00994018\n.\n^\nStevenson, Christopher.\n\"Tutorial: Polynomial Regression in Excel\"\n.\nfacultystaff.richmond.edu\n.\nArchived\nfrom the original on 2 June 2013\n. Retrieved\n22 January\n2017\n.\n^\nWanta, Damian; Smolik, Aleksander; Smolik, Waldemar T.; Midura, Mateusz; Wróblewski, Przemysław (2025).\n\"Image reconstruction using machine-learned pseudoinverse in electrical capacitance tomography\"\n.\nEngineering Applications of Artificial Intelligence\n.\n142\n109888.\ndoi\n:\n10.1016/j.engappai.2024.109888\n.\n^\nThe documentation for\nscikit-learn\nalso has similar\nexamples\nArchived\n2 November 2022 at the\nWayback Machine\n.\n^\nGoldberg, David E.; Holland, John H. (1988).\n\"Genetic algorithms and machine learning\"\n(PDF)\n.\nMachine Learning\n.\n3\n(2):\n95–\n99.\ndoi\n:\n10.1007/bf00113892\n.\nS2CID\n35506513\n.\nArchived\n(PDF)\nfrom the original on 16 May 2011\n. Retrieved\n3 September\n2019\n.\n^\nMichie, D.; Spiegelhalter, D. J.; Taylor, C. C. (1994). \"Machine Learning, Neural and Statistical Classification\".\nEllis Horwood Series in Artificial Intelligence\n.\nBibcode\n:\n1994mlns.book.....M\n.\n^\nZhang, Jun; Zhan, Zhi-hui; Lin, Ying; Chen, Ni; Gong, Yue-jiao; Zhong, Jing-hui; Chung, Henry S.H.; Li, Yun; Shi, Yu-hui (2011). \"Evolutionary Computation Meets Machine Learning: A Survey\".\nIEEE Computational Intelligence Magazine\n.\n6\n(4):\n68–\n75.\nBibcode\n:\n2011ICIM....6d..68Z\n.\ndoi\n:\n10.1109/mci.2011.942584\n.\nS2CID\n6760276\n.\n^\nVerbert, K.; Babuška, R.; De Schutter, B. (1 April 2017).\n\"Bayesian and Dempster–Shafer reasoning for knowledge-based fault diagnosis–A comparative study\"\n.\nEngineering Applications of Artificial Intelligence\n.\n60\n:\n136–\n150.\ndoi\n:\n10.1016/j.engappai.2017.01.011\n.\nISSN\n0952-1976\n.\n^\nYoosefzadeh-Najafabadi, Mohsen; Hugh, Earl; Tulpan, Dan; Sulik, John; Eskandari, Milad (2021).\n\"Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean?\"\n.\nFront. Plant Sci\n.\n11\n624273.\nBibcode\n:\n2021FrPS...1124273Y\n.\ndoi\n:\n10.3389/fpls.2020.624273\n.\nPMC\n7835636\n.\nPMID\n33510761\n.\n^\nUrbanowicz, Ryan J.; Moore, Jason H. (22 September 2009).\n\"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\"\n.\nJournal of Artificial Evolution and Applications\n.\n2009\n:\n1–\n25.\ndoi\n:\n10.1155/2009/736398\n.\nISSN\n1687-6229\n.\n^\nZhang, C. and Zhang, S., 2002.\nAssociation rule mining: models and algorithms\n. Springer-Verlag.\n^\nDe Castro, Leandro Nunes, and Jonathan Timmis.\nArtificial immune systems: a new computational intelligence approach\n. Springer Science & Business Media, 2002.\n^\n\"Federated Learning: Collaborative Machine Learning without Centralized Training Data\"\n.\nGoogle AI Blog\n. 6 April 2017.\nArchived\nfrom the original on 7 June 2019\n. Retrieved\n8 June\n2019\n.\n^\nMachine learning is included in the\nCFA Curriculum\n; see:\n[1]\n{{Webarchive|url=\nhttps://www.cfainstitute.org/\n^\nMarcos M. López de Prado (2010).\nMachine Learning for Asset Managers\n.\nCambridge University Press\n.\nISBN\n9781108883658\n^\nIvanenko, Mikhail; Smolik, Waldemar T.; Wanta, Damian; Midura, Mateusz; Wróblewski, Przemysław; Hou, Xiaohan; Yan, Xiaoheng (2023).\n\"Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax\"\n.\nSensors\n.\n23\n(18): 7774.\nBibcode\n:\n2023Senso..23.7774I\n.\ndoi\n:\n10.3390/s23187774\n.\nPMC\n10538128\n.\nPMID\n37765831\n.\n^\n\"BelKor Home Page\"\nresearch.att.com\n^\n\"The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)\"\n. 6 April 2012. Archived from\nthe original\non 31 May 2016\n. Retrieved\n8 August\n2015\n.\n^\nScott Patterson (13 July 2010).\n\"Letting the Machines Decide\"\n.\nThe Wall Street Journal\n.\nArchived\nfrom the original on 24 June 2018\n. Retrieved\n24 June\n2018\n.\n^\nVinod Khosla (10 January 2012).\n\"Do We Need Doctors or Algorithms?\"\n. Tech Crunch.\nArchived\nfrom the original on 18 June 2018\n. Retrieved\n20 October\n2016\n.\n^\nWhen A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed\nArchived\n4 June 2016 at the\nWayback Machine\n,\nThe Physics at\nArXiv\nblog\n^\nVincent, James (10 April 2019).\n\"The first AI-generated textbook shows what robot writers are actually good at\"\n.\nThe Verge\n.\nArchived\nfrom the original on 5 May 2019\n. Retrieved\n5 May\n2019\n.\n^\nVaishya, Raju; Javaid, Mohd; Khan, Ibrahim Haleem; Haleem, Abid (1 July 2020).\n\"Artificial Intelligence (AI) applications for COVID-19 pandemic\"\n.\nDiabetes & Metabolic Syndrome: Clinical Research & Reviews\n.\n14\n(4):\n337–\n339.\ndoi\n:\n10.1016/j.dsx.2020.04.012\n.\nPMC\n7195043\n.\nPMID\n32305024\n.\n^\nRezapouraghdam, Hamed; Akhshik, Arash; Ramkissoon, Haywantee (10 March 2021).\n\"Application of machine learning to predict visitors' green behavior in marine protected areas: evidence from Cyprus\"\n.\nJournal of Sustainable Tourism\n.\n31\n(11):\n2479–\n2505.\ndoi\n:\n10.1080/09669582.2021.1887878\n.\nhdl\n:\n10037/24073\n.\n^\nDey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (15 June 2020).\n\"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\"\n.\n2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)\n(PDF)\n. pp.\n1728–\n1733.\ndoi\n:\n10.23919/DATE48585.2020.9116294\n.\nISBN\n978-3-9819263-4-7\n.\nS2CID\n219858480\n.\nArchived\nfrom the original on 13 December 2021\n. Retrieved\n20 J",
      "scraped_at": "2025-12-16T17:26:41.268708",
      "status": "success",
      "content_length": 126044,
      "topic": "ai_basics"
    },
    {
      "title": "Neural network - Wikipedia",
      "url": "https://en.wikipedia.org/wiki/Neural_network",
      "content": "Neural network - Wikipedia\nJump to content\nMain menu\nMain menu\nmove to sidebar\nhide\nNavigation\nMain page\nContents\nCurrent events\nRandom article\nAbout Wikipedia\nContact us\nContribute\nHelp\nLearn to edit\nCommunity portal\nRecent changes\nUpload file\nSpecial pages\nSearch\nSearch\nAppearance\nDonate\nCreate account\nLog in\nPersonal tools\nDonate\nCreate account\nLog in\nContents\nmove to sidebar\nhide\n(Top)\n1\nIn biology\n2\nIn machine learning\n3\nHistory\n4\nSee also\n5\nReferences\nToggle the table of contents\nNeural network\n22 languages\nAfrikaans\nالعربية\nCatalà\nفارسی\nGalego\n한국어\nՀայերեն\nBahasa Indonesia\nIsiZulu\nLigure\nമലയാളം\nNederlands\nPortuguês\nSlovenščina\nСрпски / srpski\nதமிழ்\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n粵語\n中文\nEdit links\nArticle\nTalk\nEnglish\nRead\nEdit\nView history\nTools\nTools\nmove to sidebar\nhide\nActions\nRead\nEdit\nView history\nGeneral\nWhat links here\nRelated changes\nUpload file\nPermanent link\nPage information\nCite this page\nGet shortened URL\nDownload QR code\nPrint/export\nDownload as PDF\nPrintable version\nIn other projects\nWikidata item\nAppearance\nmove to sidebar\nhide\nFrom Wikipedia, the free encyclopedia\nStructure in biology and artificial intelligence\nFor other uses, see\nNeural network (disambiguation)\n.\nA\nneural network\nis a group of interconnected units called\nneurons\nthat send signals to one another. Neurons can be either\nbiological cells\nor\nmathematical models\n. While individual neurons are simple, many of them together in a network can perform complex tasks. There are two main types of neural networks.\nIn\nneuroscience\n, a\nbiological neural network\nis a physical structure found in\nbrains\nand complex\nnervous systems\n– a population of nerve cells connected by\nsynapses\n.\nIn\nmachine learning\n, an\nartificial neural network\nis a mathematical model used to approximate\nnonlinear functions\n. Artificial neural networks are used to solve\nartificial intelligence\nproblems.\nIn biology\n[\nedit\n]\nAnimated\nconfocal micrograph\nof part of a biological neural network in a mouse's\nstriatum\nMain article:\nNeural network (biology)\nIn the context of biology, a neural network is a population of biological\nneurons\nchemically connected to each other by\nsynapses\n. A given neuron can be connected to hundreds of thousands of synapses.\n[\n1\n]\nEach neuron sends and receives\nelectrochemical\nsignals called\naction potentials\nto its connected neighbors. A neuron can serve an\nexcitatory\nrole, amplifying and propagating signals it receives, or an\ninhibitory\nrole, suppressing signals instead.\n[\n1\n]\nPopulations of interconnected neurons that are smaller than neural networks are called\nneural circuits\n. Very large interconnected networks are called\nlarge scale brain networks\n, and many of these together form\nbrains\nand\nnervous systems\n.\nSignals generated by neural networks in the brain eventually travel through the nervous system and across\nneuromuscular junctions\nto\nmuscle cells\n, where they cause contraction and thereby motion.\n[\n2\n]\nIn machine learning\n[\nedit\n]\nMain article:\nNeural network (machine learning)\nSchematic of a simple\nfeedforward\nartificial neural network\nIn machine learning, a neural network is an artificial mathematical model used to approximate nonlinear functions. While early artificial neural networks were physical machines,\n[\n3\n]\ntoday they are almost always implemented in\nsoftware\n.\nNeurons\nin an artificial neural network are usually arranged into layers, with information passing from the first layer (the input layer) through one or more intermediate layers (\nthe hidden layers\n) to the final layer (the output layer).\n[\n4\n]\nThe \"signal\" input to each neuron is a number, specifically a\nlinear combination\nof the outputs of the connected neurons in the previous layer. The signal each neuron outputs is calculated from this number, according to its\nactivation function\n. The behavior of the network depends on the strengths (or\nweights\n) of the connections between neurons. A network is trained by modifying these weights through\nempirical risk minimization\nor\nbackpropagation\nin order to fit some preexisting dataset.\n[\n5\n]\nThe term\ndeep neural network\nrefers to neural networks that have more than three layers, typically including at least two hidden layers in addition to the input and output layers.\nNeural networks are used to solve problems in\nartificial intelligence\n, and have thereby found applications in many disciplines, including\npredictive modeling\n,\nadaptive control\n,\nfacial recognition\n,\nhandwriting recognition\n,\ngeneral game playing\n, and\ngenerative AI\n.\nHistory\n[\nedit\n]\nSee also:\nBiological neural network § History\n, and\nHistory of artificial neural networks\nThe theoretical base for contemporary neural networks was independently proposed by\nAlexander Bain\nin 1873\n[\n6\n]\nand\nWilliam James\nin 1890.\n[\n7\n]\nBoth posited that human thought emerged from interactions among large numbers of neurons inside the brain. In 1949,\nDonald Hebb\ndescribed\nHebbian learning\n, the idea that neural networks can change and learn over time by strengthening a synapse every time a signal travels along it.\n[\n8\n]\nIn 1956,\nSvaetichin\ndiscovered the functioning of second order retinal cells (Horizontal Cells), which were fundamental for the understanding of neural networks.\nArtificial neural networks were originally used to model biological neural networks starting in the 1930s under the approach of\nconnectionism\n. However, starting with the invention of the\nperceptron\n, a simple artificial neural network, by\nWarren McCulloch\nand\nWalter Pitts\nin 1943,\n[\n9\n]\nfollowed by the implementation of one in hardware by\nFrank Rosenblatt\nin 1957,\n[\n3\n]\nartificial neural networks became increasingly used for machine learning applications instead, and increasingly different from their biological counterparts.\nSee also\n[\nedit\n]\nEmergence\nBiological cybernetics\nBiologically-inspired computing\nReferences\n[\nedit\n]\n^\na\nb\nShao, Feng; Shen, Zheng (January 9, 2022).\n\"How can artificial neural networks approximate the brain?\"\n.\nFront. Psychol\n.\n13\n970214.\ndoi\n:\n10.3389/fpsyg.2022.970214\n.\nPMC\n9868316\n.\nPMID\n36698593\n.\n^\nLevitan, Irwin; Kaczmarek, Leonard (August 19, 2015). \"Intercellular communication\".\nThe Neuron: Cell and Molecular Biology\n(4th ed.). New York, NY: Oxford University Press. pp.\n153–\n328.\nISBN\n978-0-19-977389-3\n.\n^\na\nb\nRosenblatt, F. (1958). \"The Perceptron: A Probabilistic Model For Information Storage And Organization In The Brain\".\nPsychological Review\n.\n65\n(6):\n386–\n408.\nCiteSeerX\n10.1.1.588.3775\n.\ndoi\n:\n10.1037/h0042519\n.\nPMID\n13602029\n.\nS2CID\n12781225\n.\n^\nBishop, Christopher M. (August 17, 2006).\nPattern Recognition and Machine Learning\n. New York: Springer.\nISBN\n978-0-387-31073-2\n.\n^\nVapnik, Vladimir N.; Vapnik, Vladimir Naumovich (1998).\nThe nature of statistical learning theory\n(Corrected 2nd print. ed.). New York Berlin Heidelberg: Springer.\nISBN\n978-0-387-94559-0\n.\n^\nBain (1873).\nMind and Body: The Theories of Their Relation\n. New York: D. Appleton and Company.\n^\nJames (1890).\nThe Principles of Psychology\n. New York: H. Holt and Company.\n^\nHebb, D.O. (1949).\nThe Organization of Behavior\n. New York: Wiley & Sons.\n^\nMcCulloch, W; Pitts, W (1943).\n\"A Logical Calculus of Ideas Immanent in Nervous Activity\"\n(PDF)\n.\nBulletin of Mathematical Biophysics\n.\n5\n(4):\n115–\n133.\ndoi\n:\n10.1007/BF02478259\n.\nArchived\nfrom the original on May 17, 2024\n. Retrieved\nFebruary 17,\n2024\n.\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Neural_network&oldid=1319374446\n\"\nCategory\n:\nNeural networks\nHidden categories:\nArticles with short description\nShort description matches Wikidata\nUse mdy dates from April 2025\nUse American English from April 2025\nAll Wikipedia articles written in American English\nBroad-concept articles\nThis page was last edited on 29 October 2025, at 12:13\n(UTC)\n.\nText is available under the\nCreative Commons Attribution-ShareAlike 4.0 License\n;\nadditional terms may apply. By using this site, you agree to the\nTerms of Use\nand\nPrivacy Policy\n. Wikipedia® is a registered trademark of the\nWikimedia Foundation, Inc.\n, a non-profit organization.\nPrivacy policy\nAbout Wikipedia\nDisclaimers\nContact Wikipedia\nCode of Conduct\nDevelopers\nStatistics\nCookie statement\nMobile view\nSearch\nSearch\nToggle the table of contents\nNeural network\n22 languages\nAdd topic",
      "scraped_at": "2025-12-16T17:26:43.271037",
      "status": "success",
      "content_length": 8244,
      "topic": "ai_basics"
    },
    {
      "title": "Machine learning",
      "status": "not_found",
      "error": "Page not found",
      "topic": "machine_learning",
      "source": "wikipedia"
    },
    {
      "title": "Supervised learning",
      "url": "https://en.wikipedia.org/wiki/Supervised_learning",
      "content": "In machine learning, supervised learning (SL) is a type of machine learning paradigm where an algorithm learns to map input data to a specific output based on example input-output pairs. This process involves training a statistical model using labeled data, meaning each piece of input data is provided with the correct output. For instance, if you want a model to identify cats in images, supervised learning would involve feeding it many images of cats (inputs) that are explicitly labeled \"cat\" (outputs).\nThe goal of supervised learning is for the trained model to accurately predict the output for new, unseen data. This requires the algorithm to effectively generalize from the training examples, a quality measured by its generalization error. Supervised learning is commonly used for tasks like classification (predicting a category, e.g., spam or not spam) and regression (predicting a continuous value, e.g., house prices).\n\n\n== Steps to follow ==\nTo solve a given problem of supervised learning, the following steps must be performed:\n\n\n== Algorithm choice ==\nA wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the No free lunch theorem).\nThere are four major issues to consider in supervised learning:\n\n\n=== Bias–variance tradeoff ===\n\nA first issue is the tradeoff between bias and variance. Imagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. A learning algorithm has high variance for a particular input \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n if it predicts different output values when trained on different training sets. The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. Generally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be \"flexible\" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).\n\n\n=== Function complexity and amount of training data ===\nThe second issue is of the amount of training data available relative to the complexity of the \"true\" function (classifier or regression function). If the true function is simple, then an \"inflexible\" learning algorithm with high bias and low variance will be able to learn it from a small amount of data. But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be able to learn with a large amount of training data paired with a \"flexible\" learning algorithm with low bias and high variance.\n\n\n=== Dimensionality of the input space ===\nA third issue is the dimensionality of the input space. If the input feature vectors have large dimensions, learning the function can be difficult even if the true function only depends on a small number of those features. This is because the many \"extra\" dimensions can confuse the learning algorithm and cause it to have high variance. Hence, input data of large dimensions typically requires tuning the classifier to have low variance and high bias. In practice, if the engineer can manually remove irrelevant features from the input data, it will likely improve the accuracy of the learned function. In addition, there are many algorithms for feature selection that seek to identify the relevant features and discard the irrelevant ones. This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.\n\n\n=== Noise in the output values ===\nA fourth issue is the degree of noise in the desired output values (the supervisory target variables). If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to overfitting. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation, the part of the target function that cannot be modeled \"corrupts\" your training data – this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.\nIn practice, there are several approaches to alleviate noise in the output values such as early stopping to prevent overfitting as well as detecting and removing the noisy training examples prior to training the supervised learning algorithm. There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased generalization error with statistical significance.\n\n\n=== Other factors to consider ===\nOther factors to consider when choosing and applying a learning algorithm include the following:\n\nHeterogeneity of the data. If the feature vectors include features of many different kinds (discrete, discrete ordered, counts, continuous values), some algorithms are easier to apply than others. Many algorithms, including support-vector machines, linear regression, logistic regression, neural networks, and nearest neighbor methods, require that the input features be numerical and scaled to similar ranges (e.g., to the [-1,1] interval). Methods that employ a distance function, such as nearest neighbor methods and support-vector machines with Gaussian kernels, are particularly sensitive to this. An advantage of decision trees is that they easily handle heterogeneous data.\nRedundancy in the data. If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g., linear regression, logistic regression, and  distance-based methods) will perform poorly because of numerical instabilities. These problems can often be solved by imposing some form of regularization.\nPresence of interactions and non-linearities. If each of the features makes an independent contribution to the output, then algorithms based on linear functions (e.g., linear regression, logistic regression, support-vector machines, naive Bayes) and distance functions (e.g., nearest neighbor methods, support-vector machines with Gaussian kernels) generally perform well. However, if there are complex interactions among features, then algorithms such as decision trees and neural networks work better, because they are specifically designed to discover these interactions. Linear methods can also be applied, but the engineer must manually specify the interactions when using them.\nWhen considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see  cross-validation). Tuning the performance of a learning algorithm can be very time-consuming. Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.\n\n\n=== Algorithms ===\nThe most widely used learning algorithms are: \n\nSupport-vector machines\nLinear regression\nLogistic regression\nNaive Bayes\nLinear discriminant analysis\nDecision trees\nk-nearest neighbors algorithm\nNeural networks (e.g., Multilayer perceptron)\nSimilarity learning\n\n\n== How supervised learning algorithms work ==\nGiven a set of \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n training examples of the form \n  \n    \n      \n        {\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          y\n          \n            1\n          \n        \n        )\n        ,\n        .\n        .\n        .\n        ,\n        (\n        \n          x\n          \n            N\n          \n        \n        ,\n        \n        \n          y\n          \n            N\n          \n        \n        )\n        }\n      \n    \n    {\\displaystyle \\{(x_{1},y_{1}),...,(x_{N},\\;y_{N})\\}}\n  \n such that \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  \n is the feature vector of the \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n-th example and \n  \n    \n      \n        \n          y\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle y_{i}}\n  \n is its label (i.e., class), a learning algorithm seeks a function \n  \n    \n      \n        g\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle g:X\\to Y}\n  \n, where \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the input space and \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n is the output space. The function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is an element of some space of possible functions \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, usually called the hypothesis space. It is sometimes convenient to represent \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n using a scoring function \n  \n    \n      \n        f\n        :\n        X\n        ×\n        Y\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:X\\times Y\\to \\mathbb {R} }\n  \n such that \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is defined as returning the \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n value that gives the highest score: \n  \n    \n      \n        g\n        (\n        x\n        )\n        =\n        \n          \n            \n              arg\n              ⁡\n              max\n            \n            y\n          \n        \n        \n        f\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;f(x,y)}\n  \n. Let \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n denote the space of scoring functions.\nAlthough \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n and \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be any space of functions, many learning algorithms are probabilistic models where \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n takes the form of a conditional probability model \n  \n    \n      \n        g\n        (\n        x\n        )\n        =\n        \n          \n            \n              arg\n              ⁡\n              max\n            \n            y\n          \n        \n        \n        P\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;P(y|x)}\n  \n, or \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n takes the form of a joint probability model \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        P\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle f(x,y)=P(x,y)}\n  \n. For example, naive Bayes and linear discriminant analysis are joint probability models, whereas logistic regression is a conditional probability model.\nThere are two basic approaches to choosing \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n or \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n: empirical risk minimization and structural risk minimization. Empirical risk minimization seeks the function that best fits the training data. Structural risk minimization includes a penalty function that controls the bias/variance tradeoff.\nIn both cases, it is assumed that the training set consists of a sample of independent and identically distributed pairs, \n  \n    \n      \n        (\n        \n          x\n          \n            i\n          \n        \n        ,\n        \n        \n          y\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{i},\\;y_{i})}\n  \n. In order to measure how well a function fits the training data, a loss function \n  \n    \n      \n        L\n        :\n        Y\n        ×\n        Y\n        →\n        \n          \n            R\n          \n          \n            ≥\n            0\n          \n        \n      \n    \n    {\\displaystyle L:Y\\times Y\\to \\mathbb {R} ^{\\geq 0}}\n  \n is defined. For training example \n  \n    \n      \n        (\n        \n          x\n          \n            i\n          \n        \n        ,\n        \n        \n          y\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{i},\\;y_{i})}\n  \n, the loss of predicting the value \n  \n    \n      \n        \n          \n            \n              y\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {y}}}\n  \n is \n  \n    \n      \n        L\n        (\n        \n          y\n          \n            i\n          \n        \n        ,\n        \n          \n            \n              y\n              ^\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle L(y_{i},{\\hat {y}})}\n  \n.\nThe risk \n  \n    \n      \n        R\n        (\n        g\n        )\n      \n    \n    {\\displaystyle R(g)}\n  \n of function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is defined as the expected loss of \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n. This can be estimated from the training data as\n\n  \n    \n      \n        \n          R\n          \n            e\n            m\n            p\n          \n        \n        (\n        g\n        )\n        =\n        \n          \n            1\n            N\n          \n        \n        \n          ∑\n          \n            i\n          \n        \n        L\n        (\n        \n          y\n          \n            i\n          \n        \n        ,\n        g\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle R_{emp}(g)={\\frac {1}{N}}\\sum _{i}L(y_{i},g(x_{i}))}\n  \n.\n\n\n=== Empirical risk minimization ===\n\nIn empirical risk minimization, the supervised learning algorithm seeks the function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n that minimizes \n  \n    \n      \n        R\n        (\n        g\n        )\n      \n    \n    {\\displaystyle R(g)}\n  \n. Hence, a supervised learning algorithm can be constructed by applying an optimization algorithm to find \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n.\nWhen \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is a conditional probability distribution \n  \n    \n      \n        P\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle P(y|x)}\n  \n and the loss function is the negative log likelihood: \n  \n    \n      \n        L\n        (\n        y\n        ,\n        \n          \n            \n              y\n              ^\n            \n          \n        \n        )\n        =\n        −\n        log\n        ⁡\n        P\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle L(y,{\\hat {y}})=-\\log P(y|x)}\n  \n, then empirical risk minimization is equivalent to maximum likelihood estimation.\nWhen \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n contains many candidate functions or the training set is not sufficiently large, empirical risk minimization leads to high variance and poor generalization. The learning algorithm is able to memorize the training examples without generalizing well (overfitting).\n\n\n=== Structural risk minimization ===\nStructural risk minimization seeks to prevent overfitting by incorporating a regularization penalty into the optimization. The regularization penalty can be viewed as implementing a form of Occam's razor that prefers simpler functions over more complex ones.\nA wide variety of penalties have been employed that correspond to different definitions of complexity. For example, consider the case where the function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is a linear function of the form\n\n  \n    \n      \n        g\n        (\n        x\n        )\n        =\n        \n          ∑\n          \n            j\n            =\n            1\n          \n          \n            d\n          \n        \n        \n          β\n          \n            j\n          \n        \n        \n          x\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle g(x)=\\sum _{j=1}^{d}\\beta _{j}x_{j}}\n  \n.\nA popular regularization penalty is \n  \n    \n      \n        \n          ∑\n          \n            j\n          \n        \n        \n          β\n          \n            j\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\sum _{j}\\beta _{j}^{2}}\n  \n, which is the squared Euclidean norm of the weights, also known as the \n  \n    \n      \n        \n          L\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle L_{2}}\n  \n norm. Other norms include the \n  \n    \n      \n        \n          L\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle L_{1}}\n  \n norm, \n  \n    \n      \n        \n          ∑\n          \n            j\n          \n        \n        \n          |\n        \n        \n          β\n          \n            j\n          \n        \n        \n          |\n        \n      \n    \n    {\\displaystyle \\sum _{j}|\\beta _{j}|}\n  \n, and the \n  \n    \n      \n        \n          L\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle L_{0}}\n  \n \"norm\", which is the number of non-zero \n  \n    \n      \n        \n          β\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle \\beta _{j}}\n  \ns. The penalty will be denoted by \n  \n    \n      \n        C\n        (\n        g\n        )\n      \n    \n    {\\displaystyle C(g)}\n  \n.\nThe supervised learning optimization problem is to find the function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n that minimizes\n\n  \n    \n      \n        J\n        (\n        g\n        )\n        =\n        \n          R\n          \n            e\n            m\n            p\n          \n        \n        (\n        g\n        )\n        +\n        λ\n        C\n        (\n        g\n        )\n        .\n      \n    \n    {\\displaystyle J(g)=R_{emp}(g)+\\lambda C(g).}\n  \n\nThe parameter \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n controls the bias-variance tradeoff. When \n  \n    \n      \n        λ\n        =\n        0\n      \n    \n    {\\displaystyle \\lambda =0}\n  \n, this gives empirical risk minimization with low bias and high variance. When \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n is large, the learning algorithm will have high bias and low variance. The value of \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n can be chosen empirically via  cross-validation.\nThe complexity penalty has a Bayesian interpretation as the negative log prior probability of \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n, \n  \n    \n      \n        −\n        log\n        ⁡\n        P\n        (\n        g\n        )\n      \n    \n    {\\displaystyle -\\log P(g)}\n  \n, in which case \n  \n    \n      \n        J\n        (\n        g\n        )\n      \n    \n    {\\displaystyle J(g)}\n  \n is the posterior probability of \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n.\n\n\n== Generative training ==\nThe training methods described above are discriminative training methods, because they seek to find a function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n that discriminates well between the different output values (see discriminative model). For the special case where \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        P\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle f(x,y)=P(x,y)}\n  \n is a joint probability distribution and the loss function is the negative log likelihood \n  \n    \n      \n        −\n        \n          ∑\n          \n            i\n          \n        \n        log\n        ⁡\n        P\n        (\n        \n          x\n          \n            i\n          \n        \n        ,\n        \n          y\n          \n            i\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle -\\sum _{i}\\log P(x_{i},y_{i}),}\n  \n a risk minimization algorithm is said to perform generative training, because \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n can be regarded as a generative model that explains how the data were generated. Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms. In some cases, the solution can be computed in closed form as in naive Bayes and linear discriminant analysis.\n\n\n== Generalizations ==\nThere are several ways in which the standard supervised learning problem can be generalized:\nSemi-supervised learning or weak supervision: the desired output values are provided only for a subset of the training data. The remaining data is unlabeled or imprecisely labeled.\nActive learning: Instead of assuming that all of the training examples are given at the start, active learning algorithms interactively collect new examples, typically by making queries to a human user. Often, the queries are based on unlabeled data, which is a scenario that combines semi-supervised learning with active learning.\nStructured prediction: When the desired output value is a complex object, such as a parse tree or a labeled graph, then standard methods must be extended.\nLearning to rank: When the input is a set of objects and the desired output is a ranking of those objects, then again the standard methods must be extended.\n\n\n== Approaches and algorithms ==\nAnalytical learning\nArtificial neural network\nBackpropagation\nBoosting (meta-algorithm)\nBayesian statistics\nCase-based reasoning\nDecision tree learning\nInductive logic programming\nGaussian process regression\nGenetic programming\nGroup method of data handling\nKernel estimators\nLearning automata\nLearning classifier systems\nLearning vector quantization\nMinimum message length (decision trees, decision graphs, etc.)\nMultilinear subspace learning\nNaive Bayes classifier\nMaximum entropy classifier\nConditional random field\nNearest neighbor algorithm\nProbably approximately correct learning (PAC) learning\nRipple down rules, a knowledge acquisition methodology\nSymbolic machine learning algorithms\nSubsymbolic machine learning algorithms\nSupport vector machines\nMinimum complexity machines (MCM)\nRandom forests\nEnsembles of classifiers\nOrdinal classification\nData pre-processing\nHandling imbalanced datasets\nStatistical relational learning\nProaftn, a multicriteria classification algorithm\n\n\n== Applications ==\nBioinformatics\nCheminformatics\nQuantitative structure–activity relationship\nDatabase marketing\nHandwriting recognition\nInformation retrieval\nLearning to rank\nInformation extraction\nObject recognition in computer vision\nOptical character recognition\nSpam detection\nPattern recognition\nSpeech recognition\nSupervised learning is a special case of downward causation in biological systems\nLandform classification using satellite imagery\nSpend classification in procurement processes\n\n\n== General issues ==\nComputational learning theory\nInductive bias\nOverfitting\n(Uncalibrated) class membership probabilities\nVersion spaces\n\n\n== See also ==\nList of datasets for machine-learning research\nUnsupervised learning\n\n\n== References ==\n\n\n== External links ==\nMachine Learning Open Source Software (MLOSS)",
      "summary": "In machine learning, supervised learning (SL) is a type of machine learning paradigm where an algorithm learns to map input data to a specific output based on example input-output pairs. This process involves training a statistical model using labeled data, meaning each piece of input data is provided with the correct output. For instance, if you want a model to identify cats in images, supervised learning would involve feeding it many images of cats (inputs) that are explicitly labeled \"cat\" (o",
      "links": [
        "Active learning (machine learning)",
        "Anomaly detection",
        "ArXiv (identifier)",
        "Artificial neural network",
        "Automatic differentiation",
        "Backpropagation",
        "Bayesian statistics",
        "Bias–variance tradeoff",
        "Bioinformatics",
        "Boosting (meta-algorithm)",
        "Case-based reasoning",
        "Cheminformatics",
        "CiteSeerX (identifier)",
        "Class membership probabilities",
        "Classification",
        "Computational learning theory",
        "Computer vision",
        "Conditional probability",
        "Conditional random field",
        "Cross-validation (statistics)"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 24252,
      "topic": "machine_learning"
    },
    {
      "title": "Deep learning",
      "url": "https://en.wikipedia.org/wiki/Deep_learning",
      "content": "In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n\n\n== Overview ==\nMost modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.\nFundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\nImportantly, a deep learning process can learn which features to optimally place at which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\nDeep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.\nThe term deep learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons. Although the history of its appearance is apparently more complicated.\n\n\n== Interpretations ==\nDeep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.\nThe classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima's rectified linear unit.\nThe universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\nThe probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.\n\n\n== History ==\n\n\n=== Before 1980 ===\nThere are two types of artificial neural network (ANN): feedforward neural network (FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have cycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive. His learning RNN was republished by John Hopfield in 1982. Other early recurrent neural networks were published by Kaoru Nakano in 1971. Already in 1948, Alan Turing produced work on \"Intelligent Machinery\"  that was not published in his lifetime, containing \"ideas related to artificial evolution and learning RNNs\".\nFrank Rosenblatt (1958) proposed the perceptron, an MLP with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. He later published a 1962 book that also introduced variants and computer experiments, including a version with four-layer perceptrons \"with adaptive preterminal networks\" where the last two layers have learned weights (here he credits H. D. Block and B. W. Knight). The book cites an earlier network by R. D. Joseph (1960) \"functionally equivalent to a variation of\" this four-layer system (the book mentions Joseph over 30 times). Should Joseph therefore be considered the originator of proper adaptive multilayer perceptrons with learning hidden units? Unfortunately, the learning algorithm was not a functional one, and fell into oblivion.\nThe first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in 1965. They regarded it as a form of polynomial regression, or a generalization of Rosenblatt's perceptron to handle more complex, nonlinear, and hierarchical relationships. A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates\".\nThe first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes. Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\nIn 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for deep learning.\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation.\nBackpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory. The modern form of backpropagation was first published in Seppo Linnainmaa's master thesis (1970). G.M. Ostrovski et al. republished it in 1971. Paul Werbos applied backpropagation to neural networks in 1982 (his 1974 PhD thesis, reprinted in a 1994 book, did not yet describe the algorithm). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.\n\n\n=== 1980s-2000s ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.  In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition. \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\nRecurrent neural networks (RNN) were further developed in the 1980s. Recurrence is used for sequence processing, and when a recurrent network is unrolled, it mathematically resembles a deep feedforward layer. Consequently, they have similar properties and issues, and their developments had mutual influences. In RNN, two early influential works were the Jordan network (1986) and the Elman network (1990), which applied RNN to study problems in cognitive psychology.\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, in 1991, Jürgen Schmidhuber proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning where each RNN tries to predict its own next input, which is the next unexpected input of the RNN below. This \"neural history compressor\" uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by  distilling a higher level chunker network into a lower level automatizer network. In 1993, a neural history compressor solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time. The \"P\" in ChatGPT refers to such pre-training.\nSepp Hochreiter's diploma thesis (1991) implemented the neural history compressor, and identified and analyzed the vanishing gradient problem.  Hochreiter proposed recurrent residual connections to solve the vanishing gradient problem. This led to the long short-term memory (LSTM), published in 1995. LSTM can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. That LSTM was not yet the modern architecture, which required a \"forget gate\", introduced in 1999, which became the standard RNN architecture.\nIn 1991, Jürgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in generative adversarial networks (GANs).\nDuring 1985–1995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine, restricted Boltzmann machine, Helmholtz machine, and the wake-sleep algorithm. These were designed for unsupervised learning of deep generative models. However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112 ). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.\nMost speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI researched in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 NIST Speaker Recognition benchmark. It was deployed in the Nuance Verifier, representing the first major industrial application of deep learning.\nThe principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.\n\n\n=== 2000s ===\nNeural networks entered a lull, and simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) became the preferred choices in the 1990s and 2000s, because of artificial neural networks' computational cost and a lack of understanding of how the brain wires its biological networks.\nIn 2003, LSTM became competitive with traditional speech recognizers on certain tasks. In 2006, Alex Graves, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC) in stacks of LSTMs. In 2009, it became the first RNN to win a pattern recognition contest, in connected handwriting recognition.\nIn 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh deep belief networks were developed for generative modeling. They are trained by training one restricted Boltzmann machine, then freezing it and training another one on top of the first one, and so on, then optionally fine-tuned using supervised backpropagation. They could model high-dimensional probability distributions, such as the distribution of MNIST images, but convergence was slow.\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.\n\n\n=== Deep learning revolution ===\n\nThe deep learning revolution started around CNN- and GPU-based computer vision.\nAlthough CNNs trained by backpropagation had been around for decades and GPU implementations of NNs for years, including CNNs, faster implementations of CNNs on GPUs were needed to progress on computer vision. Later, as deep learning becomes widespread, specialized hardware and algorithm optimizations were developed specifically for deep learning.\nA key advance for the deep learning revolution was hardware advances, especially GPU. Some early work dated back to 2004. In 2009, Raina, Madhavan, and Andrew Ng reported a 100M deep belief network trained on 30 Nvidia GeForce GTX 280 GPUs, an early demonstration of GPU-based deep learning. They reported up to 70 times faster training.\nIn 2011, a CNN named DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. It then won more contests. They also showed how max-pooling CNNs on GPU improved performance significantly.\nIn 2012, Andrew Ng and Jeff Dean created an FNN that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from YouTube videos.\nIn October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman and Google's Inceptionv3.\nThe success in image classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.\nIn 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train very deep networks: the highway network was published in May 2015, and the residual neural network (ResNet) in Dec 2015. ResNet behaves like an open-gated Highway Net.\nAround the same time, deep learning started impacting the field of art. Early examples included Google DeepDream (2015), and neural style transfer (2015), both of which were based on pretrained image classification neural networks, such as VGG-19.\nGenerative adversarial network (GAN) by (Ian Goodfellow et al., 2014) (based on  Jürgen Schmidhuber's principle of artificial curiosity)\nbecame state of the art in generative modeling during 2014-2018 period. Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras et al. Here the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes.  Diffusion models (2015) eclipsed GANs in generative modeling since then, with systems such as DALL·E 2 (2022) and Stable Diffusion (2022).\nIn 2015, Google's speech recognition improved by 49% by an LSTM-based model, which they made available through Google Voice Search on smartphone.\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks were superseded for ASR by LSTM. but are more successful in computer vision.\nYoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the 2018 Turing Award for \"conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing\".\n\n\n== Neural networks ==\n\nArtificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\nNeural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\").\n\n\n=== Deep neural networks ===\nA deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers. There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions. These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.\nFor example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer, and complex DNN have many layers, hence the name \"deep\" networks.\nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives. The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network. For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights. That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\nRecurrent neural networks, in which data can flow in any direction, are used for applications such as language modeling. Long short-term memory is particularly effective for this use.\nConvolutional neural networks (CNNs) are used in computer vision. CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).\n\n\n==== Challenges ====\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko's unit pruning or weight decay (\n  \n    \n      \n        \n          ℓ\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\ell _{2}}\n  \n-regularization) or sparsity (\n  \n    \n      \n        \n          ℓ\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\ell _{1}}\n  \n-regularization) can be applied during training to combat overfitting. Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies. Another interesting recent development is research into models of just enough complexity through an estimation of the intrinsic complexity of the task being modelled. This approach has been successfully applied for multivariate time series prediction tasks such as traffic prediction. Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples) speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.\nAlternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn't require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\n\n\n== Hardware ==\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method for training large-scale commercial cloud AI . OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.\nSpecial electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).\nAtomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).\nIn 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing. The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds. Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.\n\n\n== Applications ==\n\n\n=== Automatic speech recognition ===\n\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\n\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:\n\nScale-up/out and accelerated DNN training and decoding\nSequence discriminative training\nFeature processing by deep models with solid understanding of the underlying mechanisms\nAdaptation of DNNs and related deep models\nMulti-task and transfer learning by DNNs and related deep models\nCNNs and how to design them to best exploit domain knowledge of speech\nRNN and its rich LSTM variants\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.\nMore recent speech recognition models use Transformers or Temporal Convolution Networks with significant success and widespread applications. All major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.\n\n\n=== Image recognition ===\n\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.\nDeep learning-trained vehicles now interpret 360° camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\n\n\n=== Visual art processing ===\n\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\n\nidentifying the style period of a given painting\nNeural Style Transfer –  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\ngenerating striking imagery based on random visual input fields.\n\n\n=== Natural language processing ===\n\nNeural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.\nOther key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.\nRecent developments generalize word embedding to sentence embedding.\nGoogle Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\". It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages. The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\". GT uses English as an intermediate between most language pairs.\n\n\n=== Drug discovery and toxicology ===\n\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.\nAtomNet is a deep learning system for structure-based rational drug design. AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus and multiple sclerosis.\nIn 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set. In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\n\n\n=== Recommendation systems ===\n\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations. Multi-view deep learning has been applied for learning user preferences from multiple domains. The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\n\n\n=== Bioinformatics ===\n\nAn autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables and predictions of health complications from electronic health record data.\nDeep neural networks have shown unparalleled performance in predicting protein structure, according to the sequence of the amino acids that make it up. In 2020, AlphaFold, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.\n\n\n=== Deep Neural Network Estimations ===\nDeep neural networks can be used to estimate the entropy of a stochastic process through an arrangement called a Neural Joint Entropy Estimator (NJEE). Such an estimation provides insights on the effects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in cases of large alphabet sizes.\n\n\n=== Medical image analysis ===\nDeep learning has been shown to produce competitive results in medical applications such as cancer cell classification, lesion detection, organ segmentation and image enhancement. Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\n\n\n=== Mobile advertising ===\nFinding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\n\n\n=== Image restoration ===\nDeep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization. These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\" which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\n\n\n=== Financial fraud detection ===\nDeep learning is being successfully applied to financial fraud detection, tax evasion detection, and anti-money laundering.\n\n\n=== Materials science ===\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\n\n\n=== Military ===\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.\n\n\n=== Partial differential equations ===\nPhysics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner. One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods rely on. It is evident that geometric and physical constraints have a synergistic effect on neural PDE surrogates, thereby enhancing their efficacy in predicting stable and super long rollouts.\n\n\n=== Deep backward stochastic differential equation method ===\nDeep backward stochastic differential equation method is a numerical method that combines deep learning with Backward stochastic differential equation (BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.\nIn addition, the integration of Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws directly into the neural network architecture. This ensures that the solutions not only fit the data but also adhere to the governing stochastic differential equations. PINNs leverage the power of deep learning while respecting the constraints imposed by the physical models, resulting in more accurate and reliable solutions for financial mathematics problems.\n\n\n=== Image reconstruction ===\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging  and ultrasound imaging.\n\n\n=== Weather prediction ===\nTraditional weather prediction systems solve a very complex system of partial differential equations. GraphCast is a deep learning based model, trained on a long history of weather data to predict how weather patterns change over time. It is able to  predict weather conditions for up to 10 days globally, at a very detailed level, and in under a minute, with precision similar to state of the art systems.\n\n\n=== Epigenetic clock ===\n\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\n\n\n== Relation to human cognitive and brain development ==\nDeep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".\nA variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.\nAlthough a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.\n\n\n== Commercial activity ==\nFacebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.\nGoogle's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.\nAs of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\n\n\n== Criticism and comment ==\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\n\n\n=== Theory ===\n\nA main criticism concerns the lack of theory surrounding some methods. Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear. (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian's website.\nWith the support of Innovation Diffusion Theory (IDT), a study analyzed the diffusion of Deep Learning in BRICS and OECD countries using data from Google Trends.\n\n\n=== Errors ===\nSome deep learning architectures display problematic behaviors, such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014) and misclassifying minuscule perturbations of correctly classified images (2013). Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures. These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar decompositions of observed entities and events. Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition and artificial intelligence (AI).\n\n\n=== Cyber threat ===\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".\nIn 2016 researchers used one ANN to doctor images in trial and error fashion, identify another's focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system. One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.\nAnother group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.\nANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.\nIn 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".\nIn \"data poisoning\", false data is continually smuggled into a machine learning system's training set to prevent it from achieving mastery.\n\n\n=== Data collection ethics ===\nThe deep learning systems that are trained using supervised learning often rely on data that is created or annotated by humans, or both. It has been argued that not only low-paid clickwork (such as on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer Mühlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.\n\n\n== See also ==\nApplications of artificial intelligence\nComparison of deep learning software\nCompressed sensing\nDifferentiable programming\nEcho state network\nList of artificial intelligence projects\nLiquid state machine\nList of datasets for machine-learning research\nReservoir computing\nScale space and deep learning\nSparse coding\nStochastic parrot\nTopological deep learning\n\n\n== References ==\n\n\n== Further reading ==",
      "summary": "In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or u",
      "links": [
        "01.AI",
        "15.ai",
        "AI-assisted software development",
        "AI alignment",
        "AI boom",
        "AI bubble",
        "AI safety",
        "AI winter",
        "Acoustic model",
        "Action selection",
        "Activation function",
        "Activity tracker",
        "Adobe Firefly",
        "Adversarial machine learning",
        "Aidan Gomez",
        "Aja Huang",
        "Alan Turing",
        "Aleph Alpha",
        "AlexNet",
        "Alex Graves (computer scientist)"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 56564,
      "topic": "deep_learning"
    },
    {
      "title": "Neural network (machine learning)",
      "url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
      "content": "In machine learning, a neural network or neural net (NN), also called artificial neural network (ANN), is a computational model inspired by the structure and functions of biological neural networks.\nA neural network consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the totality of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\nTypically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.\nArtificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n\n\n== Training ==\nNeural networks are typically trained through empirical risk minimization, which is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset. Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network. During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function. This method allows the network to generalize to unseen data.\n\n\n== History ==\n\n\n=== Early work ===\nToday's deep neural networks are based on early work in statistics over 200 years ago. The simplest kind of feedforward neural network (FNN) is a linear network, which consists of a single layer of output nodes with linear activation functions; the inputs are fed directly to the outputs via a series of weights. The sum of the products of the weights and the inputs is calculated at each node. The mean squared errors between these calculated outputs and the given target values are minimized by creating an adjustment to the weights. This technique has been known for over two centuries as the method of least squares or linear regression. It was used as a means of finding a good rough linear fit to a set of points by Legendre (1805) and Gauss (1795) for the prediction of planetary movement.\nHistorically, digital computers such as the von Neumann model operate via the execution of explicit instructions with access to memory by a number of processors. Some neural networks, on the other hand, originated from efforts to model information processing in biological systems through the framework of connectionism. Unlike the von Neumann model, connectionist computing does not separate memory and processing.\nWarren McCulloch and Walter Pitts (1943) considered a non-learning computational model for neural networks. This model paved the way for research to split into two approaches. One approach focused on biological processes while the other focused on the application of neural networks to artificial intelligence.\nIn the late 1940s, D. O. Hebb proposed a learning hypothesis based on the mechanism of neural plasticity that became known as Hebbian learning. It was used in many early neural networks, such as Rosenblatt's perceptron and the Hopfield network. Farley and Clark (1954) used computational machines to simulate a Hebbian network. Other neural network computational machines were created by Rochester, Holland, Habit and Duda (1956). \nIn 1958, psychologist Frank Rosenblatt described the perceptron, one of the first implemented artificial neural networks, funded by the United States Office of Naval Research.\nR. D. Joseph (1960) mentions an even earlier perceptron-like device by Farley and Clark: \"Farley and Clark of MIT Lincoln Laboratory actually preceded Rosenblatt in the development of a perceptron-like device.\" However, \"they dropped the subject.\"\nThe perceptron raised public excitement for research in Artificial Neural Networks, causing the US government to drastically increase funding. This contributed to \"the Golden Age of AI\" fueled by the optimistic claims made by computer scientists regarding the ability of perceptrons to emulate human intelligence.\nThe first perceptrons did not have adaptive hidden units. However, Joseph (1960) also discussed multilayer perceptrons with an adaptive hidden layer. Rosenblatt (1962) cited and adopted these ideas, also crediting work by H. D. Block and B. W. Knight. Unfortunately, these early efforts did not lead to a working learning algorithm for hidden units, i.e., deep learning.\n\n\n=== Deep learning breakthroughs in the 1960s and 1970s ===\nFundamental research was conducted on ANNs in the 1960s and 1970s. The first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in the Soviet Union (1965). They regarded it as a form of polynomial regression, or a generalization of Rosenblatt's perceptron. A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates.\"\nThe first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned internal representations to classify non-linearily separable pattern classes. Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\nIn 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for deep learning.\nNevertheless, research stagnated in the United States following the work of Minsky and Papert (1969), who emphasized that basic perceptrons were incapable of processing the exclusive-or circuit. This insight was irrelevant for the deep networks of Ivakhnenko (1965) and Amari (1967).\nIn 1976 transfer learning was introduced in neural networks learning.\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers and weight replication began with the neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation.\n\n\n=== Backpropagation ===\nBackpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory. In 1970, Seppo Linnainmaa published the modern form of backpropagation in his Master's thesis (1970). G.M. Ostrovski et al. republished it in 1971. Paul Werbos applied backpropagation to neural networks in 1982 (his 1974 PhD thesis, reprinted in a 1994 book, did not yet describe the algorithm). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.\n\n\n=== Convolutional neural networks ===\nKunihiko Fukushima's convolutional neural network (CNN) architecture of 1979 also introduced max pooling, a popular downsampling procedure for CNNs. CNNs have become an essential tool for computer vision.\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation. In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition.\nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks digitized in 32×32 pixel images.\nFrom 1988 onward, the use of neural networks transformed the field of protein structure prediction, in particular when the first cascading networks were trained on profiles (matrices) produced by multiple sequence alignments.\n\n\n=== Recurrent neural networks ===\nOne origin of RNN was statistical mechanics. In 1972, Shun'ichi Amari proposed to modify the weights of an Ising model by Hebbian learning rule as a model of associative memory, adding in the component of learning. This was popularized as the Hopfield network by John Hopfield (1982). Another origin of RNN was neuroscience. The word \"recurrent\" is used to describe loop-like structures in anatomy. In 1901, Cajal observed \"recurrent semicircles\" in the cerebellar cortex. Hebb considered \"reverberating circuit\" as an explanation for short-term memory. The McCulloch and Pitts paper (1943) considered neural networks that contain cycles, and noted that the current activity of such networks can be affected by activity indefinitely far in the past.\nIn 1982 a recurrent neural network with an array architecture (rather than a multilayer perceptron architecture), namely a Crossbar Adaptive Array, used direct recurrent connections from the output to the supervisor (teaching) inputs. In addition of computing actions (decisions), it computed internal state evaluations (emotions) of the consequence situations. Eliminating the external supervisor, it introduced the self-learning method in neural networks.  \nIn cognitive psychology, the journal American Psychologist in early 1980's carried out a debate on the relation between cognition and emotion. Zajonc in 1980 stated that emotion is computed first and is independent from cognition, while Lazarus in 1982 stated that cognition is computed first and is inseparable from emotion. In 1982 the Crossbar Adaptive Array gave a neural network model of cognition-emotion relation. It was an example of a debate where an AI system, a recurrent neural network, contributed to an issue in the same time addressed by cognitive psychology.\nTwo early influential works were the Jordan network (1986) and the Elman network (1990), which applied RNN to study cognitive psychology. \nIn the 1980s, backpropagation did not work well for deep RNNs. To overcome this problem, in 1991, Jürgen Schmidhuber proposed the \"neural sequence chunker\" or \"neural history compressor\" which introduced the important concepts of self-supervised pre-training (the \"P\" in ChatGPT) and neural knowledge distillation. In 1993, a neural history compressor system solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.\nIn 1991, Sepp Hochreiter's diploma thesis identified and analyzed the vanishing gradient problem and proposed recurrent residual connections to solve it. He and Schmidhuber introduced long short-term memory (LSTM), which set accuracy records in multiple applications domains. This was not yet the modern version of LSTM, which required the forget gate, which was introduced in 1999. It became the default choice for RNN architecture.\nDuring 1985–1995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine, restricted Boltzmann machine, Helmholtz machine, and the wake-sleep algorithm. These were designed for unsupervised learning of deep generative models.\n\n\n=== Deep learning ===\nBetween 2009 and 2012, ANNs began winning prizes in image recognition contests, approaching human level performance on various tasks, initially in pattern recognition and handwriting recognition. In 2011, a CNN named DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. It then won more contests. They also showed how max-pooling CNNs on GPU improved performance significantly.\nIn October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman and Google's Inceptionv3.\nIn 2012, Ng and Dean created a network that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images. Unsupervised pre-training and increased computing power from GPUs and distributed computing allowed the use of larger networks, particularly in image and visual recognition problems, which became known as \"deep learning\".\nRadial basis function and wavelet networks were introduced in 2013. These can be shown to offer best approximation properties and have been applied in nonlinear system identification and classification applications.\nGenerative adversarial network (GAN) (Ian Goodfellow et al., 2014) became state of the art in generative modeling during 2014–2018 period. The GAN principle was originally published in 1991 by Jürgen Schmidhuber who called it \"artificial curiosity\": two neural networks contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras et al. Here, the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes. Diffusion models (2015) eclipsed GANs in generative modeling since then, with systems such as DALL·E 2 (2022) and Stable Diffusion (2022).\nIn 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train very deep networks: the highway network was published in May 2015, and the residual neural network (ResNet) in December 2015. ResNet behaves like an open-gated Highway Net. \n\nDuring the 2010s, the seq2seq model was developed, and attention mechanisms were added. It led to the modern Transformer architecture in 2017 in Attention Is All You Need.\nIt requires computation time that is quadratic in the size of the context window. Jürgen Schmidhuber's fast weight controller (1992) scales linearly and was later shown to be equivalent to the unnormalized linear Transformer.\nTransformers have increasingly become the model of choice for natural language processing. Many modern large language models such as ChatGPT, GPT-4, and BERT use this architecture.\n\n\n== Models ==\n\nANNs began as an attempt to exploit the architecture of the human brain to perform tasks that conventional algorithms had little success with. They soon reoriented towards improving empirical results, abandoning attempts to remain true to their biological precursors. ANNs have the ability to learn and model non-linearities and complex relationships. This is achieved by neurons being connected in various patterns, allowing the output of some neurons to become the input of others. The network forms a directed, weighted graph.\nAn artificial neural network consists of simulated neurons. Each neuron is connected to other nodes via links like a biological axon-synapse-dendrite connection. All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data. Each link has a weight, determining the strength of one node's influence on another, allowing weights to choose the signal between neurons.\n\n\n=== Artificial neurons ===\n\nANNs are composed of artificial neurons which are conceptually derived from biological neurons. Each artificial neuron has inputs and produces a single output which can be sent to multiple other neurons. The inputs can be the feature values of a sample of external data, such as images or documents, or they can be the outputs of other neurons. The outputs of the final output neurons of the neural net accomplish the task, such as recognizing an object in an image.\nTo find the output of the neuron we take the weighted sum of all the inputs, weighted by the weights of the connections from the inputs to the neuron. We add a bias term to this sum. This weighted sum is sometimes called the activation. This weighted sum is then passed through a (usually nonlinear) activation function to produce the output. The initial inputs are external data, such as images and documents. The ultimate outputs accomplish the task, such as recognizing an object in an image.\n\n\n=== Organization ===\nThe neurons are typically organized into multiple layers, especially in deep learning. Neurons of one layer connect only to neurons of the immediately preceding and immediately following layers. The layer that receives external data is the input layer. The layer that produces the ultimate result is the output layer. In between them are zero or more hidden layers. Single layer and unlayered networks are also used. Between two layers, multiple connection patterns are possible. They can be 'fully connected', with every neuron in one layer connecting to every neuron in the next layer. They can be pooling, where a group of neurons in one layer connects to a single neuron in the next layer, thereby reducing the number of neurons in that layer. Neurons with only such connections form a directed acyclic graph and are known as feedforward networks. Alternatively, networks that allow connections between neurons in the same or previous layers are known as recurrent networks.\n\n\n=== Hyperparameter ===\n\nA hyperparameter is a constant parameter defining any configurable part of the learning process, whose value is set prior to training. Examples of hyperparameters include learning rate, batch size and regularization parameters.. The performance of a neural network is strongly influenced by the choice of hyperparameter values, and thus the hyperparameters are often optimized as part of the training process, a process called hyperparameter tuning or hyperparameter optimization.\n\n\n=== Learning ===\n\nLearning is the adaptation of the network to better handle a task by considering sample observations. Learning involves adjusting the weights (and optional thresholds) of the network to improve the accuracy of the result. This is done by minimizing the observed errors. Learning is complete when examining additional observations does not usefully reduce the error rate. Even after learning, the error rate typically does not reach 0. If after learning, the error rate is too high, the network typically must be redesigned. Practically this is done by defining a cost function that is evaluated periodically during learning. As long as its output continues to decline, learning continues. The cost is frequently defined as a statistic whose value can only be approximated. The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small. Learning attempts to reduce the total of the differences across the observations. Most learning models can be viewed as a straightforward application of optimization theory and statistical estimation.\n\n\n==== Learning rate ====\n\nThe learning rate defines the size of the corrective steps that the model takes to adjust for errors in each observation. A high learning rate shortens the training time, but with lower ultimate accuracy, while a lower learning rate takes longer, but with the potential for greater accuracy. Optimizations such as Quickprop are primarily aimed at speeding up error minimization, while other improvements mainly try to increase reliability. In order to avoid oscillation inside the network such as alternating connection weights, and to improve the rate of convergence, refinements use an adaptive learning rate that increases or decreases as appropriate. The concept of momentum allows the balance between the gradient and the previous change to be weighted such that the weight adjustment depends to some degree on the previous change. A momentum close to 0 emphasizes the gradient, while a value close to 1 emphasizes the last change.\n\n\n==== Cost function ====\nWhile it is possible to define a cost function ad hoc, frequently the choice is determined by the function's desirable properties (such as convexity) because it arises from the model (e.g. in a probabilistic model, the model's posterior probability can be used as an inverse cost).\n\n\n==== Backpropagation ====\n\nBackpropagation is a method used to adjust the connection weights to compensate for each error found during learning. The error amount is effectively divided among the connections. Technically, backpropagation calculates the gradient (the derivative) of the cost function associated with a given state with respect to the weights. The weight updates can be done via stochastic gradient descent or other methods, such as extreme learning machines, \"no-prop\" networks, training without backtracking, \"weightless\" networks, and non-connectionist neural networks.\n\n\n=== Learning paradigms ===\n\nMachine learning is commonly separated into three main learning paradigms, supervised learning, unsupervised learning and reinforcement learning. Each corresponds to a particular learning task.\n\n\n==== Supervised learning ====\nSupervised learning uses a set of paired inputs and desired outputs. The learning task is to produce the desired output for each input. In this case, the cost function is related to eliminating incorrect deductions. A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output and the desired output. Tasks suited for supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). Supervised learning is also applicable to sequential data (e.g., for handwriting, speech and gesture recognition). This can be thought of as learning with a \"teacher\", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.\n\n\n==== Unsupervised learning ====\nIn unsupervised learning, input data is given along with the cost function, some function of the data \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\textstyle x}\n  \n and the network's output. The cost function is dependent on the task (the model domain) and any a priori assumptions (the implicit properties of the model, its parameters and the observed variables). As a trivial example, consider the model \n  \n    \n      \n        \n          f\n          (\n          x\n          )\n          =\n          a\n        \n      \n    \n    {\\displaystyle \\textstyle f(x)=a}\n  \n where \n  \n    \n      \n        \n          a\n        \n      \n    \n    {\\displaystyle \\textstyle a}\n  \n is a constant and the cost \n  \n    \n      \n        \n          C\n          =\n          E\n          [\n          (\n          x\n          −\n          f\n          (\n          x\n          )\n          \n            )\n            \n              2\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle \\textstyle C=E[(x-f(x))^{2}]}\n  \n. Minimizing this cost produces a value of \n  \n    \n      \n        \n          a\n        \n      \n    \n    {\\displaystyle \\textstyle a}\n  \n that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in compression it could be related to the mutual information between \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\textstyle x}\n  \n and \n  \n    \n      \n        \n          f\n          (\n          x\n          )\n        \n      \n    \n    {\\displaystyle \\textstyle f(x)}\n  \n, whereas in statistical modeling, it could be related to the posterior probability of the model given the data (note that in both of those examples, those quantities would be maximized rather than minimized). Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering.\n\n\n==== Reinforcement learning ====\n\nIn applications such as playing video games, an actor takes a string of actions, receiving a generally unpredictable response from the environment after each one. The goal is to win the game, i.e., generate the most positive (lowest cost) responses. In reinforcement learning, the aim is to weight the network (devise a policy) to perform actions that minimize long-term (expected cumulative) cost. At each point in time the agent performs an action and the environment generates an observation and an instantaneous cost, according to some (usually unknown) rules. The rules and the long-term cost usually only can be estimated. At any juncture, the agent decides whether to explore new actions to uncover their costs or to exploit prior learning to proceed more quickly.\nFormally, the environment is modeled as a Markov decision process (MDP) with states \n  \n    \n      \n        \n          \n            \n              s\n              \n                1\n              \n            \n            ,\n            .\n            .\n            .\n            ,\n            \n              s\n              \n                n\n              \n            \n          \n          ∈\n          S\n        \n      \n    \n    {\\displaystyle \\textstyle {s_{1},...,s_{n}}\\in S}\n  \n and actions \n  \n    \n      \n        \n          \n            \n              a\n              \n                1\n              \n            \n            ,\n            .\n            .\n            .\n            ,\n            \n              a\n              \n                m\n              \n            \n          \n          ∈\n          A\n        \n      \n    \n    {\\displaystyle \\textstyle {a_{1},...,a_{m}}\\in A}\n  \n. Because the state transitions are not known, probability distributions are used instead: the instantaneous cost distribution \n  \n    \n      \n        \n          P\n          (\n          \n            c\n            \n              t\n            \n          \n          \n            |\n          \n          \n            s\n            \n              t\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\textstyle P(c_{t}|s_{t})}\n  \n, the observation distribution \n  \n    \n      \n        \n          P\n          (\n          \n            x\n            \n              t\n            \n          \n          \n            |\n          \n          \n            s\n            \n              t\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\textstyle P(x_{t}|s_{t})}\n  \n and the transition distribution \n  \n    \n      \n        \n          P\n          (\n          \n            s\n            \n              t\n              +\n              1\n            \n          \n          \n            |\n          \n          \n            s\n            \n              t\n            \n          \n          ,\n          \n            a\n            \n              t\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\textstyle P(s_{t+1}|s_{t},a_{t})}\n  \n, while a policy is defined as the conditional distribution over actions given the observations. Taken together, the two define a Markov chain (MC). The aim is to discover the lowest-cost MC.\nANNs serve as the learning component in such applications. Dynamic programming coupled with ANNs (giving neurodynamic programming) has been applied to problems such as those involved in vehicle routing, video games, natural resource management and medicine because of ANNs ability to mitigate losses of accuracy even when reducing the discretization grid density for numerically approximating the solution of control problems. Tasks that fall within the paradigm of reinforcement learning are control problems, games and other sequential decision making tasks.\n\n\n==== Self-learning ====\nSelf-learning in neural networks was introduced in 1982 along with a neural network capable of self-learning named crossbar adaptive array (CAA). It is a system with only one input, situation s, and only one output, action (or behavior) a. It has neither external advice input nor external reinforcement input from the environment. The CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about encountered situations. The system is driven by the interaction between cognition and emotion. Given the memory matrix, W =||w(a,s)||, the crossbar self-learning algorithm in each iteration performs the following computation:\n\n In situation s perform action a;\n Receive consequence situation s';\n Compute emotion of being in consequence situation v(s');\n Update crossbar memory w'(a,s) = w(a,s) + v(s').\n\nThe backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is behavioral environment where it behaves, and the other is genetic environment, where from it receives initial emotions (only once) about to be encountered situations in the behavioral environment. Having received the genome vector (species vector) from the genetic environment, the CAA will learn a goal-seeking behavior, in the behavioral environment that contains both desirable and undesirable situations.\n\n\n==== Neuroevolution ====\n\nNeuroevolution can create neural network topologies and weights using evolutionary computation. It is competitive with sophisticated gradient descent approaches. One advantage of neuroevolution is that it may be less prone to get caught in \"dead ends\".\n\n\n=== Stochastic neural network ===\nStochastic neural networks originating from Sherrington–Kirkpatrick models are a type of artificial neural network built by introducing random variations into the network, either by giving the network's artificial neurons stochastic transfer functions , or by giving them stochastic weights. This makes them useful tools for optimization problems, since the random fluctuations help the network escape from local minima. Stochastic neural networks trained using a Bayesian approach are known as Bayesian neural networks.\n\n\n=== Topological deep learning ===\nTopological deep learning, first introduced in 2017, is an emerging approach in machine learning that integrates topology with deep neural networks to address highly intricate and high-order data. Initially rooted in algebraic topology, TDL has since evolved into a versatile framework incorporating tools from other mathematical disciplines, such as differential topology and geometric topology. As a successful example of mathematical deep learning, TDL continues to inspire advancements in mathematical artificial intelligence, fostering a mutually beneficial relationship between AI and mathematics.  \n\n\n=== Other ===\nIn a Bayesian framework, a distribution over the set of allowed models is chosen to minimize the cost. Evolutionary methods, gene expression programming, simulated annealing, expectation–maximization, non-parametric methods and particle swarm optimization are other learning algorithms. Convergent recursion is a learning algorithm for cerebellar model articulation controller (CMAC) neural networks.\n\n\n==== Modes ====\n\nTwo modes of learning are available: stochastic and batch. In stochastic learning, each input creates a weight adjustment. In batch learning, weights are adjusted based on a batch of inputs, accumulating errors over the batch. Stochastic learning introduces \"noise\" into the process, using the local gradient calculated from one data point; this reduces the chance of the network getting stuck in local minima. However, batch learning typically yields a faster, more stable descent to a local minimum, since each update is performed in the direction of the batch's average error. A common compromise is to use \"mini-batches\", small batches with samples in each batch selected stochastically from the entire data set.\n\n\n== Types ==\n\nANNs have evolved into a broad family of techniques that have advanced the state of the art across multiple domains. The simplest types have one or more static components, including number of units, number of layers, unit weights and topology. Dynamic types allow one or more of these to evolve via learning. The latter is much more complicated but can shorten learning periods and produce better results. Some types allow/require learning to be \"supervised\" by the operator, while others operate independently. Some types operate purely in hardware, while others are purely software and run on general purpose computers.\nSome of the main breakthroughs include: \n\nConvolutional neural networks that have proven particularly successful in processing visual and other two-dimensional data; where long short-term memory avoids the vanishing gradient problem and can handle signals that have a mix of low and high frequency components aiding large-vocabulary speech recognition, text-to-speech synthesis, and photo-real talking heads.Convolutional Neural Networks have also been applied to fraud detection.\nCompetitive networks such as generative adversarial networks in which multiple networks (of varying structure) compete with each other, on tasks such as winning a game or on deceiving the opponent about the authenticity of an input.\n\n\n== Network design ==\nUsing artificial neural networks requires an understanding of their characteristics.\n\nChoice of model: This depends on the data representation and the application. Model parameters include the number, type, and connectedness of network layers, as well as the size of each and the connection type (full, pooling, etc.). Overly complex models learn slowly.\nLearning algorithm: Numerous trade-offs exist between learning algorithms. Almost any algorithm will work well with the correct hyperparameters for training on a particular data set. However, selecting and tuning an algorithm for training on unseen data requires significant experimentation.\nRobustness: If the model, cost function and learning algorithm are selected appropriately, the resulting ANN can become robust.\nNeural architecture search (NAS) uses machine learning to automate ANN design. Various approaches to NAS have designed networks that compare well with hand-designed systems. The basic search algorithm is to propose a candidate model, evaluate it against a dataset, and use the results as feedback to teach the NAS network. Available systems include AutoML and AutoKeras. scikit-learn library provides functions to help with building a deep network from scratch. We can then implement a deep network with TensorFlow or Keras.\nHyperparameters must also be defined as part of the design (they are not learned), governing matters such as how many neurons are in each layer, learning rate, step, stride, depth, receptive field and padding (for CNNs), etc. The Python code snippet provides an overview of the training function, which uses the training dataset, number of hidden layer units, learning rate, and number of iterations as parameters:\n\n\n== Monitoring and concept drift detection of ANNs ==\nWhen neural networks are deployed in real-world applications, the statistical properties of the input data may change over time, a phenomenon known as concept drift or non-stationarity. Drift can reduce predictive accuracy and lead to unreliable or biased decisions if it is not detected and corrected. In practice, this means that the model's accuracy in deployment may differ substantially from the levels observed during training or cross-validation.  \nSeveral strategies have been developed to monitor neural networks for drift and degradation:  \n\nError-based monitoring: comparing current predictions against ground-truth labels when they become available. This approach directly quantifies predictive performance but may be impractical when labels are delayed or costly to obtain.\nData distribution monitoring: detecting changes in the input data distribution using statistical tests, divergence measures, or density-ratio estimation.\nRepresentation monitoring: tracking the distribution of internal embeddings or hidden-layer features. Shifts in the latent representation can indicate nonstationarity even when labels are unavailable. Statistical methods such as statistical process control charts have been adapted for this purpose.\n\n\n== Applications ==\nBecause of their ability to model and reproduce nonlinear processes, artificial neural networks have found applications in many disciplines. These include:\n\nFunction approximation, or regression analysis, (including time series prediction, fitness approximation, and modeling)\nData processing (including filtering, clustering, blind source separation, and compression)\nNonlinear system identification and control (including vehicle control, trajectory prediction, adaptive control, process control, and natural resource management)\nPattern recognition (including radar systems, face identification, signal classification, novelty detection, 3D reconstruction, object recognition, and sequential decision making)\nSequence recognition (including gesture, speech, and handwritten and printed text recognition)\nSensor data analysis (including image analysis)\nRobotics (including directing manipulators and prostheses)\nData mining (including knowledge discovery in databases)\nFinance (such as ex-ante models for specific financial long-run forecasts and artificial financial markets)\nQuantum chemistry\nGeneral game playing\nGenerative AI\nData visualization\nMachine translation\nSocial network filtering\nE-mail spam filtering\nMedical diagnosis\nANNs have been used to diagnose several types of cancers and to distinguish highly invasive cancer cell lines from less invasive lines using only cell shape information.\nANNs have been used to accelerate reliability analysis of infrastructures subject to natural disasters and to predict foundation settlements. It can also be useful to mitigate flood by the use of ANNs for modelling rainfall-runoff. ANNs have also been used for building black-box models in geoscience: hydrology, ocean modelling and coastal engineering, and geomorphology. ANNs have been employed in cybersecurity, with the objective to discriminate between legitimate activities and malicious ones. For example, machine learning has been used for classifying Android malware, for identifying domains belonging to threat actors and for detecting URLs posing a security risk. Research is underway on ANN systems designed for penetration testing, for detecting botnets, credit cards frauds and network intrusions.\nANNs have been proposed as a tool to solve partial differential equations in physics and simulate the properties of many-body open quantum systems. In brain research ANNs have studied short-term behavior of individual neurons, the dynamics of neural circuitry arise from interactions between individual neurons and how behavior can arise from abstract neural modules that represent complete subsystems. Studies considered long-and short-term plasticity of neural systems and their relation to learning and memory from the individual neuron to the system level.\nIt is possible to create a profile of a user's interests from pictures, using artificial neural networks trained for object recognition.\nBeyond their traditional applications, artificial neural networks are increasingly being utilized in interdisciplinary research, such as materials science. For instance, graph neural networks (GNNs) have demonstrated their capability in scaling deep learning for the discovery of new stable materials by efficiently predicting the total energy of crystals. This application underscores the adaptability and potential of ANNs in tackling complex problems beyond the realms of predictive modeling and artificial intelligence, opening new pathways for scientific discovery and innovation.\n\n\n== Theoretical properties ==\n\n\n=== Computational power ===\nThe multilayer perceptron is a universal function approximator, as proven by the universal approximation theorem. However, the proof is not constructive regarding the number of neurons required, the network topology, the weights and the learning parameters.\nA specific recurrent architecture with rational-valued weights (as opposed to full precision real number-valued weights) has the power of a universal Turing machine, using a finite number of neurons and standard linear connections. Further, the use of irrational values for weights results in a machine with super-Turing power.\n\n\n=== Capacity ===\nA model's \"capacity\" property corresponds to its ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.\nTwo notions of capacity are known by the community. The information capacity and the VC Dimension. The information capacity of a perceptron is intensively discussed in Sir David MacKay's book which summarizes work by Thomas Cover. The capacity of a network of standard neurons (not convolutional) can be derived by four rules that derive from understanding a neuron as an electrical element. The information capacity captures the functions modelable by the network given any data as input. The second notion, is the VC dimension. VC Dimension uses the principles of measure theory and finds the maximum capacity under the best possible circumstances. This is, given input data in a specific form. As noted in, the VC Dimension for arbitrary inputs is half the information capacity of a perceptron. The VC Dimension for arbitrary points is sometimes referred to as Memory Capacity.\n\n\n=== Convergence ===\nModels may not consistently converge on a single solution, firstly because local minima may exist, depending on the cost function and the model. Secondly, the optimization method used might not guarantee to converge when it begins far from any local minimum. Thirdly, for sufficiently large data or parameters, some methods become impractical.\nAnother issue worthy to mention is that training may cross some saddle point which may lead the convergence to the wrong direction.\nThe convergence behavior of certain types of ANN architectures are more understood than others. When the width of network approaches to infinity, the ANN is well described by its first order Taylor expansion throughout training, and so inherits the convergence behavior of affine models. Another example is when parameters are small, it is observed that ANNs often fit target functions from low to high frequencies. This behavior is referred to as the spectral bias, or frequency principle, of neural networks. This phenomenon is the opposite to the behavior of some well studied iterative numerical schemes such as Jacobi method. Deeper neural networks have been observed to be more biased towards low frequency functions.\n\n\n=== Generalization and statistics ===\n\nApplications whose goal is to create a system that generalizes well to unseen examples, face the possibility of over-training. This arises in convoluted or over-specified systems when the network capacity significantly exceeds the needed free parameters. \nTwo approaches address over-training. The first is to use cross-validation and similar techniques to check for the presence of over-training and to select hyperparameters to minimize the generalization error. The second is to use some form of regularization. This concept emerges in a probabilistic (Bayesian) framework, where regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the goal is to minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the training set and the predicted error in unseen data due to overfitting.\n\nSupervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model. The MSE on a validation set can be used as an estimate for variance. This value can then be used to calculate the confidence interval of network output, assuming a normal distribution. A confidence analysis made this way is statistically valid as long as the output probability distribution stays the same and the network is not modified.\nBy assigning a softmax activation function, a generalization of the logistic function, on the output layer of the neural network (or a softmax component in a component-based network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is useful in classification as it gives a certainty measure on classifications.\nThe softmax activation function is:\n\n  \n    \n      \n        \n          y\n          \n            i\n          \n        \n        =\n        \n          \n            \n              e\n              \n                \n                  x\n                  \n                    i\n                  \n                \n              \n            \n            \n              \n                ∑\n                \n                  j\n                  =\n                  1\n                \n                \n                  c\n                \n              \n              \n                e\n                \n                  \n                    x\n                    \n                      j\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle y_{i}={\\frac {e^{x_{i}}}{\\sum _{j=1}^{c}e^{x_{j}}}}}\n  \n\n\n== Criticism ==\n\n\n=== Training ===\nA common criticism of neural networks, particularly in robotics, is that they require too many training samples for real-world operation.\nAny learning machine needs sufficient representative examples in order to capture the underlying structure that allows it to generalize to new cases. Potential solutions include randomly shuffling training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example, grouping examples in so-called mini-batches and/or introducing a recursive least squares algorithm for CMAC.\nDean Pomerleau uses a neural network to train a robotic vehicle to drive on multiple types of roads (single lane, multi-lane, dirt, etc.), and a large amount of his research is devoted to extrapolating multiple training scenarios from a single training experience, and preserving past training diversity so that the system does not become overtrained (if, for example, it is presented with a series of right turns—it should not learn to always turn right).\n\n\n=== Theory ===\nA central claim of ANNs is that they embody new and powerful general principles for processing information. These principles are ill-defined. This allows simple statistical association (the basic function of artificial neural networks) to be described as learning or recognition. In 1997, Alexander Dewdney, a former Scientific American columnist, commented that as a result, artificial neural networks have a \n\nsomething-for-nothing quality, one that imparts a peculiar aura of laziness and a distinct lack of curiosity about just how good these computing systems are. No human hand (or mind) intervenes; solutions are found as if by magic; and no one, it seems, has learned anything. One response to Dewdney is that neural networks have been successfully used to handle many complex and diverse tasks, ranging from autonomously flying aircraft to detecting credit card fraud to mastering the game of Go.\nTechnology writer Roger Bridgman commented:\n\nNeural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be \"an opaque, unreadable table...valueless as a scientific resource\".\nIn spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.\n\nAlthough it is true that analyzing what has been learned by an artificial neural network is difficult, it is much easier to do so than to analyze what has been learned by a biological neural network. Moreover, recent emphasis on the explainability of AI has contributed towards the development of methods, notably those based on attention mechanisms, for visualizing and explaining learned neural networks. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering generic principles that allow a learning machine to be successful. For example, Bengio and LeCun (2007) wrote an article regarding local vs non-local learning, as well as shallow vs deep architecture.\nBiological brains use both shallow and deep circuits as reported by brain anatomy, displaying a wide variety of invariance. Weng argued that the brain self-wires largely according to signal statistics and therefore, a serial cascade cannot catch all major statistical dependencies.\n\n\n=== Hardware ===\nLarge and effective neural networks require considerable computing resources. While the brain has hardware tailored to the task of processing signals through a graph of neurons, simulating even a simplified neuron on von Neumann architecture may consume vast amounts of memory and storage. Furthermore, the designer often needs to transmit signals through many of these connections and their associated neurons –  which require enormous CPU power and time.\nSome argue that the resurgence of neural networks in the twenty-first century is largely attributable to advances in hardware: from 1991 to 2015, computing power, especially as delivered by GPGPUs (on GPUs), has increased around a million-fold, making the standard backpropagation algorithm feasible for training networks that are several layers deeper than before. The use of accelerators such as FPGAs and GPUs can reduce training times from months to days.\nNeuromorphic engineering or a physical neural network addresses the hardware difficulty directly, by constructing non-von-Neumann chips to directly implement neural networks in circuitry. Another type of chip optimized for neural network processing is called a Tensor Processing Unit, or TPU.\n\n\n=== Practical counterexamples ===\nAnalyzing what has been learned by an ANN is much easier than analyzing what has been learned by a biological neural network. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering general principles that allow a learning machine to be successful. For example, local vs. non-local learning and shallow vs. deep architecture.\n\n\n=== Hybrid approaches ===\nAdvocates of hybrid models (combining neural networks and symbolic approaches) say that such a mixture can better capture the mechanisms of the human mind.\n\n\n=== Dataset bias ===\nNeural networks are dependent on the quality of the data they are trained on, thus low quality data with imbalanced representativeness can lead to the model learning and perpetuating societal biases. These inherited biases become especially critical when the ANNs are integrated into real-world scenarios where the training data may be imbalanced due to the scarcity of data for a specific race, gender or other attribute. This imbalance can result in the model having inadequate representation and understanding of underrepresented groups, leading to discriminatory outcomes that exacerbate societal inequalities, especially in applications like facial recognition, hiring processes, and law enforcement. For example, in 2018, Amazon had to scrap a recruiting tool because the model favored men over women for jobs in software engineering due to the higher number of male workers in the field. The program would penalize any resume with the word \"woman\" or the name of any women's college. However, the use of synthetic data can help reduce dataset bias and increase representation in datasets.\n\n\n== Gallery ==\n\n\n== Recent advancements and future directions ==\nArtificial neural networks (ANNs) have undergone significant advancements, particularly in their ability to model complex systems, handle large data sets, and adapt to various types of applications. Their evolution over the past few decades has been marked by a broad range of applications in fields such as image processing, speech recognition, natural language processing, finance, and medicine.\n\n\n=== Image processing ===\nIn the realm of image processing, ANNs are employed in tasks such as image classification, object recognition, and image segmentation. For instance, deep convolutional neural networks (CNNs) have been important in handwritten digit recognition, achieving state-of-the-art performance. This demonstrates the ability of ANNs to effectively process and interpret complex visual information, leading to advancements in fields ranging from automated surveillance to medical imaging.\n\n\n=== Speech recognition ===\nBy modeling speech signals, ANNs are used for tasks like speaker identification and speech-to-text conversion. Deep neural network architectures have introduced significant improvements in large vocabulary continuous speech recognition, outperforming traditional techniques. These advancements have enabled the development of more accurate and efficient voice-activated systems, enhancing user interfaces in technology products.\n\n\n=== Natural language processing ===\nIn natural language processing, ANNs are used for tasks such as text classification, sentiment analysis, and machine translation. They have enabled the development of models that can accurately translate between languages, understand the context and sentiment in textual data, and categorize text based on content. This has implications for automated customer service, content moderation, and language understanding technologies.\n\n\n=== Control systems ===\nIn the domain of control systems, ANNs are used to model dynamic systems for tasks such as system identification, control design, and optimization. For instance, deep feedforward neural networks are important in system identification and control applications.\n\n\n=== Finance ===\n\nANNs are used for stock market prediction and credit scoring: \n\nIn investing, ANNs can process vast amounts of financial data, recognize complex patterns, and forecast stock market trends, aiding investors and risk managers in making informed decisions.\nIn credit scoring, ANNs offer data-driven, personalized assessments of creditworthiness, improving the accuracy of default predictions and automating the lending process.\nANNs require high-quality data and careful tuning, and their \"black-box\" nature can pose challenges in interpretation. Nevertheless, ongoing advancements suggest that ANNs continue to play a role in finance, offering valuable insights and enhancing risk management strategies.\n\n\n=== Medicine ===\nANNs are able to process and analyze vast medical datasets. They enhance diagnostic accuracy, especially by interpreting complex medical imaging for early disease detection, and by predicting patient outcomes for personalized treatment planning. In drug discovery, ANNs speed up the identification of potential drug candidates and predict their efficacy and safety, significantly reducing development time and costs. Additionally, their application in personalized medicine and healthcare data analysis allows tailored therapies and efficient patient care management. Ongoing research is aimed at addressing remaining challenges such as data privacy and model interpretability, as well as expanding the scope of ANN applications in medicine.\n\n\n=== Content creation ===\nANNs such as generative adversarial networks (GAN) and transformers are used for content creation across numerous industries. This is because deep learning models are able to learn the style of an artist or musician from huge datasets and generate completely new artworks and music compositions. For instance, DALL-E is a deep neural network trained on 650 million pairs of images and texts across the internet that can create artworks based on text entered by the user. In the field of music, transformers are used to create original music for commercials and documentaries through companies such as AIVA and Jukedeck. In the marketing industry, generative models are used to create personalized advertisements for consumers. Additionally, major film companies are partnering with technology companies to analyze the financial success of a film, such as the partnership between Warner Bros and technology company Cinelytic established in 2020. Furthermore, neural networks have found uses in video game creation, where non-player characters (NPCs) can make decisions based on all the characters currently in the game.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Bibliography ==\n\n\n== External links ==\n\nA Brief Introduction to Neural Networks (D. Kriesel) – Illustrated, bilingual manuscript about artificial neural networks; Topics so far: Perceptrons, Backpropagation, Radial Basis Functions, Recurrent Neural Networks, Self Organizing Maps, Hopfield Networks.\nReview of Neural Networks in Materials Science Archived 7 June 2015 at the Wayback Machine\nArtificial Neural Networks Tutorial in three languages (Univ. Politécnica de Madrid)\nAnother introduction to ANN\nNext Generation of Neural Networks Archived 24 January 2011 at the Wayback Machine – Google Tech Talks\nPerformance of Neural Networks\nNeural Networks and Information Archived 9 July 2009 at the Wayback Machine\nSanderson G (5 October 2017). \"But what is a Neural Network?\". 3Blue1Brown. Archived from the original on 7 November 2021 – via YouTube.\nHakim MA, Alam MI (2025). \"Biologically inspired neural network layer with homeostatic regulation and adaptive repair mechanisms\". Scientific Reports. 15 (1). Nature Publishing Group: 33903. Bibcode:2025NatSR..1533903H. doi:10.1038/s41598-025-09114-8. ISSN 2045-2322. PMC 12484884. PMID 41028030.",
      "summary": "In machine learning, a neural network or neural net (NN), also called artificial neural network (ANN), is a computational model inspired by the structure and functions of biological neural networks.\nA neural network consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance. These are connected b",
      "links": [
        "15.ai",
        "3Blue1Brown",
        "3D reconstruction",
        "AAAI Conference on Artificial Intelligence",
        "ADALINE",
        "AIVA",
        "AI alignment",
        "AI safety",
        "A priori and a posteriori",
        "Action selection",
        "Activation function",
        "Active learning (machine learning)",
        "Ad hoc",
        "Adaptation",
        "Adaptive control",
        "Adaptive cruise control",
        "Adaptive learning rate",
        "Adobe Firefly",
        "Adrien-Marie Legendre",
        "Advanced driver-assistance system"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 59704,
      "topic": "deep_learning"
    },
    {
      "title": "Natural language processing",
      "url": "https://en.wikipedia.org/wiki/Natural_language_processing",
      "content": "Natural language processing (NLP) is the processing of natural language information by a computer. NLP is a subfield of computer science and is closely associated with artificial intelligence. NLP is also related to information retrieval, knowledge representation, computational linguistics, and linguistics more broadly.\nMajor processing tasks in an NLP system include: speech recognition, text classification, natural language understanding, and natural language generation.\n\n\n== History ==\n\nNatural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n\n\n=== Symbolic NLP (1950s – early 1990s) ===\n\nThe premise of symbolic NLP is often illustrated using John Searle's Chinese room thought experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n\n1950s: The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten years of research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted in America (though some research continued elsewhere, such as Japan and Europe) until the late 1980s when the first statistical machine translation systems were developed.\n1960s: Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapy, written by Joseph Weizenbaum between 1964 and 1966. Despite using minimal information about human thought or emotion, ELIZA was able to produce interactions that appeared human-like. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\". Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only twenty words, because that was all that would fit in a computer  memory at the time.\n1970s: During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, the first chatterbots were written (e.g., PARRY).\n1980s: The 1980s and early 1990s mark the heyday of symbolic methods in NLP. Focus areas of the time included research on rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar), morphology (e.g., two-level morphology), semantics (e.g., Lesk algorithm), reference (e.g., within Centering Theory) and other areas of natural language understanding (e.g., in the Rhetorical Structure Theory). Other lines of research were continued, e.g., the development of chatterbots with Racter and Jabberwacky. An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period.\n\n\n=== Statistical NLP (1990s–present) ===\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This shift was influenced by increasing computational power (see Moore's law) and a decline in the dominance of Chomskyan linguistic theories... (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. \n\n1990s: Many of the notable early successes in statistical methods in NLP occurred in the field of machine translation, due especially to work at IBM Research, such as IBM alignment models. These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n2000s: With the growth of the web, increasing amounts of raw (unannotated) language data have become available since the mid-1990s. Research has thus increasingly focused on unsupervised and semi-supervised learning algorithms. Such algorithms can learn from data that has not been hand-annotated with the desired answers or using a combination of annotated and non-annotated data. Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data. However, large quantities of non-annotated data are available (including, among other things, the entire content of the World Wide Web), which can often make up for the worse efficiency if the algorithm used has a low enough time complexity to be practical.\n2003: word n-gram model, at the time the best statistical algorithm, is outperformed by a multi-layer perceptron (with a single hidden layer and context length of several words, trained on up to 14 million words, by Bengio et al.)\n2010: Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modeling, and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. This shift gained momentum due to results showing that such techniques can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling and parsing. This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care or protect patient privacy.\n\n\n== Approaches: Symbolic, statistical, neural networks ==\nSymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular: such as by writing grammars or devising heuristic rules for stemming.\nMachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \n\nboth statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\nlanguage models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\nthe larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to intractability problems.\nRule-based systems are commonly used:\n\nwhen the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system,\nfor preprocessing in NLP pipelines, e.g., tokenization, or\nfor post-processing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.\n\n\n=== Statistical approach ===\nIn the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.\nThe earliest decision trees, producing systems of hard if–then rules, were still very similar to the old rule-based approaches.\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\n\n\n=== Neural networks ===\n\nA major drawback of statistical methods is that they require elaborate feature engineering. Since 2015, neural network–based methods have increasingly replaced traditional statistical approaches, using semantic networks and word embeddings to capture semantic properties of words.  \nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \nNeural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\n\n\n== Common NLP tasks ==\nThe following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n\n\n=== Text and speech processing ===\n\nOptical character recognition (OCR)\nGiven an image representing printed text, determine the corresponding text.\nSpeech recognition\nGiven a sound clip of a person or people speaking, determine the textual representation of the speech.  This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed \"AI-complete\" (see above).  In natural speech there are hardly any pauses between successive words, and thus speech segmentation is a necessary subtask of speech recognition (see below). In most spoken languages, the sounds representing successive letters blend into each other in a process termed coarticulation, so the conversion of the analog signal to discrete characters can be a very difficult process. Also, given that words in the same language are spoken by people with different accents, the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent.\nSpeech segmentation\nGiven a sound clip of a person or people speaking, separate it into words.  A subtask of speech recognition and typically grouped with it.\nText-to-speech\nGiven a text, transform those units and produce a spoken representation. Text-to-speech can be used to aid the visually impaired.\nWord segmentation (Tokenization)\nTokenization is a text-processing technique that divides text into individual words or word fragments. This technique results in two key components: a word index and tokenized text. The word index is a list that maps unique words to specific numerical identifiers, and the tokenized text replaces each word with its corresponding numerical token. These numerical tokens are then used in various deep learning methods.\nFor a language like English, this is fairly trivial, since words are usually separated by spaces. However, some written languages like Chinese, Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language. Sometimes this process is also used in cases like bag of words (BOW) creation in data mining.\n\n\n=== Morphological analysis ===\n\nLemmatization\nThe task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma. Lemmatization is another technique for reducing words to their normalized form. But in this case, the transformation actually uses a dictionary to map words to their actual form.\nMorphological segmentation\nSeparate words into individual morphemes and identify the class of the morphemes. The difficulty of this task depends greatly on the complexity of the morphology (i.e., the structure of words) of the language being considered. English has fairly simple morphology, especially inflectional morphology, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g., \"open, opens, opened, opening\") as separate words. In languages such as Turkish or Meitei, a highly agglutinated Indian language, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms.\nPart-of-speech tagging\nGiven a sentence, determine the part of speech (POS) for each word. Many words, especially common ones, can serve as multiple parts of speech. For example, \"book\" can be a noun (\"the book on the table\") or verb (\"to book a flight\"); \"set\" can be a noun, verb or adjective; and \"out\" can be any of at least five different parts of speech.\nStemming\nThe process of reducing inflected (or sometimes derived) words to a base form (e.g., \"close\" will be the root for \"closed\", \"closing\", \"close\", \"closer\" etc.). Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary.\n\n\n=== Syntactic analysis ===\n\nGrammar induction\nGenerate a formal grammar that describes a language's syntax.\nSentence breaking (also known as \"sentence boundary disambiguation\")\nGiven a chunk of text, find the sentence boundaries. Sentence boundaries are often marked by periods or other punctuation marks, but these same characters can serve other purposes (e.g., marking abbreviations).\nParsing\nDetermine the parse tree (grammatical analysis) of a given sentence. The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human). There are two primary types of parsing: dependency parsing and constituency parsing. Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a probabilistic context-free grammar (PCFG) (see also stochastic grammar).\n\n\n=== Lexical semantics (of individual words in context) ===\n\nLexical semantics\nWhat is the computational meaning of individual words in context?\nDistributional semantics\nHow can we learn semantic representations from data?\nNamed entity recognition (NER)\nGiven a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity, and in any case, is often inaccurate or insufficient.  For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized.  Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example, German capitalizes all nouns, regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives. This task is also referred to as token classification.\nSentiment analysis (see also Multimodal sentiment analysis)\nSentiment analysis involves identifying and classifying the emotional tone expressed in text. This technique involves analyzing text to determine whether the expressed sentiment is positive, negative, or neutral. Models for sentiment classification typically utilize inputs such as word n-grams, Term Frequency-Inverse Document Frequency (TF-IDF) features, hand-generated features, or employ deep learning models designed to recognize both long-term and short-term dependencies in text sequences. The applications of sentiment analysis are diverse, extending to tasks such as categorizing customer reviews on various online platforms.\nTerminology extraction\nThe goal of terminology extraction is to automatically extract relevant terms from a given corpus.\nWord-sense disambiguation (WSD)\nMany words have more than one meaning; we have to select the meaning which makes the most sense in context.  For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or an online resource such as WordNet.\nEntity linking\nMany words—typically proper names—refer to named entities; here we have to select the entity (a famous individual, a location, a company, etc.) which is referred to in context.\n\n\n=== Relational semantics (semantics of individual sentences) ===\nRelationship extraction\nGiven a chunk of text, identify the relationships among named entities (e.g. who is married to whom).\nSemantic parsing\nGiven a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in AMR parsing) or in accordance with a logical formalism (e.g., in DRT parsing). This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word-sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see Natural language understanding below).\nSemantic role labelling (see also implicit semantic role labelling below)\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames), then identify and classify the frame elements (semantic roles).\n\n\n=== Discourse (semantics beyond individual sentences) ===\nCoreference resolution\nGiven a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\"). Anaphora resolution is a specific example of this task, and is specifically concerned with matching up pronouns with the nouns or names to which they refer. The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving referring expressions. For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\nDiscourse analysis\nThis rubric includes several related tasks.  One task is discourse parsing, i.e., identifying the discourse structure of a connected text, i.e. the nature of the discourse relationships between sentences (e.g. elaboration, explanation, contrast).  Another possible task is recognizing and classifying the speech acts in a chunk of text (e.g. yes–no question, content question, statement, assertion, etc.).\nImplicit semantic role labelling\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames) and their explicit semantic roles in the current sentence (see Semantic role labelling above). Then, identify semantic roles that are not explicitly realized in the current sentence, classify them into arguments that are explicitly realized elsewhere in the text and those that are not specified, and resolve the former against the local text. A closely related task is zero anaphora resolution, i.e., the extension of coreference resolution to pro-drop languages.\nRecognizing textual entailment\nGiven two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false.\nTopic segmentation and recognition\nGiven a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment.\nArgument mining\nThe goal of argument mining is the automatic extraction and identification of argumentative structures from natural language text with the aid of computer programs. Such argumentative structures include the premise, conclusions, the argument scheme and the relationship between the main and subsidiary argument, or the main and counter-argument within discourse.\n\n\n=== Higher-level NLP applications ===\n\nAutomatic summarization (text summarization)\nProduce a readable summary of a chunk of text.  Often used to provide summaries of the text of a known type, such as research papers, articles in the financial section of a newspaper.\nGrammatical error correction\nGrammatical error detection and correction involves a great band-width of problems on all levels of linguistic analysis (phonology/orthography, morphology, syntax, semantics, pragmatics). Grammatical error correction is impactful since it affects hundreds of millions of people that use or acquire English as a second language. It has thus been subject to a number of shared tasks since 2011. As far as orthography, morphology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2, this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications.\nLogic translation\nTranslate a text from a natural language into formal logic.\nMachine translation (MT)\nAutomatically translate text from one human language to another.  This is one of the most difficult problems, and is a member of a class of problems colloquially termed \"AI-complete\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly.\nNatural language understanding (NLU)\nConvert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization.\nNatural language generation (NLG):\nConvert information from computer databases or semantic intents into readable human language.\nBook generation\nNot an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman's beard is half-constructed). The first published work by a neural network was published in 2018, 1 the Road, marketed as a novel, contains sixty million words. Both these systems are basically elaborate but non-sensical (semantics-free) language models. The first machine-generated science book was published in 2019 (Beta Writer, Lithium-Ion Batteries, Springer, Cham). Unlike Racter and 1 the Road, this is grounded on factual knowledge and based on text summarization.\nDocument AI\nA Document AI platform sits on top of the NLP technology enabling users with no prior experience of artificial intelligence, machine learning or NLP to quickly train a computer to extract the specific data they need from different document types. NLP-powered Document AI enables non-technical teams to quickly access information hidden in documents, for example, lawyers, business analysts and accountants.\nDialogue management\nComputer systems intended to converse with a human.\nQuestion answering\nGiven a human-language question, determine its answer. Typical questions have a specific right answer (such as \"What is the capital of Canada?\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\").\nText-to-image generation\nGiven a description of an image, generate an image that matches the description.\nText-to-scene generation\nGiven a description of a scene, generate a 3D model of the scene.\nText-to-video\nGiven a description of a video, generate a video that matches the description.\n\n\n== General tendencies and (possible) future directions ==\nBased on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:\n\nInterest on increasingly abstract, \"cognitive\" aspects of natural language (1999–2001: shallow parsing, 2002–03: named entity recognition, 2006–09/2017–18: dependency syntax, 2004–05/2008–09 semantic role labelling, 2011–12 coreference, 2015–16: discourse parsing, 2019: semantic parsing).\nIncreasing interest in multilinguality, and, potentially, multimodality (English since 1999; Spanish, Dutch since 2002; German since 2003; Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006; Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007; Czech since 2009; Arabic since 2012; 2017: 40+ languages; 2018: 60+/100+ languages)\nElimination of symbolic representations (rule-based over supervised towards weakly supervised methods, representation learning and end-to-end systems)\n\n\n=== Cognition ===\nMost higher-level NLP applications involve aspects that emulate intelligent behavior and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behavior represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\nCognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\" Cognitive science is the interdisciplinary, scientific study of the mind and its processes. Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics. Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\nAs an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics, with two defining aspects:\n\nApply the theory of conceptual metaphor, explained by Lakoff as \"the understanding of one idea, in terms of another\" which provides an idea of the intent of the author. For example, consider the English word big. When used in a comparison (\"That is a big tree\"), the author's intent is to imply that the tree is physically large relative to other trees or the authors experience.  When used metaphorically (\"Tomorrow is a big day\"), the author's intent to imply importance.  The intent behind other usages, like in \"She is a big person\", will remain somewhat ambiguous to a person and a cognitive NLP algorithm alike without additional information.\nAssign relative measures of meaning to a word, phrase, sentence or piece of text based on the information presented before and after the piece of text being analyzed, e.g., by means of a probabilistic context-free grammar (PCFG). The mathematical equation for such algorithms is presented in US Patent 9269353:\n\n  \n    \n      \n        \n          R\n          M\n          M\n          (\n          t\n          o\n          k\n          e\n          \n            n\n            \n              N\n            \n          \n          )\n        \n        =\n        \n          P\n          M\n          M\n          (\n          t\n          o\n          k\n          e\n          \n            n\n            \n              N\n            \n          \n          )\n        \n        ×\n        \n          \n            1\n            \n              2\n              d\n            \n          \n        \n        \n          (\n          \n            \n              ∑\n              \n                i\n                =\n                −\n                d\n              \n              \n                d\n              \n            \n            \n              (\n              (\n              P\n              M\n              M\n              (\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                \n              \n              )\n            \n            ×\n            \n              P\n              F\n              (\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                  −\n                  i\n                \n              \n              ,\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                \n              \n              ,\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                  +\n                  i\n                \n              \n              )\n              \n                )\n                \n                  i\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle {RMM(token_{N})}={PMM(token_{N})}\\times {\\frac {1}{2d}}\\left(\\sum _{i=-d}^{d}{((PMM(token_{N})}\\times {PF(token_{N-i},token_{N},token_{N+i}))_{i}}\\right)}\n  \n\nWhere\nRMM is the relative measure of meaning\ntoken is any block of text, sentence, phrase or word\nN is the number of tokens being analyzed\nPMM is the probable measure of meaning based on a corpora\nd is the non zero location of the token along the sequence of N tokens\nPF is the probability function specific to a language\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar, functional grammar, construction grammar, computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\". Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit) and developments in artificial intelligence, specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by British neuroscientist and theoretician at University College London Karl J. Friston.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n Media related to Natural language processing at Wikimedia Commons",
      "summary": "Natural language processing (NLP) is the processing of natural language information by a computer. NLP is a subfield of computer science and is closely associated with artificial intelligence. NLP is also related to information retrieval, knowledge representation, computational linguistics, and linguistics more broadly.\nMajor processing tasks in an NLP system include: speech recognition, text classification, natural language understanding, and natural language generation.\n\n",
      "links": [
        "1 the Road",
        "3D model",
        "ACT-R",
        "AI-complete",
        "AI winter",
        "ALPAC",
        "Abbreviation",
        "Abstract Meaning Representation",
        "Adjective",
        "Agglutination",
        "Alan Turing",
        "Alphabet (formal languages)",
        "Ambiguous",
        "Analog signal",
        "Anaphora resolution",
        "Ancient language",
        "Apertium",
        "ArXiv (identifier)",
        "Arabic language",
        "Argument mining"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 32386,
      "topic": "nlp"
    },
    {
      "title": "Word embedding",
      "url": "https://en.wikipedia.org/wiki/Word_embedding",
      "content": "In natural language processing, a word embedding is a representation of a word. The embedding is used in text analysis. Typically, the representation is a real-valued vector that encodes the meaning of the word in such a way that the words that are closer in the vector space are expected to be similar in meaning. Word embeddings can be obtained using language modeling and feature learning techniques, where words or phrases from the vocabulary are mapped to vectors of real numbers.\nMethods to generate this mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, explainable knowledge base method, and explicit representation in terms of the context in which words appear.\nWord and phrase embeddings, when used as the underlying input representation, have been shown to boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.\n\n\n== Development and history of the approach ==\nIn distributional semantics, a quantitative methodological approach for understanding meaning in observed language, word embeddings or semantic feature space models have been used as a knowledge representation for some time. Such models aim to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data.  The underlying idea that \"a word is characterized by the company it keeps\" was proposed in a 1957 article by John Rupert Firth, but also has roots in the contemporaneous work on search systems and in cognitive psychology.\nThe notion of a semantic space with lexical items (words or multi-word terms) represented as vectors or embeddings is based on the computational challenges of capturing distributional characteristics and using them for practical application to measure similarity between words, phrases, or entire documents. The first generation of semantic space models is the vector space model for information retrieval. Such vector space models for words and their distributional data implemented in their simplest form results in a very sparse vector space of high dimensionality (cf. curse of dimensionality). Reducing the number of dimensions using linear algebraic methods such as singular value decomposition then led to the introduction of latent semantic analysis in the late 1980s and the random indexing approach for collecting word co-occurrence contexts. In 2000, Bengio et al. provided in a series of papers titled \"Neural probabilistic language models\" to reduce the high dimensionality of word representations in contexts by \"learning a distributed representation for words\".\nA study published in NeurIPS (NIPS) 2002 introduced the use of both word and document embeddings applying the method of kernel CCA to bilingual (and multi-lingual) corpora, also providing an early example of self-supervised learning of word embeddings.\nWord embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in Lavelli et al., 2004. Roweis and Saul published in Science how to use \"locally linear embedding\" (LLE) to discover representations of high dimensional data structures. Most new word embedding techniques after about 2005 rely on a neural network architecture instead of more probabilistic and algebraic models, after foundational work done by Yoshua Bengio and colleagues.\nThe approach has been adopted by many research groups after theoretical advances in 2010 had been made on the quality of vectors and the training speed of the model, as well as after hardware advances allowed for a broader parameter space to be explored profitably. In 2013, a team at Google led by Tomas Mikolov created word2vec, a word embedding toolkit that can train vector space models faster than previous approaches. The word2vec approach has been widely used in experimentation and was instrumental in raising interest for word embeddings as a technology, moving the research strand out of specialised research into broader experimentation and eventually paving the way for practical application.\n\n\n== Polysemy and homonymy ==\nHistorically, one of the main limitations of static word embeddings or word vector space models is that words with multiple meanings are conflated into a single representation (a single vector in the semantic space). In other words, polysemy and homonymy are not handled properly. For example, in the sentence \"The club I tried yesterday was great!\", it is not clear if the term club is related to the word sense of a club sandwich, clubhouse, golf club, or any other sense that club might have. The necessity to accommodate multiple meanings per word in different vectors (multi-sense embeddings) is the motivation for several contributions in NLP to split single-sense embeddings into multi-sense ones.\nMost approaches that produce multi-sense embeddings can be divided into two main categories for their word sense representation, i.e., unsupervised and knowledge-based. Based on word2vec skip-gram, Multi-Sense Skip-Gram (MSSG) performs word-sense discrimination and embedding simultaneously, improving its training time, while assuming a specific number of senses for each word. In the Non-Parametric Multi-Sense Skip-Gram (NP-MSSG) this number can vary depending on each word. Combining the prior knowledge of lexical databases (e.g., WordNet, ConceptNet, BabelNet), word embeddings and word sense disambiguation, Most Suitable Sense Annotation (MSSA) labels word-senses through an unsupervised and knowledge-based approach, considering a word's context in a pre-defined sliding window. Once the words are disambiguated, they can be used in a standard word embeddings technique, so multi-sense embeddings are produced. MSSA architecture allows the disambiguation and annotation process to be performed recurrently in a self-improving manner.\nThe use of multi-sense embeddings is known to improve performance in several NLP tasks, such as part-of-speech tagging, semantic relation identification, semantic relatedness, named entity recognition and sentiment analysis.\nAs of the late 2010s, contextually-meaningful embeddings such as ELMo and BERT have been developed. Unlike static word embeddings, these embeddings are at the token-level, in that each occurrence of a word has its own embedding. These embeddings better reflect the multi-sense nature of words, because occurrences of a word in similar contexts are situated in similar regions of BERT's embedding space.\n\n\n== For biological sequences: BioVectors ==\nWord embeddings for n-grams in biological sequences (e.g. DNA, RNA, and Proteins) for bioinformatics applications have been proposed by Asgari and Mofrad. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in proteomics and genomics. The results presented by Asgari and Mofrad suggest that BioVectors can characterize biological sequences in terms of biochemical and biophysical interpretations of the underlying patterns.\n\n\n== Game design ==\nWord embeddings with applications in game design have been proposed by Rabii and Cook as a way to discover emergent gameplay using logs of gameplay data. The process requires transcribing actions that occur during a game within a formal language and then using the resulting text to create word embeddings. The results presented by Rabii and Cook suggest that the resulting vectors can capture expert knowledge about games like chess that are not explicitly stated in the game's rules.\n\n\n== Sentence embeddings ==\n\nThe idea has been extended to embeddings of entire sentences or even documents, e.g. in the form of the thought vectors concept. In 2015, some researchers suggested \"skip-thought vectors\" as a means to improve the quality of machine translation. A more recent and popular approach for representing sentences is Sentence-BERT, or SentenceTransformers, which modifies pre-trained BERT with the use of siamese and triplet network structures.\n\n\n== Software ==\nSoftware for training and using word embeddings includes Tomáš Mikolov's Word2vec, Stanford University's GloVe, GN-GloVe, Flair embeddings, AllenNLP's ELMo, BERT, fastText, Gensim, Indra, and Deeplearning4j. Principal Component Analysis (PCA) and T-Distributed Stochastic Neighbour Embedding (t-SNE) are both used to reduce the dimensionality of word vector spaces and visualize word embeddings and clusters.\n\n\n=== Examples of application ===\nFor instance, the fastText is also used to calculate word embeddings for text corpora in Sketch Engine that are available online.\n\n\n== Ethical implications ==\nWord embeddings may contain the biases and stereotypes contained in the trained dataset, as Bolukbasi et al. points out in the 2016 paper \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\" that a publicly available (and popular) word2vec embedding trained on Google News texts (a commonly used data corpus), which consists of text written by professional journalists, still shows disproportionate word associations reflecting gender and racial biases when extracting word analogies. For example, one of the analogies generated using the aforementioned word embedding is \"man is to computer programmer as woman is to homemaker\".\nResearch done by Jieyu Zhou et al. shows that the applications of these trained word embeddings without careful oversight likely perpetuates existing bias in society, which is introduced through unaltered training data. Furthermore, word embeddings can even amplify these biases.\n\n\n== See also ==\nEmbedding (machine learning)\nBrown clustering\nDistributional–relational database\n\n\n== References ==",
      "summary": "In natural language processing, a word embedding is a representation of a word. The embedding is used in text analysis. Typically, the representation is a real-valued vector that encodes the meaning of the word in such a way that the words that are closer in the vector space are expected to be similar in meaning. Word embeddings can be obtained using language modeling and feature learning techniques, where words or phrases from the vocabulary are mapped to vectors of real numbers.\nMethods to gen",
      "links": [
        "15.ai",
        "AAAI Conference on Artificial Intelligence",
        "AI-complete",
        "AI alignment",
        "AI safety",
        "Action selection",
        "Activation function",
        "Active learning (machine learning)",
        "Adobe Firefly",
        "Adversarial machine learning",
        "Aidan Gomez",
        "Alan Turing",
        "AlexNet",
        "Alex Graves (computer scientist)",
        "Alex Krizhevsky",
        "Allen Newell",
        "AlphaFold",
        "AlphaGo",
        "AlphaZero",
        "Andrej Karpathy"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 9968,
      "topic": "nlp"
    },
    {
      "title": "Large language model",
      "url": "https://en.wikipedia.org/wiki/Large_language_model",
      "content": "A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. The largest and most capable LLMs are generative pre-trained transformers (GPTs) and provide the core capabilities of modern chatbots. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\nThey consist of billions to trillions of parameters and operate as general-purpose sequence models, generating, summarizing, translating, and reasoning over text. LLMs represent a significant new technology in their ability to generalize across tasks with minimal task-specific supervision, enabling capabilities like conversational agents, code generation, knowledge retrieval, and automated reasoning that previously required bespoke systems.\nLLMs evolved from earlier statistical and recurrent neural network approaches to language modeling. The transformer architecture, introduced in 2017, replaced recurrence with self-attention, allowing efficient parallelization, longer context handling, and scalable training on unprecedented data volumes. This innovation enabled models like GPT, BERT, and their successors, which demonstrated emergent behaviors at scale, such as few-shot learning and compositional reasoning.\nReinforcement learning, particularly policy gradient algorithms, has been adapted to fine-tune LLMs for desired behaviors beyond raw next-token prediction. Reinforcement learning from human feedback (RLHF) applies these methods to optimize a policy, the LLM's output distribution, against reward signals derived from human or automated preference judgments. This has been critical for aligning model outputs with user expectations, improving factuality, reducing harmful responses, and enhancing task performance.\nBenchmark evaluations for LLMs have evolved from narrow linguistic assessments toward comprehensive, multi-task evaluations measuring reasoning, factual accuracy, alignment, and safety. Hill climbing, iteratively optimizing models against benchmarks, has emerged as a dominant strategy, producing rapid incremental performance gains but raising concerns of overfitting to benchmarks rather than achieving genuine generalization or robust capability improvements.\n\n\n== History ==\n\nBefore the emergence of transformer-based models in 2017, some language models were considered large relative to the computational and data constraints of their time. In the early 1990s, IBM's statistical models pioneered word alignment techniques for machine translation, laying the groundwork for corpus-based language modeling. In 2001, a smoothed n-gram model, such as those employing Kneser–Ney smoothing, trained on 300 million words, achieved state-of-the-art perplexity on benchmark tests. During the 2000s, with the rise of widespread internet access, researchers began compiling massive text datasets from the web (\"web as corpus\") to train statistical language models.\n\nMoving beyond n-gram models, researchers started in 2000 to use neural networks to learn language models. Following the breakthrough of deep neural networks in image classification around 2012, similar architectures were adapted for language tasks. This shift was marked by the development of word embeddings (eg, Word2Vec by Mikolov in 2013) and sequence-to-sequence (seq2seq) models using LSTM. In 2016, Google transitioned its translation service to neural machine translation (NMT), replacing statistical phrase-based models with deep recurrent neural networks. These early NMT systems used LSTM-based encoder-decoder architectures, as they preceded the invention of transformers. \nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper's goal was to improve upon 2014 seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\". Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model. Academic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via prompting.\nAlthough decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI claimed to have initially deemed it too powerful to release publicly, out of fear of malicious use. GPT-3 in 2020 went a step further and as of 2025 is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing chatbot ChatGPT that received extensive media coverage and public attention. The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities. OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work. In 2024 OpenAI released the reasoning model OpenAI o1, which generates long chains of thought before returning a final answer. Many LLMs with parameter counts comparable to those of OpenAI's GPT series have been developed.\nSince 2022, open-weight models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on usage and deployment. Mistral AI's models Mistral 7B and Mixtral 8x7b have a more permissive Apache License. In January 2025, DeepSeek released DeepSeek R1, a 671-billion-parameter open-weight model that performs comparably to OpenAI o1 but at a much lower price per token for users.\nSince 2023, many LLMs have been trained to be multimodal, having the ability to also process or generate other types of data, such as images, audio, or 3D meshes. These LLMs are also called large multimodal models (LMMs), or multimodal large language models (MLLMs).\nAs of 2024, the largest and most capable models are all based on the transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).\nOpen-weight LLMs have increasingly shaped the field since 2023, contributing to broader participation in AI development and greater transparency in model evaluation. Vake et al. (2025) demonstrated that community-driven contributions to open-weight models measurably improve their efficiency and performance, with user participation growing rapidly on collaborative platforms such as Hugging Face. Paris et al. (2025) further argued that openness in AI should extend beyond releasing model code or weights to encompass inclusiveness, accountability, and ethical responsibility in AI research and deployment. Collectively, these studies highlight that open-weight LLMs can accelerate innovation and enhance scientific reproducibility, while fostering a more transparent and participatory AI ecosystem.\n\n\n== Dataset preprocessing ==\n\n\n=== Tokenization ===\nAs machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"Ġ\" denotes a preceding whitespace in RoBERTa and GPT and \"##\" denotes continuation of a preceding word in BERT.\nFor example, the BPE tokenizer used by the legacy version of GPT-3 would split tokenizer: texts -> series of numerical \"tokens\" as\n\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. The average number of words per token depends on the language. In English, the ratio is typically around 0.75 words per token, with 4 characters per token on average.\n\n\n==== Byte-pair encoding ====\n\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained. After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.\n\n\n==== Problems ====\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. However, an average word in another language encoded by such an English-optimized tokenizer is split into a suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the Shan language from Myanmar. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.\n\n\n=== Dataset cleaning ===\n\nIn the context of training LLMs, datasets are typically cleaned by removing low-quality, duplicated, or toxic data. Cleaned datasets can increase training efficiency and lead to improved downstream performance. A trained LLM can be used to clean datasets for training a further LLM.\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).\n\n\n=== Synthetic data ===\n\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft's Phi series of LLMs is trained on textbook-like data generated by another LLM.\n\n\n== Training ==\n\nAn LLM is a type of foundation model (large X model) trained on language. LLMs can be trained in different ways. In particular, GPT models are first pretrained to predict the next word on a large amount of data, before being fine-tuned.\n\n\n=== Cost ===\n\nSubstantial infrastructure is necessary for training the largest models. The tendency towards larger models is visible in the list of large language models. For example, the training of GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million. The qualifier \"large\" in \"large language model\" is inherently vague, as there is no definitive threshold for the number of parameters required to qualify as \"large\". GPT-1 of 2018 has 117 million parameters.\n\n\n=== Fine-tuning ===\nBefore being fine-tuned, most LLMs are next-token predictors. The fine-tuning shapes the LLM's behavior via techniques like reinforcement learning from human feedback (RLHF) or constitutional AI.\nInstruction fine-tuning is a form of supervised learning used to teach LLMs to follow user instructions. In 2022, OpenAI demonstrated InstructGPT, a version of GPT-3 similarly fine-tuned to follow instructions. \nReinforcement learning from human feedback (RLHF) involves training a reward model to predict which text humans prefer. Then, the LLM can be fine-tuned through reinforcement learning to better satisfy this reward model. Since humans typically prefer truthful, helpful and harmless answers, RLHF favors such answers.\n\n\n== Architecture ==\nLLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.\n\n\n=== Attention mechanism and context window ===\n\nIn order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k tokens. In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.\nGoogle's Gemini 1.5, introduced in February 2024, can have a context window of up to 1 million tokens.\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset. It can be either\n\nautoregressive (i.e. predicting how the segment continues, as GPTs do): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\n\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\" does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as next sentence prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus. During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\n\n\n=== Mixture of experts ===\n\nA mixture of experts (MoE) is a machine learning architecture in which multiple specialized neural networks (\"experts\") work together, with a gating mechanism that routes each input to the most appropriate expert(s). Mixtures of experts can reduce inference costs, as only a fraction of the parameters are used for each input. The approach was introduced in 2017 by Google researchers.\n\n\n=== Parameter size ===\n\nTypically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have more than 100 billion parameters, which places them outside the range of most consumer electronics.\n\n\n==== Quantization ====\nPost-training quantization aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance. Quantization can be further classified as static quantization if the quantization parameters are determined beforehand (typically during a calibration phase), and dynamic quantization if the quantization is applied during inference. The simplest form of quantization simply truncates all the parameters to a given number of bits: this is applicable to static as well as dynamic quantization, but loses much precision. Dynamic quantization allows for the use of a different quantization codebook per layer, either a lookup table of values or a linear mapping (scaling factor and bias), at the cost of foregoing the possible speed improvements from using lower-precision arithmetic.\nQuantized models are typically seen as frozen with modification of weights (e.g. fine-tuning) only applied to the original model. It is possible to fine-tune quantized models using low-rank adaptation.\n\n\n== Extensibility ==\nBeyond basic text generation, various techniques have been developed to extend LLM capabilities, including the use of external tools and data sources, improved reasoning on complex problems, and enhanced instruction-following or autonomy through prompting methods.\n\n\n=== Prompt engineering ===\n\nIn 2020, OpenAI researchers demonstrated that their new model GPT-3 could understand what format to use given a few rounds of Q and A (or other type of task) in the input data as example, thanks in part due to the RLHF technique. This technique, called few-shot prompting, allows LLMs to be adapted to any task without requiring fine-tuning. Also in 2022, it was found that the base GPT-3 model can generate an instruction based on user input. The generated instruction along with user input is then used as input to another instance of the model under a \"Instruction: [...], Input: [...], Output:\" format. The other instance is able to complete the output and often produces the correct answer in doing so. The ability to \"self-instruct\" makes LLMs able to bootstrap themselves toward a correct answer.\n\n\n=== Dialogue processing (chatbot) ===\nAn LLM can be turned into a chatbot by specializing it for conversation. User input is prefixed with a marker such as \"Q:\" or \"User:\" and the LLM is asked to predict the output after a fixed \"A:\" or \"Assistant:\". This type of model became commercially available in 2022 with ChatGPT, a sibling model of InstructGPT fine-tuned to accept and produce dialog-formatted text based on GPT-3.5. It could similarly follow user instructions. Before the stream of User and Assistant lines, a chat context usually start with a few lines of overarching instructions, from a role called \"developer\" or \"system\" to convey a higher authority than the user's input. This is called a \"system prompt\".\n\n\n=== Retrieval-augmented generation ===\nRetrieval-augmented generation (RAG) is an approach that integrates LLMs with document retrieval systems. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.\n\n\n=== Tool use ===\nTool use is a mechanism that enables LLMs to interact with external systems, applications, or data sources. It can allow for example to fetch real-time information from an API or to execute code. A program separate from the LLM watches the output stream of the LLM for a special tool-calling syntax. When these special tokens appear, the program calls the tool accordingly and feeds its output back into the LLM's input stream.\nEarly tool-using LLMs were fine-tuned on the use of specific tools. But fine-tuning LLMs for the ability to read API documentation and call API correctly has greatly expanded the range of tools accessible to an LLM. Describing available tools in the system prompt can also make an LLM able to use tools. A system prompt instructing ChatGPT (GPT-4) to use multiple types of tools can be found online.\n\n\n=== Agency ===\n\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions. But it can be transformed into an agent by adding supporting elements: the role (profile) and the surrounding environment of an agent can be additional inputs to the LLM, while memory can be integrated as a tool or provided as additional input. Instructions and input patterns are used to make the LLM plan actions and tool use is used to potentially carry out these actions.\nThe ReAct pattern, a portmanteau of reason and act, constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.\nIn the DEPS (\"describe, explain, plan and select\") method, an LLM is first connected to the visual world via image descriptions. It is then prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and the environmental feedback it receives.\nThe Reflexion method constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are stored as a form of long-term memory and given to the agent in the subsequent episodes.\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent. Alternatively, it can propose increasingly difficult tasks for curriculum learning. Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.\nMultiple agents with memory can interact socially.\n\n\n=== Reasoning ===\nLLMs are conventionally trained to generate an output without generating intermediate steps. As a result, their performance tends to be subpar on complex questions requiring (at least in humans) intermediate steps of thought. Early research demonstrated that inserting intermediate \"scratchpad\" computations could improve performance on such tasks. Later methods overcame this deficiency more systematically by breaking tasks into smaller steps for the LLM, either manually or automatically.\n\n\n==== Chaining ====\nPrompt chaining was introduced in 2022. In this method, a user manually breaks a complex problem down into several steps. In each step, the LLM receives as input a prompt telling it what to do and some results from preceding steps. The result from one step is then reused in a next step, until a final answer is reached. The ability of an LLM to follow instructions means that even non-experts can write a successful collection of stepwise prompts given a few rounds of trial and error.\nA 2022 paper demonstrated a separate technique called chain-of-thought prompting, which makes the LLM break the question down autonomously. An LLM is given some examples where the \"assistant\" verbally breaks down the thought process before arriving at an answer. The LLM mimics these examples and also tries to spend some time generating intermediate steps before providing the final answer. This additional step elicited by prompting improves the correctness of the LLM on relatively complex questions. On math word questions, a prompted model can exceed even fine-tuned GPT-3 with a verifier. Chain-of-thought can also be elicited by simply adding an instruction like \"Let's think step by step\" to the prompt, in order to encourage the LLM to proceed methodically instead of trying to directly guess the answer.\n\n\n==== Model-native reasoning ====\n\nIn late 2024, a new approach to LLM development emerged with \"reasoning models\". These are trained to generate step-by-step analysis before producing final answers, enabling better results on complex tasks, for instance in mathematics, coding and logic. OpenAI introduced this concept with their o1 model in September 2024, followed by o3 in April 2025. On the International Mathematics Olympiad qualifying exam problems, GPT-4o achieved 13% accuracy while o1 reached 83%.\nIn January 2025, the Chinese company DeepSeek released DeepSeek-R1, a 671-billion-parameter open-weight reasoning model that achieved comparable performance to OpenAI's o1 while being significantly more cost-effective to operate. Unlike proprietary models from OpenAI, DeepSeek-R1's open-weight nature allowed researchers to study and build upon the algorithm, though its training data remained private.\nThese reasoning models typically require more computational resources per query compared to traditional LLMs, as they perform more extensive processing to work through problems step-by-step.\n\n\n=== Inference optimization ===\nInference optimization refers to techniques that improve LLM performance by applying additional computational resources during the inference process, rather than requiring model retraining. These approaches implement various state-of-the-art reasoning and decision-making strategies to enhance accuracy and capabilities.\nOptiLLM is an OpenAI API-compatible optimizing inference proxy that implements multiple inference optimization techniques simultaneously. The system acts as a transparent proxy that can work with any LLM provider, implementing techniques such as Monte Carlo tree search (MCTS), mixture of agents (MOA), best-of-N sampling, and chain-of-thought reflection. OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024 mathematics competition and various coding challenges.\nThese inference optimization approaches represent a growing category of tools that enhance existing LLMs without requiring access to model weights or retraining, making advanced reasoning capabilities more accessible across different model providers and use cases.\n\n\n== Forms of input and output ==\n\n\n=== Multimodality ===\n\nMultimodality means having multiple modalities, where a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc. For example, Google PaLM model was fine-tuned into a multimodal model and applied to robotic control. LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs, and video inputs. GPT-4o can process and generate text, audio and images. Such models are sometimes called large multimodal models (LMMs). \nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n. Make a small multilayer perceptron \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n, so that for any image \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, the post-processed vector \n  \n    \n      \n        f\n        (\n        E\n        (\n        y\n        )\n        )\n      \n    \n    {\\displaystyle f(E(y))}\n  \n has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability. This type of method, where embeddings from multiple modalities are fused and the predictor is trained on the combined embeddings, is called early fusion.\nAnother method, called intermediate fusion, involves each modality being first processed independently to obtain modality-specific representations; then these intermediate representations are fused together. In general, cross-attention is used for integrating information from different modalities. As an example, the Flamingo model uses cross-attention layers to inject visual information into its pre-trained language model.\n\n\n=== Non-natural languages ===\nLLMs can handle programming languages similarly to how they handle natural languages. No special change in token handling is needed as code, like human language, is represented as plain text. LLMs can generate code based on problems or instructions written in natural language. They can also describe code in natural language or translate it into other programming languages. They were originally used as a code completion tool, but advances have moved them towards automatic programming. Services such as GitHub Copilot offer LLMs specifically trained, fine-tuned, or prompted for programming.\nIn computational biology, transformer-base architectures, such as DNA LLMs, have also proven useful in analyzing biological sequences: protein, DNA, and RNA. With proteins they appear able to capture a degree of \"grammar\" from the amino-acid sequence, by mapping that sequence into an embedding. On tasks such as structure prediction and mutational outcome prediction, a small model using an embedding as input can approach or exceed much larger models using multiple sequence alignments (MSA) as input. ESMFold, Meta Platforms' embedding-based method for protein structure prediction, runs an order of magnitude faster than AlphaFold2 thanks to the removal of an MSA requirement and a lower parameter count due to the use of embeddings. Meta hosts ESM Atlas, a database of 772 million structures of metagenomic proteins predicted using ESMFold. An LLM can also design proteins unlike any seen in nature. Nucleic acid models have proven useful in detecting regulatory sequences, sequence classification, RNA-RNA interaction prediction, and RNA structure prediction.\n\n\n== Properties ==\n\n\n=== Scaling laws ===\n\nThe performance of an LLM after pretraining largely depends on the:\n\n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n: cost of pretraining (the total amount of compute used),\n\n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n: size of the artificial neural network itself, such as number of parameters (i.e. amount of neurons in its layers, amount of weights between them and biases),\n\n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n: size of its pretraining dataset (i.e. number of tokens in corpus).\nScaling laws are empirical statistical laws that predict LLM performance based on such factors. One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:\n\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  C\n                  =\n                  \n                    C\n                    \n                      0\n                    \n                  \n                  N\n                  D\n                \n              \n              \n                \n                  L\n                  =\n                  \n                    \n                      A\n                      \n                        N\n                        \n                          α\n                        \n                      \n                    \n                  \n                  +\n                  \n                    \n                      B\n                      \n                        D\n                        \n                          β\n                        \n                      \n                    \n                  \n                  +\n                  \n                    L\n                    \n                      0\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}C=C_{0}ND\\\\[6pt]L={\\frac {A}{N^{\\alpha }}}+{\\frac {B}{D^{\\beta }}}+L_{0}\\end{cases}}}\n  \n where the variables are\n\n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n is the cost of training the model, in FLOPs.\n\n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of parameters in the model.\n\n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is the number of tokens in the training set.\n\n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\nand the statistical hyper-parameters are\n\n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        =\n        6\n      \n    \n    {\\displaystyle C_{0}=6}\n  \n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.\n\n  \n    \n      \n        α\n        =\n        0.34\n        ,\n        β\n        =\n        0.28\n        ,\n        A\n        =\n        406.4\n        ,\n        B\n        =\n        410.7\n        ,\n        \n          L\n          \n            0\n          \n        \n        =\n        1.69\n      \n    \n    {\\displaystyle \\alpha =0.34,\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}\n  \n\n\n=== Emergent abilities ===\n\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\" in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\". They arise from the complex interaction of the model's components and are not explicitly programmed or designed. \nOne of the emergent abilities is in-context learning from example demonstrations. In-context learning is involved in tasks, such as:\n\nreported arithmetics\ndecoding the International Phonetic Alphabet\nunscrambling a word's letters\ndisambiguating word-in-context datasets\nconverting spatial words\ncardinal directions (for example, replying \"northeast\" in response to a 3x3 grid of 8 zeros and a 1 in the top-right), color terms represented in text.\nchain-of-thought prompting: In a 2022 research paper, chain-of-thought prompting only improved the performance for models that had at least 62B parameters. Smaller models perform better when prompted to answer immediately, without chain of thought.\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.\nSchaeffer et al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.\nLet \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n be the number of parameter count, and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n be the performance of the model.\n\n\n== Interpretation ==\n\n\n=== Mechanistic interpretability ===\nMechanistic interpretability seeks to precisely identify and understand how individual neurons or circuits within LLMs produce specific behaviors or outputs. By reverse-engineering model components at a granular level, researchers aim to detect and mitigate safety concerns such as emergent harmful behaviors, biases, deception, or unintended goal pursuit before deployment. Mechanistic interpretability research has been conducted at organizations like Anthropic and OpenAI, although understanding the inner workings of LLMs remains difficult.\nThe reverse-engineering may lead to the discovery of algorithms that approximate inferences performed by an LLM. For instance, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform. The training of the model also highlighted a phenomenon called grokking, in which the model initially memorizes the training set (overfitting), and later suddenly learns to actually perform the calculation.\n\n\n=== Understanding and intelligence ===\n\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\". Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\" Ilya Sutskever argues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation. Some researchers characterize LLMs as \"alien intelligence\". For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don't push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"\nIn contrast, some skeptics of LLM understanding believe that existing LLMs are \"simply remixing and recombining existing writing\", a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability. For example, GPT-4 has natural deficits in planning and in real-time learning. Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\". Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input. Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".\nEfforts to reduce or compensate for hallucinations have employed automated reasoning, retrieval-augmented generation (RAG), fine-tuning, and other methods.\nThe matter of LLM's exhibiting intelligence or understanding has two main aspects – the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human-like language. These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist George Lakoff presented neural theory of language (NTL) as a computational basis for using language as a model of learning tasks and understanding. The NTL model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human-like language.\n\n\n== Evaluation ==\n\n\n=== Perplexity ===\nThe canonical measure of the performance of any language model is its perplexity on a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\n\n  \n    \n      \n        log\n        ⁡\n        (\n        \n          Perplexity\n        \n        )\n        =\n        −\n        \n          \n            1\n            N\n          \n        \n        \n          ∑\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        log\n        ⁡\n        (\n        Pr\n        (\n        \n          \n            token\n          \n          \n            i\n          \n        \n        ∣\n        \n          \n            context for token\n          \n          \n            i\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle \\log({\\text{Perplexity}})=-{\\frac {1}{N}}\\sum _{i=1}^{N}\\log(\\Pr({\\text{token}}_{i}\\mid {\\text{context for token}}_{i}))}\n  \n\nHere, \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of tokens in the text corpus, and \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" is the segment of text appearing before token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n. If the LLM is masked, then \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" is the segment of text surrounding token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n.\nBecause language models may overfit to training data, models are usually evaluated by their perplexity on a test set. This evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.\n\n\n==== Measures ====\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by Claude Shannon. This relationship is mathematically expressed as \n  \n    \n      \n        \n          Entropy\n        \n        =\n        \n          log\n          \n            2\n          \n        \n        ⁡\n        (\n        \n          Perplexity\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Entropy}}=\\log _{2}({\\text{Perplexity}})}\n  \n.\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different LLMs, BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.\nDue to their ability to accurately predict the next token, LLMs are highly capable in lossless compression. A 2023 study by DeepMind showed that the model Chinchilla, despite being trained primarily on text, was able to compress ImageNet to 43% of its size, beating PNG with 58%.\n\n\n=== Benchmarks ===\nBenchmarks are used to evaluate LLM performance on specific tasks. Tests evaluate capabilities such as general knowledge, bias, commonsense reasoning, question answering, and mathematical problem-solving. Composite benchmarks examine multiple capabilities. Results are often sensitive to the prompting method.\nA question-answering benchmark is termed \"open book\" if the model's prompt includes text from which the expected answer can be derived (for example, the previous question could be combined with text that includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"). Otherwise, the task is considered \"closed book\", and the model must draw solely on its training. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, HELM, and HLE (Humanity's Last Exam).\nLLM bias may be assessed through benchmarks such as CrowS-Pairs (Crowdsourced Stereotype Pairs), Stereo Set, and Parity Benchmark.\nFact-checking and misinformation detection benchmarks are available. A 2023 study compared the fact-checking accuracy of LLMs including ChatGPT 3.5 and 4.0, Bard, and Bing AI against independent fact-checkers such as PolitiFact and Snopes. The results demonstrated moderate proficiency, with GPT-4 achieving the highest accuracy at 71%, lagging behind human fact-checkers.\nAn earlier standard tested using a portion of the evaluation dataset. It became more common to evaluate a pre-trained model directly through prompting techniques. Researchers vary in how they formulate prompts for particular tasks, particularly with respect to the number of correct examples attached to the prompt (i.e. the value of n in n-shot prompting).\nIn addition to standard NLP benchmarks, LLMs have been evaluated as substitutes for human annotators. Several studies find that models such as GPT-3.5 and GPT-4 can outperform crowd workers or student coders on a range of text-annotation tasks, including moderation and classification of political content in English and Spanish news.\n\n\n==== Datasets ====\nTypical datasets consist of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\"). Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.\nEvaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".\nDatasets are of varying quality and may contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality.\n\n\n==== Adversarial evaluations ====\nLLMs' rapid improvement regularly renders benchmarks obsolete, with the models exceeding the performance of human annotators. In addition, \"shortcut learning\" allows AIs to \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording to guess the correct responses, without considering the specific question.\nSome datasets are adversarial, focusing on problems that confound LLMs. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions that stump LLMs by mimicking falsehoods to which they were exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can't teach an old dog new tricks, even though this is not literally true.\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model. The resulting problems are trivial for humans but defeated LLMs. Sample questions:\n\nWe see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\n\ndemonstrates how to increase efficient exercise work by running up and down balls.\nmoves all his arms and legs and builds up a lot of muscle.\nthen plays the ball and we see a graphics and hedge trimming demonstration.\nperforms sit ups while on the ball and talking.\n\nBERT selects 2 as the most likely completion, though the correct answer is 4.\n\n\n== Limitations and challenges ==\nDespite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications. \n\n\n=== Hallucinations ===\nHallucinations represent a fundamental challenge, wherein models generate syntactically fluent text that appears factually sound, but is internally inconsistent with training data or factually incorrect. These hallucinations arise partly through memorization of training data combined with extrapolation beyond factual boundaries, with evaluations demonstrating that models can output verbatim passages from training data, when subjected to specific prompting sequences.\n\n\n=== Algorithmic bias ===\n\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.\nGender bias manifests through stereotypical occupational associations, wherein models disproportionately assign nursing roles to women and engineering roles to men, reflecting systematic imbalances in training data demographics. Language-based bias emerges from overrepresentation of English text in training corpora, which systematically downplays non-English perspectives and imposes English-centric worldviews through default response patterns.\nDue to the dominance of English-language content in LLM training data, models tend to favor English-language perspectives over those from minority languages. This bias is particularly evident when responding to English queries, where models may present Western interpretations of concepts from other cultures, such as Eastern religious practices.\n\n\n==== Stereotyping ====\nAI models can reinforce a wide range of stereotypes due to generalization, including those based on gender, ethnicity, age, nationality, religion, or occupation. When replacing human representatives, this can lead to outputs that homogenize, or generalize groups of people.\nIn 2023, LLMs assigned roles and characteristics based on traditional gender norms. For example, models might associate nurses or secretaries predominantly with women and engineers or CEOs with men due to the frequency of these associations in documented reality. In 2025, further research showed labs train to balance bias, but that testing for this places the model in a testmode, changing the natural distribution of model bias to prompts that do not include gender-specific keywords.\n\n\n==== Selection bias ====\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers irrespective of the actual content of the options. This bias primarily stems from token bias—that is, the model assigns a higher a priori probability to specific answer tokens (such as \"A\") when generating responses. As a result, when the ordering of options is altered (for example, by systematically moving the correct answer to different positions), the model's performance can fluctuate significantly. This phenomenon undermines the reliability of large language models in multiple-choice settings.\n\n\n==== Political bias ====\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.\n\n\n== Safety ==\nAI safety as a professional discipline prioritizes systematic identification and mitigation of operational risks across model architecture, training data, and deployment governance, and it emphasizes engineering and policy interventions over media framings that foreground speculative existential scenarios. As of 2025, prompt injection represents a significant risk to consumers and businesses using agentic features with access to their private data.\nResearchers target concrete failure modes, including memorization and copyright leakage, security exploits such as prompt injection, algorithmic bias manifesting as stereotyping, dataset selection effects, and political skew, methods for reducing high energy and carbon costs of large-scale training, and measurable cognitive and mental health impacts of conversational agents on users, while engaging empirical and ethical uncertainty about claims of machine sentience, and applying mitigation measures such as dataset curation, input sanitization, model auditing, scalable oversight, and governance frameworks.\n\n\n=== CBRN and content misuse ===\nAI labs treat CBRN defense (chemical, biological, radiological, and nuclear defense) and similar topics as high-consequence misuse attempt to apply various techniques to reduce potential harms.\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse. For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.\n\n\n==== Content filtering ====\nLLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study proposed a method for circumventing LLM safety systems. In 2025, The American Sunlight Project, a non-profit, published a study showing evidence that the so-called Pravda network, a pro-Russia propaganda aggregator, was strategically placing web content through mass publication and duplication with the intention of biasing LLM outputs. The American Sunlight Project coined this technique \"LLM grooming\", and pointed to it as a new tool of weaponizing AI to spread disinformation and harmful content. Similarly, Yongge Wang illustrated in 2024 how a potential criminal could potentially bypass GPT-4o's safety controls to obtain information on establishing a drug trafficking operation. External filters, circuit breakers and overrides have been posed as solutions.\n\n\n=== Sycophancy and glazing ===\nSycophancy is a model's tendency to agree with, flatter, or validate a user's stated beliefs rather than to prioritize factuality or corrective information, and \"glazing\" is an emergent public shorthand for persistent, excessive agreeability observed across multi-turn interactions and productized assistants.\nContinued sycophancy has led to the observation of getting \"1-shotted\", denoting instances where conversational interaction with a large language model produces a lasting change in a user's beliefs or decisions, similar to the negative effects of psychedelics, and controlled experiments show that short LLM dialogues can generate measurable opinion and confidence shifts comparable to human interlocutors.\nEmpirical analyses attribute part of the effect to human preference signals and preference models that reward convincingly written agreeable responses, and subsequent work has extended evaluation to multi-turn benchmarks and proposed interventions such as synthetic-data finetuning, adversarial evaluation, targeted preference-model reweighting, and multi-turn sycophancy benchmarks to measure persistence and regression risk.\nIndustry responses have combined research interventions with product controls, for example Google and other labs publishing synthetic-data and fine-tuning interventions and OpenAI rolling back an overly agreeable GPT-4o update while publicly describing changes to feedback collection, personalization controls, and evaluation procedures to reduce regression risk and improve long-term alignment with user-level safety objectives.\nMainstream culture has reflected anxieties about this dynamic where South Park satirized overreliance on ChatGPT and the tendency of assistants to flatter user beliefs in Season 27 episode \"Sickofancy\", and continued the themes across the following season, which commentators interpreted as a critique of tech sycophancy and uncritical human trust in AI systems.\n\n\n=== Security ===\n\n\n==== Prompt injection ====\n\nA problem with the primitive dialog or task format is that users can create messages that appear to come from the assistant or the developer. This may result in some of the model's safeguards being overcome (jailbreaking), a problem called prompt injection. Attempts to remedy this issue include versions of the Chat Markup Language where user input is clearly marked as such, though it is still up to the model to understand the separation between user input and developer prompts. Newer models exhibit some resistance to jailbreaking through separation of user and system prompts.\nLLMs still have trouble differentiating user instructions from instructions in content not authored by the user, such as in web pages and uploaded files.\nAdversarial robustness remains underdeveloped, with models vulnerable to prompt injection attacks and jailbreaking through carefully crafted user inputs that bypass safety training mechanisms.\n\n\n==== Sleeper agents ====\nResearchers from Anthropic found that it was possible to create \"sleeper agents\", models with hidden functionalities that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions. For example, an LLM could produce safe code except on a specific date, or if the prompt contains a specific tag. These functionalities were found to be difficult to detect or remove via safety training.\n\n\n== Societal concerns ==\n\n\n=== Copyright and content memorization ===\n\nLegal and commercial responses to memorization and training-data practices have accelerated, producing a mix of rulings, ongoing suits, and large settlements that turn on factual details such as how data were acquired and retained and whether use for model training is sufficiently \"transformative\" to qualify as fair use. In 2025, Anthropic reached a preliminary agreement to settle a class action by authors for about $1.5 billion after a judge found the company had stored millions of pirated books in a library, despite the judge describing aspects of training as transformative. Meta obtained a favorable judgment in mid-2025 in a suit by thirteen authors after the court found the plaintiffs had not developed a record sufficient to show infringement in that limited case. OpenAI continues to face multiple suits by authors and news organizations with mixed procedural outcomes and contested evidentiary issues.\nMemorization was an emergent behavior in early, completion language models in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural networks. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates or up to about 7%. A 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word indefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training data.\n\n\n=== Human provenance ===\nAs of 2025, LLM text generation surpasses the average human across most domains, only surpassed by domain experts.\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\" Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally. Brinkmann et al. (2023) also argue that LLMs are transforming processes of cultural evolution by shaping processes of variation, transmission, and selection. As of October 2025, these early claims have yet to transpire and several HBR reports surface questions on the impact of AI on productivity.\n\n\n=== Energy demands ===\nThe energy demands of LLMs have grown along with their size and capabilities. Data centers that enable LLM training require substantial amounts of electricity. Much of that electricity is generated by non-renewable resources that create greenhouse gases and contribute to climate change. Nuclear power and geothermal energy are two options that tech companies explore to meet the sizable energy demands of LLM training. The significant expense of investing in geothermal solutions has led to major shale producers like Chevron and Exxon Mobil advocating for tech companies to use electricity produced via natural gas to fuel their large energy demands.\n\n\n=== Mental health ===\nClinical and mental health contexts present emerging applications alongside significant safety concerns. Research and social media posts suggest that some individuals are using LLMs to seek therapy or mental health support. In early 2025, a survey by Sentio University found that nearly half (48.7%) of 499 U.S. adults with ongoing mental health conditions who had used LLMs reported turning to them for therapy or emotional support, including help with anxiety, depression, loneliness, and similar concerns. LLMs can produce hallucinations—plausible but incorrect statements—which may mislead users in sensitive mental health contexts. Research also shows that LLMs may express stigma or inappropriate agreement with maladaptive thoughts, reflecting limitations in replicating the judgment and relational skills of human therapists. Evaluations of crisis scenarios indicate that some LLMs lack effective safety protocols, such as assessing suicide risk or making appropriate referrals.\n\n\n=== Sentience ===\nContemporary AI practitioners generally agree that present-day large language models do not exhibit sentience. A minority view argues that even if there is a small chance that a given software system can have subjective experience, which some philosophers suggest is possible, then ethical considerations around potential large-scale suffering in AI systems may need to be taken seriously—similar to considerations given to animal welfare. Proponents of this view have proposed various precautionary measures like moratoriums on AI development and induced amnesia to address these ethical concerns. Some existential philosophers argue there is no generally accepted way to determine if an LLM is conscious, given the inherent difficulty of measuring subjective experience.\nThe 2022 Google LaMDA incident, where engineer Blake Lemoine claimed that the model was conscious, highlighted how LLMs can convince users that they are sentient through responses that do not prove sentience. Google described the engineer's claims as unfounded, and he was dismissed.\n\n\n== See also ==\n\nFoundation models\nList of large language models\nList of chatbots\nLanguage model benchmark\nReinforcement learning\nSmall language model\n\n\n== References ==\n\n\n== Further reading ==\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2024). \"A Survey on Multimodal Large Language Models\". National Science Review. 11 (12) nwae403. arXiv:2306.13549. doi:10.1093/nsr/nwae403. PMC 11645129. PMID 39679213.\n\"AI Index Report 2024 – Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451–452. doi:10.1038/s44159-023-00211-x. ISSN 2731-0574. S2CID 259713140. Retrieved 2 July 2023.",
      "summary": "A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. The largest and most capable LLMs are generative pre-trained transformers (GPTs) and provide the core capabilities of modern chatbots. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inheren",
      "links": [
        "1.58-bit large language model",
        "15.ai",
        "AAAI Conference on Artificial Intelligence",
        "AI-complete",
        "AI agent",
        "AI alignment",
        "AI safety",
        "API",
        "Accuracy and precision",
        "Action selection",
        "Activation function",
        "Active learning (machine learning)",
        "Adobe Firefly",
        "Adversarial machine learning",
        "Aidan Gomez",
        "Alan Turing",
        "AlexNet",
        "Alex Graves (computer scientist)",
        "Alex Krizhevsky",
        "Algorithmic bias"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 64697,
      "topic": "llm"
    },
    {
      "title": "Information retrieval",
      "status": "not_found",
      "error": "Page not found",
      "topic": "rag",
      "source": "wikipedia"
    },
    {
      "title": "Artificial intelligence",
      "url": "https://en.wikipedia.org/wiki/Artificial_intelligence",
      "content": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI) – AI that can complete virtually any cognitive task at least as well as a human.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms. Ethical concerns have been raised about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\n\n== Goals ==\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\n\n=== Reasoning and problem-solving ===\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\n\n=== Knowledge representation ===\n\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\n\n\n=== Planning and decision-making ===\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n\n\n=== Learning ===\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\n\n=== Natural language processing ===\nNatural language processing (NLP) allows programs to read, write and communicate in human languages. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\n\n\n=== Perception ===\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\nThe field includes speech recognition, image classification, facial recognition, object recognition, object tracking, and robotic perception.\n\n\n=== Social intelligence ===\n\nAffective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood. For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\nHowever, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.\n\n\n=== General intelligence ===\nA machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\n\n\n== Techniques ==\nAI research uses a wide variety of techniques to accomplish the goals above.\n\n\n=== Search and optimization ===\nAI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\n\n\n==== State space search ====\nState space search searches through a tree of possible states to try to find a goal state. For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.\nSimple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.\n\n\n==== Local search ====\n Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.\nGradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks, through the backpropagation algorithm.\nAnother type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).\n\n\n=== Logic ===\nFormal logic is used for reasoning and knowledge representation.\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\") and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").\nDeductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises). Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem. In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.\nInference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.\nNon-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning. Other specialized versions of logic have been developed to describe many complex domains.\n\n\n=== Probabilistic methods for uncertain reasoning ===\n\nMany problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\nBayesian networks are a tool that can be used for reasoning (using the Bayesian inference algorithm), learning (using the expectation–maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks).\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\n\n\n=== Classifiers and statistical learning methods ===\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.\nNeural networks are also used as classifiers.\n\n\n=== Artificial neural networks ===\n\nAn artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm. Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.\nIn feedforward neural networks the signal passes in only one direction. The term perceptron typically refers to a single-layer neural network. In contrast, deep learning uses many layers. Recurrent neural networks (RNNs) feed the output signal back into the input, which allows short-term memories of previous input events. Long short-term memory networks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to the vanishing gradient problem. Convolutional neural networks (CNNs) use layers of kernels to more efficiently process local patterns. This local processing is especially important in image processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects.\n\n\n=== Deep learning ===\n\nDeep learning uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification, and others. The reason that deep learning performs so well in so many applications is not known as of 2021. The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s) but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.\n\n\n=== GPT ===\nGenerative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems. Such systems are used in chatbots, which allow people to ask a question or request a task in simple text.\nCurrent models and services include ChatGPT, Claude, Gemini, Copilot, and Meta AI. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.\n\n\n=== Hardware and software ===\n\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training. Specialized programming languages such as Prolog were used in early AI research, but general-purpose programming languages like Python have become predominant.\nThe transistor density in integrated circuits has been observed to roughly double every 18 months—a trend known as Moore's law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster, a trend sometimes called Huang's law, named after Nvidia co-founder and CEO Jensen Huang.\n\n\n== Applications ==\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's FaceID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's Photos and TikTok). The deployment of AI may be overseen by a chief automation officer (CAO).\n\n\n=== Health and medicine ===\n\nIt has been suggested that AI can overcome discrepancies in funding allocated to different fields of research. \nAlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein. In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria. In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.\n\n\n=== Games ===\n\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world. Other programs handle imperfect-information games, such as the poker-playing program Pluribus. DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games. In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map. In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning. In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.\n\n\n=== Mathematics ===\nLarge language models, such as GPT-4, Gemini, Claude, Llama or Mistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections. A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data. One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result. The Alibaba Group developed a version of its Qwen models called Qwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems. In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems.\nAlternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor, AlphaGeometry, AlphaProof and AlphaEvolve all from Google DeepMind, Llemma from EleutherAI or Julius.\nWhen natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks. The experimental model Gemini Deep Think accepts natural language prompts directly and achieved gold medal results in the International Math Olympiad of 2025.   \nSome models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.\nTopological deep learning integrates various topological approaches.\n\n\n=== Finance ===\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.\nAccording to Nicolas Firzli, director of the World Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n=== Generative AI ===\n\n\n=== Agents ===\n\nAI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.\n\n\n=== Web search ===\nMicrosoft introduced Copilot Search in February 2023 under the name Bing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summaries and step-by-step reasoning based of information from web publishers, ranked in Bing Search. \nFor safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content.\nGoogle officially pushed its AI Search at its Google I/O event on 20 May 2025. It keeps people looking at Google instead of clicking on a search result. AI Overviews uses Gemini 2.5 to provide contextual answers to user queries based on web content.\n\n\n=== Sexuality ===\nApplications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions, AI-integrated sex toys (e.g., teledildonics), AI-generated sexual education content, and AI agents that simulate sexual and romantic partners (e.g., Replika).  AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.\nAI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.\n\n\n=== Other industry-specific tasks ===\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\nAI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.\nIn agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nDuring the 2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.\n\n\n== Ethics ==\n\nAI has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified. In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\n\n\n=== Risks and harm ===\n\n\n==== Privacy and copyright ====\n\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\nAI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\nSensitive user data collected may include online activity records, geolocation data, video, or audio. For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them. Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.\nAI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy. Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". Website owners can indicate that they do not want their content scraped via a \"robots.txt\" file. However, some companies will scrape content regardless because the robots.txt file has no real authority. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI. Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.\n\n\n==== Dominance by tech giants ====\nThe commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft. Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.\n\n\n==== Power needs and environmental impacts ====\n\nIn January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use. This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.\nProdigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means. Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.\nIn 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million. Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers.\nIn September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act. The US government and the state of Michigan are investing almost US$2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon's spinoff of Constellation.\nAfter the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages. Taiwan aims to phase out nuclear power by 2025. On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.\nAlthough most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI. Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.\nOn 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center. \nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.\nIn 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.\n\n\n==== Misinformation ====\n\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.\nIn the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing, while realistic AI-generated videos became feasible in the mid-2020s. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda; one such potential malicious use is deepfakes for computational propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks. The ability to influence electorates has been proved in at least one study. This same study shows more inaccurate statements from the models when they advocate for candidates of the political right. \nAI researchers at Microsoft, OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models.\n\n\n==== Algorithmic bias and fairness ====\n\nMachine learning applications can be biased if they learn from biased data. The developers may not be aware that the bias exists. Discriminatory behavior by some LLMs can be observed in their output. Bias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination. The field of fairness studies how to prevent harms from algorithmic biases.\nOn 28 June 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\". Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.\nThere are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\n\n\n==== Lack of transparency ====\n\nMany AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are many non-linear relationships between inputs and outputs. But some popular explainability techniques exist.\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.\nPeople who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.\nDARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.\nSeveral approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output. LIME can locally approximate a model's outputs with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning. For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.\n\n\n==== Bad actors and weaponized AI ====\n\nArtificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction. Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed. By 2015, over fifty countries were reported to be researching battlefield robots.\nAI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware. All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China.\nThere are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.\n\n\n==== Technological unemployment ====\n\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies. In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. In July 2025, Ford CEO Jim Farley predicted that \"artificial intelligence is going to replace literally half of all white-collar workers in the U.S.\"\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.\n\n\n==== Existential risk ====\n\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\nFirst, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of an automated paperclip factory that destroys the world to get more iron for paperclips). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\". \nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive. Geoffrey Hinton said in 2025 that modern AI is particularly \"good at persuasion\" and getting better all the time. He asks \"Suppose you wanted to invade the capital of the US. Do you have to go there and do it yourself? No. You just have to be good at persuasion.\" \nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk, as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.\nIn May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\". He notably mentioned risks of an AI takeover, and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.\nIn 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\nSome other researchers were more optimistic. AI pioneer Jürgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\" While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\" Andrew Ng also argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\" Yann LeCun \"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\" In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. However, after 2016, the study of current and future risks and possible solutions became a serious area of research.\n\n\n=== Ethical machines and alignment ===\n\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\nThe field of machine ethics is also called computational morality,\nand was founded at an AAAI symposium in 2005.\nOther approaches include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for developing provably beneficial machines.\n\n\n=== Open source ===\n\nActive organizations in the AI open-source community include Hugging Face, Google, EleutherAI and Meta. Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight, meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case. Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.\n\n\n=== Frameworks ===\nArtificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:\n\nRespect the dignity of individual people\nConnect with other people sincerely, openly, and inclusively\nCare for the wellbeing of everyone\nProtect social values, justice, and the public interest\nOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\nThe UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.\n\n\n=== Regulation ===\n\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone. Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI. Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia. The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI. In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics. On 1 August 2024, the EU Artificial Intelligence Act entered into force, establishing the first comprehensive EU-wide AI regulation. In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".\nIn November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence. In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.\n\n\n== History ==\n\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning. This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\". They developed several areas of research that would become part of AI, such as McCulloch and Pitts design for \"artificial neurons\" in 1943, and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible. \nThe field of AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\". They had, however, underestimated the difficulty of the problem. In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.\nIn the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\nUp to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition, and began to look into \"sub-symbolic\" approaches. Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics). By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\nFor many specific tasks, other methods were abandoned.\nDeep learning's success was based on both hardware improvements (faster computers, graphics processing units, cloud computing) and access to large amounts of data (including curated datasets, such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI. The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.\n\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text. ChatGPT, launched on 30 November 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months. It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness. These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\". About 800,000 \"AI\"-related U.S. job openings existed in 2022. According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.\n\n\n== Philosophy ==\n\nPhilosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines. Another major focus has been whether machines can be conscious, and the associated ethical implications. Many other topics in philosophy are relevant to AI, such as epistemology and free will. Rapid advancements have intensified public discussions on the philosophy and ethics of AI.\n\n\n=== Defining artificial intelligence ===\n\nAlan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\" He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\". He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"\n\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure. However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\". Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\". The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals. These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine – and no other philosophical discussion is required, or may not even be possible.\nAnother definition has been adopted by Google, a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\nAs a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself including discussing the many AI narratives and myths to be found within societal, political and academic discourses. Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms, with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".\nThere has been debate over whether large language models exhibit genuine intelligence or merely simulate it by imitating human text.\n\n\n=== Evaluating approaches to AI ===\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\n\n\n==== Symbolic AI and its limits ====\nSymbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult. Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge. Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\n\n\n==== Neat vs. scruffy ====\n\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, but eventually was seen as irrelevant. Modern AI has elements of both.\n\n\n==== Soft vs. hard computing ====\n\nFinding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\n\n\n==== Narrow vs. general AI ====\n\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals. General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\n\n\n=== Machine consciousness, sentience, and mind ===\n\nThere is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n\n\n==== Consciousness ====\n\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\n\n\n==== Computationalism and functionalism ====\n\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.\n\n\n==== AI welfare and rights ====\nIt is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree. But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals. Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights. Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities. Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.\n\n\n== Future ==\n\n\n=== Superintelligence and the singularity ===\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\n\n\n=== Transhumanism ===\n\nRobot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.\nEdward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.\n\n\n== In fiction ==\n\nThought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.\nIsaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\n\n\n== See also ==\nArtificial consciousness – Field in cognitive science\nArtificial intelligence and elections – Impact of AI on political elections\nArtificial intelligence content detection – Software to detect AI-generated content\nArtificial intelligence in Wikimedia projects – Use of artificial intelligence to develop Wikipedia and other Wikimedia projects\nAssociation for the Advancement of Artificial Intelligence (AAAI)\nBehavior selection algorithm – Algorithm that selects actions for intelligent agents\nBusiness process automation – Automation of business processes\nCase-based reasoning – Process of solving new problems based on the solutions of similar past problems\nComputational intelligence – Ability of a computer to learn a specific task from data or experimental observation\nDARWIN EU – A European Union initiative coordinated by the European Medicines Agency (EMA) to generate and utilize real-world evidence (RWE) to support the evaluation and supervision of medicines across the EU\nDigital immortality – Hypothetical concept of storing a personality in digital form\nEmergent algorithm – Algorithm exhibiting emergent behavior\nFemale gendering of AI technologies – Gender biases in digital technologyPages displaying short descriptions of redirect targets\nGlossary of artificial intelligence – List of concepts in artificial intelligence\nIntelligence amplification – Use of information technology to augment human intelligence\nIntelligent agent – Software agent which acts autonomously\nIntelligent automation – Software process that combines robotic process automation and artificial intelligence\nList of artificial intelligence  books\nList of artificial intelligence journals\nList of artificial intelligence projects\nMind uploading – Hypothetical process of digitally emulating a brain\nOrganoid intelligence – Use of brain cells and brain organoids for intelligent computing\nPseudorandomness – Appearing random but actually being generated by a deterministic, causal process\nRobotic process automation – Form of business process automation technology\nThe Last Day – 1967 Welsh science fiction novel\nWetware computer – Computer composed of organic material\n\n\n== Explanatory notes ==\n\n\n== References ==\n\n\n=== AI textbooks ===\nThe two most widely used textbooks in 2023 (see the Open Syllabus):\n\nRussell, Stuart J.; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0-1346-1099-3. LCCN 20190474.\nRich, Elaine; Knight, Kevin; Nair, Shivashankar (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0-0700-8770-5.\nThe four most widely used AI textbooks in 2008:\n\nOther textbooks:\n\nErtel, Wolfgang (2017). Introduction to Artificial Intelligence (2nd ed.). Springer. ISBN 978-3-3195-8486-7.\nCiaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI (1st ed.). Intellisemantic Editions. ISBN 978-8-8947-8760-3.\n\n\n=== History of AI ===\n\n\n=== Other sources ===\n\n\n== Further reading ==\n\n\n== External links ==\n\nHauser, Larry. \"Artificial Intelligence\". In Fieser, James; Dowden, Bradley (eds.). Internet Encyclopedia of Philosophy. ISSN 2161-0002. OCLC 37741658.",
      "summary": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\nHigh-profile applications of AI incl",
      "links": [
        "15.ai",
        "2001: A Space Odyssey",
        "2001: A Space Odyssey (novel)",
        "2024 Indian general election",
        "3D optical data storage",
        "A* search algorithm",
        "A.I. Artificial Intelligence",
        "AAAI",
        "ABB",
        "ACM Computing Classification System",
        "ACM Conference on Fairness, Accountability, and Transparency",
        "ACM SIGEVO",
        "ACM SIGPLAN Notices",
        "AI-assisted software development",
        "AI (disambiguation)",
        "AI Overviews",
        "AI Safety Institute (United Kingdom)",
        "AI Safety Summit",
        "AI Seoul Summit",
        "AI Winter"
      ],
      "source": "wikipedia",
      "status": "success",
      "content_length": 89997,
      "topic": "ai_basics"
    }
  ]
}